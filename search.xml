<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AIGC 汇总</title>
    <url>/www6vHomeHexo/2022/11/16/gptSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="basic">Basic</span><a href="#basic" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2022/06/11/aiDeepLearning/" title="Deep Learning">Deep Learning</a></li>
<li><a href="/www6vHomeHexo/2022/06/07/aiMachineLearning/" title="Machine Learning">Machine Learning</a></li>
<li><a href="/www6vHomeHexo/2021/08/11/ai/" title="AI 应用场景">AI 应用场景</a> </li>
<li><a href="/www6vHomeHexo/2022/01/22/aiOverview/" title="人工智能 知识点">人工智能 知识点</a></li>
<li><a href="/www6vHomeHexo/2023/02/05/gptNLPTask/" title="NLP 任务">NLP 任务</a></li>
</ul>
<h2><span id="model">Model</span><a href="#model" class="header-anchor">#</a></h2><ul>
<li>基础<ul>
<li><a href="/www6vHomeHexo/2022/10/30/gptLargeModelSurvey/" title="大模型 综述">大模型 综述</a></li>
<li><a href="/www6vHomeHexo/2023/02/17/gptLargeModel/" title="大模型">大模型</a> </li>
<li><a href="/www6vHomeHexo/2022/11/30/gptTransformer/" title="Transformer">Transformer</a> </li>
<li><a href="/www6vHomeHexo/2023/02/16/gptTransformerCode/" title="Transformer-实现">Transformer-实现</a></li>
</ul>
</li>
<li>基座模型<ul>
<li><a href="/www6vHomeHexo/2022/12/11/gptFamily/" title="GPT 系列">GPT 系列</a>  </li>
<li><a href="/www6vHomeHexo/2023/01/01/gptLlama/" title="LLaMA">LLaMA</a>   </li>
<li><a href="/www6vHomeHexo/2023/01/06/gptChatGLM/" title="ChatGLM">ChatGLM</a>   </li>
<li><a href="/www6vHomeHexo/2023/01/04/gptLeaderBoard/" title="排行榜">排行榜</a></li>
</ul>
</li>
<li><a href="/www6vHomeHexo/2023/01/18/gptMultimodal/" title="多模态">多模态</a>  </li>
<li><a href="/www6vHomeHexo/2023/01/25/gptImpossibleTriangle/" title="不可能三角">不可能三角</a> </li>
<li><a href="/www6vHomeHexo/2023/02/03/gptEmergent/" title="涌现现象（Emergent）">涌现现象（Emergent）</a>   </li>
<li><a href="/www6vHomeHexo/2023/02/06/gptHallucination/" title="幻觉问题">幻觉问题</a>    </li>
<li><a href="/www6vHomeHexo/2023/02/07/gptEval/" title="测评">测评</a></li>
</ul>
<h2><span id="training-amp-inference">Training &amp; Inference</span><a href="#training-amp-inference" class="header-anchor">#</a></h2><ul>
<li>训练<ul>
<li><a href="/www6vHomeHexo/2022/11/19/gptLargeModelTraining/" title="训练">训练</a></li>
<li><a href="/www6vHomeHexo/2023/01/15/gptLargeModelTrainingPractice/" title="训练Train-实战">训练Train-实战</a> </li>
<li><a href="/www6vHomeHexo/2023/01/06/gptTrainParallelism/" title="训练-并行">训练-并行</a></li>
<li><a href="/www6vHomeHexo/2023/02/03/gptContinualPretraining/" title="继续-预训练">继续-预训练</a>  </li>
<li><a href="/www6vHomeHexo/2024/02/01/gptPrecision/" title="混合精度">混合精度</a></li>
</ul>
</li>
<li>推理 <ul>
<li><a href="/www6vHomeHexo/2023/02/02/gptInferenceFramework/" title="推理-框架">推理-框架</a> </li>
<li><a href="/www6vHomeHexo/2023/01/01/gptInference/" title="推理-优化">推理-优化</a></li>
</ul>
</li>
<li>Data<ul>
<li><a href="/www6vHomeHexo/2023/01/08/gptDataSet/" title="数据集">数据集</a> </li>
<li><a href="/www6vHomeHexo/2023/02/05/gptDataProcess/" title="数据处理">数据处理</a></li>
</ul>
</li>
</ul>
<h2><span id="finetuning">FineTuning</span><a href="#finetuning" class="header-anchor">#</a></h2><ul>
<li>基础<ul>
<li><a href="/www6vHomeHexo/2022/11/18/gptFineTuning/" title="SFT-PEFT">SFT-PEFT</a> </li>
<li><a href="/www6vHomeHexo/2022/12/28/gptFineTuningWhen/" title="Fine-Tuning 时机">Fine-Tuning 时机</a>  </li>
<li><a href="/www6vHomeHexo/2023/01/06/gptPromptTuning/" title="Prompt Tuning">Prompt Tuning</a> </li>
<li><a href="/www6vHomeHexo/2023/01/06/gptInstructTuning/" title="Instruct Tuning">Instruct Tuning</a></li>
</ul>
</li>
<li>实战<ul>
<li><a href="/www6vHomeHexo/2022/12/20/gptFineTuningPEFT/" title="PEFT 实战">PEFT 实战</a>  
<ul>
<li><a href="/www6vHomeHexo/2023/01/05/gptPEFTLora/" title="PEFT Lora 实战">PEFT Lora 实战</a> </li>
<li><a href="/www6vHomeHexo/2024/01/12/gptPEFTQLora/" title="PEFT QLoRA 实战">PEFT QLoRA 实战</a> </li>
<li><a href="/www6vHomeHexo/2023/01/25/gptPromptTuningPractice/" title="PromptTuning 实战">PromptTuning 实战</a>    </li>
<li><a href="/www6vHomeHexo/2024/01/28/gptPEFTPtuning/" title="PEFT P-Tuning">PEFT P-Tuning</a></li>
</ul>
</li>
<li><a href="/www6vHomeHexo/2024/01/26/gptFineTuningBert/" title="Fine Tuning-Bert">Fine Tuning-Bert</a></li>
</ul>
</li>
<li>Data<ul>
<li><a href="/www6vHomeHexo/2023/02/06/gptSTFData/" title="STF 数据">STF 数据</a></li>
</ul>
</li>
</ul>
<h2><span id="prompt">Prompt</span><a href="#prompt" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/11/10/gptPromptEngineering/" title="Prompt Engineering">Prompt Engineering</a></li>
<li><a href="/www6vHomeHexo/2023/02/08/gptCOT/" title="COT">COT</a> </li>
<li><a href="/www6vHomeHexo/2021/05/28/gptPromptCode/" title="Prompt-Code">Prompt-Code</a></li>
<li><a href="/www6vHomeHexo/2021/05/26/gptPrompt/" title="Prompt-How to use">Prompt-How to use</a></li>
</ul>
<h2><span id="rag">RAG</span><a href="#rag" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/11/02/gptRAG/" title="RAG 原理">RAG 原理</a></li>
<li><a href="/www6vHomeHexo/2022/12/31/gptRAGPractice/" title="RAG 实践">RAG 实践</a> </li>
<li><a href="/www6vHomeHexo/2022/12/07/gptRAGPerformance/" title="RAG 性能">RAG 性能</a></li>
<li><a href="/www6vHomeHexo/2022/12/27/gptRAGPerformanceOpenAI/" title="RAG 性能-OpenAI案例">RAG 性能-OpenAI案例</a></li>
</ul>
<h2><span id="langchain">Langchain</span><a href="#langchain" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/11/02/gptLangchain/" title="Langchain">Langchain</a></li>
<li><a href="/www6vHomeHexo/2022/12/31/gptRetrievers/" title="Retrievers">Retrievers</a> </li>
<li><a href="/www6vHomeHexo/2023/01/11/gptLangchainAgent/" title="Langchain  Agent">Langchain  Agent</a></li>
</ul>
<h2><span id="agent">Agent</span><a href="#agent" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/11/02/gptAgent/" title="Agent 原理">Agent 原理</a></li>
<li><a href="/www6vHomeHexo/2023/01/21/gptMultiAgents/" title="Multi-Agents">Multi-Agents</a>  </li>
<li><a href="/www6vHomeHexo/2023/01/01/gptAgentPractice/" title="Agent 实践">Agent 实践</a> </li>
<li>Tools<ul>
<li><a href="/www6vHomeHexo/2022/11/16/gptFunctionCall/" title="Function Call">Function Call</a> </li>
<li><a href="/www6vHomeHexo/2023/01/27/gptAgentTool/" title="Agent-Tools">Agent-Tools</a>  </li>
<li><a href="/www6vHomeHexo/2023/02/03/gptToolformer/" title="Toolformer">Toolformer</a></li>
</ul>
</li>
</ul>
<h2><span id="application">Application</span><a href="#application" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/05/09/gpt/" title="GPT-工具和应用">GPT-工具和应用</a></li>
<li><a href="/www6vHomeHexo/2022/12/28/gptLLMOps/" title="LLMOps">LLMOps</a> </li>
<li><a href="/www6vHomeHexo/2022/11/27/gptVectorStore/" title="向量数据库">向量数据库</a></li>
<li><a href="/www6vHomeHexo/2023/01/03/gptNL2SQL/" title="NL2SQL">NL2SQL</a> </li>
<li>垂类模型<ul>
<li><a href="/www6vHomeHexo/2023/01/04/gptDomain/" title="垂类大模型">垂类大模型</a> </li>
<li><a href="/www6vHomeHexo/2022/11/24/gptDomainFinance/" title="金融大模型">金融大模型</a>   </li>
<li><a href="/www6vHomeHexo/2023/02/07/gptDomainMed/" title="医疗大模型">医疗大模型</a>   </li>
<li><a href="/www6vHomeHexo/2024/02/07/gptDomainLaw/" title="法律大模型">法律大模型</a></li>
</ul>
</li>
</ul>
<h2><span id="study">Study</span><a href="#study" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/08/01/gptStudy/" title="GPT  学习资源">GPT  学习资源</a></li>
<li><a href="/www6vHomeHexo/2022/01/22/aiStudyResouce/" title="人工智能-学习资源">人工智能-学习资源</a></li>
</ul>
<h2><span id="research">Research</span><a href="#research" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2024/02/11/gptPaperTools/" title="科研-工具">科研-工具</a> </li>
<li><a href="/www6vHomeHexo/2023/01/20/gptStudyPaper/" title="GPT 论文">GPT 论文</a></li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>汇总</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据  汇总</title>
    <url>/www6vHomeHexo/2022/09/19/bigDataSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="存储">存储</span><a href="#存储" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2022/09/07/clickhouse/" title="Clickhouse">Clickhouse</a>
</li>
<li><a href="/www6vHomeHexo/2022/01/08/elasticsearchModel/" title="Elasticsearch 数据模型Model">Elasticsearch 数据模型Model</a></li>
<li><a href="/www6vHomeHexo/2019/08/03/elasticsearchDistributed/" title="Elasticsearch 分布式集群">Elasticsearch 分布式集群</a></li>
<li><a href="/www6vHomeHexo/2019/08/02/elasticsearch/" title="Elasticsearch基础(ES)">Elasticsearch基础(ES)</a>
</li>
<li><a href="/www6vHomeHexo/2023/04/02/hbaselsmTree/" title="HBase - LSM-Tree">HBase - LSM-Tree</a></li>
<li><a href="/www6vHomeHexo/2021/06/07/hbaseHotkey/" title="HBase Hotkey-预分区和Rowkey设计">HBase Hotkey-预分区和Rowkey设计</a></li>
<li><a href="/www6vHomeHexo/2020/09/04/hbase/" title="HBase总结">HBase总结</a>
</li>
<li><a href="/www6vHomeHexo/2018/06/07/hdfs/" title="HDFS NameNode HA 解决方案">HDFS NameNode HA 解决方案</a>
</li>
<li><a href="/www6vHomeHexo/2022/09/01/iceberg/" title="Iceberg">Iceberg</a>
</li>
<li><a href="/www6vHomeHexo/2022/09/08/bigDataMetaMgt/" title="大数据 元数据管理">大数据 元数据管理</a>
</li>
<li><a href="/www6vHomeHexo/2019/09/15/bigDataStorage/" title="大数据存储">大数据存储</a></li>
</ul>
<h1><span id="平台">平台</span><a href="#平台" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2022/10/16/dataMiddlePlatform/" title="数据中台">数据中台</a>
</li>
<li><a href="/www6vHomeHexo/2022/07/18/realtimeDataWarehouse/" title="实时数仓">实时数仓</a>
</li>
<li><a href="/www6vHomeHexo/2022/08/04/streamingBatchIntegration/" title="批流一体">批流一体</a>
</li>
<li><a href="/www6vHomeHexo/2022/09/15/userBehaviorAnalysis/" title="用户行为分析">用户行为分析</a>
</li>
<li><a href="/www6vHomeHexo/2021/06/15/olap/" title="OLAP 在线分析处理">OLAP 在线分析处理</a>
</li>
<li><a href="/www6vHomeHexo/2022/09/21/personProflie/" title="用户画像">用户画像</a></li>
</ul>
<h1><span id="计算">计算</span><a href="#计算" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2022/06/17/bigDataComputing/" title="大数据 计算Computing">大数据 计算Computing</a>
</li>
<li><a href="/www6vHomeHexo/2022/09/08/bigDataSchedule/" title="大数据 调度">大数据 调度</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>流处理 汇总</title>
    <url>/www6vHomeHexo/2022/04/22/streamingSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#flink">Flink</a><ul>
<li><a href="#basic">Basic</a></li>
<li><a href="#checkpoint">Checkpoint</a></li>
<li><a href="#table">Table</a></li>
</ul>
</li>
<li><a href="#spark">Spark</a></li>
<li><a href="#beam">Beam</a></li>
<li><a href="#%E6%89%B9%E6%B5%81%E4%B8%80%E4%BD%93">批流一体</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
<li><a href="#streaming-system%E7%BF%BB%E8%AF%91">《Streaming System》翻译</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="flink">Flink</span><a href="#flink" class="header-anchor">#</a></h1><h3><span id="basic">Basic</span><a href="#basic" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2019/07/29/streamingFlink/" title="Flink 总结">Flink 总结</a>
</li>
<li><a href="/www6vHomeHexo/2022/03/31/streamingFlinkWindow/" title="Flink-Window">Flink-Window</a>
</li>
<li><a href="/www6vHomeHexo/2022/03/29/streamingFlinkWatermarkWindow/" title="Flink-Watermark &amp; Window">Flink-Watermark &amp; Window</a>
</li>
<li><a href="/www6vHomeHexo/2022/03/31/streamingFlinkDeploy/" title="Flink-部署方式">Flink-部署方式</a></li>
</ul>
<h3><span id="checkpoint">Checkpoint</span><a href="#checkpoint" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/02/03/streamingFlinkCheckpoint/" title="Flink Checkpoint-分布式快照方法">Flink Checkpoint-分布式快照方法</a></li>
<li><a href="/www6vHomeHexo/2022/02/01/streamingFlinkExactlyOnce/" title="Flink 端到端Exactly-once">Flink 端到端Exactly-once</a></li>
</ul>
<h3><span id="table">Table</span><a href="#table" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/07/18/flinkSQL/" title="Flink SQL">Flink SQL</a></li>
<li><a href="/www6vHomeHexo/2022/01/22/streamingFlinkJoin/" title="Flink 双流Join">Flink 双流Join</a></li>
</ul>
<h1><span id="spark">Spark</span><a href="#spark" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2019/03/09/streamingSpark/" title="Spark 总结">Spark 总结</a></li>
<li><a href="/www6vHomeHexo/2022/05/19/streamingSparkPerformance/" title="Spark 性能优化">Spark 性能优化</a></li>
<li><a href="/www6vHomeHexo/2019/03/10/streamingSparkTrain/" title="Spark公司内部培训">Spark公司内部培训</a></li>
</ul>
<h1><span id="beam">Beam</span><a href="#beam" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2022/04/21/streamingBeam/" title="流计算-Beam">流计算-Beam</a></li>
</ul>
<h1><span id="批流一体">批流一体</span><a href="#批流一体" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2022/08/04/streamingBatchIntegration/" title="批流一体">批流一体</a></li>
</ul>
<h1><span id="总结">总结</span><a href="#总结" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2019/07/19/streamComputing/" title="流式计算[Flink Beam Spark]">流式计算[Flink Beam Spark]</a></li>
</ul>
<h1><span id="streaming-system翻译">《Streaming System》翻译</span><a href="#streaming-system翻译" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2000/03/18/streamingSystemChapter1/" title="《Streaming System》- 第一章：流处理入门[完整]">《Streaming System》- 第一章：流处理入门[完整]</a></li>
<li><a href="/www6vHomeHexo/2000/03/17/streamingSystemChapter2/" title="《Streaming System》-第二章： 数据处理的什么、何地、何时以及如何进行[完整]">《Streaming System》-第二章： 数据处理的什么、何地、何时以及如何进行[完整]</a></li>
<li><a href="/www6vHomeHexo/2000/03/15/streamingSystemChapter3/" title="《Streaming System》-第三章：水位线[完整]">《Streaming System》-第三章：水位线[完整]</a></li>
<li><a href="/www6vHomeHexo/2000/03/14/streamingSystemChapter4/" title="《Streaming System》-第四章：高级窗口 [完整]">《Streaming System》-第四章：高级窗口 [完整]</a></li>
<li><a href="/www6vHomeHexo/2000/03/16/streamingSystemChapter5/" title="《Streaming System》-第五章：精确一次和副作用 [完整]">《Streaming System》-第五章：精确一次和副作用 [完整]</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>流处理</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>云计算 汇总</title>
    <url>/www6vHomeHexo/2022/04/09/cloudComputing/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%8E%82%E5%95%86">厂商</a><br>- <a href="#%E5%88%86%E7%B1%BB">分类</a><br>- <a href="#%E6%A8%AA%E5%90%91%E6%AF%94%E8%BE%83">横向比较</a></li>
<li><a href="#%E9%80%9A%E7%94%A8%E6%80%BB%E7%BB%93">通用总结</a></li>
</ul>
<!-- tocstop -->

</div>

<h2><span id="厂商">厂商</span><a href="#厂商" class="header-anchor">#</a></h2><h5><span id="分类">分类</span><a href="#分类" class="header-anchor">#</a></h5><ul>
<li><a href="/www6vHomeHexo/2018/10/04/awsSummary/" title="AWS 汇总">AWS 汇总</a></li>
<li><a href="/www6vHomeHexo/2022/05/16/aliyunSummary/" title="阿里云 汇总">阿里云 汇总</a></li>
<li><a href="/www6vHomeHexo/2022/06/30/tencentTCPSummary/" title="腾讯云TCP-汇总">腾讯云TCP-汇总</a></li>
</ul>
<h5><span id="横向比较">横向比较</span><a href="#横向比较" class="header-anchor">#</a></h5><ul>
<li><a href="/www6vHomeHexo/2022/04/30/cloudProduct/" title="云计算产品-计算">云计算产品-计算</a></li>
<li><a href="/www6vHomeHexo/2022/05/22/cloudProduct-Network/" title="云计算产品-网络Network">云计算产品-网络Network</a></li>
<li><a href="/www6vHomeHexo/2022/05/22/cloudProduct-Storage/" title="云计算产品-存储Storage">云计算产品-存储Storage</a></li>
</ul>
<h2><span id="通用总结">通用总结</span><a href="#通用总结" class="header-anchor">#</a></h2><table>
<thead>
<tr>
<th>类型</th>
<th>总结</th>
</tr>
</thead>
<tbody><tr>
<td>Overview<br></td>
<td><a href="../../../../2019/02/07/xaas/">云计算中的Xaas</a></td>
</tr>
<tr>
<td>计算 <br></td>
<td><a href="../../../../2020/07/29/vm/">云计算中的虚拟机vm</a><br><a href="../../../../2019/10/10/serverless/">Serverless</a> <br><a href="../../../../2022/06/03/serverlessOptimize/">Serverless 优化</a> <br><a href="../../../../2022/06/25/serverlessConcern/">Serverless 关注点</a></td>
</tr>
<tr>
<td>网络<br></td>
<td><a href="../../../../2022/04/09/vpc/">VPC</a></td>
</tr>
<tr>
<td>存储  <br></td>
<td><a href="../../../../2019/10/08/storage/">非结构化存储</a></td>
</tr>
<tr>
<td>计费 <br></td>
<td><a href="../../../../2022/05/21/cloudComputingBilling/">云计算计费</a></td>
</tr>
<tr>
<td>迁移<br></td>
<td><a href="../../../../2022/04/11/dbMigrate/">数据库迁移</a></td>
</tr>
<tr>
<td>数据中心<br></td>
<td><a href="../../../../2019/05/15/netConnection/">IDC网络互通</a> <br><a href="../../../../2022/01/30/cloudDatacenter/">云计算-数据中心</a></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>汇总</category>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes 汇总</title>
    <url>/www6vHomeHexo/2022/01/22/k8sSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%BC%96%E6%8E%92%E5%8E%9F%E7%90%86">编排原理</a></li>
<li><a href="#operator-controller">Operator &amp;&amp; Controller</a></li>
<li><a href="#container-runtime">Container Runtime</a></li>
<li><a href="#%E7%BD%91%E7%BB%9C">网络</a></li>
<li><a href="#%E6%9C%8D%E5%8A%A1%E5%92%8Cdns">服务和DNS</a></li>
<li><a href="#%E5%AD%98%E5%82%A8">存储</a></li>
<li><a href="#%E8%B0%83%E5%BA%A6">调度</a></li>
<li><a href="#%E7%9B%91%E6%8E%A7%E5%92%8Cautoscale">监控和AutoScale</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E5%8C%96">生产化</a></li>
<li><a href="#paas">PaaS</a></li>
<li><a href="#%E5%AE%89%E5%85%A8">安全</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81%E8%B5%B0%E8%AF%BB">代码走读</a></li>
<li><a href="#%E9%97%AE%E9%A2%98%E5%92%8C%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5">问题和最佳实践</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
<li><a href="#%E5%85%B6%E4%BB%96">其他</a></li>
<li><a href="#%E5%AD%A6%E4%B9%A0">学习</a></li>
<li><a href="#%E5%AE%89%E8%A3%85">安装</a></li>
</ul>
<!-- tocstop -->

</div>

<h2><span id="编排原理">编排原理</span><a href="#编排原理" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/04/25/k8s/" title="Kubernetes 架构">Kubernetes 架构</a> </li>
<li><a href="/www6vHomeHexo/2019/06/09/k8sResource/" title="Kubernetes Workload">Kubernetes Workload</a> </li>
<li><a href="/www6vHomeHexo/2022/02/16/k8sDeployment/" title="Kubernetes Deployment">Kubernetes Deployment</a> </li>
<li><a href="/www6vHomeHexo/2019/11/11/k8sStatefulSet/" title="Kubernetes StatefulSet原理和源码">Kubernetes StatefulSet原理和源码</a> </li>
<li><a href="/www6vHomeHexo/2019/11/14/k8sResouceModel/" title="Kubenetes资源模型">Kubenetes资源模型</a> </li>
<li><a href="/www6vHomeHexo/2022/04/03/k8sPLEG/" title="kubelet和PLEG">kubelet和PLEG</a></li>
</ul>
<h2><span id="operator-ampamp-controller">Operator &amp;&amp; Controller</span><a href="#operator-ampamp-controller" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2021/12/30/k8s-operator/" title="Kubernetes Operator-kubebuilder">Kubernetes Operator-kubebuilder</a> </li>
<li><a href="/www6vHomeHexo/2019/11/19/k8sOperator/" title="Kubernetes Operator-Etcd">Kubernetes Operator-Etcd</a> </li>
<li><a href="/www6vHomeHexo/2019/08/29/k8sDeclarativeAPI/" title="Kubernetes声明式API">Kubernetes声明式API</a> </li>
<li><a href="/www6vHomeHexo/2022/02/17/k8sOperator-redis/" title="Kubernetes Operator-Redis">Kubernetes Operator-Redis</a></li>
<li><a href="/www6vHomeHexo/2023/10/16/k8sAdmissionWebhook/" title="K8s  AdmissionWebhook">K8s  AdmissionWebhook</a></li>
</ul>
<h2><span id="container-runtime">Container Runtime</span><a href="#container-runtime" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/11/19/k8sRuntime/" title="Kubernetes Runtime">Kubernetes Runtime</a> </li>
<li><a href="/www6vHomeHexo/2021/06/01/k8sAbandonDocker/" title="K8S 弃用Docker">K8S 弃用Docker</a></li>
</ul>
<h2><span id="网络">网络</span><a href="#网络" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/08/23/k8sNetwork/" title="Kubernetes网络">Kubernetes网络</a> </li>
<li><a href="/www6vHomeHexo/2022/05/03/k8sCalico/" title="Calico">Calico</a></li>
</ul>
<h2><span id="服务和dns">服务和DNS</span><a href="#服务和dns" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/11/04/k8sService/" title="Kubernetes服务">Kubernetes服务</a> </li>
<li><a href="/www6vHomeHexo/2022/01/12/k8sDNS/" title="Kubernetes CoreDNS">Kubernetes CoreDNS</a> </li>
<li><a href="/www6vHomeHexo/2022/02/10/k8sIngressNginx/" title="Kubernetes Nginx Ingress">Kubernetes Nginx Ingress</a></li>
</ul>
<h2><span id="存储">存储</span><a href="#存储" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/09/01/k8sStorage/" title="Kubernetes存储">Kubernetes存储</a> </li>
<li><a href="/www6vHomeHexo/2022/01/12/k8sRook/" title="Kubernetes Rook">Kubernetes Rook</a> </li>
<li><a href="/www6vHomeHexo/2022/01/08/ceph/" title="Ceph 总结">Ceph 总结</a> </li>
<li><a href="/www6vHomeHexo/2022/04/06/etcd/" title="etcd 总结">etcd 总结</a></li>
</ul>
<h2><span id="调度">调度</span><a href="#调度" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/06/09/k8sScheduler/" title="Kubernetes调度器">Kubernetes调度器</a> </li>
<li><a href="/www6vHomeHexo/2022/05/27/k8sAdvancedScheduling/" title="Kubernetes 高级调度">Kubernetes 高级调度</a></li>
</ul>
<h2><span id="监控和autoscale">监控和AutoScale</span><a href="#监控和autoscale" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/11/16/k8sAutoScale/" title="Kubernetes自动伸缩和HPA">Kubernetes自动伸缩和HPA</a> </li>
<li><a href="/www6vHomeHexo/2022/04/10/observabilityPrometheus/" title="可观测性-Prometheus">可观测性-Prometheus</a> </li>
<li><a href="/www6vHomeHexo/2022/02/11/observabilityPrometheusHA/" title="可观测性-Prometheus  HA">可观测性-Prometheus  HA</a> </li>
<li><a href="/www6vHomeHexo/2022/01/30/k8sObservability/" title="可观测性-Kubernetes">可观测性-Kubernetes</a></li>
</ul>
<h2><span id="生产化">生产化</span><a href="#生产化" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/02/02/k8sAppMigrate/" title="K8S 应用迁移至K8S">K8S 应用迁移至K8S</a> </li>
<li><a href="/www6vHomeHexo/2022/01/02/k8sHA/" title="K8S高可用-控制面">K8S高可用-控制面</a> </li>
<li><a href="/www6vHomeHexo/2022/04/05/k8sAvailable/" title="K8S高可用-零停机[自主中断]">K8S高可用-零停机[自主中断]</a> </li>
<li><a href="/www6vHomeHexo/2022/10/22/k8sAvailableHealth/" title="K8S高可用-零停机[探针]">K8S高可用-零停机[探针]</a> </li>
<li><a href="/www6vHomeHexo/2020/08/16/linuxKernelParam/" title="虚拟机和容器中的内核参数 kernel">虚拟机和容器中的内核参数 kernel</a> </li>
<li><a href="/www6vHomeHexo/2022/01/16/k8sUpgrade/" title="Kubernetes 升级upgrade">Kubernetes 升级upgrade</a></li>
</ul>
<h2><span id="paas">PaaS</span><a href="#paas" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/01/12/k8sPaaS/" title="Kubernetes PaaS平台">Kubernetes PaaS平台</a> </li>
<li><a href="/www6vHomeHexo/2022/01/05/k8sOpenShift/" title="Kubernetes OpenShift">Kubernetes OpenShift</a> </li>
<li><a href="/www6vHomeHexo/2021/10/18/k8sMultiTenancy/" title="Kubernetes 多租户">Kubernetes 多租户</a> </li>
<li><a href="/www6vHomeHexo/2019/11/14/k8sRBAC/" title="Kubenetes RBAC">Kubenetes RBAC</a> </li>
<li><a href="/www6vHomeHexo/2022/05/08/k8sMultiCluster/" title="Kubernetes 多集群管理">Kubernetes 多集群管理</a> </li>
<li><a href="/www6vHomeHexo/2022/06/03/k8sVM/" title="Kubernetes和VM">Kubernetes和VM</a></li>
</ul>
<h2><span id="安全">安全</span><a href="#安全" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/05/22/k8sSecurity/" title="Kubernetes安全-Security">Kubernetes安全-Security</a> </li>
<li><a href="/www6vHomeHexo/2022/01/15/k8sCKS/" title="Kubernetes CKS">Kubernetes CKS</a> </li>
<li><a href="/www6vHomeHexo/2022/01/16/k8sSecurityPractice/" title="Kubernetes 安全实践">Kubernetes 安全实践</a></li>
</ul>
<h2><span id="代码走读">代码走读</span><a href="#代码走读" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/01/15/k8sCodeOfApiServer/" title="Kubernetes ApiServer 代码走读">Kubernetes ApiServer 代码走读</a> </li>
<li><a href="/www6vHomeHexo/2022/01/15/k8sCodeOfInformerFramework/" title="Kubernetes Informer Framework 代码走读">Kubernetes Informer Framework 代码走读</a> </li>
<li><a href="/www6vHomeHexo/2022/01/15/k8sCodeOfKubelet/" title="Kubernetes Kubelet 代码走读">Kubernetes Kubelet 代码走读</a> </li>
<li><a href="/www6vHomeHexo/2022/01/15/k8sCodeOfKubeScheduler/" title="Kubernetes KubeScheduler 代码走读">Kubernetes KubeScheduler 代码走读</a></li>
</ul>
<h2><span id="问题和最佳实践">问题和最佳实践</span><a href="#问题和最佳实践" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/04/03/k8sProblem/" title="Kubernetes问题排查-troubleshooting">Kubernetes问题排查-troubleshooting</a> </li>
<li><a href="/www6vHomeHexo/2022/01/23/k8sBestPractice/" title="Kubernetes最佳实践-BestPractice">Kubernetes最佳实践-BestPractice</a> </li>
<li><a href="/www6vHomeHexo/2022/06/08/k8sTroubleshoot/" title="kubernetes 问题Troubleshoot">kubernetes 问题Troubleshoot</a></li>
</ul>
<h2><span id="总结">总结</span><a href="#总结" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/11/03/k8sSkill/" title="Kubernetes技能图谱">Kubernetes技能图谱</a> </li>
<li><a href="/www6vHomeHexo/2019/11/13/k8sPattern/" title="Kubernetes模式">Kubernetes模式</a> </li>
<li><a href="/www6vHomeHexo/2019/08/11/k8sInterface/" title="Kubernetes开放接口">Kubernetes开放接口</a></li>
</ul>
<h2><span id="其他">其他</span><a href="#其他" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/06/09/k8sCommand/" title="Kubernetes命令">Kubernetes命令</a> </li>
<li><a href="/www6vHomeHexo/2020/05/26/k8sDeclarativeManage/" title="k8s声明式应用管理">k8s声明式应用管理</a></li>
</ul>
<h2><span id="学习">学习</span><a href="#学习" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/05/21/k8sStudy/" title="Kubernetes 学习资源">Kubernetes 学习资源</a> </li>
<li><a href="/www6vHomeHexo/2020/06/14/cloudNativeResource/" title="云原生-学习资源">云原生-学习资源</a></li>
</ul>
<h2><span id="安装">安装</span><a href="#安装" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/06/03/k8sSetupSummary/" title="Kubernetes 安装方式">Kubernetes 安装方式</a> </li>
<li><a href="/www6vHomeHexo/2021/06/02/k8sDeploy/" title="Kubernetes安装-kubeasz">Kubernetes安装-kubeasz</a> </li>
<li><a href="/www6vHomeHexo/2019/01/17/k8sSetup/" title="Kubernetes集群搭建(二进制)">Kubernetes集群搭建(二进制)</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Service Mesh 汇总</title>
    <url>/www6vHomeHexo/2021/06/07/istioSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="原理">原理</span><a href="#原理" class="header-anchor">#</a></h2><ul>
<li><a href="../../../../2019/07/02/istio/">istio</a></li>
<li><a href="../../../../2022/01/14/istioControlPanel/">istio 控制面ControlPanel</a> </li>
<li><a href="../../../../2019/11/21/istioTrafficManagement/">Istio流量管理</a></li>
<li><a href="../../../../2019/11/21/istioDataplane/">istio数据面</a> </li>
<li><a href="/www6vHomeHexo/2022/07/02/istioDataplaneAmbient/" title="istio 数据平面-ambient 模式">istio 数据平面-ambient 模式</a></li>
<li><a href="../../../../2019/07/20/istio-k8s-service/">Istio、Kubernetes和Spring Cloud中服务的比对</a>    </li>
<li><a href="../../../../2019/11/18/istioKnowledgeMap/">Istio知识图谱</a></li>
</ul>
<h2><span id="实践">实践</span><a href="#实践" class="header-anchor">#</a></h2><ul>
<li><a href="../../../../2019/07/15/istioCommand/">istio常用命令</a></li>
<li><a href="../../../../2019/07/02/istioSetup-bookinfo/">istio安装 + Bookinfo示例</a></li>
<li><a href="../../../../2022/01/06/istioMigrateFromSpringCloud/">SpringCloud迁移到istio</a></li>
<li><a href="../../../../2022/02/06/istioServiceFailover/">Istio Service Failover</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>serviceMesh</category>
      </categories>
      <tags>
        <tag>istio</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 汇总</title>
    <url>/www6vHomeHexo/2021/05/27/linuxSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<p>关键词: linux, 计算机组成</p>
<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%80%BB%E4%BD%93%E6%9E%B6%E6%9E%84">总体架构</a></li>
<li><a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F3">操作系统[3]</a></li>
<li><a href="#cpu-and-cache1">CPU and Cache[1]</a></li>
<li><a href="#memory">Memory</a></li>
<li><a href="#file-block">File， block</a></li>
<li><a href="#network">Network</a></li>
<li><a href="#frameworks-and-tools">Frameworks and Tools</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h2><span id="总体架构">总体架构</span><a href="#总体架构" class="header-anchor">#</a></h2><ul>
<li>北桥<br>主桥 - 处理高速信号 </li>
<li>南桥<br>IO桥 - [低速]</li>
</ul>
<h2><span id="操作系统3">操作系统[3]</span><a href="#操作系统3" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/01/30/linuxKernel/" title="Linux Kernel总结">内核</a>  self</li>
<li>栈<br>用函数和寄存器的方式记录了线程的执行历史</li>
<li>中断</li>
<li><a href="/www6vHomeHexo/2019/08/22/linuxProcess/" title="Linux 进程">进程</a>  self</li>
<li><a href="/www6vHomeHexo/2022/01/30/linuxSystemCall/" title="Linux 系统调用SystemCall">系统调用</a>  self</li>
<li>虚拟内存</li>
<li><a href="/www6vHomeHexo/2019/08/23/linuxMemory/" title="Linux内存管理">内存管理</a>  self</li>
<li><a href="/www6vHomeHexo/2022/05/29/linuxSceduling/" title="Linux 调度">调度器</a>  self
<ul>
<li>cpu调度级别</li>
<li>io调度级别<br>deadline， CFQ</li>
</ul>
</li>
<li><a href="/www6vHomeHexo/2019/08/24/linuxFile/" title="Linux文件系统">文件系统</a> self</li>
<li>网络</li>
</ul>
<h2><span id="cpu-and-cache1">CPU and Cache[1]</span><a href="#cpu-and-cache1" class="header-anchor">#</a></h2><ul>
<li>CPU架构<ul>
<li>SMP UMA<br>系统总线成了系统瓶颈，应运而生了NUMA</li>
<li>NUMA</li>
<li>Bus 总线<br>[cpu和内存之间的通道]</li>
</ul>
</li>
<li>CPU Cache<ul>
<li>L1 的存取速度：4 个CPU时钟周期</li>
<li>L2 的存取速度：11 个CPU时钟周期</li>
<li>L3 的存取速度：39 个CPU时钟周期</li>
<li>RAM内存的存取速度：107 个CPU时钟周期</li>
</ul>
</li>
<li>cacheline<br>Cache Line是最小单位（64Bytes）<br>eg. L1有32KB，32KB&#x2F;64B &#x3D; 512个Cache Line  </li>
<li>缓存的一致性<ul>
<li>cache line对齐</li>
<li>一致性协议  <ul>
<li>Directory 协议</li>
<li>Snoopy 协议<br> MESI协议, cache line的4个状态</li>
</ul>
</li>
</ul>
</li>
<li>Cache 预取    </li>
<li>TLB(Translation Lookaside Buffer)  <ul>
<li>快表，解决MMU查找page慢的问题</li>
<li>专门用于cache内存中的页表项</li>
</ul>
</li>
</ul>
<h2><span id="memory">Memory</span><a href="#memory" class="header-anchor">#</a></h2><ul>
<li>MMU(Memory Management Unit)</li>
<li>page - 4K<ul>
<li>Hugepage: 2M, 1G</li>
</ul>
</li>
<li>虚拟内存</li>
<li>overcommit</li>
<li>SLUB slab</li>
<li>buffer &amp;&amp; cache<br>page cache - 文件<br>buffer - 磁盘</li>
</ul>
<h2><span id="file-block">File， block</span><a href="#file-block" class="header-anchor">#</a></h2><ul>
<li>POSIX</li>
<li>io_uring<br>linux 5.1引入的异步io接口，适合io密集型应用</li>
</ul>
<h2><span id="network">Network</span><a href="#network" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/08/07/tcpUdpControlCongestion/" title="TCP流控和拥塞控制">TCP 阻塞</a>  self</li>
<li><a href="/www6vHomeHexo/2022/01/30/linuxNetwork/" title="Linux 协议栈">Linux 协议栈</a> self</li>
<li>epoll</li>
</ul>
<h2><span id="frameworks-and-tools">Frameworks and Tools</span><a href="#frameworks-and-tools" class="header-anchor">#</a></h2><ul>
<li>data plan <ul>
<li><a href="/www6vHomeHexo/2022/01/25/linuxDPDK/" title="DPDK">DPDK</a>  self        </li>
<li><a href="https://spdk.io/">SPDK</a> 官网<ul>
<li>用户态的TCP&#x2F;IP协议栈 libuns</li>
</ul>
</li>
<li>VPP</li>
</ul>
</li>
<li><a href="/www6vHomeHexo/2022/05/22/linux-ebpf/" title="eBPF">eBPF</a>  self
<ul>
<li>LLVM</li>
<li>bcc</li>
</ul>
</li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li>《深入浅出DPDK》</li>
<li><a href="https://coolshell.cn/articles/20793.html">与程序员相关的CPU缓存知识</a>   ***   有代码</li>
<li>&lt;&lt;性能之巅&gt;&gt;</li>
</ol>
]]></content>
      <categories>
        <category>汇总</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>故障模型 &amp;&amp; 故障排查</title>
    <url>/www6vHomeHexo/2021/05/23/troubleshootingSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5">故障模型 &amp;&amp; 故障排查</a><br>- <a href="#java-core-%E5%BA%94%E7%94%A8">Java Core &amp;&amp; 应用</a><br>- <a href="#%E4%B8%AD%E9%97%B4%E4%BB%B6">中间件</a><br>- <a href="#infra">Infra</a><br>- <a href="#k8s">K8s</a><br>- <a href="#basic">Basic</a></li>
</ul>
<!-- tocstop -->

</div>


<h2><span id="故障模型-ampamp-故障排查">故障模型 &amp;&amp; 故障排查</span><a href="#故障模型-ampamp-故障排查" class="header-anchor">#</a></h2><h5><span id="java-core-ampamp-应用">Java Core &amp;&amp; 应用</span><a href="#java-core-ampamp-应用" class="header-anchor">#</a></h5><ul>
<li><a href="/www6vHomeHexo/2018/10/27/faultModel1/" title="故障模型-应用层">故障模型-应用层</a>
<ul>
<li><a href="/www6vHomeHexo/2014/02/02/javaMemoryLeak/" title="Java内存泄漏的案例和解决方案">Java内存泄漏的案例和解决方案</a> </li>
<li><a href="/www6vHomeHexo/2014/07/21/twoGCcase/" title="两个GC案例">两个GC案例</a></li>
<li><a href="/www6vHomeHexo/2017/08/09/interrupted/" title="关于任务取消相关异常的排查">关于任务取消相关异常的排查</a></li>
<li><a href="/www6vHomeHexo/2014/09/06/classloader/" title="Classloader相关的故障排查">Classloader相关的故障排查</a></li>
<li><a href="/www6vHomeHexo/2021/05/04/multiAgent/" title="多个Java Agent同时使用的类增强冲突问题">多个Java Agent同时使用的类增强冲突问题</a>  ***</li>
<li><a href="/www6vHomeHexo/2021/05/17/lostTraceId/" title="TraceId 丢失问题">TraceId 丢失问题</a>  ***</li>
<li><a href="/www6vHomeHexo/2022/07/20/springTransactionInvalid/" title="Spring  Transaction  失效">Spring  Transaction  失效</a></li>
</ul>
</li>
</ul>
<h5><span id="中间件">中间件</span><a href="#中间件" class="header-anchor">#</a></h5><ul>
<li><a href="/www6vHomeHexo/2018/05/03/faultModel2/" title="故障模型-中间件层">故障模型-中间件层</a>
<ul>
<li>微服务<ul>
<li><a href="/www6vHomeHexo/2019/07/06/findProblem/" title="故障排查的流程和方法">故障排查的流程和方法</a></li>
<li><a href="/www6vHomeHexo/2017/10/17/slowRT/" title="服务慢响应超时排查">服务慢响应超时排查</a> </li>
<li><a href="/www6vHomeHexo/2017/07/28/zookeeperBug/" title="zookeeper未通知到服务客户端的异常排查">zookeeper未通知到服务客户端的异常排查</a>  ***</li>
</ul>
</li>
<li>Redis<ul>
<li><a href="/www6vHomeHexo/2021/05/21/redisBigKey/" title="Redis 大Key">Redis 大Key</a> ***</li>
<li><a href="/www6vHomeHexo/2022/05/23/redisNodeId/" title="Redis 集群扩容时NodeId问题">Redis 集群扩容时NodeId问题</a> ***</li>
</ul>
</li>
<li>Kafka<ul>
<li><a href="/www6vHomeHexo/2021/05/18/kafkaGracefulDown/" title="Kafka  单副本缩容问题排查">Kafka  单副本缩容问题排查</a>  ***</li>
</ul>
</li>
<li>多线程 - 死锁<ul>
<li><a href="/www6vHomeHexo/2017/09/25/mybatisBug/" title="线上不能下单问题排查">线上不能下单问题排查</a></li>
</ul>
</li>
<li>数据库<ul>
<li><a href="/www6vHomeHexo/2021/06/05/tidbTroubleshooting/" title="TiDB  故障排查">TiDB  故障排查</a>   </li>
<li><a href="/www6vHomeHexo/2020/06/21/mysqlBestPractice/" title="使用MySQL的性能问题和紧急处理手段">使用MySQL的性能问题和紧急处理手段</a></li>
<li><a href="/www6vHomeHexo/2023/08/15/mysqlDeadLock/" title="MySQL  锁和死锁">MySQL  锁和死锁</a>  ***</li>
<li><a href="/www6vHomeHexo/2022/08/16/mysqlMasterSlaveDelay/" title="MySQL 主从延迟">MySQL 主从延迟</a></li>
</ul>
</li>
<li><a href="/www6vHomeHexo/2017/02/19/splitBrain/" title="Split Brain">Split Brain</a></li>
</ul>
</li>
</ul>
<h5><span id="infra">Infra</span><a href="#infra" class="header-anchor">#</a></h5><ul>
<li><a href="/www6vHomeHexo/2018/05/03/faultModel3/" title="故障模型-基础设施层">故障模型-基础设施层</a>
<ul>
<li><a href="/www6vHomeHexo/2022/01/11/haproxyTcpdump/" title="HAProxy抓包">HAProxy抓包</a>   网络</li>
<li><a href="/www6vHomeHexo/2020/08/09/tcpTimewait/" title="TIME_WAIT和优化">TIME_WAIT和优化</a> ***</li>
<li><a href="/www6vHomeHexo/2020/08/16/linuxPerformance-cpu/" title="Linux性能优化 之 cpu优化">Linux性能优化 之 cpu优化</a></li>
</ul>
</li>
</ul>
<h5><span id="k8s">K8s</span><a href="#k8s" class="header-anchor">#</a></h5><ul>
<li><a href="/www6vHomeHexo/2022/06/08/k8sTroubleshoot/" title="kubernetes 问题Troubleshoot">kubernetes 问题Troubleshoot</a>  </li>
<li><a href="/www6vHomeHexo/2022/04/03/k8sProblem/" title="Kubernetes问题排查-troubleshooting">Kubernetes问题排查-troubleshooting</a>      ***</li>
<li><a href="/www6vHomeHexo/2022/01/23/k8sBestPractice/" title="Kubernetes最佳实践-BestPractice">Kubernetes最佳实践-BestPractice</a>   ***</li>
</ul>
<h5><span id="basic">Basic</span><a href="#basic" class="header-anchor">#</a></h5><ul>
<li><a href="/www6vHomeHexo/2020/08/08/tcpFault/" title="TCP故障模式">TCP故障模式</a></li>
<li><a href="/www6vHomeHexo/2019/10/12/crashDetect/" title="宕机检测-Lease、心跳">宕机检测-Lease、心跳</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>故障排查</category>
      </categories>
      <tags>
        <tag>故障排查</tag>
      </tags>
  </entry>
  <entry>
    <title>架构 汇总</title>
    <url>/www6vHomeHexo/2021/03/20/archSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="应用架构">应用架构</span><a href="#应用架构" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/11/01/apiDesign/" title="OpenAPI 设计">OpenAPI 设计</a></li>
<li><a href="/www6vHomeHexo/2018/02/25/cqrs/" title="CQRS 简介和案例分析">CQRS 简介和案例分析</a></li>
<li><a href="/www6vHomeHexo/2020/05/22/ddd/" title="DDD  领域驱动设计">DDD  领域驱动设计</a></li>
<li><a href="/www6vHomeHexo/2023/07/06/dddPractice/" title="DDD-落地实战 Practice">DDD-落地实战 Practice</a> </li>
<li><a href="/www6vHomeHexo/2018/04/07/EAI/" title="应用集成方式">应用集成方式</a></li>
<li><a href="/www6vHomeHexo/2018/03/17/DomainLogicAndSQL/" title="领域逻辑和SQL">领域逻辑和SQL</a></li>
</ul>
<h2><span id="系统架构">系统架构</span><a href="#系统架构" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/05/02/middleStage/" title="中台战略">中台战略</a></li>
<li><a href="/www6vHomeHexo/2022/02/02/disaggregationOfComputeAndStorage/" title="存算分离-数据应用">存算分离-数据应用</a></li>
<li><a href="/www6vHomeHexo/2019/04/28/haSummary/" title="高可用+容灾  汇总">高可用+容灾  汇总</a>
<ul>
<li><a href="/www6vHomeHexo/2022/06/26/available/" title="高可用 Available">高可用 Available</a></li>
</ul>
</li>
<li><a href="/www6vHomeHexo/2023/05/13/unifyModel/" title="统一模型">统一模型</a> </li>
<li><a href="/www6vHomeHexo/2017/06/17/multiLive/" title="异地多活 总结">异地多活 总结</a></li>
</ul>
<h2><span id="系统设计">系统设计</span><a href="#系统设计" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/09/13/feed/" title="Feed流 总结">Feed流 总结</a></li>
<li><a href="/www6vHomeHexo/2022/03/02/systemDesign/" title="系统设计 总结">系统设计 总结</a></li>
<li><a href="/www6vHomeHexo/2018/05/21/secKillSummary/" title="秒杀系统总结">秒杀系统总结</a></li>
<li><a href="/www6vHomeHexo/2018/05/06/seckill/" title="秒杀系统和商品详情页系统(培训讲义)">秒杀系统和商品详情页系统(培训讲义)</a></li>
</ul>
<h2><span id="设计原则">设计原则</span><a href="#设计原则" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2018/09/28/designPrinciple/" title="设计原则">设计原则</a></li>
<li><a href="/www6vHomeHexo/2023/04/02/designOCPspi/" title="开闭原则 - SPI">开闭原则 - SPI</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>服务治理  汇总</title>
    <url>/www6vHomeHexo/2021/03/03/serviceGovernanceSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86-%E6%B1%87%E6%80%BB">服务治理 汇总</a><ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#api-gateway">API Gateway</a></li>
<li><a href="#config-discovery">Config &amp; Discovery</a></li>
<li><a href="#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">负载均衡</a></li>
<li><a href="#%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B">线程模型</a></li>
<li><a href="#%E5%AE%B9%E9%94%99%E9%99%90%E6%B5%81">容错&amp;限流</a></li>
</ul>
<ul>
<li><a href="#%E5%AE%89%E5%85%A8">安全</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="服务治理-汇总">服务治理  汇总</span><a href="#服务治理-汇总" class="header-anchor">#</a></h1><h3><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2019/09/09/microservice/" title="微服务 总结">微服务 总结</a></li>
<li><a href="/www6vHomeHexo/2015/05/07/soaFeature/" title="分布式服务框架功能">分布式服务框架功能</a></li>
</ul>
<h3><span id="api-gateway">API Gateway</span><a href="#api-gateway" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/01/21/apiGateway/" title="API Gateway网关">API Gateway网关</a></li>
<li><a href="/www6vHomeHexo/2022/03/22/apiGatawayApisix/" title="API 网关-apisix">API 网关-apisix</a></li>
<li><a href="/www6vHomeHexo/2022/03/22/apiGatawaySpringGateway/" title="API 网关-SpringCloud Gateway">API 网关-SpringCloud Gateway</a></li>
<li><a href="/www6vHomeHexo/2022/03/23/apiGatewayGray/" title="API 网关-灰度发布">API 网关-灰度发布</a></li>
</ul>
<h3><span id="config-amp-discovery">Config &amp; Discovery</span><a href="#config-amp-discovery" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2020/07/27/config/" title="服务治理-分布式配置">服务治理-分布式配置</a></li>
<li><a href="/www6vHomeHexo/2022/08/14/soaDiscovery/" title="服务发现">服务发现</a></li>
</ul>
<h3><span id="负载均衡">负载均衡</span><a href="#负载均衡" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/05/06/loadBalance/" title="负载均衡-算法">负载均衡-算法</a></li>
<li><a href="/www6vHomeHexo/2019/08/22/nginx/" title="Nginx总结">Nginx总结</a></li>
<li><a href="/www6vHomeHexo/2020/03/26/nginxOptimize/" title="Nginx优化">Nginx优化</a></li>
</ul>
<h3><span id="线程模型">线程模型</span><a href="#线程模型" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2015/07/09/jsfThreadModel/" title="京东服务框架JSF服务提供者线程模型">京东服务框架JSF服务提供者线程模型</a></li>
</ul>
<h3><span id="容错amp限流">容错&amp;限流</span><a href="#容错amp限流" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2015/06/17/soaTolerate/" title="分布式服务框架 容错机制">分布式服务框架 容错机制</a></li>
<li><a href="/www6vHomeHexo/2016/10/07/soaTolerateFramework/" title="容错框架">容错框架</a></li>
<li><a href="/www6vHomeHexo/2016/09/26/ratelimit/" title="限流-总结">限流-总结</a></li>
<li><a href="/www6vHomeHexo/2022/03/28/ratelimitSentinel/" title="流量治理-Sentinel">流量治理-Sentinel</a></li>
<li><a href="/www6vHomeHexo/2016/01/17/soaTimeout/" title="超时和重试 总结">超时和重试 总结</a></li>
<li><a href="/www6vHomeHexo/2022/08/14/soaGracefulStart/" title="优雅启动">优雅启动</a> </li>
<li><a href="/www6vHomeHexo/2022/08/14/soaGracefulClose/" title="优雅关闭">优雅关闭</a></li>
</ul>
<h2><span id="安全">安全</span><a href="#安全" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/08/10/soaAuth/" title="服务治理-鉴权">服务治理-鉴权</a></li>
<li><a href="/www6vHomeHexo/2020/03/20/securityOAuth2/" title="安全-OAuth2">安全-OAuth2</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>service</category>
      </categories>
      <tags>
        <tag>service</tag>
      </tags>
  </entry>
  <entry>
    <title>消息系统 汇总</title>
    <url>/www6vHomeHexo/2021/02/11/mqSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2016/04/19/mq/" title="消息中间件总结">消息中间件总结</a></li>
<li><a href="/www6vHomeHexo/2022/05/12/mqCompare/" title="MQ总结(Kafka, Rocketmq, Rabbitmq)">MQ总结(Kafka, Rocketmq, Rabbitmq)</a></li>
<li><a href="/www6vHomeHexo/2021/05/19/mqOrdering/" title="消息系统 顺序消息">消息系统 顺序消息</a></li>
</ul>
<h2><span id="kafka">Kafka</span><a href="#kafka" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2016/05/11/kafka/" title="Kafka总结">Kafka总结</a></li>
<li><a href="/www6vHomeHexo/2022/05/15/kafkaProducer/" title="Kafka Producer生产者">Kafka Producer生产者</a></li>
<li><a href="/www6vHomeHexo/2016/06/25/kafkaConsumer/" title="Kafka消费者总结">Kafka消费者总结</a></li>
<li><a href="/www6vHomeHexo/2022/05/11/kafkaRebalance/" title="Kafka消费者-Rebalance机制">Kafka消费者-Rebalance机制</a></li>
<li><a href="/www6vHomeHexo/2016/07/05/kafkaReliability/" title="Kafka 可靠性总结">Kafka 可靠性总结</a></li>
<li><a href="/www6vHomeHexo/2021/05/15/kafkaIndex/" title="Kafka 索引">Kafka 索引</a>   #1</li>
<li><a href="/www6vHomeHexo/2021/05/16/kafkaZeroCopy/" title="Kafka-ZeroCopy">Kafka-ZeroCopy</a> </li>
<li><a href="/www6vHomeHexo/2021/05/16/kafkaController/" title="Kafka Controller-控制器">Kafka Controller-控制器</a></li>
<li><a href="/www6vHomeHexo/2021/05/16/kafkaReplica/" title="Kafka Replication-副本机制">Kafka Replication-副本机制</a></li>
<li><a href="/www6vHomeHexo/2021/05/16/kafkaElection/" title="Kafka 中的选主">Kafka 中的选主</a></li>
<li><a href="/www6vHomeHexo/2019/05/15/kafkaQ-A/" title="Kafka  Q&amp;A">Kafka  Q&amp;A</a></li>
<li><a href="/www6vHomeHexo/2022/05/04/kafkaTransaction/" title="Kafka 幂等性和事务">Kafka 幂等性和事务</a>  #2</li>
</ul>
<h2><span id="rocketmq">RocketMQ</span><a href="#rocketmq" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/06/18/mqRocketmq/" title="RocketMQ总结">RocketMQ总结</a>  </li>
<li><a href="/www6vHomeHexo/2020/08/12/mqRocketmqTransaction/" title="Rocketmq中的事务">Rocketmq中的事务</a>   #2 </li>
<li><a href="/www6vHomeHexo/2023/02/26/mqRocketmqStorage/" title="RocketMQ 文件系统">RocketMQ 文件系统</a>  #1</li>
</ul>
<h2><span id="pulsar">Pulsar</span><a href="#pulsar" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/05/31/mqPulsar/" title="Pulsar">Pulsar</a>  </li>
<li><a href="/www6vHomeHexo/2022/06/18/mqPulsarSync/" title="Pulsar-数据同步">Pulsar-数据同步</a>  </li>
<li><a href="/www6vHomeHexo/2022/06/10/mqComparePulsarVsKafka/" title="Pulsar vs. Kafka">Pulsar vs. Kafka</a></li>
</ul>
<h2><span id="resource">Resource</span><a href="#resource" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2021/05/19/mqStudy/" title="MQ 学习资料&amp;案例">MQ 学习资料&amp;案例</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>关系型数据库 汇总</title>
    <url>/www6vHomeHexo/2021/02/09/rmdbSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="单机">单机</span><a href="#单机" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2020/08/14/mysqlTransactionAndLock/" title="MySQL 事务-隔离性">MySQL 事务-隔离性</a></li>
<li><a href="/www6vHomeHexo/2020/06/26/mysqlUpdate/" title="MySQL中的SQL更新语句">MySQL中的SQL更新语句</a></li>
<li><a href="/www6vHomeHexo/2020/06/21/mysqlReliability/" title="MySQL的主从 高可用 容灾">MySQL的主从 高可用 容灾</a></li>
<li><a href="/www6vHomeHexo/2019/09/10/mysqlIndex/" title="MySQL的索引和优化">MySQL的索引和优化</a></li>
<li><a href="/www6vHomeHexo/2015/02/21/mysqlTransaction/" title="MySQL事务-总结">MySQL事务-总结</a>   </li>
<li><a href="/www6vHomeHexo/2022/02/27/mysqlLog/" title="MySQL Logs">MySQL Logs</a>   </li>
<li><a href="/www6vHomeHexo/2023/08/15/mysqlDeadLock/" title="MySQL  锁和死锁">MySQL  锁和死锁</a>  </li>
<li><a href="/www6vHomeHexo/2022/08/16/mysqlMasterSlaveDelay/" title="MySQL 主从延迟">MySQL 主从延迟</a></li>
</ul>
<h2><span id="分布式">分布式</span><a href="#分布式" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/02/09/distributedDatabase/" title="分布式 数据库 总结">分布式 数据库 总结</a>
</li>
<li><a href="/www6vHomeHexo/2022/03/11/distributedDatabaseCompare/" title="分布式 数据库 比较">分布式 数据库 比较</a>
</li>
<li><a href="/www6vHomeHexo/2023/04/10/tikvMVCCTransaction/" title="TiKV Transaction-MVCC+TSO">TiKV Transaction-MVCC+TSO</a>
</li>
<li><a href="/www6vHomeHexo/2022/04/11/distributedDatabaseGlobalTime/" title="分布式数据库-全局时钟">分布式数据库-全局时钟</a>  
</li>
<li><a href="/www6vHomeHexo/2021/05/30/distributedDatabaseJoinQuery/" title="数据库  关联查询">数据库  关联查询</a>
</li>
<li><a href="/www6vHomeHexo/2023/06/05/globalSecondaryIndex/" title="全局二级索引-GSI">全局二级索引-GSI</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>关系型数据库</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis+缓存 汇总</title>
    <url>/www6vHomeHexo/2021/02/07/nosqlRedisSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#redis-%E5%9F%BA%E7%A1%80">Redis 基础</a><ul>
<li><a href="#overviw">overviw</a></li>
<li><a href="#arch-redis-cluster">Arch &amp; Redis Cluster</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B">数据类型</a></li>
<li><a href="#%E4%BA%8B%E5%8A%A1">事务</a></li>
<li><a href="#%E6%8C%81%E4%B9%85%E5%8C%96">持久化</a></li>
<li><a href="#%E8%B5%84%E6%BA%90%E5%9B%9E%E6%94%B6">资源回收</a></li>
<li><a href="#%E5%85%B6%E4%BB%96">其他</a></li>
</ul>
</li>
<li><a href="#redis-%E6%95%85%E9%9A%9C%E4%BC%98%E5%8C%96">Redis 故障&amp;优化</a></li>
<li><a href="#redis-%E5%BA%94%E7%94%A8">Redis 应用</a></li>
<li><a href="#redis-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90">Redis 学习资源</a></li>
<li><a href="#%E7%BC%93%E5%AD%98">缓存</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="redis-基础">Redis 基础</span><a href="#redis-基础" class="header-anchor">#</a></h1><h3><span id="overviw">overviw</span><a href="#overviw" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2016/11/12/redis/" title="Redis 总结">Redis 总结</a></li>
<li><a href="/www6vHomeHexo/2022/01/18/redisIO/" title="Redis 的IO模型">Redis 的IO模型</a></li>
</ul>
<h3><span id="arch-amp-redis-cluster">Arch &amp; Redis Cluster</span><a href="#arch-amp-redis-cluster" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2021/05/25/redisArch/" title="Redis 架构">Redis 架构</a></li>
<li><a href="/www6vHomeHexo/2022/03/28/redisError/" title="Redis Error-MOVED和ASK指令">Redis Error-MOVED和ASK指令</a></li>
<li><a href="/www6vHomeHexo/2022/07/11/redisCluster/" title="Redis Cluster">Redis Cluster</a>    </li>
<li><a href="/www6vHomeHexo/2022/07/11/redisClusterSpec/" title="Redis Cluster Spec">Redis Cluster Spec</a>  </li>
<li><a href="/www6vHomeHexo/2022/07/31/redisHA/" title="Redis 集群  容灾（同城多活）">Redis 集群  容灾（同城多活）</a></li>
</ul>
<h3><span id="数据类型">数据类型</span><a href="#数据类型" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2021/06/20/redisRehash/" title="Redis Rehash机制">Redis Rehash机制</a></li>
<li><a href="/www6vHomeHexo/2021/05/05/redisDataStructure/" title="Redis数据结构">Redis数据结构</a></li>
</ul>
<h3><span id="事务">事务</span><a href="#事务" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/01/18/redisTransaction/" title="Redis 事务">Redis 事务</a></li>
</ul>
<h3><span id="持久化">持久化</span><a href="#持久化" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2021/01/02/redisRDB/" title="Redis RDB">Redis RDB</a></li>
<li><a href="/www6vHomeHexo/2021/12/08/rdb/" title="Redis RDB源码">Redis RDB源码</a></li>
<li><a href="/www6vHomeHexo/2022/01/18/redisAOF/" title="Redis AOF">Redis AOF</a></li>
<li><a href="/www6vHomeHexo/2021/11/21/aofRewrite/" title="Redis AOF Rewrite">Redis AOF Rewrite</a></li>
<li><a href="/www6vHomeHexo/2023/07/10/redisBothAofAndRDB/" title="Redis 混合持久化">Redis 混合持久化</a></li>
<li><a href="/www6vHomeHexo/2022/07/10/redisReplica/" title="Redis 主从复制">Redis 主从复制</a></li>
</ul>
<h3><span id="资源回收">资源回收</span><a href="#资源回收" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/06/01/redisLazyFree/" title="Redis LazyFree">Redis LazyFree</a></li>
<li><a href="/www6vHomeHexo/2021/06/02/redisDelete/" title="Redis 回收策略">Redis 回收策略</a></li>
<li><a href="/www6vHomeHexo/2022/07/16/redisLRU/" title="Redis LRU算法">Redis LRU算法</a></li>
</ul>
<h3><span id="其他">其他</span><a href="#其他" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/05/14/redisNVM/" title="Redis NVM">Redis NVM</a></li>
</ul>
<h1><span id="redis-故障amp优化">Redis 故障&amp;优化</span><a href="#redis-故障amp优化" class="header-anchor">#</a></h1><ul>
<li><p>常见问题</p>
<ul>
<li><a href="/www6vHomeHexo/2021/05/21/redisBigKey/" title="Redis 大Key">Redis 大Key</a> </li>
<li><a href="/www6vHomeHexo/2021/05/24/redisOptimize/" title="Redis 优化建议">Redis 优化建议</a></li>
<li><a href="/www6vHomeHexo/2022/03/28/redisReliability-1/" title="Redis雪崩、击穿、穿透">Redis雪崩、击穿、穿透</a></li>
<li><a href="/www6vHomeHexo/2022/02/21/redisDbConsistent/" title="Redis和数据库之间的一致性">Redis和数据库之间的一致性</a></li>
<li><a href="/www6vHomeHexo/2022/03/25/redisSlowResponse/" title="Redis 慢查询排查">Redis 慢查询排查</a> </li>
<li><a href="/www6vHomeHexo/2022/06/03/redisHotkey/" title="Redis 热点Hotkey">Redis 热点Hotkey</a></li>
<li><a href="/www6vHomeHexo/2022/07/31/redisHitRate/" title="Redis  命中率">Redis  命中率</a></li>
</ul>
</li>
<li><a href="/www6vHomeHexo/2022/05/23/redisNodeId/" title="Redis 集群扩容时NodeId问题">Redis 集群扩容时NodeId问题</a></li>
</ul>
<h1><span id="redis-应用">Redis 应用</span><a href="#redis-应用" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2021/06/29/redisUseCase/" title="Redis 使用场景UseCase">Redis 使用场景UseCase</a></li>
<li><a href="/www6vHomeHexo/2022/05/05/redisDistKey/" title="Redis 分布式锁">Redis 分布式锁</a></li>
<li><a href="/www6vHomeHexo/2022/04/27/redisSLO/" title="Redis SLO">Redis SLO</a></li>
</ul>
<h1><span id="redis-学习资源">Redis 学习资源</span><a href="#redis-学习资源" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2021/05/24/redisStudy/" title="Redis 学习资源">Redis 学习资源</a></li>
</ul>
<h1><span id="缓存">缓存</span><a href="#缓存" class="header-anchor">#</a></h1><ul>
<li><a href="/www6vHomeHexo/2021/05/25/cacheConsistent/" title="缓存 一致性">缓存 一致性</a></li>
<li><a href="/www6vHomeHexo/2019/05/25/cacheMultiLayer/" title="多级缓存(cache)">多级缓存(cache)</a></li>
<li><a href="/www6vHomeHexo/2018/01/21/cacheSummary/" title="缓存(cache)总结">缓存(cache)总结</a></li>
<li><a href="/www6vHomeHexo/2017/12/07/cache/" title="缓存(cache)机制">缓存(cache)机制</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>可观察性  汇总</title>
    <url>/www6vHomeHexo/2020/07/17/observabilitySummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h3><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2019/08/31/observability/" title="可观测性 总结">可观测性 总结</a></li>
<li><a href="/www6vHomeHexo/2022/08/04/observabilityBuilding/" title="可观测性-系统构建">可观测性-系统构建</a></li>
</ul>
<h3><span id="统一模型">统一模型</span><a href="#统一模型" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/01/29/observabilityOpenTelemetry/" title="可观测性-OpenTelemetry">可观测性-OpenTelemetry</a></li>
</ul>
<h3><span id="tracing">Tracing</span><a href="#tracing" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2023/01/28/observabilityTracing/" title="可观测性-Tracing">可观测性-Tracing</a></li>
<li><a href="/www6vHomeHexo/2022/03/18/observabilitySkywalking/" title="可观测性-Skywalking">可观测性-Skywalking</a></li>
</ul>
<h3><span id="metric">Metric</span><a href="#metric" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/04/10/observabilityPrometheus/" title="可观测性-Prometheus">可观测性-Prometheus</a></li>
<li><a href="/www6vHomeHexo/2022/02/11/observabilityPrometheusHA/" title="可观测性-Prometheus  HA">可观测性-Prometheus  HA</a></li>
<li><a href="/www6vHomeHexo/2022/07/17/observabilityPrometheusBiz/" title="可观测性-Prometheus业务监控">可观测性-Prometheus业务监控</a></li>
</ul>
<h3><span id="log">Log</span><a href="#log" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2023/01/28/observabilityLog/" title="可观测性-Log">可观测性-Log</a></li>
</ul>
<h3><span id="k8s">K8s</span><a href="#k8s" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/01/30/k8sObservability/" title="可观测性-Kubernetes">可观测性-Kubernetes</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>可观察性</category>
      </categories>
      <tags>
        <tag>可观察性</tag>
      </tags>
  </entry>
  <entry>
    <title>LSM-Tree 汇总</title>
    <url>/www6vHomeHexo/2020/04/06/lsmTreeSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="lsm-tree-存储引擎">LSM-Tree 存储引擎</span><a href="#lsm-tree-存储引擎" class="header-anchor">#</a></h2><h3><span id="原理">原理</span><a href="#原理" class="header-anchor">#</a></h3><ul>
<li>paperlsmTreeSurvey  todo</li>
<li><a href="/www6vHomeHexo/2022/06/05/lsmTreeKeyValueSeparation/" title="LSM-Tree  KV分离">LSM-Tree  KV分离</a>   优化</li>
<li><a href="/www6vHomeHexo/2022/01/08/lsmTreeCompaction/" title="LSM-Tree Compaction压缩策略">LSM-Tree Compaction压缩策略</a>   优化</li>
</ul>
<h3><span id="工程">工程</span><a href="#工程" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2023/04/02/hbaselsmTree/" title="HBase - LSM-Tree">HBase - LSM-Tree</a> </li>
<li><a href="/www6vHomeHexo/2022/01/29/rocksdb/" title="RocksDB 总结">RocksDB 总结</a> </li>
<li><a href="/www6vHomeHexo/2022/04/05/rocksdbLsm/" title="RocksDB- LSM-Tree">RocksDB- LSM-Tree</a>  </li>
<li><a href="/www6vHomeHexo/2023/04/06/rocksdbSST/" title="Rocksdb-SST">Rocksdb-SST</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>LSM-Tree</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统 Handbook</title>
    <url>/www6vHomeHexo/2019/10/23/distributedSystemHandbook/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<p><a href="https://www6v.github.io/www6vBook/">分布式系统 Handbook</a>  Wang Wei(www6v)</p>
]]></content>
      <categories>
        <category>汇总</category>
        <category>handbook</category>
      </categories>
      <tags>
        <tag>handbook</tag>
      </tags>
  </entry>
  <entry>
    <title>性能和优化 汇总</title>
    <url>/www6vHomeHexo/2019/09/22/performanceOptimizeSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="总结">总结</span><a href="#总结" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2018/11/21/performance/" title="性能优化总结">性能优化总结</a>  ***</li>
<li><a href="/www6vHomeHexo/2022/06/16/performanceAnalysis/" title="性能分析">性能分析</a></li>
<li><a href="/www6vHomeHexo/2022/06/15/performanceTest/" title="性能测试">性能测试</a></li>
</ul>
<h2><span id="linux">Linux</span><a href="#linux" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/08/08/linuxPerformance/" title="Linux性能优化">Linux性能优化</a>   cpu， memory， io</li>
<li><a href="/www6vHomeHexo/2018/12/26/linuxProfile/" title="Linux性能分析">Linux性能分析</a>   method and tools</li>
<li><a href="/www6vHomeHexo/2020/08/16/linuxPerformance-cpu/" title="Linux性能优化 之 cpu优化">Linux性能优化 之 cpu优化</a>  ***</li>
<li><a href="/www6vHomeHexo/2020/08/16/linuxKernelParam/" title="虚拟机和容器中的内核参数 kernel">虚拟机和容器中的内核参数 kernel</a></li>
<li><a href="/www6vHomeHexo/2022/01/25/linuxDPDK/" title="DPDK">DPDK</a></li>
</ul>
<h2><span id="网络-net">网络 Net</span><a href="#网络-net" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2020/08/09/tcpTimewait/" title="TIME_WAIT和优化">TIME_WAIT和优化</a>  *** </li>
<li><a href="/www6vHomeHexo/2019/08/07/tcpUdpControlCongestion/" title="TCP流控和拥塞控制">TCP流控和拥塞控制</a></li>
</ul>
<h2><span id="java和应用">Java和应用</span><a href="#java和应用" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2017/11/27/optimize/" title="JVM性能调优">JVM性能调优</a>  内存 *** </li>
<li><a href="/www6vHomeHexo/2015/12/05/async/" title="异步化 总结">异步化 总结</a>  ***</li>
<li><a href="/www6vHomeHexo/2014/07/02/threadNum/" title="线程池最佳线程数">线程池最佳线程数</a>  线程  ***</li>
<li><a href="/www6vHomeHexo/2017/12/07/cache/" title="缓存(cache)机制">缓存(cache)机制</a>  内存</li>
<li><a href="/www6vHomeHexo/2014/03/05/falseSharing/" title="伪共享 FalseSharing">伪共享 FalseSharing</a>  内存</li>
<li><a href="/www6vHomeHexo/2022/07/14/performancePool/" title="性能优化-池化Pool">性能优化-池化Pool</a></li>
</ul>
<h2><span id="mysql">MySQL</span><a href="#mysql" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2019/09/10/mysqlIndex/" title="MySQL的索引和优化">MySQL的索引和优化</a>  ***</li>
<li><a href="/www6vHomeHexo/2020/06/21/mysqlBestPractice/" title="使用MySQL的性能问题和紧急处理手段">使用MySQL的性能问题和紧急处理手段</a>  ***</li>
</ul>
<h2><span id="spark">Spark</span><a href="#spark" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/05/19/streamingSparkPerformance/" title="Spark 性能优化">Spark 性能优化</a>   ***</li>
<li><a href="/www6vHomeHexo/2019/03/10/streamingSparkTrain/" title="Spark公司内部培训">Spark公司内部培训</a></li>
</ul>
<h2><span id="中间件">中间件</span><a href="#中间件" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2021/05/24/redisOptimize/" title="Redis 优化建议">Redis 优化建议</a></li>
<li><a href="/www6vHomeHexo/2021/05/16/kafkaZeroCopy/" title="Kafka-ZeroCopy">Kafka-ZeroCopy</a></li>
<li><a href="/www6vHomeHexo/2020/03/26/nginxOptimize/" title="Nginx优化">Nginx优化</a></li>
</ul>
<h2><span id="serverless">Serverless</span><a href="#serverless" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/06/03/serverlessOptimize/" title="Serverless 优化">Serverless 优化</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>性能</category>
      </categories>
      <tags>
        <tag>性能</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title>稳定性 汇总</title>
    <url>/www6vHomeHexo/2019/09/22/stableSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a><ul>
<li><a href="#%E7%A8%B3%E5%AE%9A%E6%80%A7">稳定性</a></li>
<li><a href="#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84">系统架构</a></li>
</ul>
</li>
<li><a href="#sre">SRE</a><ul>
<li><a href="#sre-1">SRE</a></li>
<li><a href="#%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B">故障模型</a></li>
<li><a href="#%E5%AE%B9%E9%87%8F%E4%BF%9D%E9%9A%9C">容量保障</a></li>
<li><a href="#%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B">混沌工程</a></li>
<li><a href="#%E5%8F%AF%E8%A7%82%E6%B5%8B">可观测</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="总结">总结</span><a href="#总结" class="header-anchor">#</a></h1><h3><span id="稳定性">稳定性</span><a href="#稳定性" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2017/05/09/stability/" title="稳定性总结">稳定性总结</a></li>
</ul>
<h3><span id="系统架构">系统架构</span><a href="#系统架构" class="header-anchor">#</a></h3><ul>
<li><a href="../../../../categories/%E6%9E%B6%E6%9E%84/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/">系统架构</a>  category<ul>
<li><a href="/www6vHomeHexo/2022/06/26/available/" title="高可用 Available">高可用 Available</a> </li>
<li><a href="/www6vHomeHexo/2017/06/17/multiLive/" title="异地多活 总结">异地多活 总结</a></li>
</ul>
</li>
</ul>
<h1><span id="sre">SRE</span><a href="#sre" class="header-anchor">#</a></h1><h3><span id="sre">SRE</span><a href="#sre" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/03/13/sre/" title="SRE 总结">SRE 总结</a>

</li>
<li><a href="/www6vHomeHexo/2023/02/01/sreWorkbook/" title="《SRE 工作手册》">《SRE 工作手册》</a>
<ul>
<li><a href="/www6vHomeHexo/2022/04/27/sreWorkbookBasic/" title="SRE 五大根基">SRE 五大根基</a> </li>
<li><a href="/www6vHomeHexo/2022/05/02/sreWorkbookBasicSLO/" title="SRE 五大根基-SLO">SRE 五大根基-SLO</a> </li>
<li><a href="/www6vHomeHexo/2022/05/02/sreWorkbookBasicAlert/" title="SRE 五大根基-报警">SRE 五大根基-报警</a></li>
</ul>
</li>
</ul>
<h3><span id="故障模型">故障模型</span><a href="#故障模型" class="header-anchor">#</a></h3><p> <a href="../../../../2018/10/27/fault/">故障模型</a></p>
<h3><span id="容量保障">容量保障</span><a href="#容量保障" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/03/13/capacityGuarantee/" title="容量保障与全链路压测">容量保障与全链路压测</a></li>
</ul>
<h3><span id="混沌工程">混沌工程</span><a href="#混沌工程" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2019/09/24/chaosEngineering/" title="混沌工程">混沌工程</a></li>
</ul>
<h3><span id="可观测">可观测</span><a href="#可观测" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2020/07/17/observabilitySummary/" title="可观察性  汇总">可观察性  汇总</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>稳定性</category>
      </categories>
      <tags>
        <tag>稳定性</tag>
      </tags>
  </entry>
  <entry>
    <title>网络/内存/存储 汇总</title>
    <url>/www6vHomeHexo/2019/08/31/brief/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93">网络总结</a><br>- <a href="#linux%E7%BD%91%E7%BB%9C">Linux网络</a><br>- <a href="#%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C-vpc">容器网络、VPC</a><br>- <a href="#%E5%BA%94%E7%94%A8%E5%B1%82">应用层</a></li>
<li><a href="#%E5%86%85%E5%AD%98%E6%80%BB%E7%BB%93">内存总结</a><br>- <a href="#linux">Linux</a><br>- <a href="#%E5%BA%94%E7%94%A8%E5%B1%82-1">应用层</a></li>
<li><a href="#%E6%96%87%E4%BB%B6%E5%92%8C%E5%AD%98%E5%82%A8">文件和存储</a><br>- <a href="#linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F20190824linuxfile">Linux文件系统</a><br>- <a href="#%E5%BA%94%E7%94%A8%E5%B1%82-2">应用层</a></li>
</ul>
<!-- tocstop -->

</div>

<h2><span id="网络总结">网络总结</span><a href="#网络总结" class="header-anchor">#</a></h2><h5><span id="linux网络">Linux网络</span><a href="#linux网络" class="header-anchor">#</a></h5><ul>
<li><a href="../../../../2019/08/19/iptables/">iptables总结</a></li>
<li><a href="../../../../2019/08/07/tcpUdpControlCongestion/">TCP流控和拥塞控制</a></li>
<li><a href="../../../../2015/04/25/tcp/">TCP总结</a></li>
<li><a href="../../../../2019/08/25/linux-socket/">Socket总结</a></li>
</ul>
<h5><span id="容器网络-vpc">容器网络、VPC</span><a href="#容器网络-vpc" class="header-anchor">#</a></h5><ul>
<li><a href="../../../../2019/08/04/docker-network/">Docker网络</a></li>
<li><a href="../../../../2019/08/11/k8sInterface/">Kubernetes开放接口</a>   </li>
<li><a href="../../../../2019/05/15/netConnection/">IDC网络互通</a></li>
</ul>
<h5><span id="应用层">应用层</span><a href="#应用层" class="header-anchor">#</a></h5><ul>
<li><a href="../../../../2015/08/23/nettySummary/">Netty总结</a></li>
<li><a href="../../../../2015/10/03/nettyEpollEventLoop/">Netty EpollEventLoop</a></li>
<li><a href="../../../../2015/09/06/nettyEventLoop-Accept/">Netty中NioEventLoop的accept过程</a></li>
<li><a href="../../../../2019/08/14/https/">HTTPS总结</a></li>
</ul>
<h2><span id="内存总结">内存总结</span><a href="#内存总结" class="header-anchor">#</a></h2><h5><span id="linux">Linux</span><a href="#linux" class="header-anchor">#</a></h5><ul>
<li><a href="../../../../2019/08/23/linuxMemory/">Linux内存管理</a>  </li>
<li><a href="../../../../2019/09/14/zeroCopy/">Linux zero copy</a>   （todo: kafka zero-copy）</li>
</ul>
<h5><span id="应用层">应用层</span><a href="#应用层" class="header-anchor">#</a></h5><ul>
<li><a href="../../../../2014/01/03/memoryModel/">Java内存模型</a></li>
<li>golang内存分配<br><a href="https://mp.weixin.qq.com/s/7bTGxhl7RXBmw5bxaR7Cnw">图解Go语言内存分配</a><br><a href="https://www.infoq.cn/article/IEhRLwmmIM7-11RYaLHR">图解 Go 内存分配器</a></li>
<li><a href="http://arthurchiao.art/blog/memory-models-underlie-programming-languages-zh/">[译] 编程语言中的 6 种内存模型（2016）</a></li>
<li>Redis[todo]</li>
</ul>
<h2><span id="文件和存储">文件和存储</span><a href="#文件和存储" class="header-anchor">#</a></h2><h5><span id="linux文件系统"></span><a href="#linux文件系统" class="header-anchor">#</a></h5><table>
<thead>
<tr>
<th>系统</th>
<th>组件</th>
<th>缓存</th>
</tr>
</thead>
<tbody><tr>
<td>虚拟文件系统</td>
<td>dentry， inode(索引文件)</td>
<td>page cache</td>
</tr>
<tr>
<td>块设备</td>
<td>dev</td>
<td>buffer</td>
</tr>
</tbody></table>
<h5><span id="应用层">应用层</span><a href="#应用层" class="header-anchor">#</a></h5><table>
<thead>
<tr>
<th>总结</th>
<th>知识点</th>
</tr>
</thead>
<tbody><tr>
<td><a href="../../../../2022/01/08/ceph/">Ceph</a></td>
<td>Block, File, Object</td>
</tr>
<tr>
<td><a href="../../../../2017/04/23/fileIO/">文件IO总结</a></td>
<td>mmap，NIO(FileChannel)</td>
</tr>
<tr>
<td><a href="../../../../2016/05/11/kafka/">Kafka总结</a></td>
<td>Partition的Segment中的index文件，data文件</td>
</tr>
<tr>
<td><a href="../../../../2019/06/18/mqRocketmq/">RocketMQ总结</a></td>
<td>CommitLog， ComsumeQueue， 索引文件(todo mmap优化)</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>汇总</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>编程语言Examples 汇总</title>
    <url>/www6vHomeHexo/2019/06/19/languageDemo/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<p><a href="https://github.com/www6v/myExamples.git">myExamples</a></p>
]]></content>
      <categories>
        <category>汇总</category>
        <category>语言</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>高可用+容灾  汇总</title>
    <url>/www6vHomeHexo/2019/04/28/haSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E9%AB%98%E5%8F%AF%E7%94%A8">高可用</a><ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#%E4%B8%AD%E9%97%B4%E4%BB%B6">中间件</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1">数据服务</a></li>
<li><a href="#k8s-%E9%AB%98%E5%8F%AF%E7%94%A8">K8S 高可用</a></li>
</ul>
</li>
<li><a href="#%E5%AE%B9%E7%81%BE%E5%A4%9A%E6%B4%BB">容灾&amp;多活</a><ul>
<li><a href="#%E6%9C%8D%E5%8A%A1%E5%BA%94%E7%94%A8%E5%AE%B9%E7%81%BE">服务&amp;应用容灾</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%AE%B9%E7%81%BE">数据容灾</a></li>
<li><a href="#%E7%8E%AF%E5%A2%83%E5%AE%B9%E7%81%BE">环境容灾</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="高可用">高可用</span><a href="#高可用" class="header-anchor">#</a></h1><h3><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/06/26/available/" title="高可用 Available">高可用 Available</a>
<ul>
<li><a href="/www6vHomeHexo/2017/02/19/splitBrain/" title="Split Brain">Split Brain</a></li>
</ul>
</li>
<li><a href="/www6vHomeHexo/2022/01/25/tencentTCP3/" title="腾讯云TCP3-构建腾讯云上高可用架构">腾讯云TCP3-构建腾讯云上高可用架构</a></li>
</ul>
<h3><span id="中间件">中间件</span><a href="#中间件" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2016/07/05/kafkaReliability/" title="Kafka 可靠性总结">Kafka 可靠性总结</a></li>
<li><a href="/www6vHomeHexo/2021/05/16/kafkaElection/" title="Kafka 中的选主">Kafka 中的选主</a></li>
<li><a href="/www6vHomeHexo/2021/05/16/kafkaController/" title="Kafka Controller-控制器">Kafka Controller-控制器</a></li>
</ul>
<h3><span id="数据服务">数据服务</span><a href="#数据服务" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2020/06/21/mysqlReliability/" title="MySQL的主从 高可用 容灾">MySQL的主从 高可用 容灾</a></li>
<li>dbTradeoff</li>
</ul>
<h3><span id="k8s-高可用">K8S  高可用</span><a href="#k8s-高可用" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/01/02/k8sHA/" title="K8S高可用-控制面">K8S高可用-控制面</a></li>
<li><a href="/www6vHomeHexo/2022/04/05/k8sAvailable/" title="K8S高可用-零停机[自主中断]">K8S高可用-零停机[自主中断]</a></li>
</ul>
<h1><span id="容灾amp多活">容灾&amp;多活</span><a href="#容灾amp多活" class="header-anchor">#</a></h1><h3><span id="服务amp应用容灾">服务&amp;应用容灾</span><a href="#服务amp应用容灾" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2017/06/17/multiLive/" title="异地多活 总结">异地多活 总结</a> </li>
<li><a href="/www6vHomeHexo/2019/07/20/istio-k8s-service/" title="Istio、Kubernetes和Spring Cloud中服务的比对">Istio、Kubernetes和Spring Cloud中服务的比对</a></li>
</ul>
<h3><span id="数据容灾">数据容灾</span><a href="#数据容灾" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/07/13/aliyunDB/" title="阿里云 数据库">阿里云 数据库</a> </li>
<li><a href="/www6vHomeHexo/2022/07/31/redisHA/" title="Redis 集群  容灾（同城多活）">Redis 集群  容灾（同城多活）</a></li>
</ul>
<h3><span id="环境容灾">环境容灾</span><a href="#环境容灾" class="header-anchor">#</a></h3><ul>
<li><a href="/www6vHomeHexo/2022/06/26/aliyunDisasterRecovery/" title="阿里云-容灾恢复DR">阿里云-容灾恢复DR</a></li>
<li><a href="/www6vHomeHexo/2022/01/04/aliyunHybridCloud/" title="阿里云-混合云HybridCloud">阿里云-混合云HybridCloud</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>HA</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>安全 汇总</title>
    <url>/www6vHomeHexo/2019/03/12/securitySummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="网络安全">网络安全</span><a href="#网络安全" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/10/23/cyberSecurity/" title="网络空间安全-Cyber Security">网络空间安全-Cyber Security</a></li>
<li><a href="/www6vHomeHexo/2022/03/12/cyberSecurityTool/" title="安全产品">安全产品</a></li>
<li><a href="/www6vHomeHexo/2020/03/20/securityOAuth2/" title="安全-OAuth2">安全-OAuth2</a></li>
</ul>
<h2><span id="云计算安全">云计算安全</span><a href="#云计算安全" class="header-anchor">#</a></h2><ul>
<li><a href="../../../../2022/10/01/awsSecurity">aws 安全</a></li>
<li><a href="/www6vHomeHexo/2022/01/11/tencentTCP5/" title="腾讯云TCP5-云上信息安全">腾讯云TCP5-云上信息安全</a></li>
</ul>
<h2><span id="容器安全">容器安全</span><a href="#容器安全" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeHexo/2022/05/22/k8sSecurity/" title="Kubernetes安全-Security">Kubernetes安全-Security</a></li>
<li><a href="/www6vHomeHexo/2022/01/15/k8sCKS/" title="Kubernetes CKS">Kubernetes CKS</a></li>
<li><a href="/www6vHomeHexo/2022/01/16/k8sSecurityPractice/" title="Kubernetes 安全实践">Kubernetes 安全实践</a></li>
</ul>
]]></content>
      <categories>
        <category>汇总</category>
        <category>安全</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>学习资源-汇总</title>
    <url>/www6vHomeHexo/2018/12/04/studyResouceSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="comprehensive">Comprehensive</span><a href="#comprehensive" class="header-anchor">#</a></h2><p><a href="../../../../2022/01/27/categoryOfGithub/">github资源分类</a> ***<br><a href="../../../../2022/11/30/paperStudy/">Paper 学习资源</a></p>
<h2><span id="dev">Dev</span><a href="#dev" class="header-anchor">#</a></h2><h5><span id="cloud-native">cloud native</span><a href="#cloud-native" class="header-anchor">#</a></h5><p><a href="../../../../2022/10/01/awsStudyResource/">AWS 学习资源</a><br><a href="../../../../2022/05/21/k8sStudy/">Kubernetes 学习资源</a><br><a href="../../../../2020/06/14/cloudNativeResource/">云原生-学习资源</a></p>
<h5><span id="distributed">distributed</span><a href="#distributed" class="header-anchor">#</a></h5><p><a href="../../../../2022/06/25/devopsStudyResource/">Devops 学习资源</a><br><a href="../../../../2022/05/30/linuxStudy/">Linux-学习资源</a><br><a href="../../../../2019/10/13/distributedStudy/">分布式系统学习资源-个人</a><br><a href="../../../../2019/01/21/distributedStudyTeam/">分布式系统学习资源-团队</a></p>
<h5><span id="language">language</span><a href="#language" class="header-anchor">#</a></h5><p><a href="../../../../2022/09/09/golangStudy/">Golang 学习资源</a><br><a href="../../../../2022/08/25/languageStudy/">语言 学习资源</a></p>
<h2><span id="data">Data</span><a href="#data" class="header-anchor">#</a></h2><p><a href="../../../../2022/01/22/aiStudyResouce/">人工智能-学习资源</a><br><a href="../../../../2022/05/28/bigDataStudy/">大数据 学习资源</a></p>
<p><a href="../../../../2019/09/10/others/">资料收集</a> *</p>
]]></content>
      <categories>
        <category>汇总</category>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>科研-工具</title>
    <url>/www6vHomeHexo/2024/02/11/gptPaperTools/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="论文管理1">论文管理[1]</span><a href="#论文管理1" class="header-anchor">#</a></h1><ul>
<li><p>Readpaper<br><a href="https://readpaper.com/new">https://readpaper.com/new</a><br>论文在线阅读，论文搜索，管理</p>
</li>
<li><p>Connected Papers 引用关系<br><a href="https://www.connectedpapers.com/">https://www.connectedpapers.com/</a></p>
</li>
<li><p>AI 顶会倒计时<br><a href="https://aideadlin.es/?sub=ML,CV,NLP">https://aideadlin.es/?sub=ML,CV,NLP</a></p>
</li>
<li><p>Aminer<br><a href="https://www.aminer.cn/">https://www.aminer.cn/</a><br>最新的进展如何<br>还有个必读论文系列</p>
</li>
</ul>
<h1><span id="写作1">写作[1]</span><a href="#写作1" class="header-anchor">#</a></h1><ul>
<li><p>DeepL翻译<br>deepl.com&#x2F;translator</p>
</li>
<li><p>overleaf<br>overleaf.com&#x2F;project</p>
</li>
</ul>
<h1><span id="论文元素-1">论文元素 [1]</span><a href="#论文元素-1" class="header-anchor">#</a></h1><ul>
<li><p>quillbot.com&#x2F;<br>改写, 检查语法, 摘要生成</p>
</li>
<li><p>Table generator<br><a href="https://www.tablesgenerator.com/latex_tables">https://www.tablesgenerator.com/latex_tables</a><br>latex表格生成</p>
</li>
<li><p>echarts<br><a href="https://echarts.apache.org/examples/en/index.html#chart-type-bar">https://echarts.apache.org/examples/en/index.html#chart-type-bar</a><br>画图</p>
</li>
<li><p>detexify Latex符号<br><a href="http://detexify.kirelabs.org/classify.html">http://detexify.kirelabs.org/classify.html</a><br>手绘符号转换成latex代码</p>
</li>
<li><p>DBLP<br>dblp.uni-trier.de&#x2F;<br>latex引用</p>
</li>
<li><p>esoda 词组用法示例<br>esoda.org&#x2F;</p>
</li>
<li><p>wikidiff 近义词理解<br><a href="https://wikidiff.com/neglect/omit">https://wikidiff.com/neglect/omit</a></p>
</li>
<li><p>在线latex公式编辑器<br><a href="https://www.latexlive.com/##">https://www.latexlive.com/##</a></p>
</li>
<li><p>mathpix 公式图片转换成latex<br><a href="https://mathpix.com/">https://mathpix.com/</a><br>公式图片识别成latex公式</p>
</li>
</ul>
<h1><span id="aigc-文档分析amp科研">AIGC 文档分析&amp;科研</span><a href="#aigc-文档分析amp科研" class="header-anchor">#</a></h1><ul>
<li><p>在线文档分析<br>Microsoft Edge Dev + new Bing  ***</p>
</li>
<li><p>文献查找 + 润色<br>Skype + new Bing  ***</p>
</li>
<li><p>本地文档分析</p>
<ul>
<li><p>VPN</p>
<ul>
<li>chatpdf  收费  ***<br><a href="https://www.chatpdf.com/">Chat with any PDF</a> 总结文献</li>
<li><a href="https://chatdoc.com/">Chat with documents</a></li>
</ul>
</li>
<li><p>非VPN</p>
<ul>
<li><a href="https://chatpaper.org/">ChatPaper</a>  Paper 中文<br><a href="https://github.com/kaixindelele/ChatPaper">ChatPaper</a> git</li>
<li><a href="https://chat2doc.cn/">阅读文档的好帮手</a>  收费</li>
<li><a href="https://lightpdf.com/chatdoc">LightPDF AI Tools</a> *** </li>
<li><a href="https://docalysis.com/files/hwylw4">docalysis</a> ***</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="newbing-chat-2">NewBing chat [2]</span><a href="#newbing-chat-2" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2024/02/11/gptPaperTools/newBing.jpg" class>

<h3><span id="学术prompt">学术Prompt</span><a href="#学术prompt" class="header-anchor">#</a></h3><ul>
<li>在线文献全文分析 [new Bing] <ul>
<li>帮我总结一下这篇文章的<strong>要点</strong></li>
<li>帮我正对本研究论文写一篇<strong>总结报告</strong>， 600字</li>
<li>帮我总结本研究的讨论部分 采用了哪种<strong>写作框架</strong>， 是否进行了与其它研究的对比，有无表明本研究的<strong>局限性</strong>和<strong>未来研究可能性</strong>?</li>
<li>帮我总结本研究的方法部分用了哪些<strong>研究方法</strong>？</li>
<li>本研究方法部分的Western Blot是如何实施的？</li>
<li>总结下本论文Introduction部分在写作方面，有哪些<strong>词汇和句式</strong>值得在SCI论文写作中积累借鉴</li>
</ul>
</li>
</ul>
<h1><span id="tools">Tools</span><a href="#tools" class="header-anchor">#</a></h1><ul>
<li><a href="https://app.seaml.es/">Seamless for science</a> bibi1<br>abstract</li>
<li><a href="https://typeset.io/">scispace</a>  bibi1<br>润色 判重</li>
<li><a href="https://www.txyz.ai/">txyz</a></li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/661767969">工欲善科研，必先利其器</a></li>
<li><a href="https://www.bilibili.com/video/BV18M4y1C7HY/">整合chatGPT的新必应（NewBing chat）简直就是科研神器！</a></li>
</ol>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>法律大模型</title>
    <url>/www6vHomeHexo/2024/02/07/gptDomainLaw/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h3><span id="法律大模型">法律大模型</span><a href="#法律大模型" class="header-anchor">#</a></h3><ul>
<li>ChatLaw </li>
<li>LawGPT_zh</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402872&idx=1&sn=0649e8f7490e057680cff1be16157209">再看法律领域微调模型及外挂知识库问答优化方案：从引入关键词、领域嵌入到知识库细化、意图识别及知识增强项目案例 </a></p>
<p>1xx. <a href="https://finisky.github.io/lawyer-llama-summary/">训练中文垂类大模型：Lawyer LLaMA </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>垂类大模型</category>
      </categories>
      <tags>
        <tag>垂类大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>混合精度</title>
    <url>/www6vHomeHexo/2024/02/01/gptPrecision/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E4%BD%BF%E7%94%A8%E7%9A%84%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E5%8E%9F%E5%9B%A0">使用的混合精度原因</a></li>
<li><a href="#%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">混合精度解决方案</a><ul>
<li><a href="#fp32-%E6%9D%83%E9%87%8D%E5%A4%87%E4%BB%BD-12">FP32 权重备份 [1][2]</a></li>
<li><a href="#loss-scale12">Loss Scale[1][2]</a></li>
</ul>
</li>
<li><a href="#%E5%AE%9E%E6%88%98">实战</a><ul>
<li><a href="#llama%E5%8D%8A%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%8320">llama半精度训练[20]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E5%8E%9F%E7%90%86">原理</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81">代码</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="使用的混合精度原因">使用的混合精度原因</span><a href="#使用的混合精度原因" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2024/02/01/gptPrecision/solution.png" class>

<h1><span id="混合精度解决方案">混合精度解决方案</span><a href="#混合精度解决方案" class="header-anchor">#</a></h1><h3><span id="fp32-权重备份-12">FP32 权重备份 [1][2]</span><a href="#fp32-权重备份-12" class="header-anchor">#</a></h3><p>这种方法主要是用于<strong>解决舍入误差</strong>的问题。</p>
<img src="/www6vHomeHexo/2024/02/01/gptPrecision/weight-backup.jpg" class> 

<h3><span id="loss-scale12">Loss Scale[1][2]</span><a href="#loss-scale12" class="header-anchor">#</a></h3><p>Loss Scale 主要是为了<strong>解决 fp16 underflow</strong>的问题。</p>
<img src="/www6vHomeHexo/2024/02/01/gptPrecision/loss-scale.jpg" class> 


<h1><span id="实战">实战</span><a href="#实战" class="header-anchor">#</a></h1><h3><span id="llama半精度训练20">llama半精度训练[20]</span><a href="#llama半精度训练20" class="header-anchor">#</a></h3><ul>
<li>现象<br>loss先变大，再为0<br>loss爆炸，loss消失</li>
<li>解决方案<br>padding&#x3D;left<br>改为padding&#x3D;right</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="原理">原理</span><a href="#原理" class="header-anchor">#</a></h3><ol>
<li><a href="https://www.bilibili.com/video/BV1R94y1g78L?p=6">混合精度</a>  *** V</li>
<li><a href="https://zhuanlan.zhihu.com/p/103685761">浅谈混合精度训练</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/441591808">全网最全-混合精度训练原理</a>  ***<br>1xx. <a href="https://zhuanlan.zhihu.com/p/608634079">【深度学习】混合精度训练与显存分析</a></li>
</ol>
<h3><span id="代码">代码</span><a href="#代码" class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://www.bilibili.com/video/BV1CB4y1R78v/">半精度训练与LLaMA2训练实战</a> 有代码<br>1xx. <a href="https://www.bilibili.com/video/BV1y34y1M7t1/">低精度训练与大模型下载</a> 有代码<br>1xx. <a href="https://zhuanlan.zhihu.com/p/165152789">PyTorch的自动混合精度（AMP）</a><br>1xx. <a href="https://tensorflow.google.cn/guide/mixed_precision?hl=zh-cn">混合精度</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Precision</category>
      </categories>
      <tags>
        <tag>Precision</tag>
      </tags>
  </entry>
  <entry>
    <title>PEFT P-Tuning</title>
    <url>/www6vHomeHexo/2024/01/28/gptPEFTPtuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h3><span id="最佳实践1">最佳实践[1]</span><a href="#最佳实践1" class="header-anchor">#</a></h3><ul>
<li>要看losss, 也要看业务的loss</li>
<li>生成模型常用的评价方法<ul>
<li>BLEU 能评估流畅度</li>
<li>结果都是流畅的前提下，ROUGE 反应参照句中多少内容被生成的句子包含（召回）</li>
</ul>
</li>
<li>垂直模型<ul>
<li>stf之后失去通用能力</li>
<li>要有通用能力, 需要pre-train和STF中都融入通用的语料</li>
</ul>
</li>
<li>每个模型的学习率lr不一样<ul>
<li>chatglm的学习率<br>LR&#x3D;2e-2</li>
</ul>
</li>
</ul>
<h3><span id="学习率">学习率</span><a href="#学习率" class="header-anchor">#</a></h3><ul>
<li>改的特别大<br>模型训练的时候会震荡</li>
<li>改的特别小<br> 模型训练的时候会收敛非常慢</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://github.com/www6v/fine-tuning-lab/blob/agiclass-v1/chatglm/train_pt2.sh">train_pt2.sh</a> git   基于法律文本的chatglm的p-tuning<br><a href="https://github.com/www6v/fine-tuning-lab/blob/agiclass-v1/chatglm2/train_pt2.sh">train_pt2.sh</a> git   基于法律文本的chatglm-2的P-tuning v2<br><a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/peft/index.ipynb">十一、小参数量微调</a><br>bili有相关的总结的视频</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>Fine Tuning-Bert</title>
    <url>/www6vHomeHexo/2024/01/26/gptFineTuningBert/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="基于bert的二分类">基于bert的二分类</span><a href="#基于bert的二分类" class="header-anchor">#</a></h1><ul>
<li>代码 - 全参FT,非PEFT<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_metric</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer</span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorWithPadding</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">SEED=<span class="number">42</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ALBERT是一种压缩过的BERT</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;albert-base-v2&quot;</span></span><br><span class="line">DATASET_NAME = <span class="string">&quot;glue&quot;</span> <span class="comment"># 一组NLP评测任务</span></span><br><span class="line">DATASET_TASK = <span class="string">&quot;mrpc&quot;</span> <span class="comment"># MRPC 是其中一个子任务 -- Microsoft Research Paraphrase Corpus</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在Bert的基础上加了一个线性分类器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyClassifier</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, backbone</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.bert_encoder = backbone</span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">768</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_loss</span>(<span class="params">self, logits, labels</span>):</span><br><span class="line">        loss_fct = nn.CrossEntropyLoss()</span><br><span class="line">        <span class="keyword">return</span> loss_fct(logits, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask,labels=<span class="literal">None</span></span>):</span><br><span class="line">        output = self.bert_encoder(input_ids=input_ids, attention_mask=attention_mask)</span><br><span class="line">        output = output.last_hidden_state[:, <span class="number">0</span>, :]</span><br><span class="line">        output = self.linear(output)</span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = self.compute_loss(output, labels)</span><br><span class="line">            <span class="keyword">return</span> loss, output</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集对应的评估方法</span></span><br><span class="line">glue_metric = datasets.load_metric(DATASET_NAME, DATASET_TASK)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_pred</span>):</span><br><span class="line">    logits, labels = eval_pred</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> glue_metric.compute(predictions=predictions, references=labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">raw_datasets = load_dataset(DATASET_NAME,DATASET_TASK)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集</span></span><br><span class="line">raw_train_dataset = raw_datasets[<span class="string">&quot;train&quot;</span>]</span><br><span class="line"><span class="comment"># 验证集</span></span><br><span class="line">raw_valid_dataset = raw_datasets[<span class="string">&quot;validation&quot;</span>]</span><br><span class="line"></span><br><span class="line">columns = raw_train_dataset.column_names</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机种子</span></span><br><span class="line">transformers.set_seed(SEED)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义tokenizer</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义数据处理函数，把原始数据转成input_ids, attention_mask, labels</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_fn</span>(<span class="params">examples</span>):</span><br><span class="line">    inputs = tokenizer(examples[<span class="string">&quot;sentence1&quot;</span>], examples[<span class="string">&quot;sentence2&quot;</span>], truncation=<span class="literal">True</span>, max_length=<span class="number">128</span>)</span><br><span class="line">    examples[<span class="string">&quot;input_ids&quot;</span>] = inputs[<span class="string">&quot;input_ids&quot;</span>]</span><br><span class="line">    examples[<span class="string">&quot;attention_mask&quot;</span>] = inputs[<span class="string">&quot;attention_mask&quot;</span>]</span><br><span class="line">    examples[<span class="string">&quot;labels&quot;</span>] = examples[<span class="string">&quot;label&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> examples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenized_train_dataset = raw_train_dataset.<span class="built_in">map</span>(</span><br><span class="line">    process_fn,</span><br><span class="line">    batched=<span class="literal">True</span>,</span><br><span class="line">    remove_columns=columns</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tokenized_valid_dataset = raw_valid_dataset.<span class="built_in">map</span>(</span><br><span class="line">    process_fn,</span><br><span class="line">    batched=<span class="literal">True</span>,</span><br><span class="line">    remove_columns=columns</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义数据校准器（自动生成batch）</span></span><br><span class="line">collater = DataCollatorWithPadding(</span><br><span class="line">    tokenizer=tokenizer, return_tensors=<span class="string">&quot;pt&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型 -- 其实Transformer可以直接用AutoModelForSequenceClassification</span></span><br><span class="line"><span class="comment">#model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 我手工写了分类器层，为了方便大家理解什么叫在Transformer上面做分类任务</span></span><br><span class="line">backbone = AutoModel.from_pretrained(MODEL_NAME)</span><br><span class="line">model = MyClassifier(backbone)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练参数</span></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./output&quot;</span>,        <span class="comment"># checkpoint保存路径</span></span><br><span class="line">    evaluation_strategy=<span class="string">&quot;steps&quot;</span>,    <span class="comment"># 每N步做一次eval</span></span><br><span class="line">    overwrite_output_dir=<span class="literal">True</span>,</span><br><span class="line">    num_train_epochs=<span class="number">1</span>,             <span class="comment"># 训练epoch数</span></span><br><span class="line">    per_device_train_batch_size=<span class="number">8</span>,  <span class="comment"># 每张卡的batch大小</span></span><br><span class="line">    gradient_accumulation_steps=<span class="number">4</span>,   <span class="comment"># 累加几个step做一次参数更新</span></span><br><span class="line">    per_device_eval_batch_size=<span class="number">8</span>,  <span class="comment"># evaluation batch size</span></span><br><span class="line">    logging_steps=<span class="number">20</span>,             <span class="comment"># 每20步eval一次</span></span><br><span class="line">    save_steps=<span class="number">20</span>,                <span class="comment"># 每20步保存一个checkpoint</span></span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,             <span class="comment"># 学习率</span></span><br><span class="line">    warmup_ratio=<span class="number">0.1</span>,               <span class="comment"># 预热（可选）</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练器</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model, <span class="comment"># 待训练模型</span></span><br><span class="line">    args=training_args, <span class="comment"># 训练参数</span></span><br><span class="line">    data_collator=collater, <span class="comment"># 数据校准器</span></span><br><span class="line">    train_dataset=tokenized_train_dataset, <span class="comment"># 训练集</span></span><br><span class="line">    eval_dataset=tokenized_valid_dataset, <span class="comment"># 验证集</span></span><br><span class="line">    compute_metrics=compute_metrics, <span class="comment"># 评价指标</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用wandb（与huggingface.co同步的机制）</span></span><br><span class="line">os.environ[<span class="string">&quot;WANDB_DISABLED&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure></li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p><a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/huggingface/index.ipynb">Bert fine-tuning 二分类</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Fine-Tuning</category>
      </categories>
      <tags>
        <tag>Fine-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>PEFT QLoRA 实战</title>
    <url>/www6vHomeHexo/2024/01/12/gptPEFTQLora/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86-1">技术原理 [1]</a></li>
<li><a href="#%E5%AE%9E%E6%88%981-2">实战1 [2]</a></li>
<li><a href="#%E5%AE%9E%E6%88%982-34">实战2 [3][4]</a></li>
<li><a href="#%E5%8F%82%E6%95%B0">参数</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="技术原理-1">技术原理 [1]</span><a href="#技术原理-1" class="header-anchor">#</a></h1><p>使用一种新颖的高精度技术将预训练模型量化为 4 bit，然后添加一小组可学习的低秩适配器权重，这些权重通过量化权重的反向传播梯度进行微调。<br>QLoRA提出了两种技术实现高保真 4 bit微调——4 bit NormalFloat(NF4) 量化和双量化。</p>
<ul>
<li><p>4bit NormalFloat（NF4）：对于正态分布权重而言，一种信息理论上最优的新数据类型，该数据类型对正态分布数据产生比 4 bit整数和 4bit 浮点数更好的实证结果。</p>
</li>
<li><p>双量化：对第一次量化后的那些常量再进行一次量化，减少存储空间。</p>
</li>
<li><p>分页优化器:  使用此功能为优化器状态（Optimizer）分配分页内存，然后在 GPU 内存不足时将其自动卸载到 CPU 内存，并在优化器更新步骤需要时将其加载回 GPU 内存。</p>
</li>
</ul>
<img src="/www6vHomeHexo/2024/01/12/gptPEFTQLora/qlora.png" class>

<p>实验证明，无论是使用16bit、8bit还是4bit的适配器方法，都能够复制16bit全参数微调的基准性能。这说明，尽管量化过程中会存在性能损失，但通过适配器微调，完全可以恢复这些性能。</p>
<h1><span id="实战1-2">实战1 [2]</span><a href="#实战1-2" class="header-anchor">#</a></h1><h1><span id="实战2-34">实战2 [3][4]</span><a href="#实战2-34" class="header-anchor">#</a></h1><ul>
<li><p>Training的模型</p>
<img src="/www6vHomeHexo/2024/01/12/gptPEFTQLora/dirs.png" class>
</li>
<li><p>合并后的模型</p>
<img src="/www6vHomeHexo/2024/01/12/gptPEFTQLora/dir.png" class>
</li>
<li><p>4bit量化推理</p>
<img src="/www6vHomeHexo/2024/01/12/gptPEFTQLora/xtuner-chat.png" class></li>
</ul>
<blockquote>
<p>Training的时候要用tmux</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tmux new -s finetune</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tmux attach -t finetune</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ctcl +b , D</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>16bit量化推理慢,  要用4bit量化推理</p>
</blockquote>
<h1><span id="参数">参数</span><a href="#参数" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/636215898">大模型参数高效微调技术原理综述（五）-LoRA、AdaLoRA、QLoRA</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/636644164">高效微调技术QLoRA实战，基于LLaMA-65B微调仅需48G显存，真香</a><br><a href="https://github.com/www6v/llm-action/tree/main/train/qlora">qlora</a> git</p>
</li>
<li><p><a href="https://github.com/www6v/tutorial/tree/main/xtuner">internLM fine-tuning on xtuner</a>   </p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1yK4y1B75J/">(4)XTuner 大模型单卡低成本微调实战</a> V</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/671089942">[大模型微调技术] LoRA、QLoRA、QA-LoRA 原理笔记</a> 未</p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2375230">大模型实操 | LoRA、QLoRA微调大模型实战技巧分享，含常见QA解答！</a> 未</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s  AdmissionWebhook</title>
    <url>/www6vHomeHexo/2023/10/16/k8sAdmissionWebhook/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="mutatingadmissionwebhook-是如何工作的1chat">MutatingAdmissionWebhook 是如何工作的[1][chat]</span><a href="#mutatingadmissionwebhook-是如何工作的1chat" class="header-anchor">#</a></h2><p><code>MutatingAdmissionWebhook</code>拦截与<code>MutatingWebhookConfiguration</code>中定义的规则匹配的请求，然后将其发送到Webhook服务器进行处理，然后再持久化到<a href="https://github.com/coreos/etcd">etcd</a> 中。 <code>MutatingAdmissionWebhook</code>通过向Webhook服务器发送admission请求来执行变更。Webhook服务器只是遵循<a href="https://github.com/kubernetes/kubernetes/blob/v1.9.0/pkg/apis/admission/types.go">Kubernetes的API</a>  的普通HTTP服务器。</p>
<p>以下图示了<code>MutatingAdmissionWebhook</code>的工作原理:</p>
<img src="/www6vHomeHexo/2023/10/16/k8sAdmissionWebhook/admissionWebhook.jpg" class>


<p><code>MutatingAdmissionWebhook</code>需要三个对象才能正常工作:</p>
<ol>
<li><p><strong>MutatingWebhookConfiguration</strong></p>
<p><code>MutatingAdmissionWebhook</code>需要在<code>apiserver</code>中注册，提供<code>MutatingWebhookConfiguration</code>。在注册过程中，MutatingAdmissionWebhook说明以下内容:</p>
<ul>
<li>如何连接到Webhook Admission服务器</li>
<li>如何验证Webhook Admission服务器</li>
<li>Webhook Admission服务器的URL路径</li>
<li>定义了哪些资源和操作它处理的规则</li>
<li>如何处理来自Webhook Admission服务器的无法识别的错误</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: admissionregistration.k8s.io/v1beta1</span><br><span class="line">kind: MutatingWebhookConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  name: sidecar-injector-webhook-cfg</span><br><span class="line">  labels:</span><br><span class="line">    app: sidecar-injector</span><br><span class="line">webhooks:</span><br><span class="line">  - name: sidecar-injector.morven.me</span><br><span class="line">    clientConfig:</span><br><span class="line">      service:</span><br><span class="line">        name: sidecar-injector-webhook-svc   #2</span><br><span class="line">        namespace: default</span><br><span class="line">        path: &quot;/mutate&quot;</span><br><span class="line">      caBundle: $&#123;CA_BUNDLE&#125;</span><br><span class="line">    rules:</span><br><span class="line">      - operations: [ &quot;CREATE&quot; ]</span><br><span class="line">        apiGroups: [&quot;&quot;]</span><br><span class="line">        apiVersions: [&quot;v1&quot;]</span><br><span class="line">        resources: [&quot;pods&quot;]</span><br><span class="line">    namespaceSelector:</span><br><span class="line">      matchLabels:</span><br><span class="line">        sidecar-injector: enabled</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p><strong>MutatingAdmissionWebhook本身</strong></p>
<p><code>MutatingAdmissionWebhook</code>是一种插件式的Admission控制器，可以配置到<code>apiserver</code>中。<code>MutatingAdmissionWebhook</code>插件从<code>MutatingWebhookConfiguration</code>中获取感兴趣的Admission Webhooks列表。然后，<code>MutatingAdmissionWebhook</code>观察到对apiserver的请求，并拦截与admission webhook规则匹配的请求，并并行地调用它们。</p>
</li>
<li><p><strong>Webhook Admission Server</strong></p>
<p><code>Webhook Admission服务器</code>只是一个符合Kubernetes <a href="https://github.com/kubernetes/kubernetes/blob/v1.9.0/pkg/apis/admission/types.go">API</a>的普通HTTP服务器。对于每个API server的请求，<code>MutatingAdmissionWebhook</code>将admissionReview（用于参考的<a href="https://github.com/kubernetes/kubernetes/blob/v1.9.0/pkg/apis/admission/types.go">API</a>）发送到相关的webhook admission服务器。webhook admission服务器会从admissionReview中收集信息，如<code>object</code>，<code>oldobject</code>和<code>userInfo</code>，然后返回一个admissionReview响应，其中包括填充了admission决策和可选的<code>Patch</code>以改变资源的AdmissionResponse。</p>
</li>
</ol>
<h3><span id="服务部署">服务部署</span><a href="#服务部署" class="header-anchor">#</a></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: sidecar-injector-webhook-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: sidecar-injector</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: sidecar-injector</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: sidecar-injector</span><br><span class="line">          image: morvencao/sidecar-injector:v1</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          args:</span><br><span class="line">            - -sidecarCfgFile=/etc/webhook/config/sidecarconfig.yaml  #1</span><br><span class="line">            - -tlsCertFile=/etc/webhook/certs/cert.pem</span><br><span class="line">            - -tlsKeyFile=/etc/webhook/certs/key.pem</span><br><span class="line">            - -alsologtostderr</span><br><span class="line">            - -v=4</span><br><span class="line">            - 2&gt;&amp;1</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: webhook-certs</span><br><span class="line">              mountPath: /etc/webhook/certs</span><br><span class="line">              readOnly: true</span><br><span class="line">            - name: webhook-config</span><br><span class="line">              mountPath: /etc/webhook/config</span><br><span class="line">      volumes:</span><br><span class="line">        - name: webhook-certs</span><br><span class="line">          secret:</span><br><span class="line">            secretName: sidecar-injector-webhook-certs</span><br><span class="line">        - name: webhook-config</span><br><span class="line">          configMap:</span><br><span class="line">            name: sidecar-injector-webhook-configmap</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: sidecar-injector-webhook-configmap</span><br><span class="line">data:</span><br><span class="line">  sidecarconfig.yaml: |</span><br><span class="line">    containers:</span><br><span class="line">      - name: sidecar-nginx</span><br><span class="line">        image: nginx:1.12.2</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">          - containerPort: 80</span><br><span class="line">        volumeMounts:</span><br><span class="line">          - name: nginx-conf</span><br><span class="line">            mountPath: /etc/nginx</span><br><span class="line">    volumes:</span><br><span class="line">      - name: nginx-conf</span><br><span class="line">        configMap:</span><br><span class="line">          name: nginx-configmap</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: sidecar-injector-webhook-svc  #2</span><br><span class="line">  labels:</span><br><span class="line">    app: sidecar-injector</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 443</span><br><span class="line">    targetPort: 443</span><br><span class="line">  selector:</span><br><span class="line">    app: sidecar-injector</span><br></pre></td></tr></table></figure>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://medium.com/ibm-cloud/diving-into-kubernetes-mutatingadmissionwebhook-6ef3c5695f74">Diving into Kubernetes MutatingAdmissionWebhook</a><br><a href="https://github.com/www6v/kube-sidecar-injector">kube-sidecar-injector</a>  git</li>
</ol>
]]></content>
      <categories>
        <category>云原生</category>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL  锁和死锁</title>
    <url>/www6vHomeHexo/2023/08/15/mysqlDeadLock/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E9%94%81">锁</a><ul>
<li><a href="#%E8%A1%8C%E9%94%81-%E9%94%81%E4%BC%98%E5%8C%96-3">行锁， 锁优化 [3]</a></li>
<li><a href="#%E9%9A%90%E5%BC%8F%E9%94%81%E5%92%8C%E6%98%BE%E7%A4%BA%E9%94%81">隐式锁和显示锁</a></li>
</ul>
</li>
<li><a href="#%E6%AD%BB%E9%94%81">死锁</a><ul>
<li><a href="#%E6%AD%BB%E9%94%81%E5%92%8C%E6%AD%BB%E9%94%81%E6%A3%80%E6%B5%8B-5">死锁和死锁检测 [5]</a></li>
<li><a href="#%E9%A2%84%E9%98%B2%E6%AD%BB%E9%94%81-7">预防死锁 [7]</a></li>
<li><a href="#%E6%AD%BB%E9%94%81%E7%9A%84%E6%8E%92%E6%9F%A5%E5%92%8C%E8%A7%A3%E5%86%B3-7">死锁的排查和解决 [7]</a></li>
</ul>
</li>
<li><a href="#%E6%A1%88%E4%BE%8B">案例</a><ul>
<li><a href="#case-1">Case [1]</a></li>
<li><a href="#%E5%8E%9F%E5%9B%A0">原因</a></li>
<li><a href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">解决方案</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="锁">锁</span><a href="#锁" class="header-anchor">#</a></h1><h3><span id="行锁-锁优化-3">行锁， 锁优化 [3]</span><a href="#行锁-锁优化-3" class="header-anchor">#</a></h3><ul>
<li><p>在InnoDB事务中，<strong>行锁</strong>是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是<strong>两阶段锁协议</strong>。<br>知道了这个设定，对我们使用事务有什么帮助呢？那就是，<strong>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放.</strong>[todo 加个例子]</p>
</li>
<li><p><strong>行锁是通过索引实现的</strong>，如果不通过索引条件检索数据，那么 InnoDB 将对表中所有的记录进行加锁。</p>
</li>
<li><p><strong>行锁</strong>的具体实现算法有三种：record lock、gap lock 以及 next-key lock。</p>
<ul>
<li><strong>record lock</strong>是专门对索引项加锁；</li>
<li><strong>gap lock</strong> 是对索引项之间的间隙加锁；</li>
<li><strong>next-key lock</strong> 则是前面两种的组合，对索引项以其之间的间隙加锁。<br>只在可重复读或以上隔离级别下的特定操作才会取得 gap lock 或 next-key lock，在Select 、Update 和 Delete 时，除了基于唯一索引的查询之外，其他索引查询时都会获取gap lock 或 next-key lock，即锁住其扫描的范围。</li>
</ul>
</li>
</ul>
<h3><span id="隐式锁和显示锁">隐式锁和显示锁</span><a href="#隐式锁和显示锁" class="header-anchor">#</a></h3><p>显示锁<br>SELECT … LOCK IN SHARE MODE(加共享锁);<br>SELECT … FOR UPDATE(加排他锁);</p>
<h1><span id="死锁">死锁</span><a href="#死锁" class="header-anchor">#</a></h1><h3><span id="死锁和死锁检测-5">死锁和死锁检测 [5]</span><a href="#死锁和死锁检测-5" class="header-anchor">#</a></h3><p>当出现死锁以后，有两种策略：</p>
<ul>
<li><p>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数<br><strong>innodb_lock_wait_timeout</strong>来设置。<br>innodb_lock_wait_timeout的默认值是50s。 实际中不用这种策略。</p>
</li>
<li><p>另一种策略是，发起<strong>死锁检测</strong>，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事<br>务得以继续执行。将参数 <strong>innodb_deadlock_detect</strong> 设置为on，表示开启这个逻辑。</p>
<ul>
<li><p>带来的问题：每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要<strong>消耗大量的CPU资源</strong>。</p>
</li>
<li><p>一种解决思路是<strong>控制并发度</strong>：并发控制要做在数据库服务端。如果有中间件，可以考虑在中间件实现；如果-团队有能修改MySQL源码的人，也可以做在MySQL里面。基本思路就是，<strong>对于相同行的更新，-在进入引擎之前排队</strong>。这样在InnoDB内部就不会有大量的死锁检测工作了。</p>
</li>
<li><p>另一种解决思路是<strong>在应用层上优化</strong>:你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。 比如，一个账户1条记录变10条记录。</p>
</li>
</ul>
</li>
</ul>
<h3><span id="预防死锁-7">预防死锁 [7]</span><a href="#预防死锁-7" class="header-anchor">#</a></h3><ul>
<li>减少长事务</li>
<li>大事务拆成小事务</li>
<li>保证加锁顺序一直</li>
<li>业务允许的情况下，降低隔离级别<br>RR几倍下会有间隙锁，会提高死锁发生的概率</li>
</ul>
<h3><span id="死锁的排查和解决-7">死锁的排查和解决 [7]</span><a href="#死锁的排查和解决-7" class="header-anchor">#</a></h3><ul>
<li>通过日志系统及时<strong>通知</strong>死锁事件<br> 通过ELK做通知</li>
<li>结合业务代码与<strong>死锁日志</strong> 进行分析<ul>
<li>通过 pt-deadlock-logger 监控死锁 </li>
<li>查看最近一次的死锁日志<br><code>show engine innodb status</code></li>
</ul>
</li>
</ul>
<h1><span id="案例">案例</span><a href="#案例" class="header-anchor">#</a></h1><h3><span id="case-1">Case [1]</span><a href="#case-1" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/08/15/mysqlDeadLock/case.jpg" class>

<h3><span id="原因">原因</span><a href="#原因" class="header-anchor">#</a></h3><p>死锁是在并发环境下，两个或多个事务互相等待对方持有的资源而无法继续执行的情况。在上文中，死锁的产生是因为两个事务A和事务B都持有间隙(4,+∞）的gap锁，并且两个事务都在等待对方释放锁，导致循环等待而造成死锁。</p>
<h3><span id="解决方案">解决方案</span><a href="#解决方案" class="header-anchor">#</a></h3><ul>
<li><p>innodb_lock_wait_timeout 超时时间 - 通用<br>避免死锁最直观的方法就是在两个事务相互等待时，<strong>当一个事务的等待时间超过设置的某一<br>阈值，就对这个事务进行回滚，另一个事务就可以继续执行了。</strong>这种方法简单有效，在<br>InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的。</p>
</li>
<li><p>替换  幂等性校验 - 非通用<br>我们还可以<strong>使用其它的方式来代替数据库实现幂等性校验</strong>。例如，使用 Redis 以及<br>ZooKeeper 来实现，运行效率比数据库更佳。</p>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ul>
<li><ol>
<li>《35 | 记一次线上SQL死锁事故：如何避免死锁？》 刘超</li>
</ol>
</li>
<li><ol start="3">
<li>《33 | MySQL调优之事务：高并发场景下的数据库事务调优》   刘超</li>
</ol>
</li>
<li><ol start="5">
<li>《07 | 行锁功过：怎么减少行锁对性能的影响？》 MySQL实战45讲  丁奇</li>
</ol>
</li>
<li><ol start="7">
<li><a href="https://www.bilibili.com/video/BV1V3411z7Hj/">MYSQL死锁的检测与预防</a></li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
        <category>关系型</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 混合持久化</title>
    <url>/www6vHomeHexo/2023/07/10/redisBothAofAndRDB/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#redis-%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96">Redis 混合持久化</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D%E9%A1%BA%E5%BA%8F%E5%92%8C%E5%8A%A0%E8%BD%BD%E6%B5%81%E7%A8%8B-23">数据恢复顺序和加载流程 [2][3]</a></li>
<li><a href="#%E5%BC%80%E5%90%AF">开启</a></li>
<li><a href="#%E5%8E%9F%E7%90%86-3">原理 [3]</a></li>
</ul>
</li>
<li><a href="#aofrdb%E6%B7%B7%E5%90%881">AOF+RDB混合[1]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="redis-混合持久化">Redis 混合持久化</span><a href="#redis-混合持久化" class="header-anchor">#</a></h1><h3><span id="数据恢复顺序和加载流程-23">数据恢复顺序和加载流程 [2][3]</span><a href="#数据恢复顺序和加载流程-23" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/07/10/redisBothAofAndRDB/mix.jpg" class>

<p>在这种情况下，  <strong>当redis重启的时候会优先载入AOF文件来恢复原始的数据</strong>  ，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。</p>
<p>RDB和AOF共存时会优先加载AOF文件</p>
<p><strong>【主从切换   优先加载  RDB  -&gt;  速度】</strong><br><strong>【redis重启 优先加载 AOF -&gt; 数据完整性】</strong></p>
<h3><span id="开启">开启</span><a href="#开启" class="header-anchor">#</a></h3>  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">aof-use-rdb-preamble no -&gt; yes</span><br></pre></td></tr></table></figure>

<h3><span id="原理-3">原理 [3]</span><a href="#原理-3" class="header-anchor">#</a></h3><p>RDB镜像做全量持久化，AOF做增量持久化 先使用RDB进行快照存储，然后使用AOF持久化记录所有的写操作，当重写策略满足或手动触发重写的时候，将最新的数据存储为新的RDB记录。<br>这样的话，重启服务的时候会从RDB和AOF两部分恢复数据，既保证了数据完整性，又提高了恢复数据的性能。简单来说:混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。</p>
<h1><span id="aofrdb混合1">AOF+RDB混合[1]</span><a href="#aofrdb混合1" class="header-anchor">#</a></h1><p>而<strong>混合使用 RDB 和 AOF</strong>，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li>《05丨内存快照：宕机后，Redis如何实现快速恢复？》 </li>
<li><a href="https://www.cnblogs.com/wiseblog/articles/13540042.html">redis++：Redis持久化 rdb &amp; aof 工作原理及流程图 （三）</a></li>
<li><a href="https://github.com/www6v/Learning-in-practice/blob/master/Redis/4.Redis%E6%8C%81%E4%B9%85%E5%8C%96/9.RDB-AOF%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96.md">RDB-AOF混合持久化</a><br><a href="https://www.bilibili.com/video/BV13R4y1v7sP/?p=45">尚硅谷Redis零基础到进阶，最强redis7教程，阳哥亲自带练（附redis面试题）</a></li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
        <category>KV</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>KV</tag>
      </tags>
  </entry>
  <entry>
    <title>DDD-落地实战 Practice</title>
    <url>/www6vHomeHexo/2023/07/06/dddPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#ddd-%E8%90%BD%E5%9C%B0">DDD 落地</a><ul>
<li><a href="#%E5%9F%BA%E4%BA%8Eddd%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E6%A0%B8%E5%BF%83">基于DDD应用架构的核心</a></li>
<li><a href="#%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF-4">设计思路 [4]</a></li>
<li><a href="#%E5%88%86%E5%B1%82-2">分层 [2]</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81%E5%88%86%E5%B1%82-2">代码分层 [2]</a></li>
<li><a href="#%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%8120">项目代码[20]</a></li>
</ul>
</li>
<li><a href="#%E6%A1%86%E6%9E%B6">框架</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="ddd-落地">DDD 落地</span><a href="#ddd-落地" class="header-anchor">#</a></h1><h3><span id="基于ddd应用架构的核心">基于DDD应用架构的核心</span><a href="#基于ddd应用架构的核心" class="header-anchor">#</a></h3><p>分离业务复杂度和技术复杂度</p>
<h3><span id="设计思路-4">设计思路 [4]</span><a href="#设计思路-4" class="header-anchor">#</a></h3><ul>
<li><p><strong>贫血模型</strong></p>
<ul>
<li>实现<br><strong>业务逻辑放到Service中</strong></li>
<li>缺点 [7]<br><strong>业务逻辑被埋没在存储业务中</strong></li>
<li>贫血模型的<strong>缺陷</strong>  [21]<ul>
<li>无法保护模型对象的完整性和一致性</li>
<li>对象操作的可发现性极差</li>
<li>代码逻辑重复</li>
<li>代码的健壮性差</li>
<li>强依赖底层实现</li>
</ul>
</li>
<li><strong>99%的代码都是基于贫血模型</strong>  [21]<ul>
<li>数据库思维</li>
<li>贫血模型“简单”</li>
<li>脚本思维</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>充血模型</strong></p>
<ul>
<li>实现<br> <strong>业务逻辑放到领域对象中(实体对象中有实现方法)</strong></li>
<li>开闭原则<br> 保持了对象的封装性，使得领域模型在面临多态、继承等复杂结构时，易于变更</li>
<li>适用场景<br> 类似继承、多态的情况<br>在软件设计的过程中需要将一些类型或者编码进行转换<br>更好地表现领域对象之间的关系<br>“聚合”，也就是在真实世界中那些代表整体与部分的事</li>
</ul>
</li>
<li><p>比较</p>
<ul>
<li>贫血模型比充血模型更加<strong>简单易行</strong><ul>
<li>贫血模型<br>不需要  仓库、工厂、缓存，简单粗暴</li>
</ul>
</li>
<li>充血模型需要更强的<strong>设计与协作能力</strong><ul>
<li>充血模型<br>需要开发人员有更强的OOA&#x2F;D能力、分析业务、业务建模与设计能力<br>要有较强的团队协作能力</li>
<li>贫血模型<br>所有业务处理过程都交给Service完成</li>
</ul>
</li>
<li>贫血模型更容易应对<strong>复杂的业务处理场景</strong></li>
</ul>
</li>
</ul>
<h3><span id="分层-2">分层  [2]</span><a href="#分层-2" class="header-anchor">#</a></h3><ul>
<li>用户接口层(Controller层) </li>
<li>Application层</li>
<li>Domain层</li>
<li>Infrastructure层</li>
</ul>
<h3><span id="代码分层-2">代码分层  [2]</span><a href="#代码分层-2" class="header-anchor">#</a></h3><ul>
<li><p>Interface</p>
<ul>
<li>assembler(DTO和领域对象的互转)</li>
<li>dto</li>
<li>facade（<strong>粗粒度的调用接口</strong>，将用户请求<strong>委派</strong>给一个或多个应用服务进行处理）</li>
</ul>
</li>
<li><p>Application</p>
<ul>
<li>event（pub， sub）（<strong>事件处理相关的核心业务逻辑在领域层实现</strong>）</li>
<li>service（应用服务）</li>
</ul>
</li>
<li><p>Domain</p>
<ul>
<li>aggregate<ul>
<li>entity<ul>
<li><strong>聚合根</strong> </li>
<li><strong>实体</strong>     </li>
<li><strong>值对象</strong>   </li>
<li><strong>工厂模式（Factory）</strong></li>
</ul>
</li>
<li>event<br><strong>事件实体</strong>以及<strong>与事件活动相关的业务逻辑代码</strong></li>
<li>repository<br>所在聚合的查询或持久化领域对象的代码，通常包括仓储接口和仓储实现方法<br><strong>Data Model只存在于数据层，而Domain Model在领域层，而链接了这两层的关键对象，就是Repository</strong> [7]</li>
<li>service<br>领域服务是多个实体组合出来的一段业务逻辑</li>
</ul>
</li>
</ul>
</li>
<li><p>Infrastructure</p>
<ul>
<li>config</li>
<li>Util（开发框架、消息、数据库、缓存、文件、总线、网关、第三方类库、通用算法等基础代码，）</li>
</ul>
</li>
</ul>
<h3><span id="项目代码20">项目代码[20]</span><a href="#项目代码20" class="header-anchor">#</a></h3><h1><span id="框架">框架</span><a href="#框架" class="header-anchor">#</a></h1><ul>
<li>Axon Framework</li>
<li>COLA [22]</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ul>
<li><ol start="2">
<li>《13丨代码模型（上）：如何使用DDD设计微服务代码模型？》   欧创新</li>
</ol>
</li>
<li><ol start="4">
<li>《04  领域模型是如何指导程序设计的？》 DDD 微服务落地实战-拉钩专栏</li>
</ol>
</li>
<li><ol start="7">
<li>《24 直播：框架之上的业务分层》  体系课_Go高级工程师实战营(完结)</li>
</ol>
</li>
<li><ol start="20">
<li><a href="https://zhuanlan.zhihu.com/p/343388831">阿里技术专家详解DDD系列 第二讲 - 应用架构</a><br><a href="https://github.com/www6v/jExamples/tree/master/src/main/java/ddd/transactionScript">refactor 之前的Transaction Script</a> git<br><a href="https://github.com/www6v/jExamples/tree/master/src/main/java/ddd/refactor">refactor 之后的DDD</a></li>
</ol>
</li>
<li><ol start="21">
<li><a href="https://zhuanlan.zhihu.com/p/348706530">阿里技术专家详解DDD系列 第三讲 - Repository模式</a></li>
</ol>
</li>
<li><ol start="22">
<li><a href="https://blog.csdn.net/significantfrank/article/details/110934799">COLA 4.0：应用架构的最佳实践</a>  未</li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>架构</category>
        <category>应用架构</category>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Feature</title>
    <url>/www6vHomeHexo/2023/06/10/javaFeature/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%89%88%E6%9C%AC">版本</a></li>
<li><a href="#%E7%89%88%E6%9C%AC%E7%89%B9%E6%80%A7-1">版本+特性 [1]</a><ul>
<li><a href="#java-14">Java 1.4</a></li>
<li><a href="#java-5java-15">Java 5（Java 1.5）</a></li>
<li><a href="#java-7">Java 7</a></li>
<li><a href="#java-se-8java-8-lts%E9%95%BF%E6%9C%9F%E6%94%AF%E6%8C%81%E7%89%88%E6%9C%AC">Java SE 8（Java 8）- LTS长期支持版本</a></li>
<li><a href="#java-se-9java-9">Java SE 9（Java 9）</a></li>
<li><a href="#java-se-10java-10">Java SE 10（Java 10）</a></li>
<li><a href="#java-se-11java-11-lts%E9%95%BF%E6%9C%9F%E6%94%AF%E6%8C%81%E7%89%88%E6%9C%AC">Java SE 11（Java 11）-LTS长期支持版本</a></li>
<li><a href="#java-se-12java-12">Java SE 12（Java 12）</a></li>
<li><a href="#java-se-13-java-13">Java SE 13 （Java 13）</a></li>
<li><a href="#java-se-14-java-14">Java SE 14 （Java 14）</a></li>
<li><a href="#java-se-15-java-15">Java SE 15 （Java 15）</a></li>
<li><a href="#java-se-16-java-16">Java SE 16 （Java 16）</a></li>
<li><a href="#java-se-17java-17-lts%E9%95%BF%E6%9C%9F%E6%94%AF%E6%8C%81%E7%89%88%E6%9C%AC">Java SE 17（Java 17）-LTS长期支持版本</a></li>
<li><a href="#java-se-18java-182">Java SE 18（Java 18）[2]</a></li>
<li><a href="#java-se-19java-19-3">Java SE 19（Java 19） [3]</a></li>
<li><a href="#java-se-20java-20-4">Java SE 20（Java 20） [4]</a></li>
<li><a href="#java-se-21java-21-5">Java SE 21（Java 21） [5]</a></li>
</ul>
</li>
<li><a href="#%E7%89%B9%E6%80%A7-8">特性 [8]</a><ul>
<li><a href="#%E6%96%87%E5%AD%97%E5%9D%97-text-blocks-jdk-13-jdk-15">文字块 text blocks |  JDK 13-JDK 15</a></li>
<li><a href="#record-%E6%A1%A3%E6%A1%88%E7%B1%BB-%E4%B8%8D%E5%8F%AF%E5%8F%98-jdk14-jdk16">record 档案类 [不可变] |  JDK14-JDK16</a></li>
<li><a href="#sealed-classes-%E5%B0%81%E9%97%AD%E7%B1%BB-%E6%89%A9%E5%B1%95%E6%80%A7-jdk-15-jdk-17">sealed classes 封闭类   [扩展性] |   JDK 15-JDK 17</a></li>
<li><a href="#%E7%B1%BB%E5%9E%8B%E5%8C%B9%E9%85%8D-%E5%88%87%E9%99%A4%E8%87%83%E8%82%BF%E7%9A%84%E5%BC%BA%E5%88%B6%E8%BD%AC%E6%8D%A2-jdk-14-jdk-16">类型匹配 [切除臃肿的强制转换] | JDK 14-JDK 16</a></li>
<li><a href="#switch-%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E7%AE%80%E5%8C%96%E5%A4%9A%E6%83%85%E6%99%AF%E6%93%8D%E4%BD%9C-jdk-12-jdk-14">switch 表达式 [简化多情景操作] |  JDK 12-JDK 14</a></li>
<li><a href="#switch%E5%8C%B9%E9%85%8D-%E9%80%82%E9%85%8D%E4%B8%8D%E5%90%8C%E7%9A%84%E7%B1%BB%E5%9E%8B-jdk-17-21">switch匹配 [适配不同的类型]  |  JDK 17-21</a></li>
<li><a href="#%E5%A4%96%E9%83%A8%E5%86%85%E5%AD%98%E6%8E%A5%E5%8F%A3-jdk18-">外部内存接口 | JDK18-?</a></li>
<li><a href="#%E5%A4%96%E9%83%A8%E5%87%BD%E6%95%B0%E6%8E%A5%E5%8F%A3%E5%8F%96%E4%BB%A3java%E6%9C%AC%E5%9C%B0%E6%8E%A5%E5%8F%A3-jdk-17-">外部函数接口[取代Java本地接口] |  JDK 17-?</a></li>
<li><a href="#gc">GC</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="版本">版本</span><a href="#版本" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/06/10/javaFeature/version.jpg" class width="720" height="756">

<table>
<thead>
<tr>
<th>版本</th>
<th>发布日期</th>
</tr>
</thead>
<tbody><tr>
<td>JDK 19</td>
<td>2022&#x2F;09&#x2F;20</td>
</tr>
<tr>
<td>JDK 20</td>
<td>2023&#x2F;03&#x2F;21</td>
</tr>
</tbody></table>
<h1><span id="版本特性-1">版本+特性 [1]</span><a href="#版本特性-1" class="header-anchor">#</a></h1><h3><span id="java-14">Java 1.4</span><a href="#java-14" class="header-anchor">#</a></h3><ul>
<li>NIO（New I&#x2F;O）</li>
</ul>
<h3><span id="java-5java-15">Java 5（Java 1.5）</span><a href="#java-5java-15" class="header-anchor">#</a></h3><ul>
<li>泛型</li>
<li>自动装箱&#x2F;拆箱</li>
<li>枚举类型</li>
</ul>
<h3><span id="java-7">Java 7</span><a href="#java-7" class="header-anchor">#</a></h3><ul>
<li>Try-with-resources</li>
</ul>
<h3><span id="java-se-8java-8-lts长期支持版本">Java SE 8（Java 8）- LTS长期支持版本</span><a href="#java-se-8java-8-lts长期支持版本" class="header-anchor">#</a></h3><ul>
<li><strong>Lambda 表达式</strong>：简化函数式编程。允许以更简洁的语法编写函数式接口的实例，使代码更加简洁。</li>
<li><strong>Stream API</strong>：用于处理集合，支持函数式操作，如过滤、映射和聚合。</li>
<li>方法引用：允许直接引用现有方法或构造函数，避免了重复编写类似的代码。</li>
<li><strong>接口的默认方法</strong>：在接口中提供默认实现，提高接口的灵活性。</li>
<li>时间 API：提供了一组强大的时间操作类，简化了日期和时间的操作。</li>
<li>重复注解：允许在同一个地方多次声明同一个注解，提高了代码的可读性。</li>
<li><strong>CompletableFuture 类</strong>：简化异步编程，提供更好的错误处理和异常处理机制。</li>
<li>Nashorn 引擎：提供了一种基于 JavaScript 的解决方案，允许将 JavaScript 代码嵌入到 Java 应用程序中。</li>
<li><strong>Optional 类</strong>：减少空指针异常，提高代码可读性。</li>
</ul>
<h3><span id="java-se-9java-9">Java SE 9（Java 9）</span><a href="#java-se-9java-9" class="header-anchor">#</a></h3><ul>
<li><strong>模块系统（Project Jigsaw）</strong>：将 Java 的庞大代码库划分为可重用的模块，简化大型应用的构建和维护。</li>
<li>JShell：Java 的交互式命令行工具，用于快速尝试和测试 Java 代码片段。</li>
<li>新的集合工厂方法：方便地创建不可变集合，如 List.of()、Set.of() 和 Map.of()。</li>
</ul>
<h3><span id="java-se-10java-10">Java SE 10（Java 10）</span><a href="#java-se-10java-10" class="header-anchor">#</a></h3><ul>
<li><strong>局部变量类型推断</strong>：使用 var 关键字自动推断局部变量的类型，简化代码。</li>
<li>垃圾收集器接口改进：提高了垃圾收集器的可插拔性和灵活性。</li>
</ul>
<h3><span id="java-se-11java-11-lts长期支持版本">Java SE 11（Java 11）-LTS长期支持版本</span><a href="#java-se-11java-11-lts长期支持版本" class="header-anchor">#</a></h3><ul>
<li>新的 HTTP 客户端 API：支持 HTTP&#x2F;2 和 WebSocket，提供了更现代化的编程方式。</li>
<li>改进的垃圾收集：引入了 <strong>ZGC</strong> 和 Epsilon 垃圾收集器。</li>
<li>String 类的新方法：如 lines()、isBlank()、strip() 等。</li>
</ul>
<h3><span id="java-se-12java-12">Java SE 12（Java 12）</span><a href="#java-se-12java-12" class="header-anchor">#</a></h3><ul>
<li><strong>switch 表达式</strong>：允许在 switch 语句中使用表达式，提高了代码的可读性和简洁性。</li>
<li>改进的字符串类：提供了一些新的方法，使得字符串的操作更加方便和高效。</li>
<li>Shenandoah 垃圾回收器：提供了一种低停顿时间的垃圾回收器，适用于大型堆内存的应用程序。</li>
<li>微基准测试套件：提供了一种用于快速测试性能的微基准测试框架。</li>
<li>JDK 源代码重构：对 JDK 源代码进行了重构，提高了代码的可读性和维护性。</li>
</ul>
<h3><span id="java-se-13-java-13">Java SE 13 （Java 13）</span><a href="#java-se-13-java-13" class="header-anchor">#</a></h3><ul>
<li><strong>文本块</strong>：允许以更简洁的语法创建多行字符串，提高了代码的可读性和简洁性。</li>
<li>改进的 switch 表达式：允许在 switch 语句中使用表达式，提供更好的类型推断和更灵活的写法。</li>
<li>ZGC 垃圾回收器改进：提高了 ZGC 垃圾回收器的性能和可靠性。</li>
<li>应用程序类数据共享改进：提高了应用程序类数据共享的性能和效率。</li>
</ul>
<h3><span id="java-se-14-java-14">Java SE 14 （Java 14）</span><a href="#java-se-14-java-14" class="header-anchor">#</a></h3><p>2020年3月17日</p>
<ul>
<li>instanceof 模式匹配：允许在 instanceof 操作符中使用模式匹配，提高了代码的简洁性和可读性。</li>
<li><strong>Records 类</strong>：提供了一种更简单和安全的数据类的定义方式。</li>
<li>Switch 表达式增强：允许使用箭头操作符(-&gt;)作为 lambda 表达式的简写语法。</li>
<li>文本块增强：允许在文本块中使用嵌入式表达式，使得文本块更加灵活和强大。</li>
<li>改进的 NullPointerException 信息：提供更详细的 NullPointerException 信息。</li>
</ul>
<h3><span id="java-se-15-java-15">Java SE 15 （Java 15）</span><a href="#java-se-15-java-15" class="header-anchor">#</a></h3><ul>
<li><strong>隐式的类文件</strong>：允许在 Java 源代码中定义多个类，而不需要单独的类文件。</li>
<li>改进的文本块：允许在文本块中使用转义字符和 Unicode 转义，提高了文本块的灵活性和可读性。</li>
<li>改进的 switch 表达式：允许在 switch 语句中使用多个匹配项，提供更灵活的写法。</li>
<li><strong>Sealed 类和接口</strong>：允许控制哪些类或接口可以继承或实现该类或接口，提高了代码的安全性和可维护性。</li>
<li>其他改进：包括增强的 ZGC 垃圾回收器、改进的内存管理、新增的 Unix 域套接字 API 等。</li>
</ul>
<h3><span id="java-se-16-java-16">Java SE 16 （Java 16）</span><a href="#java-se-16-java-16" class="header-anchor">#</a></h3><ul>
<li>增强的文本块：允许在文本块中使用转义字符和嵌入式表达式。</li>
<li>移除了废弃的 ParallelScavenge 垃圾回收器。</li>
<li>改进的 ZGC 垃圾回收器：提高了性能和可靠性，增加了可配置参数。</li>
<li>Records 类的增强：允许在 records 类中添加静态方法和私有构造函数。</li>
<li><strong>Vector API</strong>：提供了一种新的 API，用于高效地执行矢量化操作。</li>
</ul>
<h3><span id="java-se-17java-17-lts长期支持版本">Java SE 17（Java 17）-LTS长期支持版本</span><a href="#java-se-17java-17-lts长期支持版本" class="header-anchor">#</a></h3><ul>
<li><strong>嵌套枚举</strong>：允许在类和接口中定义嵌套枚举，提高了代码的可读性和简洁性。</li>
<li>改进的 switch 语句：允许在 switch 语句中使用 case 标签作为表达式，提供更灵活的写法。</li>
<li>预览性功能：包括<strong>模式匹配</strong>、嵌套枚举、记录类的序列化等新特性。</li>
<li>增强的垃圾回收器：提高了性能和可靠性，增加了可配置参数。</li>
<li>其他改进：包括新的内存管理和性能优化，增强的 JIT 编译器等。</li>
</ul>
<h3><span id="java-se-18java-182">Java SE 18（Java 18）[2]</span><a href="#java-se-18java-182" class="header-anchor">#</a></h3><p>400：默认使用 UTF-8<br>408：简易 Web 服务器<br>413：Java API 文档中的代码片段<br>416：使用方法句柄重新实现核心反射<br>417：矢量 API<br>418：网络地址解析 SPI<br>419：<strong>外部函数和内存 API</strong><br>420：switch 的模式匹配<br>421：废弃对象终止机制 </p>
<h3><span id="java-se-19java-19-3">Java SE 19（Java 19） [3]</span><a href="#java-se-19java-19-3" class="header-anchor">#</a></h3><p>405: 	Record Patterns (Preview)<br>422: 	Linux&#x2F;RISC-V Port<br>424: 	Foreign Function &amp; Memory API (Preview)<br>425: 	<strong>Virtual Threads (Preview)</strong><br>426: 	Vector API (Fourth Incubator)<br>427: 	Pattern Matching for switch (Third Preview)<br>428: 	<strong>Structured Concurrency (Incubator)</strong></p>
<h3><span id="java-se-20java-20-4">Java SE 20（Java 20） [4]</span><a href="#java-se-20java-20-4" class="header-anchor">#</a></h3><p>429: 	<strong>Scoped Values (Incubator)</strong><br>432: 	Record Patterns (Second Preview)<br>433: 	Pattern Matching for switch (Fourth Preview)<br>434: 	Foreign Function &amp; Memory API (Second Preview)<br>436: 	Virtual Threads (Second Preview)<br>437: 	Structured Concurrency (Second Incubator)<br>438: 	Vector API (Fifth Incubator)</p>
<h3><span id="java-se-21java-21-5">Java SE 21（Java 21） [5]</span><a href="#java-se-21java-21-5" class="header-anchor">#</a></h3><p>430: 	String Templates (Preview)<br>431: 	Sequenced Collections<br>439: 	<strong>Generational ZGC</strong><br>440: 	Record Patterns<br>441: 	<strong>Pattern Matching for switch</strong><br>442: 	Foreign Function &amp; Memory API (Third Preview)<br>443: 	Unnamed Patterns and Variables (Preview)<br>444: 	<strong>Virtual Threads</strong> [6][7]<br>445: 	Unnamed Classes and Instance Main Methods (Preview)<br>446: 	Scoped Values (Preview)<br>448: 	Vector API (Sixth Incubator)<br>449: 	Deprecate the Windows 32-bit x86 Port for Removal<br>451: 	Prepare to Disallow the Dynamic Loading of Agents<br>452: 	Key Encapsulation Mechanism API<br>453: 	Structured Concurrency (Preview)</p>
<h1><span id="特性-8">特性 [8]</span><a href="#特性-8" class="header-anchor">#</a></h1><h3><span id="文字块-text-blocks-jdk-13-jdk-15">文字块 text blocks |  JDK 13-JDK 15</span><a href="#文字块-text-blocks-jdk-13-jdk-15" class="header-anchor">#</a></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">textBlock</span> <span class="operator">=</span> <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        &lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="string">        &lt;html&gt;</span></span><br><span class="line"><span class="string">            &lt;body&gt;</span></span><br><span class="line"><span class="string">            	&lt;h1&gt;&quot;Hello World!&quot;&lt;/h1&gt;</span></span><br><span class="line"><span class="string">            &lt;/body&gt;</span></span><br><span class="line"><span class="string">        &lt;/html&gt;</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span>;</span><br><span class="line">System.out.println(</span><br><span class="line">		<span class="string">&quot;Here is the text block:\n&quot;</span> + textBlock);</span><br></pre></td></tr></table></figure>

<h3><span id="record-档案类-不可变-jdk14-jdk16">record  档案类 [不可变] |  JDK14-JDK16</span><a href="#record-档案类-不可变-jdk14-jdk16" class="header-anchor">#</a></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">record</span> <span class="title class_">Circle</span><span class="params">(<span class="type">double</span> radius)</span> <span class="keyword">implements</span> <span class="title class_">Shape</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">area</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Math.PI * radius * radius;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3><span id="sealed-classes-封闭类-扩展性-jdk-15-jdk-17">sealed classes 封闭类   [扩展性] |   JDK 15-JDK 17</span><a href="#sealed-classes-封闭类-扩展性-jdk-15-jdk-17" class="header-anchor">#</a></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">sealed</span> <span class="keyword">class</span> <span class="title class_">Shape</span> <span class="keyword">permits</span> Circle, Square &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> String id;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Shape</span><span class="params">(String id)</span> &#123;</span><br><span class="line">    	<span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="type">double</span> <span class="title function_">area</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3><span id="类型匹配-切除臃肿的强制转换-jdk-14-jdk-16">类型匹配 [切除臃肿的强制转换] | JDK 14-JDK 16</span><a href="#类型匹配-切除臃肿的强制转换-jdk-14-jdk-16" class="header-anchor">#</a></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (shape <span class="keyword">instanceof</span> Rectangle rect) &#123;</span><br><span class="line">	<span class="keyword">return</span> (rect.length == rect.width);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3><span id="switch-表达式-简化多情景操作-jdk-12-jdk-14">switch 表达式 [简化多情景操作] |  JDK 12-JDK 14</span><a href="#switch-表达式-简化多情景操作-jdk-12-jdk-14" class="header-anchor">#</a></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">daysInMonth</span> <span class="operator">=</span> <span class="keyword">switch</span> (month) &#123;</span><br><span class="line">    <span class="keyword">case</span> Calendar.JANUARY,</span><br><span class="line">        Calendar.MARCH,</span><br><span class="line">        Calendar.MAY,</span><br><span class="line">        Calendar.JULY,</span><br><span class="line">        Calendar.AUGUST,</span><br><span class="line">        Calendar.OCTOBER,</span><br><span class="line">        Calendar.DECEMBER -&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">case</span> Calendar.APRIL,</span><br><span class="line">        Calendar.JUNE,</span><br><span class="line">        Calendar.SEPTEMBER,</span><br><span class="line">        Calendar.NOVEMBER -&gt; <span class="number">30</span>;</span><br><span class="line">    <span class="keyword">case</span> Calendar.FEBRUARY -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (((year % <span class="number">4</span> == <span class="number">0</span>) &amp;&amp; !(year % <span class="number">100</span> == <span class="number">0</span>))</span><br><span class="line">        		|| (year % <span class="number">400</span> == <span class="number">0</span>)) &#123;</span><br><span class="line">        	<span class="keyword">yield</span> <span class="number">29</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        	<span class="keyword">yield</span> <span class="number">28</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">default</span> -&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(</span><br><span class="line">    	<span class="string">&quot;Calendar in JDK does not work&quot;</span>);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3><span id="switch匹配-适配不同的类型-jdk-17-21">switch匹配 [适配不同的类型]  |  JDK 17-21</span><a href="#switch匹配-适配不同的类型-jdk-17-21" class="header-anchor">#</a></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">isSquare</span><span class="params">(Shape shape)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">switch</span> (shape) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="literal">null</span>, Shape.Circle c -&gt; <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">case</span> Shape.Square s -&gt; <span class="literal">true</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3><span id="外部内存接口-jdk18-">外部内存接口 | JDK18-?</span><a href="#外部内存接口-jdk18-" class="header-anchor">#</a></h3><ul>
<li><p>ByteBuffer &amp;&amp; 零拷贝<br>  使用堆外存储最常用的办法，就是使用 ByteBuffer 这个类来分配<strong>直接存储空间（direct</strong><br>  <strong>buffer）</strong>。JVM 虚拟机会尽最大努力直接在直接存储空间上执行 IO 操作，避免数据在本<br>  地和 JVM 之间的拷贝。<br>  由于频繁的内存拷贝是性能的主要障碍之一。所以为了极致的性能，应用程序通常也会尽<br>  量避免内存的拷贝。理想的状况下，一份数据只需要一份内存空间，这就是我们常说的<strong>零<br>  拷贝</strong>。</p>
<p>  用 ByteBuffer 这个类来分配直接存储空间的方法</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> ByteBuffer <span class="title function_">allocateDirect</span><span class="params">(<span class="type">int</span> capacity)</span>;</span><br></pre></td></tr></table></figure>
<p>  第一个缺陷是没有资源释放的接口。<br>  第二个缺陷是存储空间尺寸的限制。</p>
</li>
<li><p>外部内存接口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">ResourceScope</span> <span class="variable">scope</span> <span class="operator">=</span> ResourceScope.newConfinedScope()) &#123;</span><br><span class="line">    <span class="type">MemorySegment</span> <span class="variable">segment</span> <span class="operator">=</span> MemorySegment.allocateNative(<span class="number">4</span>, scope);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123;</span><br><span class="line">    	MemoryAccess.setByteAtOffset(segment, i, (<span class="type">byte</span>)<span class="string">&#x27;A&#x27;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3><span id="外部函数接口取代java本地接口-jdk-17-">外部函数接口[取代Java本地接口] |  JDK 17-?</span><a href="#外部函数接口取代java本地接口-jdk-17-" class="header-anchor">#</a></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloWorld</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line">        <span class="keyword">try</span> (<span class="type">ResourceScope</span> <span class="variable">scope</span> <span class="operator">=</span> ResourceScope.newConfinedScope()) &#123;</span><br><span class="line">            <span class="type">CLinker</span> <span class="variable">cLinker</span> <span class="operator">=</span> CLinker.getInstance();</span><br><span class="line">            <span class="type">MemorySegment</span> <span class="variable">helloWorld</span> <span class="operator">=</span></span><br><span class="line">            		CLinker.toCString(<span class="string">&quot;Hello, world!\n&quot;</span>, scope);</span><br><span class="line">            <span class="type">MethodHandle</span> <span class="variable">cPrintf</span> <span class="operator">=</span> cLinker.downcallHandle(</span><br><span class="line">            		CLinker.systemLookup().lookup(<span class="string">&quot;printf&quot;</span>).get(),</span><br><span class="line">            		MethodType.methodType(<span class="type">int</span>.class, MemoryAddress.class),</span><br><span class="line">            		FunctionDescriptor.of(CLinker.C_INT, CLinker.C_POINTER));</span><br><span class="line">            cPrintf.invoke(helloWorld.address());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3><span id="gc">GC</span><a href="#gc" class="header-anchor">#</a></h3><p>G1,<br>ZGC, 分代式 ZGC </p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="http://justzqq.com/2023/03/23/java%E5%90%84%E4%B8%AA%E7%89%88%E6%9C%AC%E7%9A%84%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7%E6%95%B4%E7%90%86%EF%BC%81/">Java各个版本发布时间和主要特性整理！</a><br><a href="https://blog.csdn.net/wcdunf/article/details/129861244">Java 历史大版本及其详细特性介绍:</a></li>
<li><a href="https://www.bilibili.com/read/cv16596828">Java 18 的新特性</a></li>
<li><a href="https://openjdk.org/projects/jdk/19/">JDK 19</a></li>
<li><a href="https://openjdk.org/projects/jdk/20/">JDK 20</a></li>
<li><a href="https://openjdk.org/projects/jdk/21/">JDK 21</a></li>
<li><a href="https://blog.csdn.net/lewyu521/article/details/127649776">Java19 虚拟线程原理介绍及实现</a> ***</li>
<li><a href="https://www.jdon.com/63445.html">Java虚拟线程：异步编程之死</a></li>
<li>《深入剖析 Java 新特性》  范学雷<br> 02,03,04,05,06,07,08,09,12, 13</li>
<li><a href="https://www.bilibili.com/read/cv13542498">从Java 11升级到Java 17 </a> V 未</li>
</ol>
]]></content>
      <categories>
        <category>Java基础</category>
        <category>Feature</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title>全局二级索引-GSI</title>
    <url>/www6vHomeHexo/2023/06/05/globalSecondaryIndex/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%9C%BA%E6%99%AF">场景</a></li>
<li><a href="#%E5%85%A8%E5%B1%80%E7%B4%A2%E5%BC%95-vs-%E5%B1%80%E9%83%A8%E7%B4%A2%E5%BC%95-12">全局索引 vs 局部索引 [1][2]</a></li>
<li><a href="#polardb-%E5%85%A8%E5%B1%80%E7%B4%A2%E5%BC%95">PolarDB 全局索引</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h2><span id="场景">场景</span><a href="#场景" class="header-anchor">#</a></h2><p>[Claude]<br>分布式数据库的全局二级索引主要有以下几个使用场景:<br>    <strong>加速多表关联查询</strong>:用全局二级索引构建外键索引,可以有效地加速涉及多表关联的查询。<br>    <strong>全表扫描查询</strong>:当需要做全表扫描时,使用全局二级索引可以跳过不需要的行,大幅降低扫描成本。<br>    频繁查询的列上:对于数据库中经常需要根据某列进行查询的情况,建立该列的全局二级索引,可以大幅提高查询效率。<br>    <strong>需要排序的查询</strong>:当需要查询结果按某个列排序时,全局二级索引可以加速排序。<br>    模糊查询优化:通过部分键值匹配,全局二级索引可以优化like查询等模式查询。<br>    <strong>分页查询优化</strong>:结合 Cursor 标记,全局二级索引可以有效的支持分页查询。</p>
<p>总的来说,对于需要高效查询、排序、混合查询等复杂查询的分布式数据库而言,引入全局二级索引可以大大提高性能。尤其是处理大规模数据时,二级索引发挥的作用更加明显。</p>
<ul>
<li><p>全局二级索引能够解决什么问题 [1]<br>如果查询的维度与逻辑表的拆分维度不同，会<strong>产生跨分片查询</strong>。跨分片查询的增加会导致查询卡慢、连接池耗尽等性能问题。<strong>GSI</strong>能够通过增加拆分维度来<strong>减少跨分片查询，消除性能瓶颈</strong>。</p>
</li>
<li><p>增加拆分维度 [4]<br>例如，对于在线商城的订单表，假设按照买家用户维度拆分，那么对于卖家查询（例如，查询某个卖家的本月所有订单）就需要扫描所有分区。但是借助全局二级索引，可以仅仅扫描相应卖家所在的索引表分区，快速找到所需的订单信息。</p>
</li>
<li><p>全局唯一约束 [4]<br>例如，假设用户表是一张分布式表，按照用户ID分区。若要求用户手机号需要全局唯一，那么本地索引无法满足，必须构建一个按手机号作为索引键（同时也是分区键）的唯一索引。</p>
</li>
</ul>
<h2><span id="全局索引-vs-局部索引-12">全局索引 vs 局部索引 [1][2]</span><a href="#全局索引-vs-局部索引-12" class="header-anchor">#</a></h2><ul>
<li><p>全局二级索引 [DDIA  基于关键词的二级索引分区]<br>数据行和对应的索引行保存在不同分片上</p>
<ul>
<li>分类 [3]<ul>
<li>全局非分区索引（Global Non-Partitioned Index）</li>
<li>全局分区索引（Global Partitioned Index）</li>
</ul>
</li>
</ul>
</li>
<li><p>局部索引  [DDIA  基于文档的二级索引分区]<br>如果数据行和对应的索引行保存在相同分片上</p>
</li>
</ul>
<h2><span id="polardb-全局索引">PolarDB 全局索引</span><a href="#polardb-全局索引" class="header-anchor">#</a></h2><ul>
<li><p>PolarDB-X [1]</p>
<ul>
<li>XA多写，保证主表与<strong>索引表</strong>数据强一致。[性能会不会慢]</li>
<li>Online Schema Change，添加GSI不锁主表。</li>
</ul>
</li>
<li><p>PolarDB-X GSI [4]<br>每个GSI对应一张分布式索引表，和其他分布式表一样，按照指定的分区规则水平拆分为多张物理表。PolarDB-X使用分布式事务维护主表和索引表之间数据强一致。</p>
</li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li><a href="https://help.aliyun.com/document_detail/182179.html">全局二级索引</a>   PolarDB</li>
<li><a href="https://zhuanlan.zhihu.com/p/384439886">设计数据密集型应用-C6-分区和二级索引</a>  DDIA</li>
<li><a href="https://www.oceanbase.com/docs/enterprise-oceanbase-database-cn-10000000000376130">二级索引</a>  OB</li>
<li><a href="https://doc.polardbx.com/features/topics/gsi.html">全局二级索引 </a>  PolarDB</li>
<li><a href="https://zhuanlan.zhihu.com/p/572156705">PolarDB-X 全局二级索引</a> 未</li>
<li><a href="https://zhuanlan.zhihu.com/p/440801781">PolarDB-X 数据分布解读（三） ：TPCC与透明分布式</a>  未</li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
        <category>二级索引</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>统一模型</title>
    <url>/www6vHomeHexo/2023/05/13/unifyModel/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="计算密集">计算密集</span><a href="#计算密集" class="header-anchor">#</a></h2><table>
<thead>
<tr>
<th>计算密集</th>
<th>技术</th>
<th>产品</th>
</tr>
</thead>
<tbody><tr>
<td>微服务</td>
<td>RPC(2th)<br>Service Mesh(3th)<br>多运行时(4th )</td>
<td>Dubbo<br>istio proxyless<br>daper</td>
</tr>
<tr>
<td>容器</td>
<td>编排</td>
<td>K8s</td>
</tr>
<tr>
<td>Service Mesh</td>
<td>Sidecar <br>控制面， 数据面</td>
<td>Envoy xDS <br>微软SMI</td>
</tr>
<tr>
<td>可观测</td>
<td>Tracing+Metric+Logs</td>
<td>OpenTelemetry&#x3D;<br>OpenCensus+OpenTracing</td>
</tr>
<tr>
<td>Sererless</td>
<td>Sererless+ VM<br>Sererless+容器<br>Sererless+服务<br>Sererless+数据库<br></td>
<td>Ali ECS<br>Ali ECI<br>FasS<br>Aurora，TiDB Cloud<br></td>
</tr>
</tbody></table>
<h2><span id="数据密集">数据密集</span><a href="#数据密集" class="header-anchor">#</a></h2><table>
<thead>
<tr>
<th>数据密集</th>
<th>技术</th>
<th>产品</th>
</tr>
</thead>
<tbody><tr>
<td>消息队列</td>
<td>CloudEvent</td>
<td>EventMesh</td>
</tr>
<tr>
<td>数据库</td>
<td>分离: 存算分离(资源伸缩)<br>融合: HTAP(模型)</td>
<td>TiDB(TiKV, TiFlash) ，PolarDB</td>
</tr>
<tr>
<td>大数据</td>
<td>流计算</td>
<td>Beam，Flink</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>架构</category>
        <category>系统架构</category>
        <category>统一模型</category>
      </categories>
      <tags>
        <tag>统一模型</tag>
      </tags>
  </entry>
  <entry>
    <title>TiKV Transaction-MVCC+TSO</title>
    <url>/www6vHomeHexo/2023/04/10/tikvMVCCTransaction/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="原理">原理</span><a href="#原理" class="header-anchor">#</a></h1><h3><span id="percolator-1">Percolator  [1]</span><a href="#percolator-1" class="header-anchor">#</a></h3><p>  总体来说就是一个经过<strong>优化的 2PC</strong> 的实现，依赖一个<strong>单点的授时服务 TSO</strong> 来实现单调递增的事务编号生成，提供<strong>SI 的隔离级别</strong>。</p>
<h3><span id="tikv-的写事务分为两个阶段-1">TiKV 的写事务分为两个阶段  [1]</span><a href="#tikv-的写事务分为两个阶段-1" class="header-anchor">#</a></h3><ul>
<li><p>1、Prewrite 阶段<br>MVCC 在对应传统 2PC 的第一阶段的 prewrite 流程。<br>首先选出一个 primary row 和其他的 secondary rows，然后对 primary row 进行上锁，再对 secondary rows 进行类似的上锁流程。如果任何一步出错，都会进行回滚。完成 prewrite 阶段后，进入 commit 阶段，当前时间戳为 commitTs，TSO 会保证 commitTs &gt; startTs。</p>
</li>
<li><p>2、Commit 阶段<br>MVCC 中的 Commit 流程，包括在 primary 上写入 meta，删除 Lock 标记，以及异步提交 secondaries。如果 primary row 提交失败，则整个事务回滚。如果成功，则标志着整个事务提交成功。</p>
</li>
<li><p>Tidb乐观锁 [2]</p>
<img src="/www6vHomeHexo/2023/04/10/tikvMVCCTransaction/leguan.JPG" class>
</li>
<li><p>Tidb悲观锁 [2]</p>
<img src="/www6vHomeHexo/2023/04/10/tikvMVCCTransaction/beiguan.JPG" class></li>
</ul>
<h3><span id="tikv-的读事务-1">TiKV 的读事务  [1]</span><a href="#tikv-的读事务-1" class="header-anchor">#</a></h3><p>  在事务中进行读操作的过程。<br>  <strong>首先，需要检查行是否被锁定，如果被锁定，则需要等待或者清除锁。然后，需要读取最新的数据版本，方法是读取元数据并找到最大的时间戳。</strong> 锁分为两级，Primary和Secondary row，只有Primary row的锁被释放，事务才算提交成功。Secondary row的提交可以异步进行，但在此过程中可能需要清理锁。即使Secondary row提交失败，也可以通过锁找到Primary row，并根据元数据确定事务是回滚还是提交成功。</p>
<blockquote>
<p>TiKV 的事务默认隔离级别是 Repeatable Read（SI）, 也对外暴露显式的加锁的 API，用于为客户端实现 SELECT … FOR UPDATE 等隔离级别为 SSI 的语句。</p>
</blockquote>
<h3><span id="读写冲突处理-3">读写冲突处理 [3]</span><a href="#读写冲突处理-3" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/04/10/tikvMVCCTransaction/write-vs-read.JPG" class>

<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://cn.pingcap.com/blog/tidb-transaction-model">TiKV 事务模型概览，Google Spanner 开源实现</a>  *** </li>
<li>《13 | 隔离性：为什么使用乐观协议的分布式数据库越来越少? 》  分布式数据库30讲</li>
<li>《11｜隔离性：读写冲突时，快照是最好的办法吗？》 分布式数据库30讲</li>
<li><a href="https://zhuanlan.zhihu.com/p/149377959">percolator的理解与开源实现分析</a>   未</li>
<li><a href="https://zhuanlan.zhihu.com/p/261115166">Percolator - 分布式事务的理解与分析</a>   未</li>
<li>《云原生数据库 原理与实践》 8.1.3   未</li>
<li><a href="https://cn.pingcap.com/blog/pessimistic-transaction-the-new-features-of-tidb">TiDB 新特性漫谈：悲观事务</a> 未</li>
<li><a href="/www6vHomeHexo/2022/04/11/distributedDatabaseGlobalTime/" title="分布式数据库-全局时钟">分布式数据库-全局时钟</a>  self</li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
        <category>关系型</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Rocksdb-SST</title>
    <url>/www6vHomeHexo/2023/04/06/rocksdbSST/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#rocksdb-sst-%E7%B1%BB%E5%9E%8B12">Rocksdb SST 类型[1][2]</a></li>
<li><a href="#rocksdb-sst-blockbasedtable-5">Rocksdb SST- BlockBasedTable [5]</a><ul>
<li><a href="#%E7%B4%A2%E5%BC%95%E5%9D%97-index-block-3">索引块 Index Block [3]</a></li>
<li><a href="#sstable%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2%E8%BF%87%E7%A8%8B-6">SSTable的数据检索过程 [6]</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h2><span id="rocksdb-sst-类型12">Rocksdb SST 类型[1][2]</span><a href="#rocksdb-sst-类型12" class="header-anchor">#</a></h2><ul>
<li><p>BlockBasedTable [本文重点讨论]<br>**an overview of the block-based table type in Rocksdb, which is inherited from LevelDB. **<br>Data is stored in fixed-sized blocks, which can be compressed and encoded for efficient storage. To retrieve data, the block where the record may reside is located and read into memory, and a search is performed within the block. The block cache is used to avoid frequent reads of the same block.<br><strong>Rocksdb 中基于块的表类型的概述，该类型继承自 LevelDB。</strong><br>数据存储在固定大小的块中，可以压缩和编码以实现高效存储。为了检索数据，需要定位并读入可能包含记录的块，并在块内执行搜索。块缓存用于避免频繁读取相同的块。</p>
</li>
<li><p>Plain table</p>
</li>
</ul>
<h2><span id="rocksdb-sst-blockbasedtable-5">Rocksdb SST- BlockBasedTable [5]</span><a href="#rocksdb-sst-blockbasedtable-5" class="header-anchor">#</a></h2><img src="/www6vHomeHexo/2023/04/06/rocksdbSST/rocksdbSST.jpg" class>


<table>
<thead>
<tr>
<th>名称</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Footer</td>
<td>指出 IndexBlock 和 MetaIndexBlock 在文件中的偏移量信息，它是元信息的元信息，它位于 sstable 文件的尾部</td>
</tr>
<tr>
<td>IndexBlock</td>
<td>记录了 DataBlock 相关的元信息</td>
</tr>
<tr>
<td>MetaIndexBlock</td>
<td>各个元信息的Block，包括Filter、Properties(整个table的属性信息)、Compression dictionary、Range deletion tombstone</td>
</tr>
<tr>
<td>MetaBlock</td>
<td>存储布隆过滤器的二进制数据 及其他元信息数据</td>
</tr>
<tr>
<td>DataBlock</td>
<td>存储实际的数据即键值对内容</td>
</tr>
</tbody></table>
<h3><span id="索引块-index-block-3">索引块 Index Block [3]</span><a href="#索引块-index-block-3" class="header-anchor">#</a></h3><p>索引块用于查找包含指定key的数据块。是一种基于<strong>二分搜索</strong>的数据结构。一个文件可能包含一个索引块，也可能包含一组分区索引块，这取决于使用配置。即存在全局索引与分区索引两种索引方式。</p>
<h3><span id="sstable的数据检索过程-6">SSTable的数据检索过程 [6]</span><a href="#sstable的数据检索过程-6" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/04/06/rocksdbSST/querySST.jpg" class>

<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://github.com/facebook/rocksdb/wiki/A-Tutorial-of-RocksDB-SST-formats">A Tutorial of RocksDB SST formats</a></li>
<li><a href="https://github.com/facebook/rocksdb/wiki/Rocksdb-BlockBasedTable-Format">Rocksdb BlockBasedTable Format</a></li>
<li><a href="https://www.yii666.com/blog/334918.html">RocksDB基本架构与原理介绍</a></li>
<li><a href="https://leveldb-handbook.readthedocs.io/zh/latest/sstable.html">leveldb  sstable</a> ***  未</li>
<li><a href="https://www.jianshu.com/p/d6ce3593a69e">RocksDB block-based SST 文件详解</a> *** </li>
<li><a href="https://zhuanlan.zhihu.com/p/37633790">浅析RocksDB的SSTable格式</a></li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
        <category>KV</category>
        <category>RocksDB</category>
      </categories>
      <tags>
        <tag>RocksDB</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase - LSM-Tree</title>
    <url>/www6vHomeHexo/2023/04/02/hbaselsmTree/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h3><span id="column-family和lsm-tree">column family和LSM-tree</span><a href="#column-family和lsm-tree" class="header-anchor">#</a></h3><p><strong>column family本质上是一颗LSM-tree</strong>。</p>
<img src="/www6vHomeHexo/2023/04/02/hbaselsmTree/LSM-tree.JPG" class title="hbase中的LSM-tree实现">

<ul>
<li>LSM-Tree的核心思想就是将写入推迟(Defer)并转换为批量(Batch)写，首先将大量写入缓存在内存，当积攒到一定程度后，将他们批量写入文件中，这要一次I&#x2F;O可以进行多条数据的写入，充分利用每一次I&#x2F;O。</li>
<li><strong>LSM-Tree是对写操作友好的索引结构； 将写入操作全部转化为磁盘的顺序写入。一次随机IO写入转换成一次顺序IO写入（HLog顺序写）和一次内存写入（MemStore写入）。</strong></li>
<li><strong>为了提高读取效率， LSM-tree设计了异步的Compaction</strong>， 小文件合并成大文件（<strong>归并排序</strong>）。</li>
</ul>
<h3><span id="hbase的存储lsm-tree">HBase的存储[lsm-tree]</span><a href="#hbase的存储lsm-tree" class="header-anchor">#</a></h3><ul>
<li>MemStore<br>由两个ConcurrentSkipListMap实现（双缓冲）;<br>ConcurrentSkipListMap A异步flush罗盘成HFile;<br>**HDFS只允许顺序读写，MemStore在落盘生成HFile之前完成kv的排序；  **</li>
<li>HFile<br><strong>HFile Data Block（文件读取的最小单元）内的kv是按key排序的索引树，对读友好</strong>；<br>HFile Index Block的索引结构分为两种: V1 单层索引， V2 多级索引（只加载部分索引，降低内存使用）<br>HDFS的Block默认是64M，128M；HBase的Block默认是64K；<img src="/www6vHomeHexo/2023/04/02/hbaselsmTree/HFile.JPG" class title="HFile物理结构"></li>
</ul>
<table>
<thead>
<tr>
<th align="center">Block Type</th>
<th align="center">基本介绍</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Data Block</td>
<td align="center">用户Key-Value</td>
</tr>
<tr>
<td align="center">Meta Block</td>
<td align="center">Bloom过滤器相关元数据</td>
</tr>
<tr>
<td align="center">Root Index</td>
<td align="center">HFile索引树根索引</td>
</tr>
<tr>
<td align="center">Intermediate Level Index</td>
<td align="center">HFile索引树中间层级索引</td>
</tr>
<tr>
<td align="center">Leaf Level Index</td>
<td align="center">HFile索引树叶子索引</td>
</tr>
</tbody></table>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://kernelmaker.github.io/lsm-tree">【Paper笔记】The Log structured Merge-Tree（LSM-Tree）</a></li>
<li>《Hbase原理和实践》 胡争  范欣欣   第1,2,5,7，8章</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>存储</category>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>hbase</tag>
      </tags>
  </entry>
  <entry>
    <title>开闭原则 - SPI</title>
    <url>/www6vHomeHexo/2023/04/02/designOCPspi/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="开闭原则open-closed-principle">开闭原则（Open Closed Principle）</span><a href="#开闭原则open-closed-principle" class="header-anchor">#</a></h2><p><em>open for extension, but closed for modification</em></p>
<h2><span id="开闭原则实现-spi">开闭原则实现 - SPI</span><a href="#开闭原则实现-spi" class="header-anchor">#</a></h2><ul>
<li>SPI<ul>
<li>Java SPI</li>
<li>Dubbo SPI<br><code>ExtensionLoader</code></li>
<li>Spring SPI<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">@Order(Ordered.LOWEST_PRECEDENCE)</span><br><span class="line">public interface MyBeanPostProcessor extends BeanPostProcessor &#123;</span><br><span class="line">   // define your methods here</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><p><a href="https://www.cnblogs.com/mpyidudu/p/15808383.html">Java SPI机制以及和Dubbo&#x2F;Spring SPI对比 </a></p>
<p><a href="https://www.bilibili.com/video/BV1zp4y1q7fg/">面试官问烂的Dubbo中SPI机制的源码解析</a> *** 未<br><a href="https://zhuanlan.zhihu.com/p/580004065">源码级深度理解 Java SPI</a>  未<br><a href="https://zhuanlan.zhihu.com/p/529674338">剖析 SPI 在 Spring 中的应用</a> 未</p>
]]></content>
      <categories>
        <category>架构</category>
        <category>设计原则</category>
      </categories>
      <tags>
        <tag>设计原则</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 文件系统</title>
    <url>/www6vHomeHexo/2023/02/26/mqRocketmqStorage/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="rocketmq-文件系统">RocketMQ 文件系统</span><a href="#rocketmq-文件系统" class="header-anchor">#</a></h2><h5><span id="overview-8">Overview [8]</span><a href="#overview-8" class="header-anchor">#</a></h5><img src="/www6vHomeHexo/2023/02/26/mqRocketmqStorage/mqRocketmqFile.png" class title="rocketmq文件系统">

<h5><span id="逻辑存储层">逻辑存储层</span><a href="#逻辑存储层" class="header-anchor">#</a></h5><ul>
<li>Overview<img src="/www6vHomeHexo/2023/02/26/mqRocketmqStorage/rocketmq-storage.png" class width="720" height="468" title="逻辑存储层"></li>
</ul>
<img src="/www6vHomeHexo/2023/02/26/mqRocketmqStorage/rocketmq-file.png" class title="逻辑存储层">

<ul>
<li>ComsumerQueue[10]<img src="/www6vHomeHexo/2023/02/26/mqRocketmqStorage/ComsumerQueue.JPG" class title="ComsumerQueue"></li>
</ul>
<h5><span id="存储映像层8">存储映像层[8]</span><a href="#存储映像层8" class="header-anchor">#</a></h5><p>mappedByteBuffer 则是一块映射到 CommitLog 文件的内存（具体可以了解 mmap ）</p>
<h6><span id="刷盘机制38">刷盘机制[3][8]</span><a href="#刷盘机制38" class="header-anchor">#</a></h6><ul>
<li>同步刷盘</li>
<li>异步刷盘</li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><h5><span id="存储">存储</span><a href="#存储" class="header-anchor">#</a></h5><ol start="3">
<li><p><a href="https://yq.aliyun.com/articles/66110?spm=a2c4e.11155435.0.0.2cb97b3fBOIG8W">RocketMQ 关键特性</a> ***</p>
</li>
<li><p><a href="https://blog.csdn.net/xxxxxx91116/article/details/50333161">《RocketMq》二、存储篇</a>  *</p>
</li>
<li><p><a href="https://blog.csdn.net/gh670011677/article/details/75095469">分布式消息队列RocketMQ与Kafka架构上的巨大差异之2 – CommitLog与ConsumeQueue</a> **</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/396726719">分布式开放消息系统(RocketMQ)的原理与实践</a>   CHEN川  ***  消息的顺序问题  消息的重复问题</p>
</li>
<li><p><a href="https://blog.csdn.net/sjzsylkn/article/details/121897405">RocketMQ架构原理解析（三）：消息索引（ConsumeQueue &amp; IndexFile）</a> 未</p>
</li>
<li><p><a href="https://www.cnblogs.com/enoc/p/rocketmq-so-no-yon.html">RocketMQ源码详解 | Broker篇 · 其二：文件系统</a>  消息管理的结构层次  ***</p>
</li>
<li><p><a href="https://www.cnblogs.com/enoc/p/rocketmq-so-no-gou.html">RocketMQ源码详解 | Broker篇 · 其三：CommitLog、索引、消费队列</a>  未  </p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV173411H7JR/">【IT老齐134】请简述RocketMQ消息存储与检索原理</a>       ***</p>
</li>
</ol>
]]></content>
      <categories>
        <category>消息系统</category>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>消息系统</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型</title>
    <url>/www6vHomeHexo/2023/02/17/gptLargeModel/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p>1xx. <a href="http://arthurchiao.art/blog/llm-practical-guide-zh/">[译][论文] 大语言模型（LLM）综述与实用指南（Amazon，2023）</a>   实战  未<br>1xx. <a href="https://zhuanlan.zhihu.com/p/597586623">通向AGI之路：大型语言模型（LLM）技术精要</a> *** </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/671710012">高效大语言模型：综述</a>  *** 大模型各个维度的优化<br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403847&idx=1&sn=9af731e9f8418a2d869f5464530c8bd6">必看的十二个大模型前沿综述：兼论HALO大模型幻觉检测与缓解方案及Google小模型预测大模型训练不稳定的探索 </a> 12个综述</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>大模型</category>
      </categories>
      <tags>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer-实现</title>
    <url>/www6vHomeHexo/2023/02/16/gptTransformerCode/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p>1xx. <a href="https://github.com/www6v/AIGC/blob/master/transformer/transformer.ipynb">transformer.ipynb</a> git<br>   <a href="https://www.bilibili.com/video/BV1nc411y7m4/">Transformer代码实现</a></p>
<p>1xx. <a href="https://paperswithcode.com/method/transformer">Transformer</a><br>   <a href="https://github.com/tunz/transformer-pytorch/blob/e7266679f0b32fd99135ea617213f986ceede056/model/transformer.py#L201">transformer.py</a> git</p>
<p>1xx. <a href="http://arthurchiao.art/blog/transformers-from-scratch-zh/">Transformers from scratch</a> V, github<br>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/130090649">从零实现Transformer的简易版与强大版：从300多行到3000多行</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Transformer</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>COT</title>
    <url>/www6vHomeHexo/2023/02/08/gptCOT/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="cot4">CoT[4]</span><a href="#cot4" class="header-anchor">#</a></h1><ul>
<li><p>CoT(Chain of Thought)</p>
<ul>
<li>CoT-SC(Self Consistency)</li>
</ul>
</li>
<li><p>ToT(Tree of Thoughts)<br>分为了Thought Decomposition，Thought Generator，State Evaluator，Search algorithms</p>
</li>
<li><p>GoT(Graph of Thoughts)</p>
</li>
<li><p>AoT(Algorithm of Thoughts)</p>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol start="4">
<li><a href="https://zhuanlan.zhihu.com/p/654034193">2023年能够解决复杂问题的思维链技术：Cot，ToT，GoT，AoT</a></li>
</ol>
<p>1xx. <a href="https://github.com/zchuz/CoT-Reasoning-Survey">CoT-Reasoning-Survey </a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404176&idx=1&sn=2eafdf5426bfe1347869b9af268d4238">大模型COT思维链推理的几个关键问题：从评测基准、结构变体到增强方案的系统综述 </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>COT</category>
      </categories>
      <tags>
        <tag>COT</tag>
      </tags>
  </entry>
  <entry>
    <title>医疗大模型</title>
    <url>/www6vHomeHexo/2023/02/07/gptDomainMed/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h3><span id="医疗大模型">医疗大模型</span><a href="#医疗大模型" class="header-anchor">#</a></h3><ul>
<li>LLaMA<ul>
<li>ChatDoctor  </li>
<li>华驼&#x2F;本草  哈工大</li>
<li>PMC-LLaMA 上海交大</li>
</ul>
</li>
<li>ChatGLM-6B<ul>
<li>ChatGLM-Med  哈工大</li>
<li>DoctorGLM</li>
<li>明医 (MING)  MedicalGPT-zh  上海交通大学</li>
</ul>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402886&idx=1&sn=0552d60744645a84d13bb0cef57f321c">再看23个医疗领域微调大模型集合：兼看CareLlama医疗模型的一些实践经验与开放医疗数据 </a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402589&idx=1&sn=3ba9d50fad433adeb8dd6c623b06c42d">大模型遇上心理健康咨询：MeChat、QiaoBan、SoulChat、MindChat四大心理健康领域微调模型总结 </a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402638&idx=1&sn=b9329498806e2b93b2d6817a17941bff">大模型常见错误、反馈的来源及自我修正方法：兼论两个有趣的同名中医微调垂域模型 </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>垂类大模型</category>
      </categories>
      <tags>
        <tag>垂类大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>测评</title>
    <url>/www6vHomeHexo/2023/02/07/gptEval/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402223&idx=1&sn=f2ec30cd04600129bb90bc9c81413d95">一些讨论：三张关于大模型微调方案的脑图及几点llama2等行业落地的问题思考 </a><br>1xx. <a href="https://github.com/CLUEbenchmark/SuperCLUE-Llama2-Chinese">https://github.com/CLUEbenchmark/SuperCLUE-Llama2-Chinese</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402549&idx=1&sn=07a8af1db44df6125939c5c9e90f6267">如何让自己的大模型榜单评分更高：也谈榜单评测评分的一些常见方案和典型案例 </a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403046&idx=1&sn=0a9b612e9790c0bf49d5cede8fda365c">大模型落地的一些前沿观点：兼看知识图谱增强大模型问答的几个方案及CEVAL榜单评测启发 </a> 二、CEVAL榜单评测中能够得到一些启示<br><a href="https://github.com/hkust-nlp/ceval/blob/main/resources/tutorial.md">1. C-Eval 数据集评测简明教程</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403295&idx=1&sn=126c949d0a00eb85b4a3a6b0106f55a6&poc_token=HApExGWjou7N5NVcTKmJpWt9LZ8ul6wynjV5VHnQ">大模型B端落地“牛刀杀鸡”的奇怪感觉：兼看CEVAl通用评测到金融、医疗两大垂域评测的转变 </a>   CEVAl</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>eval</category>
      </categories>
      <tags>
        <tag>eval</tag>
      </tags>
  </entry>
  <entry>
    <title>STF 数据</title>
    <url>/www6vHomeHexo/2023/02/06/gptSTFData/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#stf-%E6%95%B0%E6%8D%AE%E7%BB%84%E5%90%881">STF 数据组合[1]</a><ul>
<li><a href="#%E9%97%AE%E9%A2%98">问题</a></li>
<li><a href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C">实验结果</a></li>
</ul>
</li>
<li><a href="#sft%E6%95%B0%E6%8D%AE%E9%9B%86">SFT数据集</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="stf-数据组合1">STF 数据组合[1]</span><a href="#stf-数据组合1" class="header-anchor">#</a></h1><p>《HOW ABILITIES IN LARGE LANGUAGE MODELS ARE AFFECTED BY SUPERVISED FINE-TUNING DATA COM- POSITION》</p>
<h3><span id="问题">问题</span><a href="#问题" class="header-anchor">#</a></h3><p>1、推理、编码和通用能力如何随SFT数据量而变化？<br>2、在SFT中结合三种能力时是否存在性能冲突？<br>3、导致性能冲突的关键因素是什么？<br>4、不同的SFT策略对组合数据有什么影响？</p>
<h3><span id="实验结果">实验结果</span><a href="#实验结果" class="header-anchor">#</a></h3><p>1、不同的能力表现出不同的扩展模式，在数据量相同的情况下，较大的模型通常表现出更优越的性能。<br>2、随着数据量的持续增加，数学推理和代码生成能力也在不断提高，一般能力则是在样本数达到一千左右时才得到提升，且提升速度较慢。<br>3、在数据量较低的情况下，数据组合会带来各种能力的提高，而在数据量较高的情况下，能力则会发生冲突。<br>4、组成数据量会影响性能，而组成比例的影响则微乎其微。</p>
<h1><span id="sft数据集">SFT数据集</span><a href="#sft数据集" class="header-anchor">#</a></h1><p><a href="https://github.com/chaoswork/sft_datasets">开源SFT数据集整理</a></p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404728&idx=2&sn=1cb2203648271720d421c963ebcc03b3">SFT微调的数据组合及训练策略如何影响大模型性能：4个经典问题及实验结论分享 </a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401381&idx=1&sn=c24d896aab990ffdf30107a7c6c1ea4f">再看大模型微调与应用：3大行业18个开源垂直微调模型、微调数据、工具资源及有趣的AIGC应用集合</a> 二 三</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>STF</category>
      </categories>
      <tags>
        <tag>STF</tag>
      </tags>
  </entry>
  <entry>
    <title>幻觉问题</title>
    <url>/www6vHomeHexo/2023/02/06/gptHallucination/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="幻觉-vs-事实性1">幻觉 vs 事实性[1]</span><a href="#幻觉-vs-事实性1" class="header-anchor">#</a></h1><p><strong>幻觉</strong>主要是指LLM生成毫无根据或毫无根据的内容，幻觉可以理解为模型倾向于”生成与某些来源相关的无意义或不真实的内容”。这与<strong>事实性问题</strong>不同，后者强调模型学习、获取和利用事实性知识的能力。</p>
<p>举例说明两者的<strong>区别</strong>：</p>
<p>如果一个LLM在被要求创作”一个关于兔子和狼交朋友的童话故事”时，创作出了一个关于”兔子和狗交朋友”的故事，那么它就表现出了幻觉。不过，这并不一定是事实性错误。<br>如果生成的内容包含准确的信息，但与提示的具体内容有出入，那就是<strong>幻觉</strong>，而<strong>不是事实性问题</strong>。<br>例如，如果LLM的输出包含了比提示指定更多的细节或不同的元素，但事实仍然正确，这就是<strong>幻觉</strong>。</p>
<p>相反，如果LLM避免给出直接答案，而是说”我不知道”，或者给出了一个准确的答案，但遗漏了一些正确的细节，那么这就是<strong>事实性问题</strong>，而<strong>不是幻觉</strong>。</p>
<p>此外，值得注意的是，<strong>幻觉有时会产生一些内容，虽然与原始输入内容有偏差，但在事实方面仍然是准确的</strong>。</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404394&idx=1&sn=d7cfcf2cd9aa6756d3cbff938f5f4cf2">再看大模型事实性的界定、错误的起因、评估及前沿缓解方案：Survey on Factuality in LLMS</a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403998&idx=1&sn=400cc902434bc04df508a55e192d2455">再看大模型幻觉问题如何缓解 ：Chain-of-Verification-一种基于链式验证思想的自我修正工作解读 </a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648405983&idx=2&sn=95dc9c7a12bed99b63c775d4b90519d8">也看缓解大模型幻觉的多阶段RAG框架：加入混合检索、过程理由生成与验证的方案 </a></p>
<p>1xx. <a href="https://arxiv.org/abs/2309.01219">大模型幻觉综述</a><br>   <a href="https://arxiv.org/abs/2309.05922">大模型幻觉综述</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648405791&idx=2&sn=d7dada69e6d5ab5fba1333d234b947ef">网络安全领域微调模型SecGPT：兼看大模型幻觉的度量方式、评估benchmark及RAG增强不同方式 </a> 大模型幻觉综述</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403602&idx=1&sn=f2365b05630094f8d0de7ff784abe233">大模型前沿热点最新综述：大模型微调遗忘、Agent智能体、幻觉及RAG检索增强模型推介</a> 大模型微调遗忘</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403341&idx=1&sn=86cdaaf2c3a73439d2591a2f3dd0b9e0">值得一读的大模型生成幻觉研究综述：大模型幻觉的起因、评估以及减轻策略总结 </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Hallucination</category>
      </categories>
      <tags>
        <tag>Hallucination</tag>
      </tags>
  </entry>
  <entry>
    <title>数据处理</title>
    <url>/www6vHomeHexo/2023/02/05/gptDataProcess/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%80%9A%E7%94%A8-1">数据处理[通用] [1]</a><ul>
<li><a href="#%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4">质量过滤</a></li>
<li><a href="#%E5%86%97%E4%BD%99%E5%8E%BB%E9%99%A4">冗余去除</a></li>
<li><a href="#%E9%9A%90%E7%A7%81%E6%B6%88%E9%99%A4">隐私消除</a></li>
<li><a href="#%E8%AF%8D%E5%85%83%E5%88%87%E5%88%86">词元切分</a></li>
</ul>
</li>
<li><a href="#%E6%A1%88%E4%BE%8B">案例</a><ul>
<li><a href="#%E5%8D%83%E5%B8%86llama-2%E4%B8%AD%E6%96%87%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D-sft2">千帆Llama 2中文增强技术介绍-SFT[2]</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA">数据增强</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%B2%BE%E7%AE%80">数据精简</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94">数据配比</a></li>
</ul>
</li>
<li><a href="#%E5%BA%A6%E5%B0%8F%E6%BB%A1%E8%BD%A9%E8%BE%95%E9%87%91%E8%9E%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B4">度小满轩辕金融大模型[4]</a><ul>
<li><a href="#%E9%80%9A%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E6%B5%81%E6%B0%B4%E7%BA%BF">通用的数据清洗流水线</a></li>
<li><a href="#%E5%A2%9E%E9%87%8F%E9%A2%84%E8%AE%AD%E7%BB%83-%E6%9C%80%E4%BD%B3%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94">增量预训练 最佳数据配比</a></li>
<li><a href="#%E6%9E%84%E9%80%A0%E9%80%9A%E7%94%A8%E5%92%8C%E9%87%91%E8%9E%8D%E6%8C%87%E4%BB%A4%E6%95%B0%E6%8D%AE">构造通用和金融指令数据</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%BE%AE%E8%B0%83%E6%8C%87%E4%BB%A4%E7%9A%84%E7%94%9F%E6%88%90-2021">微调指令的生成 [20][21]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#overview">overview</a></li>
<li><a href="#%E6%8C%87%E4%BB%A4%E6%95%B0%E6%8D%AE">指令数据</a></li>
<li><a href="#%E5%85%B6%E4%BB%96">其他</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="数据处理通用-1">数据处理[通用] [1]</span><a href="#数据处理通用-1" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/02/05/gptDataProcess/data_process.png" class>

<h3><span id="质量过滤">质量过滤</span><a href="#质量过滤" class="header-anchor">#</a></h3><ul>
<li>基于分类器的方法</li>
<li>基于启发 式的方法</li>
</ul>
<h3><span id="冗余去除">冗余去除</span><a href="#冗余去除" class="header-anchor">#</a></h3><p>可以在<strong>句子级</strong>、<strong>文档级</strong>和<strong>数据集级</strong>等不同粒度上去重<br>在实践中应该 共同使用这三个级别的去重</p>
<h3><span id="隐私消除">隐私消除</span><a href="#隐私消除" class="header-anchor">#</a></h3><h3><span id="词元切分">词元切分</span><a href="#词元切分" class="header-anchor">#</a></h3><ul>
<li>BPE</li>
<li>WordPiece</li>
<li>Unigram 词元分析</li>
</ul>
<h1><span id="案例">案例</span><a href="#案例" class="header-anchor">#</a></h1><h2><span id="千帆llama-2中文增强技术介绍-sft2">千帆Llama 2中文增强技术介绍-SFT[2]</span><a href="#千帆llama-2中文增强技术介绍-sft2" class="header-anchor">#</a></h2><h3><span id="数据增强">数据增强</span><a href="#数据增强" class="header-anchor">#</a></h3><ul>
<li>Self-instruct</li>
<li>wizard [3]</li>
</ul>
<h3><span id="数据精简">数据精简</span><a href="#数据精简" class="header-anchor">#</a></h3><ul>
<li>低质量过滤</li>
<li>相似数据过滤</li>
</ul>
<h3><span id="数据配比">数据配比</span><a href="#数据配比" class="header-anchor">#</a></h3><ul>
<li>领域数据</li>
<li>多语言数据</li>
</ul>
<h2><span id="度小满轩辕金融大模型4">度小满轩辕金融大模型[4]</span><a href="#度小满轩辕金融大模型4" class="header-anchor">#</a></h2><h3><span id="通用的数据清洗流水线">通用的数据清洗流水线</span><a href="#通用的数据清洗流水线" class="header-anchor">#</a></h3><ul>
<li>文本抽取<ul>
<li>多来源数据收集</li>
<li>正文提取</li>
</ul>
</li>
<li>数据清洗<ul>
<li>规则过滤</li>
<li>模型过滤</li>
</ul>
</li>
<li>去重与校验<ul>
<li>MinHashLSH</li>
<li>质量校验</li>
</ul>
</li>
</ul>
<h3><span id="增量预训练-最佳数据配比">增量预训练 最佳数据配比</span><a href="#增量预训练-最佳数据配比" class="header-anchor">#</a></h3><ul>
<li><p><strong>英文数据  vs 中文数据</strong><br><strong>1  :  3</strong></p>
</li>
<li><p>中文数据中的  <strong>通用数据 vs 金融数据</strong><br>从 9:1 变成  <strong>4:1</strong></p>
<ul>
<li>通用领域指令数据<br> 8大类 50小类</li>
<li>金融领域指令数据<br> 4大类 20小类</li>
</ul>
</li>
</ul>
<h3><span id="构造通用和金融指令数据">构造通用和金融指令数据</span><a href="#构造通用和金融指令数据" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/02/05/gptDataProcess/data.jpeg" class>
<ul>
<li>Self-Instruct[5]</li>
<li>Evol-Instruct[5]</li>
</ul>
<h1><span id="微调指令的生成-2021">微调指令的生成 [20][21]</span><a href="#微调指令的生成-2021" class="header-anchor">#</a></h1><h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li>《大规模语言模型》 </li>
<li>《千帆增强版 Llama 2》 百度 有ppt</li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401462&idx=1&sn=764f0302918174cea29ae22ac5760033">如何构造复杂多样的微调指令数据：WizardLM复杂指令构造思想与实验分析工作总结 </a> </li>
<li>《金融行业实战：度小满轩辕金融大模型应用探索与开发实践》 百度  有ppt</li>
<li><a href="/www6vHomeHexo/2023/01/06/gptInstructTuning/" title="Instruct Tuning">Instruct Tuning</a></li>
</ol>
<h3><span id="overview">overview</span><a href="#overview" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/620890799">Data-centric Artificial Intelligence: A Survey</a><br>   <a href="https://cloud.tencent.com/developer/article/2359824">机器学习数据工程的概述</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/639207933">大模型时代下数据的重要性</a> 综述</p>
<p>1xx. <a href="https://hub.baai.ac.cn/view/28740">大模型研发核心：数据工程、自动化评估及与知识图谱的结合</a><br>   <a href="https://mp.weixin.qq.com/s/SvDnQD886E3DBtw8k9asgg">大模型研发核心：数据工程、自动化评估及与知识图谱的结合 </a></p>
<h3><span id></span><a href="#" class="header-anchor">#</a></h3><p>1xx. <a href="https://finisky.github.io/textbooks-are-all-you-need-summary/">数据为王: Textbooks Are All You Need </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/641013454">数据为王：大模型预训练中的数据处理及思考—The RefinedWeb Dataset for Falcon LLM论文解读</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s/c50HrOfKOqgqGPVRHf6EpA">大模型微调究竟需要多少数据：从三个现有代表工作看几组结论及一点思考 </a><br>   &lt;&lt;LIMa：Less Is More for Alignment&gt;&gt;</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402104&idx=1&sn=7d4924b2a5a840e4ff3de43299248b1d">再谈大模型的预训数据清洗与微调数据生成：RedPajama数据处理框架与entity-centric指令生成方法解读 </a><br>    llama数据的复现项目SlimPajama</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401484&idx=1&sn=c49b5ca5fc962ca757d3a082b74f037a">“超越LLama 65B”的Falcon40B语言模型为什么好：再看精细化的数据清洗的重要性 </a> </p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399792&idx=1&sn=c70e1d13b68399b0c19cfbf658f35d77">面向大模型微调的instruction指令自动化生成技术：SELF-INSTRUCT指令自动化生成框架工作介绍</a></p>
<h3><span id="指令数据">指令数据</span><a href="#指令数据" class="header-anchor">#</a></h3><ol start="20">
<li><p><a href="https://zhuanlan.zhihu.com/p/650596719">大模型SFT微调指令数据的生成</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/618334308">让ChatGPT生成训练ChatGPT的训练数据</a></p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/658128530">如何从数据集中自动识别高质量的指令数据-IFD指标的使用</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/671183709">大模型微调技巧 | 高质量指令数据筛选方法-MoDS</a></p>
<h3><span id="其他">其他</span><a href="#其他" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/420295576">哈工大｜15种NLP数据增强方法总结与对比</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403976&idx=1&sn=694db5e2b3085b1610e8d19daa93a474">再看大模型预训数据质量如何评估：困惑度、错误L2范数和记忆化三种度量方法的效果对比分析研究</a></p>
<p>1xx. <a href="https://developer.aliyun.com/article/1311807">InsTag：大语言模型监督微调数据标签标注工具</a><br>   <a href="https://www.modelscope.cn/studios/lukeminglkm/instagger_demo/summary">InsTag指令打标工具</a> demo</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400849&idx=1&sn=58006756cccde4d06d273df59e2c8dd8">开源大模型如何更好地适应中文场景：LLAMA扩充词表、BLOOM裁剪词表基本原理与开源实现</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataProcess</category>
      </categories>
      <tags>
        <tag>dataProcess</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP 任务</title>
    <url>/www6vHomeHexo/2023/02/05/gptNLPTask/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="nlp任务">NLP任务</span><a href="#nlp任务" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/02/05/gptNLPTask/NLP_tasks.jpg" class>


<ul>
<li><strong>文本摘要</strong> text summarization</li>
<li>信息提取 information extraction</li>
<li><strong>问答</strong> question answering</li>
<li><strong>文本分类</strong> text classification</li>
<li>对话 conversation</li>
<li>代码生成 code generation</li>
<li><strong>推理</strong> reasoning</li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Toolformer</title>
    <url>/www6vHomeHexo/2023/02/03/gptToolformer/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="toolformer1">Toolformer[1]</span><a href="#toolformer1" class="header-anchor">#</a></h1><ul>
<li>🔗 文章：Toolformer: Language Models Can Teach Themselves to Use Tools <a href="https://arxiv.org/abs/2302.04761">https://arxiv.org/abs/2302.04761</a></li>
<li>🔑关键词和摘要<ul>
<li>Keywords: Large-scale PLMs,  Tool Learning</li>
<li>xxx<ul>
<li>驱动语言模型去使用简单的模型来调用外部的工具</li>
<li>Toolformer通过语言模型的方法去决定去调用哪些API，传入哪些参数</li>
<li>Tooformer是在自监督层面执行的，只需要对每个API的语言描述</li>
</ul>
</li>
</ul>
</li>
<li>⚙️研究设计和结论<ul>
<li>方法   <ul>
<li>Toolformer调用示例：xxx</li>
<li>关键要素：<ul>
<li>模型对工具的使用应该是自监督的，这样可以省去很大的标注开销</li>
<li>模型应该自行地去决定在何时间，用何方法来调用工具</li>
</ul>
</li>
<li><strong>方法概要：</strong><ul>
<li>受到in-context learning的启发，给定少量的人写的关于API的描述，让模型去自行生成潜在API调用的语言建模数据</li>
<li>构建一个自监督的Loss函数，让模型来决定哪些API的调用有助于它的语言建模的预测</li>
</ul>
</li>
<li><strong>方法细节：</strong><ul>
<li>xxx<ul>
<li>给定一个纯文本数据集，构建出一个带有API调用的数据集，然后在此数据集上做微调</li>
<li>第一步：使用in-context learning来生成大量的潜在可能的API调用</li>
<li>第二步：执行这些API，返回得到结果</li>
<li>第三步：检查返回的结果是否有助于语言模型的预测，过滤掉其他的API</li>
</ul>
</li>
<li>API调用采样<ul>
<li>给每一个API来撰写提示来鼓励模型使用这些API，例如QA的提示是 xxx</li>
<li>对于文本的每一个位置，如果这个位置是<api>（即API调用的开始）的概率大于一个阈值，则将此位置保留到一个集合I中</api></li>
<li>对于集合I中的每一个位置，通过模型生成最多m个API调用，并且以结尾（如果生成的调用没有以结尾，直接舍去）</li>
</ul>
</li>
<li>API执行<ul>
<li>去执行所有的API调用，返回文本序列</li>
</ul>
</li>
<li>API过滤<ul>
<li>构建自监督的语言模型的loss函数</li>
<li>第一个的含义：进行API的调用，并且使用API结果的Loss</li>
<li>第二个的含义：空字符串的Loss和调用API但不返回结果Loss的最小值</li>
<li>这时我们希望模型使用API并且返回结果对语言建模有帮助，且帮助很明显-&gt;前者的loss显著比后者小</li>
</ul>
</li>
<li>微调和推理<ul>
<li>在经过如上操作后，就可以得到带有API调用的数据集，然后将模型在上面进行微调</li>
<li>当模型在解码阶段输出”-&gt;”符号时，意味着需要调用API了，调用得到返回结果然后拼接上去</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>实验<ul>
<li>模型：GPT-J （67亿参数）</li>
<li>原始数据：CCNet</li>
<li>知识探测任务LAMA<ul>
<li>Toolformer可以大幅超过之前的方法，甚至是GPT-3等大模型</li>
</ul>
</li>
<li>数学数据集</li>
<li>问答</li>
<li>这里即使是Toolformer也无法超越GPT-3，可见预训练规模可以囊括更多知识</li>
<li>模型规模的影响</li>
<li>模型的参数量到一定规模后才拥有使用工具的能力</li>
</ul>
</li>
</ul>
</li>
<li>📚论文贡献<ul>
<li>优点<ul>
<li>将语言模型使用外部工具的进行很自然的结合</li>
<li><strong>不需要标注大量数据，使用自监督的方法进行学习</strong></li>
</ul>
</li>
<li>缺点<ul>
<li><strong>工具无法交互，也无法链式使用（每个API调用都是独立的）</strong></li>
<li>定义的工具尚且有限，扩展工具则需要用模型标注新的数据</li>
<li>随着基础模型zero-shot能力的增强，这种需要构建数据并且fine-tune的做法可能会比较麻烦</li>
</ul>
</li>
</ul>
</li>
<li>OpenBMB BMTools: <a href="https://github.com/OpenBMB/BMTools">https://github.com/OpenBMB/BMTools</a></li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV18s4y1u7nJ/">清华博士带你搞懂大模型自学工具使用（Toolformer)【论文速读】</a> V 有思维导图<br>1xx. <a href="https://finisky.github.io/toolformer-summary/">使LLM善假于物: Toolformer </a><br>1xx. <a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#external-apis">Prompt Engineering </a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>Tool</tag>
      </tags>
  </entry>
  <entry>
    <title>涌现现象（Emergent）</title>
    <url>/www6vHomeHexo/2023/02/03/gptEmergent/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="emergent-abilities">Emergent Abilities</span><a href="#emergent-abilities" class="header-anchor">#</a></h1><ul>
<li>🔗 文章：Emergent Abilities of Large Language Models  (2022.10)  (arxiv.org)</li>
<li>🔑关键词和摘要<ul>
<li>Keywords: LLMs, Emergent Ability, Scaling</li>
<li>abstract<ul>
<li>不可预测</li>
<li>不能从小模型的的性能外推</li>
<li>是否能通过继续扩大模型规模来获得更多涌现能力</li>
</ul>
</li>
</ul>
</li>
<li>⚙️研究设计和结论<ul>
<li>定义<ul>
<li>通常的涌现现象</li>
<li>大模型的涌现现象<ul>
<li>小模型接近随机</li>
<li><strong>大模型突然出现</strong></li>
<li>相变</li>
</ul>
</li>
<li>实验框架<ul>
<li>performance vs 1. FLOPs, model parameters</li>
<li><input checked disabled type="checkbox"> Training datasets</li>
<li>叠甲：emergent 与很多因素都有关，本文并不是说到哪个 scale 就会出现 emergent，而是说 emergent 现象普遍存在。</li>
</ul>
</li>
<li>实验1<ul>
<li>Few-shot Prompting</li>
<li>测试数据说明:<ul>
<li>A: 三位数加法，两位数乘法</li>
<li>B: [dɪfərənt], 复原 “different,” </li>
<li>C: 从 e l h l o 复原 hello</li>
<li>D: 波斯语问答</li>
<li>E: 针对GPT-3 对抗标的问答</li>
<li>…</li>
</ul>
</li>
<li>结果<ul>
<li>这些 task，以 few-shot 形式展示过以后，都有 emergent</li>
<li>不同模型 emergent scale 不一样</li>
<li>有的 task，只有 540B 的 PaLM  emerge了</li>
</ul>
</li>
</ul>
</li>
<li>实验2<ul>
<li>增强语言模型能力的 emerge 现象</li>
<li>已知的一些大模型技巧在何种规模下发挥作用？<ul>
<li>大模型技巧<ul>
<li>思维链 Chain-of-thought: Let’s think step by step.</li>
<li>指令微调 请写一段XXX的描述</li>
<li>草稿本方法： 计算 15+16, 让模型在草稿本上写“5+6&#x3D;11，进位1”</li>
</ul>
</li>
</ul>
</li>
<li>这些增强语言模型能力的方法都有一定程度的涌现</li>
<li>联想：之前的 prompt tuning，parameter efficient tuning，都是某种随着模型规模扩大的涌现？</li>
</ul>
</li>
</ul>
</li>
<li>讨论<ul>
<li><strong>Emergent 现象的解释</strong><ul>
<li><strong>多步能力说</strong><ul>
<li>每个子能力达到 90%  -&gt; 一无是处</li>
<li>每个子能力达到 95% -&gt; 能完成一些任务了</li>
</ul>
</li>
<li>指标缺陷说</li>
<li>奇怪的现象：交叉熵损失不是 emergent 的，而是在逐步下降</li>
</ul>
</li>
<li><strong>Emergent 的阈值可能会越来越小</strong><ul>
<li>更干净的数据，更好的训练技巧，更优秀的模型结构都可以是  Emergent阈值变小</li>
</ul>
</li>
<li>未来方向：<ul>
<li>继续扩大 model scale，远未达到上限</li>
<li>一些新结构的 scaling</li>
<li>数据的 scaling</li>
<li>理解 prompt 机制</li>
<li>更前沿的 task，用来指导 emergent</li>
<li>理解 emergence</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>📚论文贡献<ul>
<li>优点<ul>
<li>第一次正式提出 emergent 实验</li>
<li><strong>做了充分的实验表明该现象在各种数据集上广泛存在</strong></li>
<li>甚至验证了一些“方法”的涌现</li>
<li>提出了一些解释该现象的观点，并提出质疑</li>
</ul>
</li>
<li>改进点<ul>
<li><strong>还是不知道为啥 emerge</strong></li>
<li>实验采用各种不同模型，无法得出哪个计算量级对哪种能力有 emerge</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://www.bilibili.com/video/BV1qX4y1i78J/">清华博士带你思考大语言模型LLM的涌现现象（Emergent）</a>  有脑图<br> Emergent Abilities of Large Language Models （<a href="https://arxiv.org/abs/2206.07682%EF%BC%89">https://arxiv.org/abs/2206.07682）</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399147&idx=1&sn=6e6d416db50d9708c900ee3b5416bba3">再谈ChatGPT等大模型的涌现能力：关于涌现能力的定义、测试方法及分析工作总结 </a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Emergent</category>
      </categories>
      <tags>
        <tag>Emergent</tag>
      </tags>
  </entry>
  <entry>
    <title>继续-预训练</title>
    <url>/www6vHomeHexo/2023/02/03/gptContinualPretraining/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="继续-预训练-continual-pre-training-1">继续-预训练 continual pre-training [1]</span><a href="#继续-预训练-continual-pre-training-1" class="header-anchor">#</a></h1><ul>
<li><p>继续预训练的目的<br>为了得到<strong>适应不同行业&#x2F;任务领域</strong>的预训练模型，<strong>提升下游任务的效果</strong></p>
</li>
<li><p>什么时候需要继续预训练？<br><strong>预训练(pre-train)的语料与下游任务(finetune)语料的【数据分布&#x2F;领域差异】大时</strong></p>
</li>
</ul>
<h1><span id="千帆llama-2中文增强技术介绍-postpretrain2">千帆Llama 2中文增强技术介绍-Postpretrain[2]</span><a href="#千帆llama-2中文增强技术介绍-postpretrain2" class="header-anchor">#</a></h1><ul>
<li><p>中文词表构建 +Tokenizer<br>中文词表扩增 29k -&gt; 59k</p>
</li>
<li><p>Embedding<br>在原有Embedding矩阵后追加中文embedding映射</p>
</li>
<li><p>数据配比<br> 中文：英文约1:1</p>
</li>
<li><p>pipeline</p>
<ul>
<li>原始数据集</li>
<li><strong>异常清洗</strong></li>
<li><strong>数据过滤</strong></li>
<li><strong>去重</strong></li>
<li>隐私匿名化</li>
</ul>
</li>
</ul>
<blockquote>
<p>开源大模型预训练语料预处理流程总结： 基于基础规则处理为主 + 基于模型的质量过滤逐步成为趋势</p>
</blockquote>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/545092184">浅谈一下「继续预训练」</a></li>
<li>&lt;&lt;千帆增强版 Llama 2-提升大模型对话指令遵循能力&gt;&gt;<br>1xx. <a href="https://zhuanlan.zhihu.com/p/654463331">如何更好地继续预训练（Continue PreTraining）</a><br>warmup  +  学习率<br>1xx. <a href="https://blog.csdn.net/Kaiyuan_sjtu/article/details/120695507">Don’t stop pretraining，继续预训练！</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>推理-框架</title>
    <url>/www6vHomeHexo/2023/02/02/gptInferenceFramework/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%8E%A8%E7%90%86-%E6%A1%86%E6%9E%B611">推理 框架[1.1]</a></li>
<li><a href="#lmdeploy-%E6%8E%A8%E7%90%86%E5%AE%9E%E6%88%98-3">lmdeploy-推理实战 [3]</a><ul>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2">模型转换</a></li>
<li><a href="#turbomind-%E6%8E%A8%E7%90%86%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%9C%AC%E5%9C%B0%E5%AF%B9%E8%AF%9D">TurboMind 推理+命令行本地对话</a></li>
<li><a href="#turbomind%E6%8E%A8%E7%90%86api%E6%9C%8D%E5%8A%A1">TurboMind推理+API服务</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E6%A1%86%E6%9E%B6">框架</a></li>
<li><a href="#%E5%AE%9E%E6%88%98">实战</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="推理-框架11">推理 框架[1.1]</span><a href="#推理-框架11" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/02/02/gptInferenceFramework/inference.jpg" class>

<ul>
<li><p>server 云端<br>vLLM，TensorRT， deepspeed</p>
</li>
<li><p>pc&#x2F;edge 移动端<br> llama.cpp<br>mlc-llm<br>ollama</p>
</li>
<li><p>服务 Server<br>Triton Server</p>
</li>
</ul>
<h1><span id="lmdeploy-推理实战-3">lmdeploy-推理实战 [3]</span><a href="#lmdeploy-推理实战-3" class="header-anchor">#</a></h1><h3><span id="模型转换">模型转换</span><a href="#模型转换" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/02/02/gptInferenceFramework/convert.png" class>
<h3><span id="turbomind-推理命令行本地对话">TurboMind 推理+命令行本地对话</span><a href="#turbomind-推理命令行本地对话" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/02/02/gptInferenceFramework/infer.png" class>
<h3><span id="turbomind推理api服务">TurboMind推理+API服务</span><a href="#turbomind推理api服务" class="header-anchor">#</a></h3><ul>
<li>启动服务<img src="/www6vHomeHexo/2023/02/02/gptInferenceFramework/infer-api.png" class></li>
<li>Client访问服务<img src="/www6vHomeHexo/2023/02/02/gptInferenceFramework/infer-api-client.png" class></li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="框架">框架</span><a href="#框架" class="header-anchor">#</a></h3><p>1.1. <a href="https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzA5MTIxNTY4MQ==&scene=1&album_id=2959126655292211206">探秘LLM应用开发</a>   8-19</p>
<p>1xx. <a href="https://github.com/www6v/llm-action/tree/main/inference">https://github.com/www6v/llm-action/tree/main/inference</a><br>1xx. <a href="https://www.zhihu.com/question/625415776/answer/3243562246">https://www.zhihu.com/question/625415776/answer/3243562246</a></p>
<h3><span id="实战">实战</span><a href="#实战" class="header-anchor">#</a></h3><ol start="3">
<li><a href="https://github.com/InternLM/tutorial/blob/main/lmdeploy/lmdeploy.md">lmdeploy 量化部署</a><br><a href="https://www.bilibili.com/video/BV1iW4y1A77P/">(5)LMDeploy 大模型量化部署实践</a> V</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/666849728">TensorRT-LLM保姆级教程（一）-快速入门</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/667572720">TensorRT-LLM保姆级教程（二）-离线环境搭建、模型量化及推理</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/669576221">TensorRT-LLM（持续更新）</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/629336492">模型推理服务化框架Triton保姆式教程（一）：快速入门</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/634143650">模型推理服务化框架Triton保姆式教程（二）：架构解析</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/634444666">模型推理服务化框架Triton保姆式教程（三）：开发实践</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Inference</category>
      </categories>
      <tags>
        <tag>Inference</tag>
      </tags>
  </entry>
  <entry>
    <title>《SRE 工作手册》</title>
    <url>/www6vHomeHexo/2023/02/01/sreWorkbook/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<img src="/www6vHomeHexo/2023/02/01/sreWorkbook/sre-workbook.jpg" class title="SRE 知识体系脑图">


<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><p><a href="https://martinliu.cn/blog/sre-knowedge-body-mind-map-live-show/">SRE 实践的知识体系梳理</a></p>
]]></content>
      <categories>
        <category>稳定性</category>
        <category>sre</category>
      </categories>
      <tags>
        <tag>sre</tag>
      </tags>
  </entry>
  <entry>
    <title>可观测性-Tracing</title>
    <url>/www6vHomeHexo/2023/01/28/observabilityTracing/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%8E%9F%E7%90%86-0">原理 [0]</a></li>
<li><a href="#apm-%E4%BA%A7%E5%93%81">APM 产品</a><ul>
<li><a href="#apm%E4%BA%A7%E5%93%81%E6%AF%94%E5%AF%B9-5">APM产品比对 [5]</a></li>
<li><a href="#apm%E4%BA%A7%E5%93%81%E6%AF%94%E5%AF%B9-6">APM产品比对 [6]</a></li>
</ul>
</li>
<li><a href="#%E4%BD%BF%E7%94%A8-9">使用 [9]</a><ul>
<li><a href="#apm-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5">APM 故障排查</a></li>
<li><a href="#apm-%E7%A8%B3%E5%AE%9A%E6%80%A7%E6%8C%87%E6%A0%87">APM 稳定性指标</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><br>  * <a href="#%E6%A0%87%E5%87%86%E5%8E%9F%E7%90%86">标准&amp;原理</a><br>  * <a href="#%E4%B8%9A%E7%95%8C">业界</a><br>  * <a href="#%E4%BD%BF%E7%94%A8">使用</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="原理-0">原理 [0]</span><a href="#原理-0" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/28/observabilityTracing/tracing.JPG" class>

<h1><span id="apm-产品">APM 产品</span><a href="#apm-产品" class="header-anchor">#</a></h1><h3><span id="apm产品比对-5">APM产品比对 [5]</span><a href="#apm产品比对-5" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/01/28/observabilityTracing/apm1.JPG" class>

<h3><span id="apm产品比对-6">APM产品比对 [6]</span><a href="#apm产品比对-6" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/01/28/observabilityTracing/apm.JPG" class>

<h1><span id="使用-9">使用 [9]</span><a href="#使用-9" class="header-anchor">#</a></h1><h3><span id="apm-故障排查">APM 故障排查</span><a href="#apm-故障排查" class="header-anchor">#</a></h3><p>   <img src="https://user-images.githubusercontent.com/5608425/66256533-43942f00-e7c1-11e9-8fe8-80565025c792.png" alt="apm-fault"></p>
<h3><span id="apm-稳定性指标">APM 稳定性指标</span><a href="#apm-稳定性指标" class="header-anchor">#</a></h3><p>   <img src="https://user-images.githubusercontent.com/5608425/66256535-4727b600-e7c1-11e9-82c9-cd2222fce9bb.png" alt="apm-tracing"></p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h5><span id="标准amp原理">标准&amp;原理</span><a href="#标准amp原理" class="header-anchor">#</a></h5><ol start="0">
<li>《25 | 分布式Trace：横跨几十个分布式组件的慢请求要如何排查？》</li>
<li><a href="https://github.com/opentracing-contrib/opentracing-specification-zh/blob/master/specification.md">OpenTracing语义标准</a>  archived</li>
<li><a href="https://wu-sheng.gitbooks.io/opentracing-io/content/pages/spec.html">opentracing文档中文版</a> archived</li>
<li><a href="http://bigbully.github.io/Dapper-translation/">Dapper，大规模分布式系统的跟踪系统</a>  论文</li>
</ol>
<h5><span id="业界">业界</span><a href="#业界" class="header-anchor">#</a></h5><ol start="4">
<li><a href="https://github.com/StabilityMan/StabilityGuide/blob/master/docs/processing/monitor/%E8%99%BE%E7%B1%B3SRE%E5%AE%9E%E8%B7%B5_%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB%E5%8D%87%E7%BA%A7%E4%B9%8B%E8%B7%AF.md">虾米SRE实践_监控体系升级之路</a> ***</li>
<li><a href="https://my.oschina.net/u/3770892/blog/3005395">分布式调用链调研（pinpoint,skywalking,jaeger,zipkin等对比）</a>  对比的表格 ***</li>
<li><a href>微服务架构实战160讲 第四模块 ：微服务调用链监控CAT架构和实践 69.调用链监控产品和比较</a> 杨波</li>
<li><a href="https://www.sofastack.tech/blog/sofa-rpc-link-tracking/">剖析 | SOFARPC 框架之 SOFARPC 链路追踪剖析</a> 未</li>
</ol>
<h5><span id="使用">使用</span><a href="#使用" class="header-anchor">#</a></h5><ol start="8">
<li><a href="https://mp.weixin.qq.com/s/QA_BTF1D3GJJ7_nYQ6oAzQ">如何检测 Web 服务请求丢失问题</a> 问题排查 应用： Nginx tracing + Tomcat tracing</li>
<li><a href="https://yq.aliyun.com/articles/60994?spm=5176.100239.blogcont61320.29.6SwFH6">鹰眼跟踪、限流降级，EDAS的微服务解决之道</a></li>
</ol>
]]></content>
      <categories>
        <category>可观测性</category>
        <category>tracing</category>
      </categories>
      <tags>
        <tag>可观测性</tag>
      </tags>
  </entry>
  <entry>
    <title>可观测性-Log</title>
    <url>/www6vHomeHexo/2023/01/28/observabilityLog/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="log-模型1">Log 模型[1]</span><a href="#log-模型1" class="header-anchor">#</a></h2><img src="/www6vHomeHexo/2023/01/28/observabilityLog/log.JPG" class title="log">

<h2><span id="日志框架">日志框架</span><a href="#日志框架" class="header-anchor">#</a></h2><ul>
<li>ELK，EFK</li>
<li>Loki-基于tag</li>
</ul>
<h2><span id="日志采集">日志采集</span><a href="#日志采集" class="header-anchor">#</a></h2><ul>
<li>Java应用中<ul>
<li>API<ul>
<li>log4j</li>
</ul>
</li>
<li>基于AOP的采集[4]<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="meta">@LogRecord(</span></span><br><span class="line"><span class="meta">     content = &quot;修改了订单的配送地址：从“#oldAddress”, 修改到“#request.address”&quot;,</span></span><br><span class="line"><span class="meta">     operator = &quot;#request.userName&quot;, bizNo=&quot;#request.deliveryOrderNo&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">modifyAddress</span><span class="params">(updateDeliveryRequest request, String oldAddress)</span>&#123;</span><br><span class="line">    <span class="comment">// 更新派送信息 电话，收件人、地址</span></span><br><span class="line">    doUpdate(request);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>容器中[2]</li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li>[微服务架构实战160讲 第七模块 ：微服务监控告警Prometheus架构和实践 119.监控模式分类] 杨波 partial</li>
<li><a href="https://yq.aliyun.com/articles/674327">容器日志采集利器Log-Pilot</a>  阿里开源的Log-Pilot 容器日志采集模式</li>
<li><a href="https://microservices.io/patterns/microservices.html">Pattern: Microservice Architecture</a></li>
<li><a href="https://tech.meituan.com/2021/09/16/operational-logbook.html">如何优雅地记录操作日志？</a>  美团 ***</li>
<li><a href="https://github.com/oldratlee/translations/blob/master/log-what-every-software-engineer-should-know-about-real-time-datas-unifying/README.md">日志：每个软件工程师都应该知道的有关实时数据的统一概念</a>  论文翻译 *** 未</li>
</ol>
]]></content>
      <categories>
        <category>可观测性</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>可观测性</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent-Tools</title>
    <url>/www6vHomeHexo/2023/01/27/gptAgentTool/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h3><span id="tool-learning-with-foundation-models">Tool Learning with Foundation Models</span><a href="#tool-learning-with-foundation-models" class="header-anchor">#</a></h3><p>1xx. <a href="https://github.com/thunlp/ToolLearningPapers">ToolLearningPapers</a> git<br>1xx. <a href="https://arxiv.org/pdf/2304.08354.pdf">Tool Learning with Foundation Models</a> paper<br>1xx. <a href="https://blog.csdn.net/xixiaoyaoww/article/details/130278978">清华发布工具学习框架，让ChatGPT操控地图、股票查询，贾维斯已来？</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/624459759">大模型工具学习权威综述，BMTools 背后的论文！</a></p>
<h3><span id="augmented-language-models">Augmented Language Models</span><a href="#augmented-language-models" class="header-anchor">#</a></h3><p>1xx. <a href="https://blog.csdn.net/qq_39388410/article/details/130798125">Augmented Language Models（增强语言模型）</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/611492200">增强语言模型（ALM）之综述篇</a></p>
<h3><span id="gorilla">Gorilla</span><a href="#gorilla" class="header-anchor">#</a></h3><p>1xx. <a href="https://ar5iv.labs.arxiv.org/html/2305.15334">Gorilla: Large Language Model Connected with Massive APIs</a> paper<br>1xx. <a href="https://apposcmf8kb5033.pc.xiaoe-tech.com/live_pc/l_64a7d5afe4b09d7237a04b5b">Gorilla：链接海量API的大型语言模型</a> V<br>1xx. <a href="https://github.com/ShishirPatil/gorilla">gorilla</a> git<br>1xx. <a href="https://gorilla.cs.berkeley.edu/">Gorilla: Large Language Model Connected with Massive APIs</a><br>1xx. <a href="https://gorilla.cs.berkeley.edu/blog.html">Gorilla blog</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/632583909">大猩猩（Gorilla）🦍，连接大量 API 的大型语言模型，能成为未来AI应用的核心么？</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/640697382">Gorilla：与大规模API相连的大型语言模型</a></p>
<h3><span id="others">Others</span><a href="#others" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/633654195">LLM能够自己制作工具了：详解Large Language Models as Tool Makers</a>  ToolMaker<br>1xx. <a href="https://www.bilibili.com/video/BV1EN4y1q7Zn/">THUNLP成员领读EMNLP大模型工具创造新框架“CREATOR”</a> V 有思维导图 </p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404626&idx=1&sn=da5ac106548dd30f14a57a5ce4d90f08">基于llama7B的文本嵌入模型ANGLE：兼看Agent微调数据的生成方案</a>  AgentTuning</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>agent</category>
      </categories>
      <tags>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>PromptTuning 实战</title>
    <url>/www6vHomeHexo/2023/01/25/gptPromptTuningPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p><a href="https://zhuanlan.zhihu.com/p/646748939">大模型参数高效微调技术实战（二）-Prompt Tuning</a><br><a href="https://zhuanlan.zhihu.com/p/635686756">大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning</a><br><a href="https://github.com/www6v/llm-action/blob/main/train/peft/clm/peft_prompt_tuning_clm.ipynb">peft_prompt_tuning_clm.ipynb</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Prompt-Tuning</category>
      </categories>
      <tags>
        <tag>Prompt-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>不可能三角</title>
    <url>/www6vHomeHexo/2023/01/25/gptImpossibleTriangle/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%921">不可能三角[1]</a><ul>
<li><a href="#%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%92">不可能三角</a></li>
<li><a href="#%E5%BC%A5%E8%A1%A5%E6%96%B9%E6%B3%95">弥补方法</a></li>
</ul>
</li>
<li><a href="#%E5%85%B6%E4%BB%96-%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%92">其他 不可能三角</a><ul>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F">分布式系统</a></li>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8">分布式存储</a></li>
</ul>
</li>
<li><a href="#%E8%8C%83%E5%BC%8F">范式</a><ul>
<li><a href="#pretrain-finetune-%E8%8C%83%E5%BC%8F3">pretrain, finetune 范式[3]</a></li>
<li><a href="#pretrain-prompt-predict-%E8%8C%83%E5%BC%8F3">pretrain, prompt, predict 范式[3]</a></li>
</ul>
</li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
<li><a href="#scaling-law10">Scaling Law[10]</a><ul>
<li><a href="#scaling-law">Scaling Law</a></li>
<li><a href="#%E5%8F%82%E6%95%B0%E9%87%8F-vs-%E6%95%B0%E6%8D%AE%E9%87%8F">参数量 vs 数据量</a></li>
<li><a href="#%E5%8F%82%E6%95%B0%E9%87%8F-vs-%E6%95%B0%E6%8D%AE%E9%87%8F-1">参数量 vs 数据量</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%92-1">不可能三角</a></li>
<li><a href="#scaling-law-1">Scaling Law</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="不可能三角1">不可能三角[1]</span><a href="#不可能三角1" class="header-anchor">#</a></h1><h3><span id="不可能三角">不可能三角</span><a href="#不可能三角" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/01/25/gptImpossibleTriangle/impossibleTriangle.JPG" class>

<ul>
<li>预训练模型之所以是划时代的进展，是它具备了中等尺寸（一张卡即可精调）和全任务SOTA的精调效果</li>
<li>而最近两年预训练模型都在往大尺寸发展，也就是具备了少样本效果，但他们的<strong>少样本效果依旧比不过中等模型的精调</strong></li>
</ul>
<h3><span id="弥补方法">弥补方法</span><a href="#弥补方法" class="header-anchor">#</a></h3><ul>
<li><strong>优化size</strong><ul>
<li>对于减少模型尺寸，一条典型的故事线就是蒸馏。但其中仍存在两个问题：一是学生模型很难达到原始模型的效果，二是原始的大尺寸模型的推理效率太低</li>
</ul>
</li>
<li><strong>优化few-shot</strong><ul>
<li>对于提升少样本表现，<strong>数据增强</strong>是一个好办法，比如用无监督数据做自监督训练、或者基于其他模型生成一些伪样本，但这类方法依旧受限于现有标注样本的多样性，泛化性能提升有限</li>
</ul>
</li>
<li><strong>fine-tuning</strong><ul>
<li>对于提升精调表现和效率（其实也偏少样本），最近一个比较火的故事是prompt，但这种方式对prompt的设计非常敏感，同时效果也很难超过目前的有监督SOTA</li>
</ul>
</li>
</ul>
<h1><span id="其他-不可能三角">其他 不可能三角</span><a href="#其他-不可能三角" class="header-anchor">#</a></h1><h3><span id="分布式系统">分布式系统</span><a href="#分布式系统" class="header-anchor">#</a></h3><ul>
<li>CAP理论<ul>
<li>C 一致性</li>
<li>A 可用性</li>
<li>P 分区</li>
</ul>
</li>
</ul>
<h3><span id="分布式存储">分布式存储</span><a href="#分布式存储" class="header-anchor">#</a></h3><ul>
<li>RUM猜想<ul>
<li>Read-overhead </li>
<li>Update-overhead </li>
<li>Memory-overhead</li>
</ul>
</li>
</ul>
<h1><span id="范式">范式</span><a href="#范式" class="header-anchor">#</a></h1><h3><span id="pretrain-finetune-范式3">pretrain, finetune 范式[3]</span><a href="#pretrain-finetune-范式3" class="header-anchor">#</a></h3><p>第三阶段范式</p>
<h3><span id="pretrain-prompt-predict-范式3">pretrain, prompt, predict 范式[3]</span><a href="#pretrain-prompt-predict-范式3" class="header-anchor">#</a></h3><p>第四阶段范式</p>
<h1><span id="总结">总结</span><a href="#总结" class="header-anchor">#</a></h1><p>根据不可能三角形， pretrain, finetune 范式[3] 向pretrain, prompt, predict 范式[3]的迁移是受大模型大小的影响</p>
<h1><span id="scaling-law10">Scaling Law[10]</span><a href="#scaling-law10" class="header-anchor">#</a></h1><h3><span id="scaling-law">Scaling Law</span><a href="#scaling-law" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/01/25/gptImpossibleTriangle/scalingLaw.jpg" class>

<h3><span id="参数量-vs-数据量">参数量 vs 数据量</span><a href="#参数量-vs-数据量" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/01/25/gptImpossibleTriangle/paramVSdataSize.jpg" class>

<h3><span id="参数量-vs-数据量">参数量 vs 数据量</span><a href="#参数量-vs-数据量" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2023/01/25/gptImpossibleTriangle/computeVSDatasize.jpg" class>


<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="不可能三角">不可能三角</span><a href="#不可能三角" class="header-anchor">#</a></h3><ol>
<li><a href="https://zhuanlan.zhihu.com/p/501381510">预训练模型的下一步？突破Impossible Triangle</a></li>
<li><a href="https://arxiv.org/pdf/2204.06130.pdf">Impossible Triangle: What’s Next for Pre-trained Language Models?</a></li>
<li><a href="https://blog.csdn.net/zandaoguang/article/details/124395479">微软朱晨光：预训练模型下一步怎么走？突破PLM的「不可能三角」</a></li>
<li><a href="/www6vHomeHexo/2023/01/06/gptPromptTuning/" title="Prompt Tuning">Prompt Tuning</a> self</li>
</ol>
<h3><span id="scaling-law">Scaling Law</span><a href="#scaling-law" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://zhuanlan.zhihu.com/p/667489780">解析大模型中的Scaling Law</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/663296750">论文阅读，大模型的缩放定律，Scaling Laws for Neural Language Models</a><br>2xx. <a href="https://finisky.github.io/training-compute-optimal-large-language-models-summary/">Training Compute-Optimal Large Language Models 简读 </a></li>
</ol>
<p>2xx. <a href="https://zhuanlan.zhihu.com/p/536053110">【预训练模型】推翻OpenAI结论, DeepMind重新定义预训练的训练参数和训练规模的关系！</a><br>《Scaling Laws for Neural Language Models》<br>《Training Compute-Optimal Large Language Models》</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>AIGC</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>Multi-Agents</title>
    <url>/www6vHomeHexo/2023/01/21/gptMultiAgents/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%8D%8F%E4%BD%9C%E5%9E%8B%E7%9A%84-multi-agent-%E7%B3%BB%E7%BB%9F12">协作型的 multi-agent 系统[1][2]</a><ul>
<li><a href="#%E6%97%A0%E5%BA%8F%E5%90%88%E4%BD%9C">无序合作</a></li>
<li><a href="#%E6%9C%89%E5%BA%8F%E5%90%88%E4%BD%9C">有序合作</a></li>
</ul>
</li>
<li><a href="#%E7%AB%9E%E4%BA%89%E5%9E%8B%E7%9A%84-multi-agent-%E7%B3%BB%E7%BB%9F12">竞争型的 multi-agent 系统[1][2]</a></li>
<li><a href="#%E7%AB%9E%E4%BA%89%E5%9E%8B-vs-%E5%8D%8F%E4%BD%9C%E5%9E%8B">竞争型 vs 协作型</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="协作型的-multi-agent-系统12">协作型的 multi-agent 系统[1][2]</span><a href="#协作型的-multi-agent-系统12" class="header-anchor">#</a></h1><h3><span id="无序合作">无序合作</span><a href="#无序合作" class="header-anchor">#</a></h3><p>当系统中有三个或三个以上的Agent时，每个Agent都可以自由地公开表达自己的观点和意见。他们可以提供反馈和建议，以修改与当前任务相关的反应。<strong>整个讨论过程不受控制，没有特定的顺序，也没有引入标准化的协作工作流程</strong>。我们把这种多Agent合作称为<strong>无序合作</strong>。</p>
<p>multi-Agent系统中引入一个专门的<strong>协调Agent</strong>，负责整合和组织所有Agent的响应，从而更新最终答案。</p>
<blockquote>
<p><strong>ChatLLM 网络</strong>是这一概念的典范代表</p>
</blockquote>
<h3><span id="有序合作">有序合作</span><a href="#有序合作" class="header-anchor">#</a></h3><p>当系统中的Agent遵守特定规则时，例如按顺序逐一发表意见，下游Agent只需关注上游的产出。这样，任务完成效率就会大大提高，整个讨论过程也会变得井然有序。</p>
<blockquote>
<p><strong>CAMEL</strong> 是<strong>双Agent</strong>合作系统的成功实施案例。<br><strong>MetaGPT</strong> 从软件开发中的<strong>经典瀑布模型</strong>中汲取灵感，<strong>将Agent的输入&#x2F;输出标准化为工程文档</strong>。通过将先进的人类流程管理经验编码到Agent提示中，多个Agent之间的合作变得更有条理。然而，在 MetaGPT 的实践探索中，我们发现了Multi-Agent合作的潜在威胁。<strong>如果不制定相应的规则，多个Agent之间的频繁互动会无限放大轻微的幻觉</strong>。</p>
</blockquote>
<h1><span id="竞争型的-multi-agent-系统12">竞争型的 multi-agent 系统[1][2]</span><a href="#竞争型的-multi-agent-系统12" class="header-anchor">#</a></h1><p>当多个Agent在 “针锋相对”的状态下表达自己的论点时，一个<strong>Agent可以从其他Agent那里获得大量外部反馈，从而纠正自己扭曲的想法</strong>。</p>
<blockquote>
<p><strong>ChatEval</strong>建立了一个基于角色扮演的多Agent裁判团队。</p>
</blockquote>
<h1><span id="竞争型-vs-协作型">竞争型 vs 协作型</span><a href="#竞争型-vs-协作型" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th></th>
<th>协作型</th>
<th>竞争型</th>
</tr>
</thead>
<tbody><tr>
<td>系统目标</td>
<td>整体</td>
<td>个体</td>
</tr>
<tr>
<td>主流结构</td>
<td>中心化</td>
<td>去中心化</td>
</tr>
<tr>
<td>agent 功能</td>
<td>相对分散</td>
<td>相对同质</td>
</tr>
<tr>
<td>agent 关系</td>
<td>相互依赖</td>
<td>相互独立</td>
</tr>
<tr>
<td>是否自运行</td>
<td>否</td>
<td>是</td>
</tr>
<tr>
<td>系统资源</td>
<td>通常不共享</td>
<td>共享</td>
</tr>
</tbody></table>
<img src="/www6vHomeHexo/2023/01/21/gptMultiAgents/multi-agents.webp" class>
<p>基于 LLM 的多个代理的交互场景。在合作互动中，代理以无序或有序的方式进行协作，以实现共同目标。在对抗式交互中，代理以针锋相对的方式展开竞争，以提高各自的性能。</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/665644399">NLP（廿二）：LLM 时代的 multi-agent 系统</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/656676717">《综述：全新大语言模型驱动的Agent》</a>  *** 4.2</li>
<li><a href="https://github.com/WooooDyy/LLM-Agent-Paper-List">The Rise and Potential of Large Language Model Based Agents: A Survey</a> *** 未</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agents</category>
      </categories>
      <tags>
        <tag>Agents</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT 论文</title>
    <url>/www6vHomeHexo/2023/01/20/gptStudyPaper/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#paper">Paper</a></li>
<li><a href="#gpt%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%911">GPT研究方向[1]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="paper">Paper</span><a href="#paper" class="header-anchor">#</a></h1><ul>
<li><p><a href="https://github.com/www6v/paper-reading">paper-reading</a> 李牧大神</p>
<ul>
<li>Transformer  *** <ul>
<li>GPT-4</li>
<li>Instruct GPT *** </li>
<li>GPT, GPT-2, GPT-3 精读  ***</li>
</ul>
</li>
<li>多模态<ul>
<li>CLIP</li>
<li>ViLT</li>
</ul>
</li>
<li>Chain of Thought  ***</li>
</ul>
</li>
<li><p><a href="https://shimo.im/docs/XKq42v7061SxZ2AN/read">AI 大模型应用开发实战营1期大纲</a><br>基础篇 - 论文 *** </p>
</li>
<li><p><a href="https://blog.csdn.net/v_JULY_v/article/details/129508065">LLM&#x2F;ChatGPT与多模态必读论文150篇(已更至第101篇)</a> </p>
</li>
<li><p><a href="https://github.com/zjunlp/LLMAgentPapers">LLMAgentPapers</a> 浙江大学</p>
</li>
<li><p><a href="https://github.com/zjunlp/Prompt4ReasoningPapers">Prompt4ReasoningPapers</a> 浙江大学</p>
</li>
</ul>
<h1><span id="gpt研究方向1">GPT研究方向[1]</span><a href="#gpt研究方向1" class="header-anchor">#</a></h1><ul>
<li>Efficient (PEFT)</li>
<li>Existing stuff(pretrained model)  -应用<br>New directions</li>
<li>Plug-and-play<br> 通用模块组件，能用在各个领域， baseline</li>
<li>Dataset,  evaluation and survey</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV1oX4y1d7X6">大模型时代下做科研的四个思路【论文精读·52】</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>gpt</category>
        <category>study</category>
      </categories>
      <tags>
        <tag>gpt</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态</title>
    <url>/www6vHomeHexo/2023/01/18/gptMultimodal/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="架构">架构</span><a href="#架构" class="header-anchor">#</a></h1><h3><span id="clip">CLIP</span><a href="#clip" class="header-anchor">#</a></h3><p>双塔</p>
<h3><span id="blip">BLIP</span><a href="#blip" class="header-anchor">#</a></h3><h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="overview">overview</span><a href="#overview" class="header-anchor">#</a></h3><p><a href="https://blog.csdn.net/qq_41185868/article/details/135877268">AI之MLM：《MM-LLMs: Recent Advances in MultiModal Large Language Models多模态大语言模型的最新进展》翻译与解读</a><br><a href="https://zhuanlan.zhihu.com/p/680487634">腾讯发布的多模态大模型（MM-LLM）的最新综述、从26个最新的多模态大模型中归纳最佳实践</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/643969218">[Transformer 101系列] 多模态的大一统之路</a></p>
<p><a href="https://baoyu.io/translations/lmm/multimodality-and-large-multimodal-models">多模态和多模态大模型 (LMM)[译]</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/667942680">写在多模态征服一切之前（未来数据和模型应该是什么样的？）</a></p>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><p><a href="https://zhuanlan.zhihu.com/p/511517344">DeepMind出手！多模态小样本打败精调</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/670821058">[论文阅读] 双子座：一个功能强大的多模态模型系列，Gemini: A Family of Highly Capable Multimodal Models</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/663655741">166页超长论文阅读，大多模态模型的黎明：GPT-4V的初步探索，The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) [上]</a></p>
<p><a href="https://apposcmf8kb5033.pc.xiaoe-tech.com/live_pc/l_64a7d282e4b007b201a34052">使用大型语言模型为MiniGPT-4构建视觉语言理解能力</a> V</p>
<p><a href="https://apposcmf8kb5033.pc.xiaoe-tech.com/live_pc/l_64a7d4fde4b0d1e42e7fc7e6">基于视觉指令调整的多模态聊天机器人 LLaVA</a>  V</p>
<p><a href="https://baoyu.io/translations/ai-paper/2401.13919-webvoyager-building-an-end-to-end-web-agent-with-large-multimodal-models">WebVoyager：借助强大多模态模型，开创全新的网络智能体 [译]</a></p>
<p><a href="https://github.com/Coobiw/MiniGPT4Qwen">MiniGPT4Qwen</a> git<br><a href="https://zhuanlan.zhihu.com/p/664612306">多模态大模型实战-MiniGPT4Qwen系列1：3090+2小时+通义千问&#x3D;个人版双语多模态大模型</a></p>
<p><a href="https://arxiv.org/abs/2306.13549">多模大语言模型综述</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>训练Train-实战</title>
    <url>/www6vHomeHexo/2023/01/15/gptLargeModelTrainingPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p>1xx. <a href="https://zhuanlan.zhihu.com/p/636270877">【LLM】从零开始训练大模型</a> ***  未<br>     <a href="https://www.bilibili.com/video/BV1a14y1o7fr/">从零开始训练大模型</a> V<br>1xx. <a href="https://zhuanlan.zhihu.com/p/637996787">【Falcon Paper】我们是靠洗数据洗败 LLaMA 的！</a> 未<br>1xx. <a href="http://arthurchiao.art/blog/how-to-train-a-gpt-assistant-zh/">[译] 如何训练一个企业级 GPT 助手（OpenAI，2023）</a> 未<br>1xx. <a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/huggingface/index.ipynb">chatgpt2 训练</a>  10.5   10.6</p>
<h3><span id="小模型训练-poc">小模型训练 PoC</span><a href="#小模型训练-poc" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/660759033">LLM从0开始预训练系列：1、大模型训练踩坑</a><br>1xx. <a href="http://arthurchiao.art/blog/gpt-as-a-finite-state-markov-chain-zh/">[译] GPT 是如何工作的：200 行 Python 代码实现一个极简 GPT（2023）</a>  未</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>Langchain  Agent</title>
    <url>/www6vHomeHexo/2023/01/11/gptLangchainAgent/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h1><span id="langchain-agent">Langchain Agent</span><a href="#langchain-agent" class="header-anchor">#</a></h1><ul>
<li>Conversational</li>
<li>OpenAI assistants</li>
<li>OpenAI functions</li>
<li>OpenAI Multi Functions Agent</li>
<li>OpenAI tools<br>OpenAI parallel function calling (a.k.a. tool calling)</li>
<li>ReAct<br>ZeroShotReactAgent</li>
<li>Self-ask with search</li>
<li>Structured tool chat</li>
</ul>
<h1><span id="langchain-apps">Langchain Apps</span><a href="#langchain-apps" class="header-anchor">#</a></h1><h3><span id="rag-chroma-private-2">rag-chroma-private [2]</span><a href="#rag-chroma-private-2" class="header-anchor">#</a></h3><p><strong>本地 部署</strong><br>This template performs RAG with no reliance on external APIs.<br>It utilizes <strong>Ollama the LLM, GPT4All for embeddings, and Chroma for the vectorstore</strong>.</p>
<h3><span id="research-assistant-34">research-assistant [3][4]</span><a href="#research-assistant-34" class="header-anchor">#</a></h3><p>This template implements a version of<br>“GPT Researcher” that you can use as a starting point for a <strong>research agent</strong>.</p>
<h1><span id="langgraph5">LangGraph[5]</span><a href="#langgraph5" class="header-anchor">#</a></h1><h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://github.com/www6v/langchain-app">Langchain Apps</a> Project Code</li>
<li><a href="https://www.bilibili.com/video/BV1JV411F7Yj/">LangChain Agents 保姆级教程 | 动画演示 讲清 核心模块 Agents | Code 讲解 | Demo 演示</a></li>
<li><a href="https://blog.langchain.dev/exploring-uxs-besides-chat-with-research-assistant/">“Research Assistant”: Exploring UXs Besides Chat</a></li>
<li><a href="https://www.youtube.com/watch?v=DjuXACWYkkU">Building a Research Assistant from Scratch</a> </li>
<li><a href="https://blog.langchain.dev/langgraph/">LangGraph</a></li>
<li><a href="https://github.com/www6v/gpt-researcher/">gpt-researcher</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Langchain</category>
      </categories>
      <tags>
        <tag>GPT</tag>
      </tags>
  </entry>
  <entry>
    <title>数据集</title>
    <url>/www6vHomeHexo/2023/01/08/gptDataSet/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="dataset">DataSet</span><a href="#dataset" class="header-anchor">#</a></h1><ul>
<li><p>大而全 </p>
<ul>
<li><a href="http://opendatalab.com/">OpenDataLab 是引领AI大模型时代的开放数据平台</a><br>上海人工智能实验室  </li>
<li><a href="https://www.luge.ai/#/">千言数据集</a><br>百度</li>
</ul>
</li>
<li><p>个人收集</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/641187337">LLM大模型数据集之谜</a> Pretrain数据集</li>
<li><a href="https://github.com/brightmart/nlp_chinese_corpus">大规模中文自然语言处理语料</a></li>
<li><a href="https://github.com/Glanvery/LLM-Travel/blob/main/LLM_Pretrain_Datasets.md">开源的可用于LLM Pretrain数据集</a> Pretrain数据集</li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648405040&idx=1&sn=ad45944e78b5742337158cff80dbd9b3">再看领域微调大模型的主流基座和评测数据集：项目地址及论文指引</a> 评测数据集</li>
</ul>
</li>
<li><p>其他<br><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399359&idx=1&sn=502c65376e14b20a7dc1ceb35c62141d">大规模语言模型训练必备数据集-The Pile：涵盖22类、800GB的多样性文本数据集概述 </a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataset</category>
      </categories>
      <tags>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatGLM</title>
    <url>/www6vHomeHexo/2023/01/06/gptChatGLM/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<p><a href="https://www.bilibili.com/video/BV1ju411T74Y/">第十一课：ChatGLM</a> V<br><a href="https://blog.csdn.net/v_JULY_v/article/details/129880836">ChatGLM两代的部署&#x2F;微调&#x2F;实现：从基座GLM、ChatGLM的LoRA&#x2F;P-Tuning微调、6B源码解读到ChatGLM2的微调与实现</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/625468667">【Instruction Tuning】ChatGLM 微调实战（附源码）</a></p>
<p><a href="https://github.com/www6v/transformers_tasks/blob/main/LLM/chatglm_finetune/readme.md">Finetune ChatGLM-6B</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401516&idx=1&sn=80b3cfecc9f4338b87fcd9bc91ef2465">也看支持32K上下文的ChatGLM2-6B模型：优化点简读及现有开源模型主流训练优化点概述 </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>ChatGLM</category>
      </categories>
      <tags>
        <tag>ChatGLM</tag>
      </tags>
  </entry>
  <entry>
    <title>Instruct Tuning</title>
    <url>/www6vHomeHexo/2023/01/06/gptInstructTuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#in-context-learning-icl-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0">In Context Learning ( ICL ) 上下文学习</a></li>
<li><a href="#instruction-learning-1">Instruction Learning [1]</a><ul>
<li><a href="#instruct-tuning-">Instruct Tuning-</a></li>
<li><a href="#instructgpt">instructGPT</a></li>
<li><a href="#chatgpt">chatGPT</a></li>
</ul>
</li>
<li><a href="#instruction-tuning">Instruction Tuning</a></li>
<li><a href="#limitation-of-instruction-finetuning-2">Limitation of instruction finetuning [2]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="in-context-learning-icl-上下文学习">In Context Learning ( ICL ) 上下文学习</span><a href="#in-context-learning-icl-上下文学习" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/06/gptInstructTuning/ICL.webp" class>

<ul>
<li><strong>in context learning</strong>，大意是在<strong>prompt learning的基础上，将少量有标签样本融入prompt</strong>。</li>
<li>上图的ICL模型可以理解成<strong>有监督、无训练</strong>的<strong>小样本学习</strong>。</li>
<li>但<strong>并非所有ICL都不训练</strong>。比如下图右上角的<strong>FLAN</strong>就是用instruction tuning<strong>训练参数</strong>的。</li>
</ul>
<img src="/www6vHomeHexo/2023/01/06/gptInstructTuning/ICL-tech.webp" class>
<ul>
<li><strong>FLAN</strong>，<strong>既属于 in context learning，也属于 instruction learning</strong></li>
</ul>
<h1><span id="instruction-learning-1">Instruction Learning [1]</span><a href="#instruction-learning-1" class="header-anchor">#</a></h1><h3><span id="instruct-tuning-">Instruct Tuning-</span><a href="#instruct-tuning-" class="header-anchor">#</a></h3><pre><code>FLANv1, FLANv2
</code></pre>
<h3><span id="instructgpt">instructGPT</span><a href="#instructgpt" class="header-anchor">#</a></h3><h3><span id="chatgpt">chatGPT</span><a href="#chatgpt" class="header-anchor">#</a></h3><h1><span id="instruction-tuning">Instruction Tuning</span><a href="#instruction-tuning" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/06/gptInstructTuning/instructTuning.webp" class>

<ul>
<li><p>对于已有的预训练模型，继续在多项任务（B、C、D等）上做训练，在其他任务（A）上做预测。<strong>虽然依然没见过任务A，但是根据对B、C、D等的训练，对A的效果有所提升；</strong> [1]</p>
</li>
<li><p><strong>Instruct Tuning 本质上也是Prompt Tuning</strong> [2]</p>
</li>
<li><p>研究了缩放对指令微调的影响 [3]<br>  与微调指令的任务数量有关，<strong>任务数量越多效果越好</strong><br>  与模型的大小有关，<strong>模型越大效果越好</strong></p>
</li>
<li><p>Prompt vs. Instruction Tuning  [4]<br>  Prompt是去激发语言模型的<strong>补全能力</strong>，比如给出上半句生成下半句、或者做完形填空，都还是像在做language model任务.<br>  而Instruction Tuning则是激发语言模型的<strong>理解能力</strong>，通过给出更明显的指令&#x2F;指示，让模型去理解并做出正确的action<br>  <strong>Prompt tuning</strong>都是针对<strong>一个任务</strong>的，比如做个情感分析任务的prompt tuning，精调完的模型只能用于情感分析任务，而经过<strong>Instruction Tuning多任务</strong>精调后，可以用于其他任务的zero-shot</p>
</li>
<li><p>Instruction Tuning 指令微调  [4]</p>
<ul>
<li>Self Instruction<ul>
<li>Alpaca &#x3D; LLaMA + Intruction Tuning [2]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="limitation-of-instruction-finetuning-2">Limitation of instruction finetuning [2]</span><a href="#limitation-of-instruction-finetuning-2" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/06/gptInstructTuning/limitation.JPG" class>
<p>问题1.  开放性问题<br>问题2.  看图</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/619406727">各种tuning的简单逻辑解释</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1cm4y1e7Cc/">第九课：Instruct Tuning</a> *** V</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/646136859">FLANv2：大模型指令微调必看论文</a> </p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/408166011">Instruction Tuning｜谷歌Quoc V.Le团队提出又一精调范式</a></p>
</li>
</ol>
<p>1xx. <a href="https://yaofu.notion.site/June-2023-A-Stage-Review-of-Instruction-Tuning-f59dbfc36e2d4e12a33443bd6b2012c2">June 2023, A Stage Review of Instruction Tuning</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/629461665">【LLM系列之FLAN-T5&#x2F;PaLM】Scaling Instruction-Finetuned Language Models</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/597036814">如何优化大模型的In-Context Learning效果？</a></p>
<p>1xx. <a href="https://arxiv.org/abs/2308.10792">大语言模型指令微调综述</a><br>    <a href="https://zhuanlan.zhihu.com/p/654054370">一篇关于LLM指令微调的综述</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Instruct-Tuning</category>
      </categories>
      <tags>
        <tag>Instruct-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>Prompt Tuning</title>
    <url>/www6vHomeHexo/2023/01/06/gptPromptTuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="npl范式3">NPL范式[3]</span><a href="#npl范式3" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/06/gptPromptTuning/npl4Paragiam.jpg" class title="4种范式">

<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol start="3">
<li><a href="https://zhuanlan.zhihu.com/p/396098543">[综述]鹏飞大神的Pre-train, Prompt, and Predict [1]</a></li>
</ol>
<p><a href="https://zhuanlan.zhihu.com/p/395115779">近代自然语言处理技术发展的“第四范式”</a>  Prompt Learning</p>
<p><a href="https://zhuanlan.zhihu.com/p/396971490">Prompt范式的缘起｜Pattern-Exploiting Training</a><br><a href="https://zhuanlan.zhihu.com/p/400790006">Prompt范式第二阶段｜Prefix-tuning、P-tuning、Prompt-tuning</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/423306405">清华P-tuning v2、谷歌SPoT｜Prompt可以超过精调了吗？</a></p>
<p><a href="https://www.bilibili.com/video/BV1Wg4y1K77R/">第七课：Prompt Tuning</a> ***  V  有ppt<br><a href="https://www.bilibili.com/video/BV18P411E7VK/">清华博后带你轻松吃透Prompt Tuning顶会大模型论文</a> V</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Prompt-Tuning</category>
      </categories>
      <tags>
        <tag>Prompt-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>训练-并行</title>
    <url>/www6vHomeHexo/2023/01/06/gptTrainParallelism/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83-1">分布式训练 [1]</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C">数据并行</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C">模型并行</a><ul>
<li><a href="#%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C-3">张量并行 [3]</a></li>
<li><a href="#%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C-3">流水线并行 [3]</a></li>
</ul>
</li>
<li><a href="#3d%E5%B9%B6%E8%A1%8C">3D并行</a></li>
</ul>
</li>
<li><a href="#zero-4">ZeRO [4]</a><ul>
<li><a href="#%E7%AD%96%E7%95%A51-naive-dp%E7%9A%84%E9%80%9A%E4%BF%A1%E9%87%8F">策略1: naive DP的通信量</a></li>
<li><a href="#%E7%AD%96%E7%95%A52-zero-1%E6%96%B9%E6%A1%88">策略2: Zero-1方案</a></li>
<li><a href="#%E7%AD%96%E7%95%A53-zero-2%E6%96%B9%E6%A1%88">策略3: ZeRo-2方案</a></li>
<li><a href="#%E7%AD%96%E7%95%A54-zero-3%E6%96%B9%E6%A1%88">策略4: ZeRo-3方案</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="分布式训练-1">分布式训练 [1]</span><a href="#分布式训练-1" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/06/gptTrainParallelism/pararllelTraining.jpg" class>

<h3><span id="数据并行">数据并行</span><a href="#数据并行" class="header-anchor">#</a></h3><h3><span id="模型并行">模型并行</span><a href="#模型并行" class="header-anchor">#</a></h3><p><strong>张量并行</strong>与<strong>流水线并行</strong>都属于<strong>模型并行</strong>，<br>区别在于对模型参数的切分“方向”不同：<br><strong>张量并行</strong>把模型的<strong>每层进行切分 (intra-layer)<strong>，而</strong>流水线并行</strong>则<strong>按层进行切分 (inter-layer) 并在不同设备处理</strong>。[2]</p>
<h5><span id="张量并行-3">张量并行 [3]</span><a href="#张量并行-3" class="header-anchor">#</a></h5> <img src="/www6vHomeHexo/2023/01/06/gptTrainParallelism/tensor.png" class>
<h5><span id="流水线并行-3">流水线并行 [3]</span><a href="#流水线并行-3" class="header-anchor">#</a></h5><img src="/www6vHomeHexo/2023/01/06/gptTrainParallelism/pipeline.png" class>

<h3><span id="3d并行">3D并行</span><a href="#3d并行" class="header-anchor">#</a></h3><h1><span id="zero-4">ZeRO [4]</span><a href="#zero-4" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/06/gptTrainParallelism/zero.png" class>

<h3><span id="策略1-naive-dp的通信量">策略1: naive DP的通信量</span><a href="#策略1-naive-dp的通信量" class="header-anchor">#</a></h3><p>通信量是<strong>2X</strong><br>显存占用<strong>16X</strong></p>
<h3><span id="策略2-zero-1方案">策略2: Zero-1方案</span><a href="#策略2-zero-1方案" class="header-anchor">#</a></h3><p>总的通信量为<strong>2X，跟naive DP一致</strong><br>显存方面 约为<strong>策略1的 1&#x2F;4</strong></p>
<h3><span id="策略3-zero-2方案">策略3: ZeRo-2方案</span><a href="#策略3-zero-2方案" class="header-anchor">#</a></h3><p>通信量也是<strong>2X, 跟naive DP一致</strong><br>显存方面  约为<strong>naive DP的1&#x2F;8</strong></p>
<h3><span id="策略4-zero-3方案">策略4: ZeRo-3方案</span><a href="#策略4-zero-3方案" class="header-anchor">#</a></h3><p>总的通信量为，为<strong>naive DP的1.5倍</strong>，增加50%通信量<br>显存方面  约为<strong>naive DP的1&#x2F;32</strong></p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://lilianweng.github.io/posts/2021-09-25-train-large/">How to Train Really Large Models on Many GPUs? </a></p>
</li>
<li><p><a href="https://finisky.github.io/how-to-train-large-language-model/">大模型分布式训练的并行策略</a></p>
</li>
<li><p><a href="https://blog.csdn.net/v_JULY_v/article/details/132462452">大模型并行训练指南：通俗理解Megatron-DeepSpeed之模型并行与数据并行</a> </p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/664604792">[Transformer 101系列] LLM分布式训练面面观</a></p>
</li>
</ol>
<p>1xx. <a href="https://techdiylife.github.io/big-model-training/deepspeed/deepspeed-chat.html">第1章：DeepSpeed-Chat 模型训练实战</a>  Bili<br>      <a href="https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat">DeepSpeed-Chat</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/465967735">分布式训练硬核技术——通信原语</a> </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/613196255">图解大模型训练之：流水线并行（Pipeline Parallelism），以Gpipe为例</a>  系列文章 </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/622212228">图解大模型训练之：张量模型并行(TP)，Megatron-LM</a> ***</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/450854172">全网最全-超大模型+分布式训练架构和经典论文</a> 未</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/636488690">大模型流水线并行（Pipeline）实战</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/610587671">【深度学习】【分布式训练】DeepSpeed：AllReduce与ZeRO-DP</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>PEFT Lora 实战</title>
    <url>/www6vHomeHexo/2023/01/05/gptPEFTLora/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%9F%BA%E4%BA%8Ellama%E7%9A%84sft">基于LLaMA的SFT</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8Ebloom%E7%9A%84%E5%BE%AE%E8%B0%83">基于bloom的微调</a></li>
<li><a href="#lora-%E5%8F%82%E6%95%B0">Lora 参数</a></li>
<li><a href="#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5">最佳实践</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#bloom">bloom</a></li>
<li><a href="#llama">LLaMA</a></li>
<li><a href="#chatglm">ChatGLM</a></li>
<li><a href="#others">others</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="基于llama的sft">基于LLaMA的SFT</span><a href="#基于llama的sft" class="header-anchor">#</a></h1><ul>
<li><p>版本</p>
<ul>
<li>deepspeed的版本  [3.1]</li>
<li>AutoGPTQ的版本  0.6.0 -&gt; git下载到本地安装</li>
</ul>
</li>
<li><p>代码错误</p>
<ul>
<li>use_flash_attention_2 相关的错误 [3.2]</li>
</ul>
</li>
<li><p>脚本 [3.3]</p>
<ul>
<li>modescope 下载 shakechen&#x2F;Llama-2-7b-chat-hf</li>
<li>单卡训练<br>1个epoch 差不多7小时</li>
</ul>
</li>
<li><p>checkpoint 生成文件</p>
</li>
</ul>
<img src="/www6vHomeHexo/2023/01/05/gptPEFTLora/llama-lora.png" class>

<img src="/www6vHomeHexo/2023/01/05/gptPEFTLora/llama-lora1.png" class>

<ul>
<li>模型生成文件</li>
</ul>
<img src="/www6vHomeHexo/2023/01/05/gptPEFTLora/model1.png" class>

<img src="/www6vHomeHexo/2023/01/05/gptPEFTLora/model2.png" class>



<h1><span id="基于bloom的微调">基于bloom的微调</span><a href="#基于bloom的微调" class="header-anchor">#</a></h1><ul>
<li><p>简单基础  [2]</p>
<ul>
<li>基座模型<br>Langboat&#x2F;bloom-1b4-zh </li>
<li>数据集<br>shibing624&#x2F;alpaca-zh</li>
</ul>
</li>
<li><p>稍复杂[1]</p>
<ul>
<li>基座模型<br>bloomz-560m </li>
<li>数据集<br>ought&#x2F;raft</li>
</ul>
</li>
</ul>
<h1><span id="lora-参数">Lora 参数</span><a href="#lora-参数" class="header-anchor">#</a></h1><ul>
<li><p>LoraConfig [2]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">LoraConfig( </span><br><span class="line">base_model_name_or_path=<span class="string">&#x27;Langboat/bloom-1b4-zh&#x27;</span>, </span><br><span class="line">task_type=&lt;TaskType.CAUSAL_LM: <span class="string">&#x27;CAUSAL_LM&#x27;</span>&gt;, </span><br><span class="line">inference_mode=<span class="literal">False</span>, </span><br><span class="line">r=<span class="number">8</span>, </span><br><span class="line">target_modules=&#123;<span class="string">&#x27;query_key_value&#x27;</span>&#125;, </span><br><span class="line">lora_alpha=<span class="number">32</span>, </span><br><span class="line">lora_dropout=<span class="number">0.1</span>, </span><br><span class="line">modules_to_save=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>参数说明 [1]</p>
<ul>
<li>task_type：指定任务类型。如：条件生成任务（SEQ_2_SEQ_LM），因果语言建模（CAUSAL_LM）等。</li>
<li>inference_mode：是否在推理模式下使用Peft模型。</li>
<li>r： LoRA低秩矩阵的维数。关于秩的选择，通常，使用4，8，16即可。</li>
<li>lora_alpha： LoRA低秩矩阵的缩放系数，为一个常数超参，调整alpha与调整学习率类似。</li>
<li>lora_dropout：LoRA 层的丢弃（dropout）率，取值范围为[0, 1)。</li>
<li>target_modules：要替换为 LoRA 的模块名称列表或模块名称的正则表达式。针对不同类型的模型，模块名称不一样.</li>
</ul>
</li>
<li><p>target_modules [1]<br>在 PEFT 中支持的模型默认的模块名如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING = &#123;</span><br><span class="line">    <span class="string">&quot;t5&quot;</span>: [<span class="string">&quot;q&quot;</span>, <span class="string">&quot;v&quot;</span>],</span><br><span class="line">    <span class="string">&quot;mt5&quot;</span>: [<span class="string">&quot;q&quot;</span>, <span class="string">&quot;v&quot;</span>],</span><br><span class="line">    <span class="string">&quot;bart&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;gpt2&quot;</span>: [<span class="string">&quot;c_attn&quot;</span>], <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;bloom&quot;</span>: [<span class="string">&quot;query_key_value&quot;</span>], <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;blip-2&quot;</span>: [<span class="string">&quot;q&quot;</span>, <span class="string">&quot;v&quot;</span>, <span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;opt&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;gptj&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;gpt_neox&quot;</span>: [<span class="string">&quot;query_key_value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;gpt_neo&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;bert&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>], <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;roberta&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;xlm-roberta&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;electra&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;deberta-v2&quot;</span>: [<span class="string">&quot;query_proj&quot;</span>, <span class="string">&quot;value_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;deberta&quot;</span>: [<span class="string">&quot;in_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;layoutlm&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;llama&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],  <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;chatglm&quot;</span>: [<span class="string">&quot;query_key_value&quot;</span>],  <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;gpt_bigcode&quot;</span>: [<span class="string">&quot;c_attn&quot;</span>],</span><br><span class="line">    <span class="string">&quot;mpt&quot;</span>: [<span class="string">&quot;Wqkv&quot;</span>],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1><span id="最佳实践">最佳实践</span><a href="#最佳实践" class="header-anchor">#</a></h1><ul>
<li>秩r的大小[卢老师]<ul>
<li>模型如果是垂直类的大模型<br>eg. 私有数据<br><strong>r设置大点</strong></li>
<li>模型如果是通用类的大模型<br>eg. 运维大模型<br><strong>r设置小点</strong></li>
</ul>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="bloom">bloom</span><a href="#bloom" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/649315197">大模型参数高效微调技术实战（五）-LoRA</a><br><a href="https://github.com/www6v/llm-action/blob/main/train/peft/clm/peft_lora_clm.ipynb">bloom Lora</a> git</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV13w411y7fq/">【手把手带你实战HuggingFace Transformers-高效微调篇】LoRA 原理与实战</a> V<br> <a href="https://github.com/www6v/transformers-code/blob/master/03-PEFT/21-lora/chatbot_lora.ipynb">bloom Lora-origin</a>  <a href="https://colab.research.google.com/github/www6v/transformers-code/blob/master/03-PEFT/21-lora/chatbot_lora.ipynb">bloom Lora-origin</a> git   origin运行有问题<br> <a href="https://github.com/www6v/transformers-code/blob/master/03-PEFT/21-lora/chatbot_lora%5Bworkable%5D.ipynb">bloom Lora-modify</a>  <a href="https://colab.research.google.com/drive/1SNy35_CJOobe4AxAecMZJo4LX1TjXvTm">bloom Lora-modify</a> 修改过可以在colab运行的代码</p>
</li>
</ol>
<h3><span id="llama">LLaMA</span><a href="#llama" class="header-anchor">#</a></h3><ol start="3">
<li><a href="https://github.com/www6v/Llama2-Chinese/tree/ww-workable">Llama2-Chinese</a> 模型微调-&gt; lora SFT<br>3.1 <a href="https://github.com/www6v/Llama2-Chinese/blob/ww-workable/requirements.txt">requirements.txt</a><br>3.2 <a href="https://github.com/www6v/Llama2-Chinese/blob/ww-workable/train/sft/finetune_clm_lora.py#L460C18-L460C19">finetune_clm_lora.py</a>  注释掉第360行<br>3.3 <a href="https://github.com/www6v/Llama2-Chinese/blob/ww-workable/train/sft/finetune_lora.sh">train&#x2F;sft&#x2F;finetune_lora.sh</a></li>
</ol>
<h3><span id="chatglm">ChatGLM</span><a href="#chatglm" class="header-anchor">#</a></h3><p>1xx. <a href="https://github.com/www6v/fine-tuning-lab/blob/agiclass-v1/chatglm/train_lora.sh">train_lora.sh</a>  基于法律文本的chatglm的lora<br><a href="https://github.com/www6v/fine-tuning-lab/blob/agiclass-v1/chatglm2/train_lora.sh">train_lora.sh</a>  基于法律文本的chatglm-2的lora<br><a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/peft/index.ipynb">十一、小参数量微调</a><br>bili有相关的总结的视频</p>
<p>1xx. <a href="https://github.com/mymusise/ChatGLM-Tuning">ChatGLM-Tuning</a> 卢老师推荐</p>
<h3><span id="others">others</span><a href="#others" class="header-anchor">#</a></h3><p>1xx. <a href="https://lightning.ai/pages/community/lora-insights/">Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments</a> ***<br>     <a href="https://www.bilibili.com/video/BV16u4y1a7MH/">几百次大模型LoRA和QLoRA 微调实践的经验分享</a> V</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>排行榜</title>
    <url>/www6vHomeHexo/2023/01/04/gptLeaderBoard/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B">大模型</a><ul>
<li><a href="#%E6%8E%92%E8%A1%8C%E6%A6%9C">排行榜</a></li>
<li><a href="#%E4%B8%AD%E5%9B%BD%E6%8E%92%E8%A1%8C%E6%A6%9C">中国排行榜</a></li>
</ul>
</li>
<li><a href="#%E6%98%BE%E5%8D%A1">显卡</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="大模型">大模型</span><a href="#大模型" class="header-anchor">#</a></h1><h3><span id="排行榜">排行榜</span><a href="#排行榜" class="header-anchor">#</a></h3><p><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">HuggingFaceH 大模型排行榜</a></p>
<p><a href="https://www.promptingguide.ai/models/collection">LLM Collection</a></p>
<h3><span id="中国排行榜">中国排行榜</span><a href="#中国排行榜" class="header-anchor">#</a></h3><p><a href="https://github.com/www6v/awesome-LLMs-In-China">中国大模型 </a></p>
<ul>
<li>通用 39</li>
<li>金融 25</li>
<li>司法 8</li>
<li>法律 6</li>
<li>医学 13</li>
<li>医疗 24</li>
<li>教育 13</li>
<li>科研 17</li>
<li>工业 23</li>
<li>政务 12</li>
<li>运维 7</li>
</ul>
<h1><span id="显卡">显卡</span><a href="#显卡" class="header-anchor">#</a></h1><ul>
<li><p>显卡天梯榜<br> <a href="https://topic.expreview.com/GPU">显卡天梯榜</a></p>
</li>
<li><p>显卡<br>显卡 &#x3D; GPU +  显存</p>
</li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>leaderBoard</category>
      </categories>
      <tags>
        <tag>leaderBoard</tag>
      </tags>
  </entry>
  <entry>
    <title>垂类大模型</title>
    <url>/www6vHomeHexo/2023/01/04/gptDomain/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="垂类大模型">垂类大模型</span><a href="#垂类大模型" class="header-anchor">#</a></h1><h3><span id="领域微调模型-1">领域微调模型 [1]</span><a href="#领域微调模型-1" class="header-anchor">#</a></h3><ul>
<li>注入领域知识，分成三种：<ul>
<li>继续预训练注入</li>
<li>微调注入以及</li>
<li>外挂注入</li>
</ul>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401405&idx=1&sn=59baf4a22d9a9abeb42599ac91e11a79">领域微调大模型入局的自我和解：领域微调大模型若一定要做，则务必想的若干个前提条件 </a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/642611747">垂直领域大模型的一些思考及开源模型汇总</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403459&idx=2&sn=0219fc098c208e36cd32940e71089fd2">层出不穷的垂域微调大模型非最全汇总：12大领域、57个领域微调模型概述及对垂直行业问答的一些讨论 </a><br> <a href="https://github.com/www6v/Awesome-Domain-LLM">Awesome-Domain-LLM</a><br>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/131550529?spm=1001.2014.3001.5502">医疗金融法律大模型：从ChatDoctor到BloombergGPT&#x2F;FinGPT&#x2F;FinBERT、ChatLaw&#x2F;LawGPT_zh</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400666&idx=1&sn=bc47e8c4eca6fc4baaded42fa3c6bd77">再谈垂直领域大模型及今日前沿速递：金融领域FinBERT、BloombergGPT以及法律领域微调模型LawGPT_zh</a></li>
</ol>
<p>1xx. <a href="/www6vHomeHexo/2023/01/04/gptLeaderBoard/" title="排行榜">排行榜</a> self</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>大模型</category>
      </categories>
      <tags>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>NL2SQL</title>
    <url>/www6vHomeHexo/2023/01/03/gptNL2SQL/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p>1xx. <a href="https://github.com/www6v/NL2SQL">https://github.com/www6v/NL2SQL</a><br>1xx. <a href="https://github.com/www6v/nl2sql-">https://github.com/www6v/nl2sql-</a><br>1xx. <a href="https://blog.langchain.dev/llms-and-sql/">LLMs and SQL</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/640580808">大模型与数据科学：从Text-to-SQL 开始（一）</a> 多款产品</p>
<p>百度千帆-ppt<br>QCon-ppt</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzUxNzk5MTU3OQ==&mid=2247487028&idx=1&sn=7b6767878b7f6b891fc69e408f248ef1">语义解析 (Text-to-SQL) 技术研究及应用 上篇 </a><br>1xx. <a href="https://mp.weixin.qq.com/s/5lTLW5OOuRMo2zjbzMxr_Q">语义解析 (Text-to-SQL) 技术研究及应用 下篇 </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/670509396">LLM在中文Text2SQL的实践</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/673474672">LLM在中文Text2SQL任务上的优化V2.0</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/670913902">LLM在中文Text2SQL任务上的优化V1.0</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402400&idx=1&sn=fe122657b35f27090aaca9c144d1d23b">也看大模型与数据库查询分析的落地结合：C3 Text2SQL方案及Data-Copilot数据自动化编排机制的实现思想阅读 </a> </p>
<hr>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/668557045">C3: Zero-shot Text-to-SQL with ChatGPT笔记</a><br>1xx. <a href="https://github.com/bigbigwatermalon/C3SQL">C3SQL  </a> git</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402424&idx=1&sn=e2d26821b6e9a5a2871e0ddbca565c30">大模型再总结及ChatSQL实践案例分享：大模型训练数据及工具的5张脑图总结及ChatSQL开源项目实现解析 </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>NL2SQL</category>
      </categories>
      <tags>
        <tag>NL2SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>推理-优化</title>
    <url>/www6vHomeHexo/2023/01/01/gptInference/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%8E%A8%E7%90%86-%E4%BC%98%E5%8C%96">推理 优化</a><ul>
<li><a href="#overview22">overview[2.2]</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-21">模型压缩 [2.1]</a></li>
<li><a href="#kv-cache2324">KV Cache[2.3][2.4]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E7%BB%BC%E8%BF%B0">综述</a></li>
<li><a href="#kv-cache">kv cache</a></li>
<li><a href="#%E9%87%8F%E5%8C%96">量化</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="推理-优化">推理 优化</span><a href="#推理-优化" class="header-anchor">#</a></h1><h3><span id="overview22">overview[2.2]</span><a href="#overview22" class="header-anchor">#</a></h3><p>有几种方法可以在内存中<strong>降低推理成本</strong>或&#x2F;和<strong>加快推理速度</strong>。</p>
<ul>
<li>应用各种<strong>并行处理方式</strong>，以在大量GPU上扩展模型。智能并行处理模型组件和数据使得运行拥有数万亿参数的模型成为可能。</li>
<li><strong>内存卸载</strong>，将临时未使用的数据卸载到CPU，并在以后需要时再读回。这有助于减少内存使用，但会导致更高的延迟。</li>
<li><strong>智能批处理策略</strong>；例如，EffectiveTransformer将连续的序列打包在一起，以消除批处理内的填充。</li>
<li><strong>网络压缩技术</strong>，如<strong>修剪、量化、蒸馏</strong>。较小的模型，无论是参数数量还是位宽，应该需要更少的内存并且运行更快。</li>
<li>针对目标模型架构的特定改进。许多<strong>架构变化</strong>，特别是针对注意力层的变化，有助于提高Transformer解码速度。</li>
</ul>
<h3><span id="模型压缩-21">模型压缩 [2.1]</span><a href="#模型压缩-21" class="header-anchor">#</a></h3><p>剪枝（Pruning）<br>知识蒸馏（Knowledge Distillation，KD）<br>量化（Quantization）<br>低秩分解（Low-Rank Factorization）</p>
<h3><span id="kv-cache2324">KV Cache[2.3][2.4]</span><a href="#kv-cache2324" class="header-anchor">#</a></h3><h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="综述">综述</span><a href="#综述" class="header-anchor">#</a></h3><p>2.1. <a href="https://mp.weixin.qq.com/s/glPPSqHjsnDjC0DZSuuPzA">一文探秘LLM应用开发(13)-模型部署与推理(优化理论) </a><br>2.2 <a href="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/">https://lilianweng.github.io/posts/2023-01-10-inference-optimization/</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/656485997">大语言模型推理性能优化综述</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/642412124">NLP（十八）：LLM 的推理优化技术纵览</a> *** </p>
<h3><span id="kv-cache">kv cache</span><a href="#kv-cache" class="header-anchor">#</a></h3><p>2.3. <a href="https://zhuanlan.zhihu.com/p/659770503">NLP（二十）：漫谈 KV Cache 优化方法，深度理解 StreamingLLM</a> ***<br>2.4. <a href="https://zhuanlan.zhihu.com/p/662498827">大模型推理加速：看图学KV Cache</a> ***</p>
<h3><span id="量化">量化</span><a href="#量化" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399136&idx=1&sn=bd0a7237940c2ac800e06ae6d247349e">NLP大模型压缩关键技术解读：用于大型Transformer的8-bit矩阵乘法原理及其简单实现</a><br>   <a href="https://huggingface.co/blog/zh/hf-bitsandbytes-integration">大规模 Transformer 模型 8 比特矩阵乘简介 - 基于 Hugging Face Transformers、Accelerate 以及 bitsandbytes </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Inference</category>
      </categories>
      <tags>
        <tag>Inference</tag>
      </tags>
  </entry>
  <entry>
    <title>LLaMA</title>
    <url>/www6vHomeHexo/2023/01/01/gptLlama/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#llama-%E6%9E%B6%E6%9E%84architecture20">LLaMA 架构（Architecture）[20]</a><ul>
<li><a href="#%E9%A2%84%E5%BD%92%E4%B8%80%E5%8C%96pre-normalization%E5%8F%97-gpt3-%E5%90%AF%E5%8F%91">预归一化（Pre-normalization）：受 GPT3 启发</a></li>
<li><a href="#swiglu-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%8F%97-palm-%E5%90%AF%E5%8F%91">SwiGLU 激活函数：受 PaLM 启发</a></li>
<li><a href="#%E6%97%8B%E8%BD%AC%E5%B5%8C%E5%85%A5rotary-embeddings%E5%8F%97-gptneo-%E5%90%AF%E5%8F%91">旋转嵌入（Rotary Embeddings）：受 GPTNeo 启发</a></li>
</ul>
</li>
<li><a href="#llama21">LLaMA2[1]</a><ul>
<li><a href="#%E8%AE%AD%E7%BB%83%E7%9A%84%E6%9E%B6%E6%9E%8430">训练的架构[30]</a></li>
<li><a href="#%E4%B8%8Ellama%E4%B8%BB%E8%A6%81%E5%8C%BA%E5%88%AB31">与LLaMA主要区别：[31]</a></li>
</ul>
</li>
<li><a href="#llama-%E5%88%86%E6%94%AF1">LLaMA 分支[1]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E5%88%86%E6%94%AF">分支</a></li>
<li><a href="#llama">LLaMA</a></li>
<li><a href="#llama2">LLaMA2</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="llama-架构architecture20">LLaMA 架构（Architecture）[20]</span><a href="#llama-架构architecture20" class="header-anchor">#</a></h1><h3><span id="预归一化pre-normalization受-gpt3-启发">预归一化（Pre-normalization）：受 GPT3 启发</span><a href="#预归一化pre-normalization受-gpt3-启发" class="header-anchor">#</a></h3><p>为了提高<strong>训练稳定性</strong>，我们对每个 Transformer sub-layer 的<strong>输入</strong>进行归一化，而不是对<strong>输出</strong>进行归一化。 这里使用由 Zhang 和 Sennrich（2019）提出的 RMSNorm 归一化函数。</p>
<h3><span id="swiglu-激活函数受-palm-启发">SwiGLU 激活函数：受 PaLM 启发</span><a href="#swiglu-激活函数受-palm-启发" class="header-anchor">#</a></h3><p>用 SwiGLU 激活函数替换 ReLU 非线性，该函数由 Shazeer（2020）提出，目的是<strong>提升性能</strong>。 但我们使用的维度是 <code>2/3 * 4d</code>，而不是 PaLM 中的 <code>4d</code>。</p>
<h3><span id="旋转嵌入rotary-embeddings受-gptneo-启发">旋转嵌入（Rotary Embeddings）：受 GPTNeo 启发</span><a href="#旋转嵌入rotary-embeddings受-gptneo-启发" class="header-anchor">#</a></h3><p>去掉了绝对位置嵌入（absolute positional embeddings），并在每个网络层中添加旋转位置嵌入（rotary positional embeddings，RoPE）。 RoPE 由 Su 等（2021）提出。</p>
<h1><span id="llama21">LLaMA2[1]</span><a href="#llama21" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/01/gptLlama/llama2.png" class>

<h3><span id="训练的架构30">训练的架构[30]</span><a href="#训练的架构30" class="header-anchor">#</a></h3><p>Llama2采用了Llama 1中的大部分预训练设置和模型架构。使用RMSNorm应用预归一化，使用SwiGLU激活函数和旋转位置嵌入。</p>
<p>具体的，使用AdamW优化器进行训练，使用余弦学习率方式来动态调整学习率，预热2000步，并将最终学习率衰减到峰值学习率的10%，并使用0.1的权重衰减和1.0的梯度裁剪。</p>
<p>与Llama 1的主要架构差异包括增加了<strong>上下文长度【两倍关系】</strong>和**分组查询关注(GQA)**。</p>
<p>分词器方面，使用与Llama 1相同的标记器，采用字节对编码(BPE)算法，使用sentencepece的实现。值得注意的是，<strong>与Llama 1一样，将所有数字拆分为单个数字，并使用字节来分解未知的UTF-8字符。总词汇表大小为32k。</strong></p>
<h3><span id="与llama主要区别31">与LLaMA主要区别：[31]</span><a href="#与llama主要区别31" class="header-anchor">#</a></h3><ul>
<li>更多的训练数据<br> 1.4T -&gt; 2T</li>
<li>更⻓的上下文窗口<br> 2k-&gt; 4k</li>
<li>GQA技术</li>
<li>完整的RLHF链条</li>
</ul>
<hr>
<h1><span id="llama-分支1">LLaMA 分支[1]</span><a href="#llama-分支1" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>项目</th>
<th>描述</th>
<th>数据集</th>
</tr>
</thead>
<tbody><tr>
<td>LLaMa</td>
<td>基座模型</td>
<td>公开可用的数据集(1T token)</td>
</tr>
<tr>
<td>Stanford Alpaca</td>
<td>结合英文语料通过Self Instruct方式微调LLaMA 7B</td>
<td>Self Instruct from davinci-003 API(52K)</td>
</tr>
<tr>
<td>Vicuna-13B</td>
<td>通过ShareGPT.com的7万条对话数据微调LLaMA(Alpaca基础之上, 多轮对话和长序列, full fine-tune)</td>
<td>用户共享对话(70K sample)</td>
</tr>
<tr>
<td>BELLE</td>
<td>结合中文语料通过Self Instruct方式微调BLOOMZ-7B或LLaMA</td>
<td></td>
</tr>
<tr>
<td>Chinese-LLaMA&#x2F;Chinese-Alpaca</td>
<td>通过中文数据预训练&#x2F;指令微调LLaMA</td>
<td></td>
</tr>
<tr>
<td>姜子牙系列模型Ziya-LLaMA-13B-v1</td>
<td>基于LLaMA-13B的中英文模型</td>
<td></td>
</tr>
<tr>
<td>ChatLLaMA(英文版)</td>
<td>LLaMA的RLHF版</td>
<td></td>
</tr>
<tr>
<td>ColossalChat</td>
<td>通过self-instruct技术指令微调LLaMA且加上RLHF</td>
<td></td>
</tr>
</tbody></table>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="分支">分支</span><a href="#分支" class="header-anchor">#</a></h3><ol>
<li><a href="https://blog.csdn.net/v_JULY_v/article/details/129709105">LLaMA的解读与其微调：Alpaca-LoRA&#x2F;Vicuna&#x2F;BELLE&#x2F;中文LLaMA&#x2F;姜子牙&#x2F;LLaMA 2</a> ***<br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzUyOTA5OTcwMg==&mid=2247485019&idx=1&sn=e3417472c0c1f98aede498fbe905e1a0&">我想学大模型，应该从哪个模型开始？LLaMA生态家谱整理和分析 </a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/618695885">NLP（九）：LLaMA, Alpaca, ColossalChat 系列模型研究</a><br>1xx. <a href="https://github.com/www6v/Llama2-Chinese">https://github.com/www6v/Llama2-Chinese</a><br>1xx.  <a href="https://zhuanlan.zhihu.com/p/618321077">从0到1复现斯坦福羊驼（Stanford Alpaca 7B）</a><br> GPUs: 8 卡 A800 80GB GPUs<br>1xx. &lt;&lt;千帆增强版 Llama 2-提升大模型对话指令遵循能力&gt;&gt;</li>
</ol>
<h3><span id="llama">LLaMA</span><a href="#llama" class="header-anchor">#</a></h3><ol start="20">
<li><a href="http://arthurchiao.art/blog/llama-paper-zh/">[译][论文] LLaMA：开放和高效的基础语言模型集</a><br>1xx. <a href="https://www.bilibili.com/video/BV1nN41157a9/">第十五课：LLaMA</a>  *** 华为  V</li>
</ol>
<h3><span id="llama2">LLaMA2</span><a href="#llama2" class="header-anchor">#</a></h3><ol start="30">
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401927&idx=1&sn=3dddcb5c1d8b3c246a8b7529502fdcf0">也谈凌晨刷屏的Llama2开源可商用模型：从其数据构造、模型架构和评估方式等方面的一些总结与发现 </a></li>
<li><a href="https://www.bilibili.com/video/BV1qQ4y1t7Aj/">【对话引擎应用】千帆中文增强Llama2提升大模型对话指令遵循能力</a>  百度<br>1xx. <a href="https://zhuanlan.zhihu.com/p/649756898">Llama 2详解</a>  ***<br><a href="https://www.bilibili.com/video/BV12h4y1N7C8/">Llama 2 模型结构解析</a> *** V<br>1xx. <a href="https://www.bilibili.com/video/BV1Me411z7ZV/">第十六课：LLaMA2</a> *** 华为  V<br>1xx. <a href="http://arthurchiao.art/blog/llama2-paper-zh/">[译][论文] LLaMA 2：开放基础和微调聊天模型</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/644671690">Llama2技术细节&amp;开源影响</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401959&idx=1&sn=582fa45cd00035bac621336f47cce252">再看Llama2的实际体验与民间评测：从现有公开在线测试地址到几个测试例子看初步效果分析 </a></li>
</ol>
<p>1xx. <a href="https://llama.family/">Llama中文社区</a><br>2xx. <a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca"> Chinese-LLaMA-Alpaca</a> git</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>LLaMA</category>
      </categories>
      <tags>
        <tag>LLaMA</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent 实践</title>
    <url>/www6vHomeHexo/2023/01/01/gptAgentPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#assistant-api%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D-7">Assistant API功能介绍 [7]</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%BE%AE%E8%B0%83%E7%9A%84agent-function-call12">基于微调的Agent-function call[1][2]</a></li>
<li><a href="#multi-agnt">multi-agnt</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="assistant-api功能介绍-7">Assistant API功能介绍 [7]</span><a href="#assistant-api功能介绍-7" class="header-anchor">#</a></h1><p>从功能实现层面来说，Assistant API是截至目前最完整、性能最强大的AI应用开发API，具体功能如下：</p>
<ul>
<li>首先，Assistant API前所未有的能够<strong>调用OpenAI各模型的各项能力</strong>，包括可以调用Chat系列模型（即GPT系列模型）完成文本对话、调用DALL·E 3进行绘图、调用GPT-4-vision进行图像识别、以及调用Text-to-Speech模型进行语音转文字等，并且支持在一轮对话中调用不同模型；</li>
<li>其次，Assistant API还<strong>内置了代码解释器功能（Code interpreter）和海量文本信息提取功能（Knowledge retrieval）</strong>同时也一如既往支持借助<strong>Function calling</strong>进行模型功能层面拓展，此外，非常重要的是，Assistant API还支持在一轮对话中调用多个工具；</li>
<li>其三，此外对于开发者非常友好的一点是，Assistant API最小运行单元为持久化的线程对象（persistent Threads），因此在实际运行Assistant API时，不仅能可以精确控制每一步的执行过程，同时persistent Threads也会保留每轮对话的核心信息，并且当超出模型接收信息最大上下文限制时能够自动删除早期信息，从而实现对模型短期记忆的合理管理；</li>
<li>其四，Assistant API还能够直<strong>接连接OpenAI在线文档库</strong>，即如果用户将外部文档保存在OpenAI云空间内，则可以在调用Assistant API时实时访问文档库中的任意文件，甚至可以在不同线程中调用不同的文档。而在借助Assistant API的Knowledge retrieval功能，则可以让大模型实时获取这些文件信息，并且合理管理短期记忆；</li>
</ul>
<h1><span id="基于微调的agent-function-call12">基于微调的Agent-function call[1][2]</span><a href="#基于微调的agent-function-call12" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2023/01/01/gptAgentPractice/dirs.JPG" class>

<img src="/www6vHomeHexo/2023/01/01/gptAgentPractice/xtuner-agent.png" class>




<h1><span id="multi-agnt">multi-agnt</span><a href="#multi-agnt" class="header-anchor">#</a></h1><ul>
<li>CrewAI - OpenAI</li>
<li>AutoGPT</li>
<li>AutoGen</li>
<li>MetaGPT</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://github.com/InternLM/tutorial/blob/main/xtuner/README.md">xtuner</a> 4【补充】用 MS-Agent 数据集 赋予 LLM 以 Agent 能力</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1yK4y1B75J/">(4)XTuner 大模型单卡低成本微调实战</a></p>
</li>
<li><p><a href="https://github.com/www6v/AIGC/tree/master/%E4%B9%9D%E5%A4%A9Hector/Assistant%20API%E8%AF%A6%E8%A7%A3%E4%B8%8EAgent%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E4%B9%9D%E5%A4%A9Hector">Assistant API详解与Agent开发实战-九天Hector</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG 实践</title>
    <url>/www6vHomeHexo/2022/12/31/gptRAGPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E6%96%87%E6%9C%AC%E7%9A%84rag">基于文本的RAG</a><ul>
<li><a href="#langchain-chatchat-%E6%9E%B6%E6%9E%84">Langchain-Chatchat 架构</a></li>
<li><a href="#langchain-chatchat">Langchain-Chatchat</a></li>
</ul>
</li>
<li><a href="#%E5%A4%9A%E6%A8%A1%E6%80%81rag-%E5%A4%9A%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2%E5%99%A8-1011">多模态RAG-多向量检索器 [10][11]</a><ul>
<li><a href="#semi-structured-tables-text-rag-12">semi-structured (tables + text) RAG [12]</a></li>
<li><a href="#multi-modal-text-tables-images-rag-13">multi-modal (text + tables + images) RAG [13]</a></li>
<li><a href="#private-multi-modal-text-tables-images-rag-14">private multi-modal (text + tables + images)  RAG [14]</a></li>
<li><a href="#%E7%BB%84%E4%BB%B6">组件</a></li>
</ul>
</li>
<li><a href="#vectorkg-rag1516">Vector+KG RAG[15][16]</a></li>
<li><a href="#data-processing17">Data processing[17]</a></li>
<li><a href="#%E6%A1%86%E6%9E%B6-18">框架 [18]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E6%96%87%E6%9C%AC">文本</a></li>
<li><a href="#%E5%A4%9A%E6%A8%A1%E6%80%81">多模态</a></li>
<li><a href="#%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1">知识图谱</a></li>
<li><a href="#xxx">xxx</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="基于文本的rag">基于文本的RAG</span><a href="#基于文本的rag" class="header-anchor">#</a></h1><h3><span id="langchain-chatchat-架构">Langchain-Chatchat 架构</span><a href="#langchain-chatchat-架构" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2022/12/31/gptRAGPractice/langchain+chatglm.jpg" class>

<ul>
<li>组件<ul>
<li>本地知识库</li>
<li>Embedding 模型</li>
<li>向量数据库</li>
<li>Prompt Template</li>
</ul>
</li>
</ul>
<h3><span id="langchain-chatchat">Langchain-Chatchat</span><a href="#langchain-chatchat" class="header-anchor">#</a></h3><ul>
<li>部署 <ul>
<li>windows 10 [5]<br>部署本地， 没显存，卡</li>
<li>Linux [2]<br>部署   32C125G ，没显存， 推理很慢 </li>
<li>Docker</li>
</ul>
</li>
</ul>
<h1><span id="多模态rag-多向量检索器-1011">多模态RAG-多向量检索器 [10][11]</span><a href="#多模态rag-多向量检索器-1011" class="header-anchor">#</a></h1><h3><span id="semi-structured-tables-text-rag-12">semi-structured (tables + text) RAG [12]</span><a href="#semi-structured-tables-text-rag-12" class="header-anchor">#</a></h3><p> 分析pdf中表格 </p>
<h3><span id="multi-modal-text-tables-images-rag-13">multi-modal (text + tables + images) RAG [13]</span><a href="#multi-modal-text-tables-images-rag-13" class="header-anchor">#</a></h3><h3><span id="private-multi-modal-text-tables-images-rag-14">private multi-modal (text + tables + images)  RAG [14]</span><a href="#private-multi-modal-text-tables-images-rag-14" class="header-anchor">#</a></h3><p>分析PDF中图片<br><strong>Option 1</strong> </p>
<ul>
<li>Use multimodal embeddings <strong>(such as <a href="https://openai.com/research/clip">CLIP</a>)</strong> to embed images and text</li>
<li>Retrieve both using similarity search</li>
<li>Pass <strong>raw images and text chunks</strong> to a multimodal LLM for answer synthesis</li>
</ul>
<p><strong>Option 2</strong> </p>
<ul>
<li>Use a multimodal LLM (such as <a href="https://openai.com/research/gpt-4v-system-card">GPT4-V</a>, <a href="https://llava.hliu.cc/">LLaVA</a>, or <a href="https://www.adept.ai/blog/fuyu-8b">FUYU-8b</a>) to produce <strong>text summaries from images</strong></li>
<li>Embed and retrieve text </li>
<li>Pass text chunks to an LLM for answer synthesis</li>
</ul>
<p><strong>Option 3</strong> </p>
<ul>
<li>Use a multimodal LLM (such as <a href="https://openai.com/research/gpt-4v-system-card">GPT4-V</a>, <a href="https://llava.hliu.cc/">LLaVA</a>, or <a href="https://www.adept.ai/blog/fuyu-8b">FUYU-8b</a>) to produce text summaries from images</li>
<li>Embed and retrieve image summaries with a reference to the raw image </li>
<li>Pass <strong>raw images and text chunks</strong> to a multimodal LLM for answer synthesis</li>
</ul>
<h3><span id="组件">组件</span><a href="#组件" class="header-anchor">#</a></h3><ul>
<li>pdf解析<br>unstructured</li>
<li>store<br>MultiVectorRetriever - 元数据+数据</li>
</ul>
<h1><span id="vectorkg-rag1516">Vector+KG RAG[15][16]</span><a href="#vectorkg-rag1516" class="header-anchor">#</a></h1><h1><span id="data-processing17">Data processing[17]</span><a href="#data-processing17" class="header-anchor">#</a></h1><p>长文本   变成   QA pair</p>
<ul>
<li>规则匹配</li>
<li>利用LLM抽取</li>
<li>人工处理</li>
</ul>
<h1><span id="框架-18">框架 [18]</span><a href="#框架-18" class="header-anchor">#</a></h1><p>1）<strong>LangChain</strong>： <a href="https://github.com/langchain-ai/langchain/">https://github.com/langchain-ai/langchain/</a><br>2）QAnything： <a href="https://github.com/netease-youdao/QAnything/tree/master">https://github.com/netease-youdao/QAnything/tree/master</a><br>3）<strong>LlamaIndex</strong>： <a href="https://github.com/run-llama/llama_index/">https://github.com/run-llama/llama_index/</a><br>4）<strong>langchainchat</strong>： <a href="https://github.com/chatchat-space/Langchain-Chatchat/releases/tag/v0.2.8">https://github.com/chatchat-space/Langchain-Chatchat/releases/tag/v0.2.8</a><br>5) <strong>FastGPT</strong> ：<a href="https://github.com/labring/FastGPT">https://github.com/labring/FastGPT</a><br>6）langchain4j ：<a href="https://github.com/langchain4j/langchain4j">https://github.com/langchain4j/langchain4j</a><br>7）<strong>Unstructured</strong> ：<a href="https://github.com/Unstructured-IO/unstructured">https://github.com/Unstructured-IO/unstructured</a><br>8）GPT-RAG ：<a href="https://github.com/Azure/GPT-RAG">https://github.com/Azure/GPT-RAG</a><br>9）Quivr ：<a href="https://github.com/StanGirard/quivr">https://github.com/StanGirard/quivr</a><br>10）<strong>Dify</strong> ：<a href="https://github.com/langgenius/dify">https://github.com/langgenius/dify</a><br>11）Verba ：<a href="https://github.com/weaviate/Verba">https://github.com/weaviate/Verba</a><br>12）danswer：<a href="https://github.com/danswer-ai/danswer">https://github.com/danswer-ai/danswer</a></p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="文本">文本</span><a href="#文本" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://github.com/chatchat-space/Langchain-Chatchat">Langchain-Chatchat </a> master<br>Langchain 与 ChatGLM 等语言模型的本地知识库问答<br><a href="https://github.com/chatchat-space/Langchain-Chatchat/tree/v0.2.4">Langchain-Chatchat</a>  v0.2.4<br><a href="https://gitee.com/deepeye/langchain-ChatGLM">langchain-ChatGLM</a>  gitee </p>
</li>
<li><p><a href="https://github.com/www6v/Langchain-Chatchat-Colab">Colab for Langchain-Chatchat</a>   linux 可以部署  v0.2.6</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/649055955">langChain-ChatGLM 尝试，踩坑记录</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/651189680">Langchain-Chatchat + 阿里通义千问Qwen 保姆级教程 | 次世代知识管理解决方案</a>    Langchain-Chatchat + 通义千问</p>
</li>
<li><p><a href="https://blog.csdn.net/weixin_43094965/article/details/133044128">win10 安装 Langchain-Chatchat 避坑指南（2023年9月18日v0.2.4版本，包含全部下载内容！）</a></p>
</li>
</ol>
<h3><span id="多模态">多模态</span><a href="#多模态" class="header-anchor">#</a></h3><ol start="10">
<li><p><a href="https://www.zhihu.com/question/628651389/answer/3321989558">检索增强生成（RAG）有什么好的优化方案？</a> </p>
</li>
<li><p><a href="https://blog.langchain.dev/semi-structured-multi-modal-rag/">Multi-Vector Retriever for RAG on tables, text, and images</a> *** </p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb">Semi_Structured_RAG</a><br><a href="https://github.com/www6v/AIGC/blob/master/Advanced-RAG/01_semi_structured_data.ipynb">Advanced-RAG semi_structured_data</a>   code 半结构化-解析pdf中的表格，  运行没问题，能问表格中的数据</p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb">Semi_structured_and_multi_modal_RAG</a>  </p>
</li>
<li><p><a href="https://github.com/www6v/AIGC/blob/master/langchain-cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb">Private Semi-structured and Multi-modal RAG w&#x2F; LLaMA2 and LLaVA</a>  code 多模态- 解析pdf中的图片  运行有问题<br><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb">Private Semi-structured and Multi-modal RAG w&#x2F; LLaMA2 and LLaVA</a></p>
</li>
</ol>
<h3><span id="知识图谱">知识图谱</span><a href="#知识图谱" class="header-anchor">#</a></h3><ol start="15">
<li><p><a href="https://neo4j.com/developer-blog/unstructured-knowledge-graph-neo4j-langchain/">Enhanced QA Integrating Unstructured Knowledge Graph Using Neo4j and LangChain</a>  </p>
</li>
<li><p><a href="https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/">Using a Knowledge Graph to implement a DevOps RAG application</a></p>
</li>
</ol>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><ol start="17">
<li><p>&lt;&lt;大模型结合 RAG 构建客服场景自动问答系统&gt;&gt;  NVIDIA大模型日系列活动  </p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648407281&idx=2&sn=f39b46cad1787123b485d76dff33bc93">大模型RAG问答研发真实图鉴：一周出Demo，半年用不好，缝补之路漫漫 </a></p>
</li>
</ol>
<p>1xx. <a href="https://llamahub.ai/">LlamaHub</a><br>      Mix and match our Data Loaders and Agent Tools to build custom RAG apps or use our LlamaPacks as a starting point for your retrieval use cases.</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404338&idx=1&sn=3c8f8c44ac7a1d925216b40833525b25">再看业界大模型行业问答的困难及若干业界实践：兼看智能客服常用路线及多场景prompt </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/664921095">RAG探索之路的血泪史及曙光</a>  腾讯</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s/d2Nns1qashMbcXPMG-4McQ">阿里面向企业数字化的文档智能技术与应用</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404651&idx=2&sn=335db95e104a5b09e33ac2245bae4fd2">再看RAG在真实金融文档问答场景的实践方案：SMP2023 金融大模型挑战赛的两种代表实现思路</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>Retrievers</title>
    <url>/www6vHomeHexo/2022/12/31/gptRetrievers/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#langchain-retrievers10">Langchain Retrievers[10]</a><ul>
<li><a href="#multiqueryretriever">MultiQueryRetriever</a></li>
<li><a href="#contextual-compression">Contextual compression</a></li>
<li><a href="#ensemble-retriever">Ensemble Retriever</a></li>
<li><a href="#multivector-retriever">MultiVector Retriever</a></li>
<li><a href="#parent-document-retriever">Parent Document Retriever</a></li>
<li><a href="#self-querying">Self-querying</a></li>
</ul>
</li>
<li><a href="#langchian-retriever10">Langchian Retriever[10]</a></li>
<li><a href="#langchain-vs-llamaindex-1">langchain vs. llamaindex [1]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="langchain-retrievers10">Langchain Retrievers[10]</span><a href="#langchain-retrievers10" class="header-anchor">#</a></h1><h3><span id="multiqueryretriever">MultiQueryRetriever</span><a href="#multiqueryretriever" class="header-anchor">#</a></h3><p>The MultiQueryRetriever automates the process of prompt tuning by using an LLM to <strong>generate multiple queries from different perspectives for a given user input query</strong>. </p>
<h3><span id="contextual-compression">Contextual compression</span><a href="#contextual-compression" class="header-anchor">#</a></h3><h3><span id="ensemble-retriever">Ensemble Retriever</span><a href="#ensemble-retriever" class="header-anchor">#</a></h3><p>The EnsembleRetriever takes a list of retrievers as input and ensemble the results of their get_relevant_documents() methods and <strong>rerank the results based on the Reciprocal Rank Fusion algorithm</strong>.<br>The most common pattern is to <strong>combine a sparse retriever (like BM25) with a dense retriever (like embedding similarity)</strong>, because their strengths are complementary. It is also known as “hybrid search”.</p>
<h3><span id="multivector-retriever">MultiVector Retriever</span><a href="#multivector-retriever" class="header-anchor">#</a></h3><p>The methods to create multiple vectors per document include:<br>    - Smaller chunks: split a document into smaller chunks, and embed those (this is ParentDocumentRetriever).<br>    - Summary: create a summary for each document, embed that along with (or instead of) the document.<br>    - Hypothetical questions: create hypothetical questions that each document would be appropriate to answer, embed those along with (or instead of) the document.</p>
<h3><span id="parent-document-retriever">Parent Document Retriever</span><a href="#parent-document-retriever" class="header-anchor">#</a></h3><p>chunks of data</p>
<h3><span id="self-querying">Self-querying</span><a href="#self-querying" class="header-anchor">#</a></h3><p>This allows the retriever to not only use the user-input query for <strong>semantic similarity comparison</strong> with the contents of stored documents but to also extract filters from the user query on <strong>the metadata</strong> of stored documents and to execute those filters.</p>
<h1><span id="langchian-retriever10">Langchian Retriever[10]</span><a href="#langchian-retriever10" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>Name</th>
<th>Index Type</th>
<th>Uses an LLM</th>
<th>When to Use</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore">Vectorstore</a></td>
<td>Vectorstore</td>
<td>No</td>
<td>If you are just getting started and looking for something quick and easy.</td>
<td>This is the <strong>simplest method</strong> and the one that is easiest to get started with. It involves creating embeddings for each piece of text.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever">ParentDocument</a></td>
<td>Vectorstore + Document Store</td>
<td>No</td>
<td>If your pages have lots of smaller pieces of distinct information that are best indexed by themselves, but best retrieved all together.</td>
<td>This involves indexing <strong>multiple chunks</strong> for each document. Then you find the  chunks that are most similar in embedding space, but you retrieve the  <strong>whole parent</strong> document and <strong>return</strong> that (rather than individual chunks).</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector">Multi Vector</a></td>
<td>Vectorstore + Document Store</td>
<td>Sometimes during indexing</td>
<td>If you are able to extract information from documents that you think is more relevant to index than the text itself.</td>
<td>This involves creating multiple vectors for each document. Each vector could be created in a <strong>myriad of ways</strong> - examples include <strong>summaries of the text</strong> and <strong>hypothetical questions</strong>.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/self_query">Self Query</a></td>
<td>Vectorstore</td>
<td>Yes</td>
<td>If users are asking questions that are better answered by fetching  documents based on metadata rather than similarity with the text.</td>
<td>This uses an LLM to transform user input into two things: (1) a string to  look up semantically, (2) a <strong>metadata filer</strong> to go along with it. This is  useful because oftentimes questions are about the METADATA of documents  (not the content itself).</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression">Contextual Compression</a></td>
<td>Any</td>
<td>Sometimes</td>
<td>If you are finding that your retrieved documents contain too much irrelevant information and are distracting the LLM.</td>
<td>This puts a <strong>post-processing step</strong> on top of another retriever and extracts  only the most relevant information from retrieved documents. This can be done with embeddings or an LLM.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/time_weighted_vectorstore">Time-Weighted Vectorstore</a></td>
<td>Vectorstore</td>
<td>No</td>
<td>If you have timestamps associated with your documents, and you want to retrieve the most recent ones</td>
<td>This fetches documents based on a combination of semantic similarity (as in  normal vector retrieval) and recency (looking at timestamps of indexed  documents)</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever">Multi-Query Retriever</a></td>
<td>Any</td>
<td>Yes</td>
<td>If users are asking questions that are complex and require multiple pieces of distinct information to respond</td>
<td>This uses an LLM to <strong>generate multiple queries</strong> from the original one. This is useful when the original query needs pieces of information about  multiple topics to be properly answered. By generating multiple queries, we can then fetch documents for each of them.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble">Ensemble</a></td>
<td>Any</td>
<td>No</td>
<td>If you have multiple retrieval methods and want to try combining them.</td>
<td>This fetches documents from <strong>multiple retrievers</strong> and then <strong>combines</strong> them.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/long_context_reorder">Long-Context Reorder</a></td>
<td>Any</td>
<td>No</td>
<td>If you are working with a long-context model and noticing that it’s not  paying attention to information in the middle of retrieved documents.</td>
<td>This fetches documents from an underlying retriever, and then reorders them  so that the most similar are near the beginning and end. This is useful  because it’s been shown that for longer context models they sometimes  don’t pay attention to information in the middle of the context window.</td>
</tr>
</tbody></table>
<h1><span id="langchain-vs-llamaindex-1">langchain vs. llamaindex [1]</span><a href="#langchain-vs-llamaindex-1" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>langchain</th>
<th>llamaindex</th>
</tr>
</thead>
<tbody><tr>
<td>Ensemble</td>
<td>Hybrid Fusion</td>
</tr>
<tr>
<td>Rewrite-Retrieve-Read</td>
<td>Query Rewriting</td>
</tr>
<tr>
<td></td>
<td>AutoMerging</td>
</tr>
<tr>
<td>ParentDocumentRetrieval</td>
<td>Small-to-Big Retrieval</td>
</tr>
<tr>
<td></td>
<td>Sentence Window Retrieval</td>
</tr>
</tbody></table>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV1qe411r78b/">【高级RAG || 原理介绍】Llamaindex 5种高级RAG方法</a> V </li>
<li><a href="https://python.langchain.com/docs/modules/data_connection/retrievers">retrievers</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Retrievers</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>LLMOps</title>
    <url>/www6vHomeHexo/2022/12/28/gptLLMOps/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<ol>
<li><a href="https://drive.google.com/file/d/1LZXTrRdrloIqAJT6xaNTl4WQd6y95o7K/view">LLMOps: Deployment and Learning in Production</a><br><a href="https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/llmops/">LLMOps: Deployment and Learning in Production</a><br><a href="https://zhuanlan.zhihu.com/p/629589593">[必读] LLM 应用开发全栈指南</a> LLMOps</li>
<li><a href="https://zhuanlan.zhihu.com/p/632026876">了解一下新领域 LLMOps: 大模型运维</a><br><a href="https://wandb.ai/site/articles/understanding-llmops-large-language-model-operations">Understanding LLMOps: Large Language Model Operations</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>LLMOps</category>
      </categories>
      <tags>
        <tag>LLMOps</tag>
      </tags>
  </entry>
  <entry>
    <title>Fine-Tuning 时机</title>
    <url>/www6vHomeHexo/2022/12/28/gptFineTuningWhen/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E4%BD%95%E6%97%B6%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%831">何时进行微调[1]</a></li>
<li><a href="#what-4">what [4]</a></li>
<li><a href="#common-use-cases2">Common use cases[2]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="何时进行微调1">何时进行微调[1]</span><a href="#何时进行微调1" class="header-anchor">#</a></h1><p>语言模型（LLM）可以通过至少两种方式学习新知识：权重更新（例如预训练或微调）或提示（例如检索增强生成，RAG）。模型的权重就像长期记忆，而提示就像短期记忆。这个OpenAI Cookbook给出了一个有用的比喻：当你对模型进行微调时，就像是在离考试还有一周的时候准备复习。当你通过提示（例如检索）向提示中插入知识时，就像是在有开放笔记的考试中。</p>
<p>基于这一点，<strong>不建议使用微调来教授LLM新的知识或事实回忆</strong>；OpenAI的John Schulman在一次讲话中指出，微调可能会<strong>增加虚构</strong>。微调<strong>更适合教授专门的任务</strong>，但应与提示或RAG相对比。正如这里所讨论的，对于具有丰富示例和&#x2F;或缺乏上下文学习能力的LLM来说，微调对于定义明确的任务可能是有帮助的。这篇Anyscale博客很好地总结了这些观点：<strong>微调是为形式而非事实</strong>[3]。</p>
<h1><span id="what-4">what [4]</span><a href="#what-4" class="header-anchor">#</a></h1><p>这是一个很好的问题。我大致将微调类比为人的专业知识：</p>
<ul>
<li><strong>用文字描述一个任务 ~&#x3D; 零样本提示</strong></li>
<li><strong>给出解决任务的示例 ~&#x3D; 少样本提示</strong></li>
<li><strong>允许人们练习任务 ~&#x3D; 微调</strong></li>
</ul>
<p>考虑到这个比喻，令人惊奇的是我们有了可以仅通过提示就能在许多任务上达到高水平准确性的模型，但我也预计达到顶级性能可能需要微调，特别是在具有明确定义的具体任务的应用中，在这些任务中我们可以收集大量数据并在其上进行“练习”。</p>
<p>这可能是一个需要牢记的<strong>粗略图景</strong>。<strong>小型模型</strong>无法进行上下文学习，并且从提示工程中受益甚少，但根据任务的难度，<strong>仍然有可能将它们微调为表现良好的专家</strong>。</p>
<p>需要注意的是，所有这些都还是非常新颖的。</p>


<h1><span id="common-use-cases2">Common use cases[2]</span><a href="#common-use-cases2" class="header-anchor">#</a></h1><p>微调可以改善结果的一些常见<strong>用例</strong>包括：</p>
<ul>
<li><strong>设定风格、语气、格式或其他定性因素</strong></li>
<li><strong>提高生成所需输出的可靠性</strong></li>
<li><strong>纠正无法按照复杂提示要求执行的问题</strong></li>
<li>以特定方式处理许多边缘情况</li>
<li><strong>执行难以用提示清晰表达的新技能或任务</strong></li>
</ul>
<p>从较高层面来看，这些情况下微调更容易实现“<strong>展示而非告诉</strong>”的效果。在接下来的部分中，我们将探讨如何为微调设置数据以及各种示例，这些示例中微调改善了基线模型的性能。</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://blog.langchain.dev/using-langsmith-to-support-fine-tuning-of-open-source-llms/">Using LangSmith to Support Fine-tuning</a><br>  <a href="https://colab.research.google.com/drive/1tpywvzwOS74YndNXhI8NUaEfPeqOc7ub?usp=sharing&ref=blog.langchain.dev">colab</a>   LANGCHAIN_API_KEY</p>
</li>
<li><p><a href="https://platform.openai.com/docs/guides/fine-tuning">Fine-tuning</a>  openai *** </p>
</li>
<li><p><a href="https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts">Fine tuning is for form, not facts</a> ***</p>
</li>
<li><p><a href="https://twitter.com/karpathy/status/1655994367033884672">Andrej Karpathy twitter</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Fine-Tuning</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG 性能-OpenAI案例</title>
    <url>/www6vHomeHexo/2022/12/27/gptRAGPerformanceOpenAI/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="openai-rag-案例3">OpenAI RAG 案例[3]</span><a href="#openai-rag-案例3" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/12/27/gptRAGPerformanceOpenAI/openai-rag.jpg" class>

<ol>
<li>retrieval with consine similarity</li>
<li><strong>HyDE retrieval</strong> [5]<br>Fine-tune Embeddings<br><strong>Chunk&#x2F;embedding experiments</strong></li>
<li><strong>Reranking</strong> [6][8]<br>Classification step</li>
<li>Prompt engineering<br><strong>Tool use</strong><br><strong>Query expansion</strong>[5]</li>
</ol>
<h3><span id="query-transformations5">Query Transformations[5]</span><a href="#query-transformations5" class="header-anchor">#</a></h3><ul>
<li><strong>Query expansion</strong><br>Multi-query retriever </li>
<li><strong>HyDE</strong></li>
<li>Step back prompting<br> [抽象prompting]</li>
<li>Rewrite-Retrieve-Read</li>
</ul>
<h3><span id="query-construction-4">Query Construction [4]</span><a href="#query-construction-4" class="header-anchor">#</a></h3>

<table>
<thead>
<tr>
<th><strong>Examples</strong></th>
<th><strong>Data source</strong></th>
<th><strong>References</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Text-to-metadata-filter</strong></td>
<td>Vectorstores</td>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/?ref=blog.langchain.dev#constructing-from-scratch-with-lcel"><strong>Docs</strong></a></td>
</tr>
<tr>
<td><strong>Text-to-SQL</strong></td>
<td>SQL DB</td>
<td><a href="https://python.langchain.com/docs/use_cases/qa_structured/sql?ref=blog.langchain.dev"><strong>Docs</strong></a><strong>,</strong> <a href="https://blog.langchain.dev/llms-and-sql/"><strong>blog</strong></a><strong>,</strong> <a href="https://blog.langchain.dev/incorporating-domain-specific-knowledge-in-sql-llm-solutions/"><strong>blog</strong></a></td>
</tr>
</tbody></table>
<ul>
<li>Text-to-metadata-filter [7]</li>
</ul>
<p>A <strong>self-querying</strong> retriever is one that, as the name suggests, has the  ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a <strong>structured query</strong> and then applies that structured query to its underlying  VectorStore. This allows the retriever to not only use the user-input  query for semantic similarity comparison with the contents of stored  documents but to also <strong>extract filters from the user query on the  metadata of stored documents and to execute those filters</strong>.</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol start="3">
<li><p><a href="https://blog.langchain.dev/applying-openai-rag/">Applying OpenAI’s RAG Strategies</a>   *** </p>
</li>
<li><p><a href="https://blog.langchain.dev/query-construction/">Query Construction</a> ***</p>
</li>
<li><p><a href="https://blog.langchain.dev/query-transformations/">Query Transformations</a></p>
</li>
<li><p><a href="https://txt.cohere.com/rerank/">Say Goodbye to Irrelevant Search Results: Cohere Rerank Is Here</a><br><a href="https://github.com/langchain-ai/langchain/tree/master/templates/rag-pinecone-rerank">Rerank</a><br><a href="https://python.langchain.com/docs/integrations/retrievers/cohere-reranker">Cohere Reranker</a></p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/docs/docs/modules/data_connection/retrievers/self_query.ipynb">self_query</a></p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb">RAG Fusion</a><br><a href="https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1">Forget RAG, the Future is RAG-Fusion</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>PEFT 实战</title>
    <url>/www6vHomeHexo/2022/12/20/gptFineTuningPEFT/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="huggingface-peft中的任务1">Huggingface  PEFT中的任务[1]</span><a href="#huggingface-peft中的任务1" class="header-anchor">#</a></h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class TaskType(str, enum.Enum):</span><br><span class="line">    SEQ_CLS = &quot;SEQ_CLS&quot;  # 3. 序列分类任务</span><br><span class="line">    SEQ_2_SEQ_LM = &quot;SEQ_2_SEQ_LM&quot;  # 2. 条件生成任务</span><br><span class="line">    CAUSAL_LM = &quot;CAUSAL_LM&quot;  #  1. 因果语言建模任务</span><br><span class="line">    TOKEN_CLS = &quot;TOKEN_CLS&quot;  #  4. Token 分类任务</span><br><span class="line">    QUESTION_ANS = &quot;QUESTION_ANS&quot;</span><br><span class="line">    FEATURE_EXTRACTION = &quot;FEATURE_EXTRACTION&quot;</span><br></pre></td></tr></table></figure>

<h3><span id="1-因果语言建模任务causal-language-modeling">1. 因果语言建模任务（Causal Language Modeling）</span><a href="#1-因果语言建模任务causal-language-modeling" class="header-anchor">#</a></h3><p>  因果语言建模任务（CLM），在这种建模方法中，模型试图预测给定上下文中的下一个单词，该上下文通常包括在当前单词之前的所有单词。</p>
<h3><span id="2-条件生成任务conditional-generation">2. 条件生成任务（Conditional Generation）</span><a href="#2-条件生成任务conditional-generation" class="header-anchor">#</a></h3><p>  条件生成任务（Conditional Generation），根据给定的输入（可能是文本、图片等）生成符合条件的输出。<br>  条件生成的应用包括但不限于机器翻译、文本摘要、图像描述等。这些任务通常需要模型在输入和输出之间建立复杂的映射关系。</p>
<blockquote>
<p>因果语言建模任务  vs.  条件生成任务<br>  因果语言建模主要关注于生成连贯、自然的文本，而条件生成关注于生成满足特定条件或任务要求的文本。这两种建模方法在某些场景下可能会互相使用和结合，以实现更复杂的自然语言处理任务。</p>
</blockquote>
<h3><span id="3-序列分类任务sequence-classification">3. 序列分类任务（Sequence Classification）</span><a href="#3-序列分类任务sequence-classification" class="header-anchor">#</a></h3><p>  序列分类（Sequence Classification），对整个句子进行分类。如: 获取评论的情绪，检测电子邮件是否为垃圾邮件，确定句子在语法上是否正确或两个句子在逻辑上是否相关等</p>
<h3><span id="4-token-分类任务token-classification">4. Token 分类任务（Token Classification）</span><a href="#4-token-分类任务token-classification" class="header-anchor">#</a></h3><p>  Token 分类任务（Token Classification），对句子中的每个词进行分类。如: 识别句子的语法成分（名词、动词、形容词）或命名实体（人、地点、组织）。</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/651744834">大模型参数高效微调技术实战（一）-PEFT概述</a></li>
<li><a href="https://github.com/www6v/llm-action#llm%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98">LLM微调实战</a> 李国东</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT 系列</title>
    <url>/www6vHomeHexo/2022/12/11/gptFamily/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E8%BF%9B%E5%8C%96%E6%97%B6%E9%97%B4%E7%BA%BF">进化时间线</a></li>
<li><a href="#gpt1-1">GPT1 [1]</a></li>
<li><a href="#gpt2-1">GPT2 [1]</a><ul>
<li><a href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3">核心思想</a></li>
<li><a href="#gpt-2-vs-gpt-1">GPT-2 vs. GPT-1</a></li>
</ul>
</li>
<li><a href="#gpt3-1">GPT3 [1]</a><ul>
<li><a href="#%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95">下游任务评估方法</a></li>
<li><a href="#few-shot-vs-fine-tuning">Few-shot vs fine-tuning</a></li>
<li><a href="#gpt-3-vs-gpt-2">GPT-3 vs. GPT-2</a></li>
</ul>
</li>
<li><a href="#instructgpt-1">InstructGPT [1]</a><ul>
<li><a href="#%E6%AD%A5%E9%AA%A4">步骤</a></li>
<li><a href="#%E6%8A%80%E6%9C%AF%E6%96%B9%E6%A1%88">技术方案</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
</ul>
</li>
<li><a href="#chatgpt-%E8%AE%AD%E7%BB%83-3">ChatGPT 训练  [3]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="进化时间线">进化时间线</span><a href="#进化时间线" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/12/11/gptFamily/family.jpg" class>

<h1><span id="gpt1-1">GPT1 [1]</span><a href="#gpt1-1" class="header-anchor">#</a></h1><ol>
<li>它是最早一批提出在 NLP 任务上使用 <strong>pre-train + fine-tuning 范式</strong>的工作。</li>
<li>GPT 的实验证明了模型的精度和泛化能力会随着解码器层数增加而不断提升，而且目前还有提升空间</li>
<li><strong>预训练模型具有 zero-shot 的能力</strong>，并且能随着预训练的进行不断增强</li>
</ol>
<h1><span id="gpt2-1">GPT2 [1]</span><a href="#gpt2-1" class="header-anchor">#</a></h1><h3><span id="核心思想">核心思想</span><a href="#核心思想" class="header-anchor">#</a></h3><p>当模型的容量非常大且数据量足够丰富时，仅仅靠语言模型的学习便可以完成其他有监督学习的任务，<strong>不需要在下游任务微调</strong>。</p>
<h3><span id="gpt-2-vs-gpt-1">GPT-2 vs. GPT-1</span><a href="#gpt-2-vs-gpt-1" class="header-anchor">#</a></h3><ol>
<li><strong>主推 zero-shot</strong>，而 GPT-1 为 pre-train + fine-tuning；</li>
<li>训练数据规模更大，GPT-2 为 800w 文档 40G，GPT-1 为 5GB；</li>
<li>模型大小，GPT-2 最大 15 亿参数，GPT-1为 1 亿参数；</li>
<li>模型结构调整，层归一化和参数初始化方式；</li>
<li>训练参数，batch_size 从 64 增加到 512，上文窗口大小从 512 增加到 1024，等等；</li>
</ol>
<h1><span id="gpt3-1">GPT3 [1]</span><a href="#gpt3-1" class="header-anchor">#</a></h1><h3><span id="下游任务评估方法">下游任务评估方法</span><a href="#下游任务评估方法" class="header-anchor">#</a></h3><p>GPT-3 在下游任务的评估与预测时，提供了三种不同的方法：<br><strong>Zero-shot</strong>：仅使用当前任务的自然语言描述，不进行任何梯度更新；<br><strong>One-shot</strong>：当前任务的自然语言描述，加上一个简单的输入输出样例，不进行任何梯度更新；<br><strong>Few-shot</strong>：当前任务的自然语言描述，加上几个简单的输入输出样例，不进行任何梯度更新；</p>
<ul>
<li>Shot[2]<ul>
<li>One-shot</li>
<li>Few-Shot</li>
<li>Zero-Shot</li>
</ul>
</li>
</ul>
<h3><span id="few-shot-vs-fine-tuning">Few-shot vs fine-tuning</span><a href="#few-shot-vs-fine-tuning" class="header-anchor">#</a></h3><p>其中 <strong>Few-shot</strong> 也被称为 <strong>in-context learning</strong>，虽然它与 fine-tuning 一样都需要一些<strong>有监督标注数据</strong>，但是两者的区别是：<br>【本质区别】<br><strong>fine-tuning</strong> 基于标注数据<strong>对模型参数进行更新</strong><br>而<strong>in-context learning</strong>使用标注数据时不做任何的梯度回传, <strong>模型参数不更新</strong></p>
<h3><span id="gpt-3-vs-gpt-2">GPT-3 vs. GPT-2</span><a href="#gpt-3-vs-gpt-2" class="header-anchor">#</a></h3><ol>
<li>效果上，超出 GPT-2 非常多，能生成人类难以区分的新闻文章；</li>
<li><strong>主推 few-shot</strong>，相比于 GPT-2 的 zero-shot，具有很强的创新性；</li>
<li>模型结构略微变化，采用 <strong>sparse attention</strong> 模块；</li>
<li>海量训练语料 <strong>45TB</strong>（清洗后 570GB），相比于 GPT-2 的 40GB；</li>
<li>海量模型参数，最大模型为 <strong>1750 亿</strong>，GPT-2 最大为 15 亿参数；</li>
</ol>
<h1><span id="instructgpt-1">InstructGPT [1]</span><a href="#instructgpt-1" class="header-anchor">#</a></h1><h3><span id="步骤">步骤</span><a href="#步骤" class="header-anchor">#</a></h3><ul>
<li>有监督微调，</li>
<li>奖励模型训练，</li>
<li>强化学习训练</li>
</ul>
<h3><span id="技术方案">技术方案</span><a href="#技术方案" class="header-anchor">#</a></h3><ul>
<li><p>有监督微调（SFT）<br>本质上来说，<strong>SFT 可以理解为人工标注了一批数据，然后去微调 GPT-3</strong>。但是值得一提的是，这里<strong>标注的数据与 GPT-3 之前用来做下游任务使用的 few-shot 格式，有非常本质的区别</strong>。<br>InstructGPT 在 SFT 中标注的数据，正是为了<strong>消除这种模型预测与用户表达习惯之间的 gap</strong>。在标注过程中，他们<strong>从 GPT-3 的用户真实请求中采样</strong>大量下游任务的描述，然后让<strong>标注人员对任务描述进行续写</strong>，从而得到该问题的高质量回答。</p>
</li>
<li><p>基于人类反馈的强化学习（RLHF）</p>
<img src="/www6vHomeHexo/2022/12/11/gptFamily/instructGPT.jpg" class></li>
</ul>
<h3><span id="总结">总结</span><a href="#总结" class="header-anchor">#</a></h3><ol>
<li>解决 GPT-3 的<strong>输出与人类意图</strong>之间的<strong>Align问题</strong>；</li>
<li>让具备丰富世界知识的大模型，<strong>学习“人类偏好”</strong>；</li>
<li>标注人员明显感觉 InstructGPT 的输出比 GPT-3 的输出更好，更可靠；</li>
<li>InstructGPT 在<strong>真实性</strong>，<strong>丰富度</strong>上表现更好；</li>
<li>InstructGPT 对有害结果的生成控制的更好，但是对于<strong>“偏见”没有明显改善</strong>；</li>
</ol>
<h1><span id="chatgpt-训练-3">ChatGPT 训练  [3]</span><a href="#chatgpt-训练-3" class="header-anchor">#</a></h1><ul>
<li>基于人类反馈的强化学习微调技术 RLHF<ul>
<li>使用有监督微调 Supervised Fine-tuning（SFT）预训练语言模型<ul>
<li>Supervised fine-tuning (SFT)<br>&#x3D; Instruction Tuning</li>
</ul>
</li>
<li>训练奖励模型 Reward Model（RM）</li>
<li>使用强化学习算法微调语言模型<ul>
<li>RLHF<br>[本质  基于强化学习, 强化学习算法]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/609716668">GPT &#x2F; GPT-2 &#x2F; GPT-3 &#x2F; InstructGPT 进化之路</a> ***</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/624793654">Few-Shot, Zero-Shot &amp; One-shot 的通俗理解</a></p>
</li>
<li><p><a href="https://shimo.im/docs/KlkKv4XQDouwWRqd/read">AI 大模型微调训练营大纲</a></p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/642282717">[Transformer 101系列] ChatGPT是怎么炼成的?</a> 未</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>GPT</category>
      </categories>
      <tags>
        <tag>GPT</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG 性能</title>
    <url>/www6vHomeHexo/2022/12/07/gptRAGPerformance/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F-12">索引方式 [1][2]</a><ul>
<li><a href="#smaller-chunks">Smaller chunks</a></li>
<li><a href="#hypothetical-questions">Hypothetical questions</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E5%9D%973">分块[3]</a><ul>
<li><a href="#%E5%88%86%E5%9D%97%E5%8F%82%E6%95%B0">分块参数</a></li>
</ul>
</li>
<li><a href="#%E6%A3%80%E7%B4%A2%E5%99%A8-retriever">检索器 Retriever</a></li>
<li><a href="#embedding">Embedding</a></li>
<li><a href="#reranker">Reranker</a><ul>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AFreranker-6">什么是Reranker [6]</a></li>
<li><a href="#bge-ranker-4">BGE Ranker [4]</a></li>
<li><a href="#%E4%BC%98%E7%A7%80%E7%9A%84%E7%BB%84%E5%90%88-5">优秀的组合 [5]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="索引方式-12">索引方式  [1][2]</span><a href="#索引方式-12" class="header-anchor">#</a></h1><h3><span id="smaller-chunks">Smaller chunks</span><a href="#smaller-chunks" class="header-anchor">#</a></h3><p>Indexing by <strong>small data chunks</strong><br>按子部分索引数据块：将文本块拆分为较小的部分，如句子，进行多次索引。这有助于<br>处理复杂文本块，减少噪音输出，确保更准确匹配用户查询。</p>
<h3><span id="hypothetical-questions">Hypothetical questions</span><a href="#hypothetical-questions" class="header-anchor">#</a></h3><p>Indexing by <strong>the questions the document answers</strong><br>按文本块回答的问题索引数据块：让LLM生成与拆分的文本块相关的假设性问题，并用<br>于索引。这种方法保持用户查询与数据核心内容一致，降低模糊性。</p>
<h3><span id="summary">Summary</span><a href="#summary" class="header-anchor">#</a></h3><p>Indexing by <strong>the summary of the document</strong></p>
<p>按文本块摘要索引数据块：类似于第二种方法，使用块摘要而不是回答的假设问题来创<br>建索引。特别适用于文本块中包含多余信息或与用户查询无关的情况。</p>
<h1><span id="分块3">分块[3]</span><a href="#分块3" class="header-anchor">#</a></h1><h3><span id="分块参数">分块参数</span><a href="#分块参数" class="header-anchor">#</a></h3><p>chuck_size, ,chunk overlap<br>top_k</p>
<blockquote>
<p>最佳实践<br>  按<strong>逻辑分块</strong>可以明显提升<strong>检索器的准确率</strong></p>
</blockquote>
<h1><span id="检索器-retriever">检索器 Retriever</span><a href="#检索器-retriever" class="header-anchor">#</a></h1><ul>
<li>Ensemble Retriever<br>最常见的模式是将<strong>稀疏检索器（如BM25）</strong>与<strong>密集检索器（如嵌入相似度）</strong>结合起来，因为它们的优势是互补的。这也被称为“混合搜索”。<strong>稀疏检索器</strong>擅长基于<strong>关键词查找</strong>相关文档，而<strong>密集检索器</strong>擅长基于<strong>语义相似性查找</strong>相关文档。</li>
</ul>
<blockquote>
<p>最佳实践<br><strong>BM25+FAAIS   好于 FAAIS相似度搜索</strong><br><strong>FAAIS相似度搜索 好于 HyDE和上下文压缩</strong></p>
</blockquote>
<h1><span id="embedding">Embedding</span><a href="#embedding" class="header-anchor">#</a></h1><ul>
<li>HyDE<br>At a high level, HyDE is an embedding technique that takes queries, <strong>generates a hypothetical answer</strong>, and then embeds that generated document and uses that as the final example.</li>
</ul>
<blockquote>
<p>最佳实践<br><strong>BGE</strong> 优于 OpenAI ADA02</p>
</blockquote>
<h1><span id="reranker">Reranker</span><a href="#reranker" class="header-anchor">#</a></h1><h3><span id="什么是reranker-6">什么是Reranker [6]</span><a href="#什么是reranker-6" class="header-anchor">#</a></h3><p>A reranking model — also known as a <strong>cross-encoder</strong> — is a type of model that,** given a query and document pair, will output a similarity score.** </p>
<h3><span id="bge-ranker-4">BGE Ranker [4]</span><a href="#bge-ranker-4" class="header-anchor">#</a></h3><p><strong>交叉编码器</strong>将对查询和答案实时计算相关性分数，这比**向量模型(即双编码器)**更准确，但比向量模型更耗时。 因此，它可以用来对嵌入模型返回的前k个文档重新排序。 我们在多语言数据上训练了交叉编码器，数据格式与向量模型相同，因此您可以根据我们的示例 轻松地对其进行微调。 </p>
<h3><span id="优秀的组合-5">优秀的组合 [5]</span><a href="#优秀的组合-5" class="header-anchor">#</a></h3><p>OpenAI + CohereRerank<br>Voyage + big-reranker-large</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://www.bilibili.com/video/BV1dH4y1C7Ck/">3种高级索引方法，有效提升RAG性能</a> V<br><a href="https://thetechbuffet.substack.com/p/rag-indexing-methods">The Tech Buffet #12: Improve RAG Pipelines With These 3 Indexing Methods</a><br><a href="https://newsletter.theaiedge.io/p/how-to-optimize-your-rag-pipelines">How To Optimize Your RAG Pipelines</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1Vu4y1H72s/">【RAG实战】 Multi-Vector-Retrieval实现三种高级索引方法</a> V<br><a href="https://github.com/www6v/AIGC/blob/master/retriever%2Bindex/MultiVectorRetriever">MultiVectorRetriever</a><br>   <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector">MultiVector Retriever</a></p>
</li>
<li><p><a href="https://hustai.gitee.io/zh/posts/rag/Chunking-Strategies.html">大语言模型应用中的文本分块策略</a><br><a href="https://yangfei.me/tutorials/chunking-strategies">LLM 应用中的分块策略 </a></p>
</li>
<li><p><a href="https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md">BGE Reranker</a><br><a href="https://www.bilibili.com/video/BV1sQ4y137Ft/">transformers二次开发——bge-reranker模型微调流程</a> V</p>
</li>
<li><p><a href="https://luxiangdong.com/2023/11/06/rerank-ev/#">提升RAG——选择最佳Embedding和重新排名模型 </a><br><a href="https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83">Boosting RAG: Picking the Best Embedding &amp; Reranker models</a></p>
</li>
<li><p><a href="https://www.pinecone.io/learn/series/rag/rerankers/">Rerankers and Two-Stage Retrieval</a><br>文中的第二阶段就是指Reranker</p>
</li>
</ol>
<p>1xx. <a href="https://www.youtube.com/watch?v=ahnGLM-RC1Y">A Survey of Techniques for Maximizing LLM Performance</a>  *** V</p>
<pre><code>[A Survey of Techniques for Maximizing LLM Performance梳理](https://zhuanlan.zhihu.com/p/670880685) 
</code></pre>
<p>1xx. <a href="https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b">A Cheat Sheet and Some Recipes For Building Advanced RAG</a><br>     <a href="https://mp.weixin.qq.com/s/KM8c3PUww1SOK1dbLjn1Tw">LlamaIndex官方年度巨献：高清大图纵览高级 RAG技术，强烈推荐收藏 </a> *** 看图<br>     <a href="https://baoyu.io/translations/rag/a-cheat-sheet-and-some-recipes-for-building-advanced-rag">构建高级 RAG 的指南和技巧 [译]</a></p>
<p>1xx. <a href="https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6">Advanced RAG Techniques: an Illustrated Overview</a><br>     <a href="https://mp.weixin.qq.com/s/CO7hMv4RW7OE6zwUmVfp5A">最全的RAG技术概览 </a></p>
<p>1xx. <a href="https://baoyu.io/translations/rag/5-levels-of-text-splitting">文本分割的五个层次 [译]</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648406795&idx=1&sn=00ea4aab819eed3d622287fa1d32816f">大模型RAG问答技术架构及核心模块回顾：从Embedding、prompt-embedding到Reranker </a> ***</p>
<p>1xx. CON<br>   <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648406194&idx=1&sn=aafe667fa5a73bd89a00272c5598c98e">引入COT缓解大模型RAG问答的上下文区分问题：兼看Langchain的表格检索思路及GPTBIAS评估框架 </a> CON<br>   <a href="https://cobusgreyling.medium.com/chain-of-note-con-retrieval-for-llms-763ead1ae5c5">Chain-Of-Note (CoN) Retrieval For LLMs</a><br>   <a href="https://praveengovindaraj.com/cutting-through-the-noise-chain-of-notes-con-robust-approach-to-super-power-your-rag-pipelines-0df5f1ce7952">Cutting Through the Noise: Chain-of-Note’s (CoN) Robust Approach to super power your RAG pipelines</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer</title>
    <url>/www6vHomeHexo/2022/11/30/gptTransformer/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">神经网络</a></li>
<li><a href="#attention-3">Attention [3]</a><ul>
<li><a href="#%E4%BC%98%E5%8C%964">优化[4]</a></li>
</ul>
</li>
<li><a href="#transformer-2">Transformer [2]</a><ul>
<li><a href="#encoder-decoder%E6%9E%B6%E6%9E%84-1">Encoder-Decoder架构 [1]</a></li>
<li><a href="#self-attention">Self-attention</a></li>
<li><a href="#multi-head-attentionmha">Multi-Head Attention(MHA)</a></li>
<li><a href="#positional-encoding">Positional Encoding</a></li>
<li><a href="#layer-normalization">Layer Normalization</a></li>
</ul>
</li>
<li><a href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B">大模型</a><ul>
<li><a href="#%E6%9E%B6%E6%9E%84-67">架构 [6][7]</a></li>
<li><a href="#%E4%BC%98%E5%8C%96%E7%82%B9">优化点</a></li>
<li><a href="#%E5%85%B3%E6%B3%A8%E7%82%B95">关注点[5]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#attention">Attention</a></li>
<li><a href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81">位置编码</a></li>
<li><a href="#%E5%85%B6%E4%BB%96">其他</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="神经网络">神经网络</span><a href="#神经网络" class="header-anchor">#</a></h1><ul>
<li><p>正向传播<br>损失函数  </p>
</li>
<li><p>反相传播<br>梯度</p>
</li>
</ul>
<h1><span id="attention-3">Attention [3]</span><a href="#attention-3" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/11/30/gptTransformer/self-attention.jpg" class>

<h3><span id="优化4">优化[4]</span><a href="#优化4" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2022/11/30/gptTransformer/attentions.jpg" class>

<h1><span id="transformer-2">Transformer [2]</span><a href="#transformer-2" class="header-anchor">#</a></h1><h3><span id="encoder-decoder架构-1">Encoder-Decoder架构 [1]</span><a href="#encoder-decoder架构-1" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2022/11/30/gptTransformer/Transformer_decoder.jpg" class>
<img src="/www6vHomeHexo/2022/11/30/gptTransformer/transformer_resideual_layer_norm_3.jpg" class>

<p>transfomer 架构在GPU上的并行</p>
<h3><span id="self-attention">Self-attention</span><a href="#self-attention" class="header-anchor">#</a></h3><p>Q&#x3D;K&#x3D;V<br>aligment</p>
<h3><span id="multi-head-attentionmha">Multi-Head Attention(MHA)</span><a href="#multi-head-attentionmha" class="header-anchor">#</a></h3><h3><span id="positional-encoding">Positional Encoding</span><a href="#positional-encoding" class="header-anchor">#</a></h3><h3><span id="layer-normalization">Layer Normalization</span><a href="#layer-normalization" class="header-anchor">#</a></h3><ul>
<li>Post-LN</li>
<li>Pre-LN</li>
<li>Sandwich-LN<br>layerNorm是针对序列数据提出的一种归一化方法，主要在layer维度进行归一化，即对整个序列进行归一化。</li>
</ul>
<h1><span id="大模型">大模型</span><a href="#大模型" class="header-anchor">#</a></h1><h3><span id="架构-67">架构 [6][7]</span><a href="#架构-67" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2022/11/30/gptTransformer/bigModelArch.jpg" class>

<img src="/www6vHomeHexo/2022/11/30/gptTransformer/bigModelArch1.jpg" class>

<h3><span id="优化点">优化点</span><a href="#优化点" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2022/11/30/gptTransformer/transformers.jpg" class>

<h3><span id="关注点5">关注点[5]</span><a href="#关注点5" class="header-anchor">#</a></h3><ul>
<li><p><strong>Mask attention 的策略不同</strong></p>
<ul>
<li>bert  [双向都能看到]</li>
<li>chatgpt  [只能看到单项的]</li>
<li>chatglm  [左边像bert, 右边像gpt]</li>
</ul>
</li>
<li><p><strong>训练任务目标不同</strong></p>
<ul>
<li>bert [mask掉一个次, 在原位置把它预测出来]</li>
<li>gpt [预测下一个词]</li>
<li>chatglm [用gpt的方式来做bert的任务]</li>
</ul>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="http://jalammar.github.io/illustrated-transformer/">illustrated-transformer</a> ***<br><a href="https://baoyu.io/translations/llm/illustrated-transformer">图解 Transformer [译]</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/311156298">Transformer - Attention is all you need</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/410776234">超详细图解Self-Attention</a> ***</p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2328541">主流大语言模型的技术原理细节</a>  *** [架构]+训练+微调</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1gY4y1d7nk/">基于ChatGLM对话系统实战</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/648050614">LLM学习系列1：大模型架构要点总结</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2328541">主流大语言模型的技术原理细节</a> *** 腾讯     架构 + 训练 + 微调</p>
</li>
</ol>
<p>2xx. <a href="https://www.bilibili.com/video/BV16h4y1W7us/">第一课：Transformer</a> ***  华为<br>2xx. <a href="https://bbycroft.net/llm">LLM Visualization</a> ***  可视化<br>2xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/127411638">Transformer通俗笔记：从Word2Vec、Seq2Seq逐步理解到GPT、BERT</a> *** </p>
<h3><span id="attention">Attention</span><a href="#attention" class="header-anchor">#</a></h3><p>1xx. <a href="https://blog.csdn.net/kkm09/article/details/120855658">李宏毅《深度学习》- Self-attention 自注意力机制</a><br>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/134228287">一文通透各种注意力：从多头注意力MHA到分组查询注意力GQA、多查询注意力MQA</a></p>
<h3><span id="位置编码">位置编码</span><a href="#位置编码" class="header-anchor">#</a></h3><p>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/134085503">一文通透位置编码：从标准位置编码、旋转位置编码RoPE到ALiBi、LLaMA 2 Long</a></p>
<p>1xx.<a href="https://baoyu.io/translations/llm/the-random-transformer">深入解析随机 Transformer [译]</a> *** </p>
<h3><span id="其他">其他</span><a href="#其他" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/640784855">[Transformer 101系列] 初探LLM基座模型</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/664046612">LLM从0开始预训练系列：2、大模型技术报告总结（GPT&#x2F;PaLM&#x2F;GLM&#x2F;LLaMA&#x2F;Skywork）</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Transformer</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>向量数据库</title>
    <url>/www6vHomeHexo/2022/11/27/gptVectorStore/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#embedding">Embedding</a></li>
<li><a href="#%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93">向量数据库</a></li>
<li><a href="#%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F-7">向量数据库-索引方式 [7]</a></li>
<li><a href="#%E5%90%91%E9%87%8F%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%AE%97%E6%B3%953">向量的相似度算法[3]</a><ul>
<li><a href="#%E6%AF%94%E8%BE%834">比较[4]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="embedding">Embedding</span><a href="#embedding" class="header-anchor">#</a></h1><ul>
<li><p>example [5]</p>
<ul>
<li><strong>降维</strong>:   t-SNE  </li>
<li>K-Means 聚类</li>
<li>文本搜索  相似度搜索</li>
</ul>
</li>
<li><p>Embedding 价值 [6]</p>
<ul>
<li><strong>降维</strong><br>将这些高维数据映射到一个低维空间，大大减少了模型的复杂度。</li>
<li>捕捉语义信息<br>Embedding不仅仅是降维，更重要的是，它能够捕捉到数据的语义信息。</li>
<li>泛化能力<br>由于Embedding能够捕捉到数据的一些内在规律，因此对于这些未见过的数据，Embedding仍然能够给出合理的表示</li>
</ul>
</li>
<li><p>应用 [6]</p>
<ul>
<li>语义表示和语义相似度</li>
<li>词语关系和类比推理</li>
<li>上下文理解</li>
<li>文本分类和情感分析</li>
<li>机器翻译和生成模型</li>
</ul>
</li>
<li><p>天梯榜<br><a href="https://huggingface.co/spaces/mteb/leaderboard">mteb&#x2F;leaderboard</a></p>
</li>
</ul>
<h1><span id="向量数据库">向量数据库</span><a href="#向量数据库" class="header-anchor">#</a></h1><ul>
<li><p>国产</p>
<ul>
<li>Milvus</li>
<li>Tencent </li>
<li>zilliz cloud</li>
</ul>
</li>
<li><p>国外</p>
<ul>
<li>Pinecone</li>
<li>FAISS<br>[ANN]</li>
<li>Chroma</li>
<li>Weaviate</li>
</ul>
</li>
</ul>
<h1><span id="向量数据库-索引方式-7">向量数据库-索引方式 [7]</span><a href="#向量数据库-索引方式-7" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/11/27/gptVectorStore/index.jpg" class>

<h1><span id="向量的相似度算法3">向量的相似度算法[3]</span><a href="#向量的相似度算法3" class="header-anchor">#</a></h1><ul>
<li>Cosine Similarity *<br>余弦</li>
<li>Dot Product *</li>
<li>Squared Euclidean (L2-Squared) *<br>欧式距离</li>
<li>Manhattan (L1 Norm or Taxicab Distance) *</li>
<li>Hamming *</li>
<li>ANN</li>
</ul>
<h3><span id="比较4">比较[4]</span><a href="#比较4" class="header-anchor">#</a></h3><table>
<thead>
<tr>
<th>Similarity Metric</th>
<th>Vector properties considered</th>
</tr>
</thead>
<tbody><tr>
<td>Euclidean distance</td>
<td>Magnitudes and direction</td>
</tr>
<tr>
<td>Cosine similarity</td>
<td>Only direction</td>
</tr>
<tr>
<td>Dot product similarity</td>
<td>Magnitudes and direction</td>
</tr>
</tbody></table>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/476025527">云原生向量数据库Milvus扫盲，看完这篇就够了</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/477231485">云原生向量数据库Milvus（二）-数据与索引的处理流程、索引类型及Schema</a></p>
</li>
<li><p><a href="https://weaviate.io/blog/distance-metrics-in-vector-search?ref=blog.langchain.dev">Distance Metrics in Vector Search</a></p>
</li>
<li><p><a href="https://www.pinecone.io/learn/vector-similarity/">Vector Similarity Explained</a></p>
</li>
<li><p><a href="https://github.com/www6v/openai-quickstart/blob/main/openai_api/embedding.ipynb">embedding</a> git</p>
</li>
<li><p>《AI 大模型应用开发实战营》 03-大模型开发基础：Embedding  </p>
</li>
<li><p><a href="https://www.modb.pro/db/1694527960317513728">向量数据库（第 1 部分）：每个数据库有何不同？</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2352088">微信向量检索分析一体化数仓探索：OLAP For Embedding</a> *** 未</p>
</li>
<li><p><a href="https://blog.csdn.net/v_JULY_v/article/details/135311471">一文通透Text Embedding模型：从text2vec、openai-ada-002到m3e、bge</a> 未</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/646832642">Meta向量数据库Faiss介绍</a> 未</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>向量数据库</category>
      </categories>
      <tags>
        <tag>向量数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>金融大模型</title>
    <url>/www6vHomeHexo/2022/11/24/gptDomainFinance/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h1><span id="金融大模型">金融大模型</span><a href="#金融大模型" class="header-anchor">#</a></h1><ul>
<li>BloombergGPT(未开源)</li>
<li>FinGPT  哥大  </li>
<li>FinBERT</li>
</ul>
<h1><span id="fingpt">FinGPT</span><a href="#fingpt" class="header-anchor">#</a></h1><ul>
<li>Model:<br><a href="https://huggingface.co/FinGPT">https://huggingface.co/FinGPT</a></li>
<li>FinGPT-Forecaster:<br><a href="https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster">https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster</a></li>
<li>Github Repo:<br><a href="https://github.com/www6v/FinGPT">https://github.com/www6v/FinGPT</a></li>
<li>medium<br><a href="https://byfintech.medium.com/beginners-guide-to-fingpt-training-with-lora-chatglm2-6b-9eb5ace7fe99">https://byfintech.medium.com/beginners-guide-to-fingpt-training-with-lora-chatglm2-6b-9eb5ace7fe99</a></li>
<li>Paper<br>五篇paper</li>
</ul>
<h1><span id="disc-finllm">DISC-FinLLM</span><a href="#disc-finllm" class="header-anchor">#</a></h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404800&idx=2&sn=9c1ad9d8aa8b0725dd6289bc15e177c9">本周大模型代表进展解析:ChatGLM3的特性认识及LoRA专家模组形式的金融领域微调模型实现策略</a></p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400799&idx=1&sn=fb3778d1914849d3b41b047b33ce32a9">ChatGPT能否预测股价走势？大模型应用于金融预测与今日大模型前沿速递</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>金融大模型</category>
      </categories>
      <tags>
        <tag>金融大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>训练</title>
    <url>/www6vHomeHexo/2022/11/19/gptLargeModelTraining/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#training-pipeline0">Training Pipeline[0]</a><ul>
<li><a href="#%E8%AE%BE%E7%BD%AE%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0-2">设置训练参数 [2]</a></li>
<li><a href="#%E5%8F%82%E6%95%B0%E9%87%8F-vs-%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%87%8F-2">参数量 vs 训练数据量 [2]</a></li>
</ul>
</li>
<li><a href="#pre-training">Pre-training</a><ul>
<li><a href="#pre-training-4">Pre-training [4]</a></li>
<li><a href="#tokenizer-%E5%88%86%E8%AF%8D">tokenizer 分词</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="training-pipeline0">Training Pipeline[0]</span><a href="#training-pipeline0" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/11/19/gptLargeModelTraining/bigModelTrainingPipeline.jpg" class>

<p><strong>模型训练分为四个阶段</strong> [2]</p>
<ul>
<li>预训练（Pretraining） –&gt;Base model  <ul>
<li>预训练技术<br>预训练本质上是⼀个⽆监督学习过程</li>
</ul>
</li>
<li>监督微调（Supervised Finetuning） –&gt; SFT model<br>核⼼原因还是在于需要“赋予”⼤模型更加定制化的功能</li>
<li>奖励建模（Reward Modeling）</li>
<li>强化学习（Reinforcement Learning）</li>
</ul>
<p><strong>三个角度解析</strong> [2]</p>
<ul>
<li>数据量：<strong>预训练</strong>阶段所需的<strong>数据量很大</strong>，但<strong>质量要求不高</strong>；而<strong>后面的三个阶段</strong>恰恰相反，需要的<strong>数据质量较高</strong>。</li>
<li>训练方法：<strong>预训练和监督微调</strong>的训练方法相同，都是<strong>预测下一个单词</strong>。奖励模型和强化学习的训练方法则不同。<strong>奖励模型</strong>是<strong>二元分类学习</strong>，而<strong>强化学习</strong>则鼓励模型生成奖励模型评分较高的回答。</li>
<li>训练所需资源：预训练阶段的资源消耗巨大，使用数千颗GPU，花费<strong>数月</strong>时间，占总训练时间的99%。后面的三个阶段只需使用数十颗GPU，训练时间约<strong>数天</strong>。</li>
</ul>
<h3><span id="设置训练参数-2">设置训练参数 [2]</span><a href="#设置训练参数-2" class="header-anchor">#</a></h3><p>设置训练参数，如batch-size、learning rate等</p>
<ul>
<li>预训练阶段的<strong>Batch Size非常大</strong>，范围在0.5M到4M之间。</li>
<li><strong>Learning rate设定较小</strong>，且随着网络规模的增大，Learning rate越来越小。</li>
</ul>
<h3><span id="参数量-vs-训练数据量-2">参数量 vs 训练数据量 [2]</span><a href="#参数量-vs-训练数据量-2" class="header-anchor">#</a></h3><p><strong>参数量并不是衡量模型能力的唯一标准，训练数据量也是一个非常重要的因素。</strong><br>LLaMA模型，尽管它的参数量只有650亿，但其性能与参数量为1750亿的GPT-3模型相比也非常优秀。主要原因在于，LLaMA模型的训练数据量达到了1.4万亿，而GPT-3只有3000亿。</p>
<h1><span id="pre-training">Pre-training</span><a href="#pre-training" class="header-anchor">#</a></h1><h3><span id="pre-training-4">Pre-training [4]</span><a href="#pre-training-4" class="header-anchor">#</a></h3><ul>
<li><p>⾃回归与⽣成式</p>
<ul>
<li><strong>⾃回归模型</strong>是⼀种序列模型，它在预测下⼀个输出时，会将之前的所有输出作为输⼊，然后<strong>根据统计规律、结合已经输⼊的样本</strong>，预测下个位置各单词出现的概率，然后输出概率最⼤的单词，类似于完形填空；</li>
<li><strong>⽣成式模型</strong>的预测过程和⾃回归模型类似，都是根据统<br>计规律预测下个单词的概率，所不同的是，<strong>⽣成式模型可以根据之前的样本的<br>概率分布⽣成下⼀个词，⽣成式模型预测时会存在⼀定的随机性；</strong></li>
</ul>
</li>
<li><p>GPT来说，就是⼀个⾃回归⽣成式模型 [4]<br>⼀个⾃回归⽣成式模型在进⾏预测的时候，<strong>会⾸先根据⾃回归模型，在参考到⽬前为⽌<br>已经⽣成的词的情况下确定下⼀个词的概率分布，然后再根据⽣成式的⽅式来根据这个<br>分布⽣成下⼀个词</strong></p>
</li>
</ul>
<h3><span id="tokenizer-分词">tokenizer 分词</span><a href="#tokenizer-分词" class="header-anchor">#</a></h3><ul>
<li>单词分词法</li>
<li>单字分词法</li>
<li>子词分词法<br>BPE [GPT系列], WordPiece</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol start="0">
<li><p><a href="https://zhuanlan.zhihu.com/p/648050614">LLM学习系列1：大模型架构要点总结</a>  from ppt</p>
</li>
<li><p>xxx</p>
</li>
<li><p><a href="https://techdiylife.github.io/big-model-training/deepspeed/LLM-state-of-GPT.html">大模型训练入门实战</a>  ***<br><a href="https://karpathy.ai/stateofgpt.pdf">State of GPT</a><br><a href="https://mp.weixin.qq.com/s/zmEGzm1cdXupNoqZ65h7yg">State of GPT：大神Andrej揭秘OpenAI大模型原理和训练过程 </a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2328541">主流大语言模型的技术原理细节</a> *** 腾讯     架构 + 训练 + 微调</p>
</li>
<li><p>大模型入门必看教程  九天Hector</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/458452872">NLP（二）：浅谈分词</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399532&idx=1&sn=31b7bc5a4f3114d8215da0edc2559e47">语言模型预训练基础知识总结：标准数据流pipleline、tokenizer的认识以及常见编码模型范式 </a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>SFT-PEFT</title>
    <url>/www6vHomeHexo/2022/11/18/gptFineTuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%88%86%E7%B1%BB">分类</a></li>
<li><a href="#peft-%E5%88%86%E7%B1%BB">PEFT 分类</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E5%8E%9F%E7%90%86">原理</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="分类">分类</span><a href="#分类" class="header-anchor">#</a></h1><ul>
<li><p>全量微调</p>
</li>
<li><p>局部微调</p>
<ul>
<li>PEFT(Parameter-Efficient Fine-Tuning)  PEFT</li>
</ul>
</li>
</ul>
<h1><span id="peft-分类">PEFT 分类</span><a href="#peft-分类" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/11/18/gptFineTuning/category.png" class>

<p>高效微调技术可以粗略分为以下三大类：增加额外参数（A）、选取一部分参数更新（S）、引入重参数化（R）。而在增加额外参数这类方法中，又主要分为类适配器（Adapter-like）方法和软提示（Soft prompts）两个小类。</p>
<ul>
<li><p>PEFT</p>
<ul>
<li>[本质   基于有监督学习]</li>
</ul>
</li>
<li><p>PEFT(Parameter-Efficient Fine-Tuning)  PEFT</p>
<ul>
<li><p><strong>引入重参数化（R）</strong>    </p>
<ul>
<li><strong>LoRA</strong>: Low-Rank Adaptation of LLMs<br>LoRA   【 并联方式的外挂】 [效果比较好]</li>
<li>QLoRA: Efficient Finetuning of Quantized LLMs</li>
<li>AdaLoRA: Adaptive Budget Allocation for PEFT</li>
</ul>
</li>
<li><p>增加额外参数（A）</p>
<ul>
<li><strong>软提示（Soft prompts）</strong> <ul>
<li><strong>Prefix Tuning</strong><br>增加一个可被训练的Embedding层</li>
<li>Prompt Tuning</li>
<li><strong>P-Turning</strong></li>
</ul>
</li>
<li>Adapter-Tuning   【 串联方式的外挂】</li>
</ul>
</li>
<li><p>选取一部分参数更新（S）</p>
<ul>
<li>BitFit</li>
</ul>
</li>
<li><p>additive</p>
<ul>
<li>IA3</li>
</ul>
</li>
</ul>
</li>
<li><p>统一微调框架<br>  UniPELT</p>
</li>
</ul>
<img src="/www6vHomeHexo/2022/11/18/gptFineTuning/overview.jpg" class>


<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><h3><span id="原理">原理</span><a href="#原理" class="header-anchor">#</a></h3><ol>
<li><p>xxx</p>
</li>
<li><p>xxx</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1t8411D7v4?p=8">大模型干货教程看这一个就够了~2023年全网最硬核最全面的大模型公开课|大模型微调 | ChatGLM | LangChain</a> ***</p>
</li>
<li><p><a href="https://github.com/www6v/llm-action#llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86">llm微调技术原理</a>  李国东<br>4.1 <a href="https://zhuanlan.zhihu.com/p/635152813">大模型参数高效微调技术原理综述（一）-背景、参数高效微调简介</a></p>
<p>4.2  <a href="https://zhuanlan.zhihu.com/p/649755252">大模型参数高效微调技术原理综述（七）-最佳实践、总结</a></p>
</li>
</ol>
<p>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/132116949">LLM高效参数微调方法：从Prefix Tuning、Prompt Tuning、P-Tuning V1&#x2F;V2到LoRA、QLoRA(含对模型量化的解释)</a> *** 未<br>1xx. <a href="https://aicarrier.feishu.cn/file/H1YvbRyacopEs6xzgZ8c9DDcnIh">大模型参数高效微调技术原理及实践</a> pdf<br>   <a href="https://www.bilibili.com/video/BV1qw411c7Hd/">如何高效微调大模型？技术原理与最佳实践揭秘！</a> V<br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402136&idx=1&sn=554331e397015c4da95fb0d0929f5aa1">7月末关于大模型微调数据工程与评估的技术综述：从数据构造方案到模型评估范式的论文梳理指引 </a> 对齐-论文集<br>   <a href="https://github.com/GaryYufei/AlignLLMHumanSurvey">AlignLLMHumanSurvey</a> git</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>Function Call</title>
    <url>/www6vHomeHexo/2022/11/16/gptFunctionCall/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="function-call">Function Call</span><a href="#function-call" class="header-anchor">#</a></h1><h3><span id="调用顺序-0-12">调用顺序  [0] [1][2]</span><a href="#调用顺序-0-12" class="header-anchor">#</a></h3><ul>
<li>Function Calling 整个功能的调用顺序大致如下<ul>
<li>声明函数：定义当前函数的名称，描述，以及对应的参数信息，并请求对应的接口；</li>
<li>解析函数参数：接受对应的接口返回，并解析对应的函数参数信息；</li>
<li>执行函数：根据对应的参数信息调用本地函数；</li>
<li>上报结果：将本地函数执行的结果上报给 Chat 接口；</li>
</ul>
</li>
</ul>
<img src="/www6vHomeHexo/2022/11/16/gptFunctionCall/functioncall1.png" class>

<h3><span id="代码-2">代码 [2]</span><a href="#代码-2" class="header-anchor">#</a></h3><h3><span id="goal">goal</span><a href="#goal" class="header-anchor">#</a></h3><p> The goal of the OpenAI Function APIs is to more reliably return valid and useful function calls than a generic text completion or chat API.</p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol start="0">
<li><p><a href="http://lihuaxi.xjx100.cn/news/1382737.html">大模型开发(十一)：Chat Completions模型的Function calling功能详解</a> </p>
</li>
<li><p><a href="https://www.duidaima.com/Group/Topic/OtherTools/13709">如何使用Chat Completions接口的函数调用功能</a></p>
</li>
<li><p><a href="https://blog.csdn.net/Lvbaby_/article/details/131892482">OpenAI开发系列（十一）：Function calling功能的实际应用流程与案例解析</a>   代码  流程图<br><a href="https://github.com/www6v/AIGC/tree/master/Function%20calling%E5%8A%9F%E8%83%BD%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E6%B5%81%E7%A8%8B%E4%B8%8E%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90">代码</a></p>
</li>
<li><p><a href="https://blog.csdn.net/Lvbaby_/article/details/131933871">OpenAI开发系列（十三）：利用Function calling功能开发基于大模型的实时天气查询助手</a> 未</p>
</li>
<li><p><a href="https://blog.csdn.net/Lvbaby_/article/details/131912170">OpenAI开发系列（十二）：Function calling功能的流程优化与多轮对话实现</a> 未</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Function Call</category>
      </categories>
      <tags>
        <tag>Function Call</tag>
      </tags>
  </entry>
  <entry>
    <title>Prompt Engineering</title>
    <url>/www6vHomeHexo/2022/11/10/gptPromptEngineering/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#basic-prompting-2">Basic Prompting [2]</a><ul>
<li><a href="#zero-shot-prompting-3">Zero-Shot Prompting [3]</a></li>
<li><a href="#few-shot-prompting-3">Few-Shot Prompting [3]</a></li>
</ul>
</li>
<li><a href="#cot-2">CoT [2]</a><ul>
<li><a href="#chain-of-thought-promptingcot-3">Chain-of-Thought Prompting(CoT) [3]</a></li>
<li><a href="#self-consistencycot-sc-3">Self-Consistency(CoT-SC) [3]</a></li>
<li><a href="#tree-of-thoughts-tot">Tree of Thoughts (ToT)</a></li>
<li><a href="#cot-vs-cot-sc-vs-tot-3">CoT vs. CoT-SC vs. ToT  [3]</a></li>
<li><a href="#tips-and-extensions-2">Tips and Extensions   [2]</a></li>
</ul>
</li>
<li><a href="#automatic-prompt-design-2">Automatic Prompt Design [2]</a></li>
<li><a href="#six-strategies-for-getting-better-results1">Six strategies for getting better results[1]</a><ul>
<li><a href="#write-clear-instructions">Write clear instructions</a></li>
<li><a href="#provide-reference-text">Provide reference text</a></li>
<li><a href="#split-complex-tasks-into-simpler-subtasks">Split complex tasks into simpler subtasks</a></li>
<li><a href="#give-the-model-time-to-think">Give the model time to “think”</a></li>
<li><a href="#use-external-tools">Use external tools</a></li>
<li><a href="#test-changes-systematically">Test changes systematically</a></li>
</ul>
</li>
<li><a href="#%E4%BC%98%E7%82%B9vs-%E7%BC%BA%E7%82%B9">优点vs 缺点</a><ul>
<li><a href="#%E4%BC%98%E7%82%B9">优点</a></li>
<li><a href="#%E7%BC%BA%E7%82%B9">缺点</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E6%A1%88%E4%BE%8B">案例</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="basic-prompting-2">Basic Prompting [2]</span><a href="#basic-prompting-2" class="header-anchor">#</a></h1><h3><span id="zero-shot-prompting-3">Zero-Shot Prompting [3]</span><a href="#zero-shot-prompting-3" class="header-anchor">#</a></h3><h3><span id="few-shot-prompting-3">Few-Shot Prompting [3]</span><a href="#few-shot-prompting-3" class="header-anchor">#</a></h3><h1><span id="cot-2">CoT [2]</span><a href="#cot-2" class="header-anchor">#</a></h1><h3><span id="chain-of-thought-promptingcot-3">Chain-of-Thought Prompting(CoT) [3]</span><a href="#chain-of-thought-promptingcot-3" class="header-anchor">#</a></h3><ul>
<li>Few-shot CoT</li>
<li>Zero-shot COT<br><strong>“Let’s think step by step”</strong></li>
</ul>
<h3><span id="self-consistencycot-sc-3">Self-Consistency(CoT-SC) [3]</span><a href="#self-consistencycot-sc-3" class="header-anchor">#</a></h3><p>The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to <strong>select</strong> the most consistent answer.  </p>
<h3><span id="tree-of-thoughts-tot">Tree of Thoughts (ToT)</span><a href="#tree-of-thoughts-tot" class="header-anchor">#</a></h3><h3><span id="cot-vs-cot-sc-vs-tot-3">CoT vs. CoT-SC vs. ToT  [3]</span><a href="#cot-vs-cot-sc-vs-tot-3" class="header-anchor">#</a></h3><img src="/www6vHomeHexo/2022/11/10/gptPromptEngineering/TOT.jpg" class>

<h3><span id="tips-and-extensions-2">Tips and Extensions   [2]</span><a href="#tips-and-extensions-2" class="header-anchor">#</a></h3><p>Self-Ask </p>
<h1><span id="automatic-prompt-design-2">Automatic Prompt Design [2]</span><a href="#automatic-prompt-design-2" class="header-anchor">#</a></h1><ul>
<li>Automatic Chain-of-Thought (Auto-CoT) [3]</li>
</ul>
<h1><span id="six-strategies-for-getting-better-results1">Six strategies for getting better results[1]</span><a href="#six-strategies-for-getting-better-results1" class="header-anchor">#</a></h1><h3><span id="write-clear-instructions">Write clear instructions</span><a href="#write-clear-instructions" class="header-anchor">#</a></h3><p>   清晰的指令</p>
<h3><span id="provide-reference-text">Provide reference text</span><a href="#provide-reference-text" class="header-anchor">#</a></h3><h3><span id="split-complex-tasks-into-simpler-subtasks">Split complex tasks into simpler subtasks</span><a href="#split-complex-tasks-into-simpler-subtasks" class="header-anchor">#</a></h3><pre><code>复杂任务简单化
</code></pre>
<h3><span id="give-the-model-time-to-think">Give the model time to “think”</span><a href="#give-the-model-time-to-think" class="header-anchor">#</a></h3><p>   给模型时间去思考</p>
<h3><span id="use-external-tools">Use external tools</span><a href="#use-external-tools" class="header-anchor">#</a></h3><p>   使用外部工具</p>
<h3><span id="test-changes-systematically">Test changes systematically</span><a href="#test-changes-systematically" class="header-anchor">#</a></h3><h1><span id="优点vs-缺点">优点vs 缺点</span><a href="#优点vs-缺点" class="header-anchor">#</a></h1><h3><span id="优点">优点</span><a href="#优点" class="header-anchor">#</a></h3><p>简单  容易上手</p>
<h3><span id="缺点">缺点</span><a href="#缺点" class="header-anchor">#</a></h3><ul>
<li>上限有限  </li>
<li>模型适配<br>prompt要适配每个模型</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://platform.openai.com/docs/guides/prompt-engineering">Prompt engineering</a>  openai</li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">Prompt Engineering </a> paper</li>
<li><a href="https://www.promptingguide.ai/techniques">Prompt Engineering Guide</a> guide<br><a href="https://github.com/www6v/Prompt-Engineering-Guide">Prompt-Engineering-Guide </a> *** git</li>
</ol>
<p>1xx. <a href="https://blog.langchain.dev/the-prompt-landscape/">The Prompt Landscape</a>  langchain<br>1xx. <a href="https://colab.research.google.com/github/comet-ml/comet-llm/blob/main/examples/CometLLM_Prompts.ipynb">CometLLM - suite of LLMOps tools - track and visualize LLM prompts and chains</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/671915693">大模型 PUA 指南：来自 Google Meta Microsoft 等大厂</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/632369186">NLP（十三）：Prompt Engineering 面面观</a><br>1xx. <a href="https://github.com/brexhq/prompt-engineering?tab=readme-ov-file"> prompt-engineering</a> git<br>1xx. <a href="https://finisky.github.io/chain-of-thought-prompting-summary/">Chain-of-Thought Prompting 简读 </a></p>
<h3><span id="案例">案例</span><a href="#案例" class="header-anchor">#</a></h3><ol start="200">
<li><a href="https://mp.weixin.qq.com/s/nXoZJ4xfgihA2mnBQ8EdIQ">运维大模型探索之 Text2PromQL 问答机器人 </a>     架构图， 最后两个重点总结   未</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>prompt</category>
      </categories>
      <tags>
        <tag>Prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent 原理</title>
    <url>/www6vHomeHexo/2022/11/02/gptAgent/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%9E%B6%E6%9E%84%E5%9B%BE">架构图</a><ul>
<li><a href="#%E7%BB%84%E4%BB%B6-6">组件 [6]</a></li>
<li><a href="#planning-6">Planning [6]</a></li>
<li><a href="#memory-6">Memory [6]</a></li>
<li><a href="#tool-use-6">Tool Use [6]</a></li>
</ul>
</li>
<li><a href="#patterns-3">Patterns [3]</a></li>
<li><a href="#agent%E5%88%86%E7%B1%BB-123">Agent分类 [1][2][3]</a><ul>
<li><a href="#example">Example</a><ul>
<li><a href="#hugginggpt">HuggingGPT</a></li>
<li><a href="#babyagi-aigc">BabyAGI [AIGC]</a></li>
<li><a href="#autogpt35">AutoGPT[3][5]</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E9%97%AE%E9%A2%98%E5%92%8C%E5%B1%80%E9%99%90%E6%80%A7-4">问题和局限性 [4]</a></li>
<li><a href="#%E6%8C%91%E6%88%98-8">挑战 [8]</a><ul>
<li><a href="#%E5%A6%82%E4%BD%95%E8%AE%A9-agent-%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%B7%A5%E5%85%B7">如何让 agent 选择合适的工具</a></li>
<li><a href="#%E4%B8%8D%E5%BF%85%E8%A6%81%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8">不必要的工具使用</a></li>
<li><a href="#agent-%E8%BF%94%E5%9B%9E%E7%9A%84%E6%A0%BC%E5%BC%8F%E4%B8%8D%E7%A8%B3%E5%AE%9A">Agent 返回的格式不稳定</a></li>
<li><a href="#%E8%AE%B0%E4%BD%8F%E4%B9%8B%E5%89%8D%E7%9A%84%E6%93%8D%E4%BD%9C%E9%81%BF%E5%85%8D%E9%87%8D%E5%A4%8D">记住之前的操作，避免重复</a></li>
<li><a href="#%E5%A4%84%E7%90%86%E8%B6%85%E9%95%BF%E7%9A%84-observation">处理超长的 observation</a></li>
<li><a href="#%E4%B8%93%E6%B3%A8%E4%BA%8E%E7%9B%AE%E6%A0%87">专注于目标</a></li>
<li><a href="#%E7%BB%93%E6%9E%9C%E8%AF%84%E4%BC%B0">结果评估</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#planning">Planning</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="架构图">架构图</span><a href="#架构图" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/11/02/gptAgent/agent-overview.jpg" class>

<h3><span id="组件-6">组件  [6]</span><a href="#组件-6" class="header-anchor">#</a></h3><p>Agent &#x3D; LLM + plan[规划能力] + memory[记忆能力] +Tools[工具使用能力] </p>
<h3><span id="planning-6">Planning [6]</span><a href="#planning-6" class="header-anchor">#</a></h3><ul>
<li><p>Task Decomposition</p>
<ul>
<li>CoT </li>
<li>ToT</li>
</ul>
</li>
<li><p>Self-Reflection</p>
<ul>
<li>ReAct [20]</li>
<li>Reflexion [21][22]</li>
<li>Chain of Hindsight</li>
</ul>
</li>
</ul>
<h3><span id="memory-6">Memory [6]</span><a href="#memory-6" class="header-anchor">#</a></h3><ul>
<li>Types of Memory<ul>
<li><strong>Sensory memory</strong> as learning <strong>embedding representations for raw inputs, including text, image or other modalities</strong>;</li>
<li><strong>Short-term memory</strong> as <strong>in-context learning</strong>. It is short and finite, as it is restricted by the finite context window length of Transformer.</li>
<li><strong>Long-term memory</strong> as the external <strong>vector store</strong> that the agent can attend to at query time, accessible via fast retrieval.</li>
</ul>
</li>
</ul>
<h3><span id="tool-use-6">Tool Use [6]</span><a href="#tool-use-6" class="header-anchor">#</a></h3><ul>
<li><p>让 agent 选择合适的工具 [8]</p>
<ul>
<li>可以 retrieve 相关示例来做 <strong>few-shot prompt</strong>。</li>
<li>也可以进一步 <strong>fine tune 特定模型</strong>，例如之前的 Toolformer。</li>
</ul>
</li>
<li><p>Research</p>
<ul>
<li><strong>TALM</strong> (Tool Augmented Language Models; Parisi et al. 2022) [6]</li>
<li><strong>Toolformer</strong> (Schick et al. 2023)   [6]</li>
<li><strong>Gorilla</strong> [8]</li>
</ul>
</li>
<li><p>Production  [6]</p>
<ul>
<li>ChatGPT <strong>Plugins</strong> </li>
<li>OpenAI API <strong>function calling</strong></li>
</ul>
</li>
</ul>
<h1><span id="patterns-3">Patterns  [3]</span><a href="#patterns-3" class="header-anchor">#</a></h1><ul>
<li><p>ReACT 范式 [20]<br>把<strong>融合了Reasoning和Acting</strong>的一种范式，推理过程是浅显易懂，仅仅<strong>包含thought-action-observation步骤</strong>，很容易判断推理的过程的正确性，使用ReAct做决策甚至超过了强化学习.  </p>
<ul>
<li>chain-of-thought推理-问题<br> 事实幻想（fact hallucination）和错误传递（error propagation）</li>
</ul>
</li>
<li><p>Self-ask<br>Self-ask是一种follow-up的使用范式，仅仅包含follow-up, immediate answer步骤，至于follow-up多少个step，完全由它自己决定，估计这就是Self-ask的名字的由来。</p>
</li>
<li><p>Plan-and-execute agents<br>本质上是先计划再执行，即先把用户的问题分解成一个个的子任务，然后再执行各个子任务，最后合并输出得到结果</p>
</li>
</ul>
<h1><span id="agent分类-123">Agent分类 [1][2][3]</span><a href="#agent分类-123" class="header-anchor">#</a></h1><ul>
<li><p>Action agents  </p>
<ul>
<li>Function Call</li>
<li>ReACT<br>Thought: xxx<br>Action: xxx<br>Observation: xxx</li>
</ul>
</li>
<li><p>Simulation agents<br>  生成式智能体， CAMEL，  Generative Agents</p>
</li>
<li><p>Automomous Agent<br>  <strong>AutoGPT</strong>， <strong>BabyAGI</strong>,  <strong>AutoGen</strong><br>  <strong>MetaGPT</strong></p>
</li>
<li><p>跨模态Agents<br>  HuggingGPT</p>
</li>
<li><p>ChatDev， AutoGen</p>
</li>
</ul>
<h2><span id="example">Example</span><a href="#example" class="header-anchor">#</a></h2><h3><span id="hugginggpt">HuggingGPT</span><a href="#hugginggpt" class="header-anchor">#</a></h3><h3><span id="babyagi-aigc">BabyAGI  [AIGC]</span><a href="#babyagi-aigc" class="header-anchor">#</a></h3><p>Plan-and-execute agents<br>The <strong>planning</strong> is almost always done <strong>by an LLM</strong>.<br>The <strong>execution</strong> is usually done by a <strong>separate agent (equipped with tools)</strong>.</p>
<h3><span id="autogpt35">AutoGPT[3][5]</span><a href="#autogpt35" class="header-anchor">#</a></h3><p>AutoGPT 的核心逻辑是一个 Prompt Loop，步骤如下</p>
<ol>
<li>AutoGPT 会基于一定策略自动组装 Command Prompt，这些首次会包含用户输入的 Name, Role和Goals </li>
<li>Command Prompt 的目标不是为了拿到最终结果，而是通过 GPT Chat API(Thinking 的过程)返回下一步的 Command (包含name和arguments, 如<code>browser_website(url = &quot;www.baidu.com&quot;)</code> )</li>
<li>这些 Command 都是可扩展的，每一种命令代表一种外部能力(比如爬虫、Google搜索，也包括GPT的能力)，通过这些 Command 调用返回的 Result 又会成为到 Command Prompt 的组成元素，</li>
<li>回到第 1 步往复循环，直到拿到最终结果结果（状态为“compelete”）</li>
</ol>
<h1><span id="问题和局限性-4">问题和局限性 [4]</span><a href="#问题和局限性-4" class="header-anchor">#</a></h1><ul>
<li><p>记忆召回问题<br>只是做简单的 embedding 相似性召回，很容易发现召回的结果不是很好</p>
</li>
<li><p>错误累积问题</p>
</li>
<li><p>探索效率问题<br>中途引入人工的判断干预和反馈输入</p>
</li>
<li><p>任务终止与结果验证<br>模型 agent 的工作如何终止也是一个挑战</p>
</li>
</ul>
<h1><span id="挑战-8">挑战 [8]</span><a href="#挑战-8" class="header-anchor">#</a></h1><h3><span id="如何让-agent-选择合适的工具">如何让 agent 选择合适的工具</span><a href="#如何让-agent-选择合适的工具" class="header-anchor">#</a></h3><ul>
<li>Toolformer - fine tune</li>
<li>Gorilla - retrieval，fine tune</li>
</ul>
<h3><span id="不必要的工具使用">不必要的工具使用</span><a href="#不必要的工具使用" class="header-anchor">#</a></h3><p>“Human Input”也写成一种工具，让模型来主动发起对人类的提问<br><a href="https://python.langchain.com/docs/integrations/tools/human_tools">Human as a tool</a></p>
<h3><span id="agent-返回的格式不稳定">Agent 返回的格式不稳定</span><a href="#agent-返回的格式不稳定" class="header-anchor">#</a></h3><p>这里常见的做法是让 LLM <strong>按照 json 这类常见的 schema 来返回</strong>，一般稳定性会高一些（相比“Action:”这种）。<br>此外自动修复重试也很实用，可以利用 LangChain 里的 <strong>output parsers</strong> 来帮助完成。</p>
<h3><span id="记住之前的操作避免重复">记住之前的操作，避免重复</span><a href="#记住之前的操作避免重复" class="header-anchor">#</a></h3><p>AutoGPT - retrieval 结合近期操作记录</p>
<h3><span id="处理超长的-observation">处理超长的 observation</span><a href="#处理超长的-observation" class="header-anchor">#</a></h3><p>需要用一些工具从中<strong>提取有用信息</strong>，或者<strong>放到外部存储中再借助 retrieval 来使用</strong>。</p>
<h3><span id="专注于目标">专注于目标</span><a href="#专注于目标" class="header-anchor">#</a></h3><p>简单的做法是<strong>在 prompt 结尾处再把目标加上</strong>，引起 agent 的注意。<br>另外像 BabyAGI，HuggingGPT 这种把 <strong>planning 和 execution 分开</strong>的做法也是很有用。<strong>拆分的比较细</strong>的任务往往步骤比较短，也不容易丢失目标。</p>
<h3><span id="结果评估">结果评估</span><a href="#结果评估" class="header-anchor">#</a></h3><ul>
<li><strong>评估最终结果</strong>是否正确</li>
<li><strong>过程的细化评估</strong><ul>
<li>选择的中间步骤是否正确。</li>
<li>生成 action 的 input 是否正确。</li>
<li>生成的步骤序列是否合理高效。</li>
</ul>
</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li>公开课</li>
<li>公开课</li>
<li><a href="https://zhuanlan.zhihu.com/p/642357544">2023年新生代大模型Agents技术,ReAct,Self-Ask,Plan-and-execute,以及AutoGPT, HuggingGPT等应用</a> ***  论文+代码</li>
<li><a href="https://zhuanlan.zhihu.com/p/622947810">AutoGPT与LLM Agent解析</a> *** </li>
<li><a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a> git<br><a href="https://link.zhihu.com/?target=https://godmode.space/">带界面的 AutoGPT 产品</a></li>
<li><a href="https://lilianweng.github.io/posts/2023-06-23-agent/">LLM Powered Autonomous Agents </a> paper </li>
<li>xxx</li>
<li><a href="https://zhuanlan.zhihu.com/p/633033220">LLM 全栈开发指南补遗</a>  Agents  ***<br><a href="https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/chase-agents/">Harrison Chase: Agents</a>  ***</li>
</ol>
<h3><span id="planning">Planning</span><a href="#planning" class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://react-lm.github.io/">ReAct: Synergizing Reasoning and Acting in Language Models</a> paper</li>
<li><a href="https://zhuanlan.zhihu.com/p/639254455">【论文阅读】Reflexion: 大模型如何从错误经验中学习？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/671508578">Reflexion: 带言语强化学习的语言智体</a><br>2xx. <a href="https://zhuanlan.zhihu.com/p/671491031">ReWOO: 高效增强语言模型中解偶观测和推理</a></li>
</ol>
<p>3xx. <a href="https://zhuanlan.zhihu.com/p/678203245">智体AI在多模态交互领域的综述（上）</a><br>3xx. <a href="https://zhuanlan.zhihu.com/p/678222381">智体AI在多模态交互领域的综述（下）</a><br>3xx. <a href="https://zhuanlan.zhihu.com/p/678238642">个人LLM智体的综述</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>Langchain</title>
    <url>/www6vHomeHexo/2022/11/02/gptLangchain/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#modules">Modules</a><ul>
<li><a href="#main-modules">main modules</a><ul>
<li><a href="#model-io">Model I&#x2F;O</a></li>
<li><a href="#retrieval">Retrieval</a></li>
<li><a href="#agent">Agent</a></li>
</ul>
</li>
<li><a href="#additional-modules">Additional modules</a><ul>
<li><a href="#chains">Chains</a></li>
<li><a href="#memory-10">Memory [10]</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#function-call">Function Call</a></li>
<li><a href="#%E5%BA%94%E7%94%A84">应用[4]</a></li>
<li><a href="#chains-1-89">Chains [1] [8][9]</a></li>
<li><a href="#templates7">Templates[7]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="modules">Modules</span><a href="#modules" class="header-anchor">#</a></h1><h2><span id="main-modules">main modules</span><a href="#main-modules" class="header-anchor">#</a></h2><h3><span id="model-ix2fo">Model I&#x2F;O</span><a href="#model-ix2fo" class="header-anchor">#</a></h3><ul>
<li>Language models  [10]        <ul>
<li>LLM</li>
<li>Chat Model</li>
<li><strong>Embedding</strong></li>
</ul>
</li>
<li>Prompts <ul>
<li>Prompt Template</li>
<li>Few-shot example</li>
<li>Example Selectors [类比选择]<br>关键字  相似度  长度</li>
</ul>
</li>
<li>Output parsers</li>
<li><strong>function call</strong>[2]</li>
</ul>
<h3><span id="retrieval">Retrieval</span><a href="#retrieval" class="header-anchor">#</a></h3><ul>
<li>Document Loaders</li>
<li>Text Splitters</li>
<li><strong>Retrievers</strong>[10]</li>
<li>VectorStores</li>
<li>index</li>
</ul>
<h3><span id="agent">Agent</span><a href="#agent" class="header-anchor">#</a></h3><ul>
<li>Plan-and-execute agents</li>
</ul>
<h2><span id="additional-modules">Additional modules</span><a href="#additional-modules" class="header-anchor">#</a></h2><h3><span id="chains">Chains</span><a href="#chains" class="header-anchor">#</a></h3><ul>
<li>2大类<ul>
<li>Chain interface[Legacy]</li>
<li>LangChain Expression Language (LCEL)<br>LCEL is a declarative way to compose chains.</li>
</ul>
</li>
<li>Foundational<ul>
<li>LLM</li>
<li>Sequential- SequentialChain</li>
<li><strong>Router</strong></li>
<li>Transformation</li>
</ul>
</li>
</ul>
<h3><span id="memory-10">Memory [10]</span><a href="#memory-10" class="header-anchor">#</a></h3><ul>
<li>帮语言模型补充上下文</li>
<li>ConversationBufferMemory</li>
<li>ConversationBufferWindowMemory<br>窗口</li>
<li>ConversationSummaryMemory</li>
<li>VectorStoreRetrieverMemory</li>
</ul>
<h1><span id="function-call">Function Call</span><a href="#function-call" class="header-anchor">#</a></h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.base <span class="keyword">import</span> (</span><br><span class="line">    create_openai_fn_chain,</span><br><span class="line">    create_structured_output_chain,[<span class="number">2</span>]</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.citation_fuzzy_match <span class="keyword">import</span> (</span><br><span class="line">    create_citation_fuzzy_match_chain,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.extraction <span class="keyword">import</span> (</span><br><span class="line">    create_extraction_chain,</span><br><span class="line">    create_extraction_chain_pydantic,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.qa_with_structure <span class="keyword">import</span> (</span><br><span class="line">    create_qa_with_sources_chain,</span><br><span class="line">    create_qa_with_structure_chain,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.tagging <span class="keyword">import</span> (</span><br><span class="line">    create_tagging_chain,</span><br><span class="line">    create_tagging_chain_pydantic,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<h1><span id="应用4">应用[4]</span><a href="#应用4" class="header-anchor">#</a></h1><ul>
<li>Question &amp; Answering Using Documents As Context[3]</li>
<li>Extraction[Kor]</li>
<li>Evaluation</li>
<li>Querying Tabular Data[sqlite]</li>
<li>Code Understanding</li>
<li>Interacting with APIs</li>
<li>Chatbots</li>
</ul>
<h1><span id="chains-1-89">Chains [1] [8][9]</span><a href="#chains-1-89" class="header-anchor">#</a></h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chain = load_summarize_chain(llm, chain_type=<span class="string">&quot;stuff&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">chain = load_summarize_chain(llm, chain_type=<span class="string">&quot;map_reduce&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">chain = load_summarize_chain(llm, chain_type=<span class="string">&quot;refine&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">chain = load_qa_chain(llm, chain_type=<span class="string">&quot;map_rerank&quot;</span>, verbose=<span class="literal">True</span>, return_intermediate_steps=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th>链类型</th>
<th>整合方法</th>
<th>优缺点</th>
</tr>
</thead>
<tbody><tr>
<td>stuff</td>
<td>将所有内容放入一个提示中，输入LLM</td>
<td>简单、廉价、效果好&#x2F; 对输入文本有一定token限制</td>
</tr>
<tr>
<td>Map_reduce</td>
<td>每个问题和文本块单独给语言模型，并将答案汇总生成最终结果</td>
<td>输入任意数量文本，且并行处理&#x2F; 速度慢，费token</td>
</tr>
<tr>
<td>Refine</td>
<td>迭代处理多个文本，基于前一个文档答案构建下一个答案</td>
<td>用于组合信息，依次构建答案&#x2F; 速度慢，费token</td>
</tr>
<tr>
<td>Map_rerank</td>
<td>每个文档单独调用LLM,并要求返回一个得分，然后选择最高的得分</td>
<td>需要告诉模型评分的规则&#x2F; 费token</td>
</tr>
</tbody></table>
<img src="/www6vHomeHexo/2022/11/02/gptLangchain/chains-type.jpg" class>


<h1><span id="templates7">Templates[7]</span><a href="#templates7" class="header-anchor">#</a></h1><h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://github.com/gkamradt/langchain-tutorials">https://github.com/gkamradt/langchain-tutorials</a></p>
</li>
<li><p><a href="https://github.com/www6v/pyExamples/blob/master/langchain/langchain-functioncall.py">functioncall</a></p>
</li>
<li><p><a href="https://github.com/www6v/pyExamples/blob/master/langchain/langchain-qaOnDoc.py">qaOnDoc</a></p>
</li>
<li><p><a href="https://github.com/www6v/langchain-tutorials/blob/main/LangChain%20Cookbook%20Part%202%20-%20Use%20Cases.ipynb">LangChain Cookbook Part 2: Use Cases</a><br> 10.公开课</p>
</li>
<li><p><a href="https://github.com/kyrolabs/awesome-langchain">https://github.com/kyrolabs/awesome-langchain</a></p>
</li>
<li><p><a href="https://github.com/Crossme0809/langchain-tutorials">https://github.com/Crossme0809/langchain-tutorials</a></p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/templates/docs/INDEX.md">Templates</a> ***</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/666656208">吴恩达短课_LangChain</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/651216604">精华笔记：吴恩达 x LangChain 《使用LangChain构建与数据对话的聊天机器人》（下）</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2313918">一文入门最热的LLM应用开发框架LangChain</a> 未</p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2331337">大模型LangChain框架基础与使用示例</a> 未</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Langchain</category>
      </categories>
      <tags>
        <tag>GPT</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG 原理</title>
    <url>/www6vHomeHexo/2022/11/02/gptRAG/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#rag-overview2">RAG Overview[2]</a></li>
<li><a href="#advanced-rag">Advanced RAG</a><ul>
<li><a href="#%E6%9E%B6%E6%9E%84-1">架构 [1]</a></li>
<li><a href="#rag-fusion">RAG Fusion</a></li>
</ul>
</li>
<li><a href="#rag-vs-ft-2">RAG vs FT [2]</a></li>
<li><a href="#self-rag-3">Self-RAG [3]</a></li>
<li><a href="#%E5%A4%9A%E6%A8%A1%E6%80%81rag35">多模态+RAG[3][5]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a><ul>
<li><a href="#%E7%BB%BC%E8%BF%B0">综述</a></li>
<li><a href="#self-rag">Self-RAG</a></li>
<li><a href="#%E5%A4%9A%E6%A8%A1%E6%80%81">多模态</a></li>
<li><a href="#%E8%AF%84%E4%BC%B0">评估</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="rag-overview2">RAG Overview[2]</span><a href="#rag-overview2" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/11/02/gptRAG/rag-overview.jpg" class>

<h1><span id="advanced-rag">Advanced RAG</span><a href="#advanced-rag" class="header-anchor">#</a></h1><h3><span id="架构-1">架构 [1]</span><a href="#架构-1" class="header-anchor">#</a></h3><ul>
<li>离线 index</li>
<li>在线 查询</li>
</ul>
<img src="/www6vHomeHexo/2022/11/02/gptRAG/rag.jpg" class>

<h3><span id="rag-fusion">RAG Fusion</span><a href="#rag-fusion" class="header-anchor">#</a></h3><h1><span id="rag-vs-ft-2">RAG vs FT [2]</span><a href="#rag-vs-ft-2" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/11/02/gptRAG/rag-vs-ft.jpg" class>

<h1><span id="self-rag-3">Self-RAG [3]</span><a href="#self-rag-3" class="header-anchor">#</a></h1><p>Self-RAG 则是更加主动和智能的实现方式，主要步骤概括如下：</p>
<ol>
<li>判断是否需要额外检索事实性信息（retrieve on demand），仅当有需要时才召回</li>
<li>平行处理每个片段：生产prompt+一个片段的生成结果</li>
<li>使用**反思字段(Reflection tokens)**，检查输出是否相关，选择最符合需要的片段；</li>
<li>再重复检索</li>
<li>生成结果会引用相关片段，以及输出结果是否符合该片段，便于查证事实。</li>
</ol>
<h1><span id="多模态rag35">多模态+RAG[3][5]</span><a href="#多模态rag35" class="header-anchor">#</a></h1><h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://blog.langchain.dev/deconstructing-rag/">Deconstructing RAG</a> ***</li>
</ol>
<h3><span id="综述">综述</span><a href="#综述" class="header-anchor">#</a></h3><ol start="2">
<li><a href="https://zhuanlan.zhihu.com/p/673910600">LLM之RAG理论（二）| RAG综述论文详解</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/661465330?utm_id=0">NLP（廿一）：从 RAG 到 Self-RAG —— LLM 的知识增强</a> ***<br>1xx. <a href="https://baoyu.io/translations/ai-paper/2312.10997-retrieval-augmented-generation-for-large-language-models-a-survey">面向大语言模型的检索增强生成技术：综述 [译]</a></li>
</ol>
<h3><span id="self-rag">Self-RAG</span><a href="#self-rag" class="header-anchor">#</a></h3><ol start="4">
<li><a href="https://github.com/www6v/self-rag">original implementation of SELF-RAG</a></li>
</ol>
<h3><span id="多模态">多模态</span><a href="#多模态" class="header-anchor">#</a></h3><ol start="5">
<li><a href="https://zhuanlan.zhihu.com/p/665078079">万字综述：2023年多模态检索增强生成技术(mRAG)最新进展与趋势-图片、代码、图谱、视频、声音、文本</a></li>
</ol>
<h3><span id="评估">评估</span><a href="#评估" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404511&idx=2&sn=fefb78c1d920cb5b437f2e3da9935637">再看大模型RAG检索增强如何评估：RAGAS开源自动化评估框架</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404476&idx=2&sn=d07b27dc9162ab0aaec3108004e4cfbe">大模型RAG检索增强问答如何评估：噪声、拒答、反事实、信息整合四大能力评测任务探索 </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/673922981">高级检索增强生成技术(RAG)全面指南：原理、分块、编码、索引、微调、Agent、展望</a><br>1xx. <a href="https://baoyu.io/translations/ai-paper/2005.11401-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks">知识密集型自然语言处理任务的检索增强生成技术研究 [译]</a><br>1xx. <a href="https://baoyu.io/translations/rag/mastering-rag-how-to-architect-an-enterprise-rag-system">构建企业级 RAG 系统的高级指南 [译]</a><br>1xx. <a href="https://baoyu.io/translations/ai-paper/2401.05856v1-seven-failure-points-when-engineering-a-retrieval-augmented-generation-system">在构建检索增强型生成系统时的七大挑战 [译]</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648407638&idx=1&sn=5c167b4a11bc483f5790ef1e0340d670">大模型RAG问答行业最佳案例及微调、推理双阶段实现模式：基于模块化(Modular)RAG自定义RAG Flow </a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648406156&idx=1&sn=d91a4df105c4fc4c9523f7141bc1c24d">知识图谱用于细粒度大模型幻觉评估：兼论Langchain-RAG问答中的问题改写范式 </a><br>  RAG:  rewrite , Step back prompting, fusion</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型 综述</title>
    <url>/www6vHomeHexo/2022/10/30/gptLargeModelSurvey/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#llms%E7%9A%84%E8%83%8C%E6%99%AF1">LLMs的背景[1]</a><ul>
<li><a href="#scaling-law-of-llms">Scaling law of LLMs</a></li>
<li><a href="#llms%E7%9A%84%E6%B6%8C%E7%8E%B0%E8%83%BD%E5%8A%9B">LLMs的涌现能力</a></li>
<li><a href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF">大语言模型的关键技术 ***</a></li>
</ul>
</li>
<li><a href="#pre-training1">Pre-training[1]</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86">数据收集</a></li>
<li><a href="#%E6%9E%B6%E6%9E%84">架构</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">模型训练 ***</a></li>
</ul>
</li>
<li><a href="#adaptation-tuning-of-llms1">Adaptation Tuning of LLMs[1]</a><ul>
<li><a href="#%E6%8C%87%E4%BB%A4%E8%B0%83%E4%BC%98">指令调优 ***</a><ul>
<li><a href="#%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AE%9E%E4%BE%8B%E7%9A%84%E6%9E%84%E5%BB%BA">格式化实例的构建</a></li>
<li><a href="#%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E7%AD%96%E7%95%A5">指令微调策略</a></li>
<li><a href="#%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E7%9A%84%E6%95%88%E6%9E%9C">指令微调的效果</a></li>
</ul>
</li>
<li><a href="#%E5%AF%B9%E9%BD%90%E8%B0%83%E4%BC%98">对齐调优</a></li>
<li><a href="#%E9%AB%98%E6%95%88%E8%B0%83%E4%BC%98">高效调优</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="llms的背景1">LLMs的背景[1]</span><a href="#llms的背景1" class="header-anchor">#</a></h1><h3><span id="scaling-law-of-llms">Scaling law of LLMs</span><a href="#scaling-law-of-llms" class="header-anchor">#</a></h3><ul>
<li>KM scaling law</li>
<li>Chinchilla Scaling law</li>
</ul>
<h3><span id="llms的涌现能力">LLMs的涌现能力</span><a href="#llms的涌现能力" class="header-anchor">#</a></h3><ul>
<li>in-context learning</li>
<li>instruction following</li>
<li>step-by-step reasoning</li>
</ul>
<h3><span id="大语言模型的关键技术">大语言模型的关键技术 ***</span><a href="#大语言模型的关键技术" class="header-anchor">#</a></h3><ul>
<li>Scaling</li>
<li>Training</li>
<li>Ability Eliciting</li>
<li>Alignment Tuning</li>
<li>Tool Manipulation</li>
</ul>
<h1><span id="pre-training1">Pre-training[1]</span><a href="#pre-training1" class="header-anchor">#</a></h1><h3><span id="数据收集">数据收集</span><a href="#数据收集" class="header-anchor">#</a></h3><h3><span id="架构">架构</span><a href="#架构" class="header-anchor">#</a></h3><h3><span id="模型训练">模型训练 ***</span><a href="#模型训练" class="header-anchor">#</a></h3><ul>
<li><p>优化设置</p>
<ul>
<li>Batch Training</li>
<li>Learning Rate</li>
<li>Optimizer</li>
<li>Stabilizing the Training</li>
</ul>
</li>
<li><p>可扩展的训练技巧</p>
<ul>
<li>3D并行<br>数据并行 +  流水线并行 + 张量并行</li>
<li>ZeRO</li>
<li>混合精度训练</li>
<li>总体训练建议</li>
</ul>
</li>
</ul>
<h1><span id="adaptation-tuning-of-llms1">Adaptation Tuning of LLMs[1]</span><a href="#adaptation-tuning-of-llms1" class="header-anchor">#</a></h1><h3><span id="指令调优">指令调优 ***</span><a href="#指令调优" class="header-anchor">#</a></h3><p>本质上，指令微调是在<strong>自然语言格式的实例（instance）集合上</strong>微调预训练后的 LLM 的方法 [62]。</p>
<p>指令微调后，LLM 可以展现出<strong>泛化到未见过任务</strong>的卓越能力 [28, 62, 64]，即使在多语言场景下也能有不错表现 [98]。</p>
<h5><span id="格式化实例的构建">格式化实例的构建</span><a href="#格式化实例的构建" class="header-anchor">#</a></h5><ul>
<li>格式化已有数据集</li>
<li>格式化人类需求</li>
<li>构建实例的关键因素<ul>
<li><strong>增加指令</strong></li>
<li><strong>设计格式</strong></li>
</ul>
</li>
</ul>
<p>总的来说，指令<strong>多样性似乎比实例数量更重要</strong></p>
<h5><span id="指令微调策略">指令微调策略</span><a href="#指令微调策略" class="header-anchor">#</a></h5><ul>
<li><p><strong>平衡数据分布</strong><br>一种广泛使用的方法是实例比例混合策略 [87]，即将所有数据集合并，然后从混合数据集中按比例采样每种实例。<br>此外，根据最近的研究发现 [64, 99]，<strong>提高高质量数据集（例如 FLAN [62] 和 P3 [209]）的采样比例</strong>通常可以带来<strong>性能提升</strong>。</p>
</li>
<li><p>结合指令微调和预训练<br>为了使微调过程更加有效和稳定，OPT-IML [99] 在<strong>指令微调期间加入了预训练数据</strong>，这可以看作是对模型的正则化（regularization）。</p>
</li>
</ul>
<p>具体而言，GLM-130B [97] 和 Galactica [34] 将<strong>指令格式数据集作为预训练语料库的一小部分来预训练 LLM</strong>，这有可能同时获得预训练和指令微调的优势。</p>
<h5><span id="指令微调的效果">指令微调的效果</span><a href="#指令微调的效果" class="header-anchor">#</a></h5><ul>
<li>性能改进<br>最近的研究在多个规模上（从 7700 百万到 5400 亿不等）对 LM 进行了实验，**表明不同规模的模型都可以从指令微调中受益 [64, 216]，随着参数规模的增加，性能也得到了提升 [98]**。 【普适性】</li>
</ul>
<p>此外，**经过指令微调的较小模型甚至可以比未经微调的较大模型表现更好 [28, 64]**。</p>
<ul>
<li>任务泛化性<br>todo</li>
</ul>
<h3><span id="对齐调优">对齐调优</span><a href="#对齐调优" class="header-anchor">#</a></h3><h3><span id="高效调优">高效调优</span><a href="#高效调优" class="header-anchor">#</a></h3><h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="http://aibox.ruc.edu.cn/docs/2023-08/cb9badcb213f4c8b89d00d579eed4a4c.pdf">大语言模型综述</a> 中文  v10<br>  <a href="https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf">大语言模型综述</a> 中文<br>  <a href="https://arxiv.org/pdf/2303.18223.pdf">A Survey of Large Language Models</a> 英文<br>  <a href="https://github.com/www6v/LLMSurvey">LLMSurvey</a>  github<br>  <a href="https://zhuanlan.zhihu.com/p/630203554">[论文]大语言模型综述</a><br>  <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400817&idx=1&sn=c1ed1c9c87bf2526e02d21d84429c5cf">详谈大模型训练中的数据收集、处理与模型影响：A Survey of Large Language Models工作中的数据总结</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>大模型</category>
      </categories>
      <tags>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Network-Direct Connect</title>
    <url>/www6vHomeHexo/2022/10/30/awsNetworkDX/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="direct-connect12">Direct Connect[1][2]</span><a href="#direct-connect12" class="header-anchor">#</a></h2><ul>
<li><p>Virtual Interfaces </p>
<ul>
<li>Public VIF<br>公共 VIF 使您的网络能够访问所有区域（中国除外）的 AWS 全球骨干网络上的所有 AWS 公共 IP 地址。</li>
<li>Private VIF<br>私有 VIF 使您的网络能够通过其私有 IP 地址访问已在您的虚拟私有云 (VPC) 中配置的资源。</li>
</ul>
</li>
<li><p>高可用<br>[常规做法: DX + VPN]</p>
</li>
<li><p>双向转发检测 (BFD)<br>DR</p>
</li>
<li><p>Billing</p>
<ul>
<li>两个主要成本组成部分<ul>
<li>所有 AWS Direct Connect 位置的每端口小时定价和 [使用时长]</li>
<li>AWS Direct Connect 位置和 AWS 区域的数据传出费用  [数据传输的量]</li>
</ul>
</li>
</ul>
</li>
<li><p>Direct Connect gateway[3][4]<br>Virtual private gateway associations<br>private VIF that references the Gateway and the Connection</p>
<img src="/www6vHomeHexo/2022/10/30/awsNetworkDX/directConnectionGateway.JPG" class title="Direct Connect gateway"></li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/531166462">Chapter5 AWS Direct Connect</a> </li>
<li>[SAP-1] Direct Connect Section</li>
<li><a href="https://aws.amazon.com/blogs/aws/new-aws-direct-connect-gateway-inter-region-vpc-access/">New – AWS Direct Connect Gateway – Inter-Region VPC Access</a></li>
<li><a href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/direct-connect-gateways.html">Working with Direct Connect gateways</a></li>
</ol>
]]></content>
      <categories>
        <category>云计算</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Network-VPC</title>
    <url>/www6vHomeHexo/2022/10/30/awsNetworkVPC/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="vpc-概念和组件123">VPC 概念和组件[1][2][3]</span><a href="#vpc-概念和组件123" class="header-anchor">#</a></h2><ul>
<li><p>Subnet &amp; CIDR<br><a href="https://www.bilibili.com/video/BV1Ff4y1S7Lf/">010-计算机网络-无分类编址CIDR</a><br><a href="https://network00.com/NetworkTools/IPv4SubnetCreator/">Tool</a></p>
</li>
<li><p>Routing Table<br>[实际中没有看到路由器,只有路由表]<br><a href="https://help.aliyun.com/document_detail/106224.html">路由表概述</a> 阿里云 有例子</p>
</li>
<li><p>Security Groups &amp; Network ACLs [1]</p>
<ul>
<li>Security Groups<br>EC2 level-工作在EC2 instance level<br>stateful firewall</li>
<li>Network ACLs<br>工作在subnet level<br>stateless firewall</li>
</ul>
</li>
<li><p>NAT Gateway &amp;&amp; NAT Instance [1]</p>
<ul>
<li>NAT Gateway<br>[通过internet gateway,访问外网, 外网访问不到内部, 多对一]</li>
<li>NAT Instance</li>
</ul>
</li>
<li><p>Internet Gateway<br>[一对一的, 静态ip绑定到internet gateway, 外网访问内网的EC2]</p>
</li>
<li><p>弹性网络接口ENI[2]</p>
<ul>
<li>弹性网络接口必须有一个主要的私有 IPv4 地址，并且始终与至少一个安全组相关联。</li>
<li>弹性网络接口可以在运行时（热连接）、停止时（热连接）或启动时（冷连接）连接到实例。</li>
<li>不能分离主网络接口。</li>
<li>弹性网络接口仅限于单个可用区。</li>
</ul>
</li>
<li><p>IP 寻址</p>
</li>
<li><p>仅出口 Internet 网关 (EIGW)</p>
</li>
<li><p>虚拟专用网关 (VGW)、客户网关和VPN</p>
</li>
<li><p>VPC peering</p>
</li>
<li><p>归置组</p>
</li>
<li><p>DNS 服务器</p>
</li>
</ul>
<h2><span id="bring-your-own-ip-addresses-byoip">Bring your own IP addresses (BYOIP)</span><a href="#bring-your-own-ip-addresses-byoip" class="header-anchor">#</a></h2><p><strong>Bring Your Own IP (BYOIP) enables customers to move all or part of their existing publicly routable IPv4 or IPv6 address space to AWS for use with their AWS resources.</strong> Customers will continue to own the IP range. Customers can create Elastic IPs from the IPv4 space they bring to AWS and use them with EC2 instances, NAT Gateways, and Network Load Balancers. Customers can also associate up to 5 CIDRs to a VPC from the IPv6 space they bring to AWS. Customers will continue to have access to Amazon-supplied IPs and can choose to use BYOIP Elastic IPs, Amazon-supplied IPs, or both.</p>
<p>参考<br><a href="https://aws.amazon.com/cn/vpc/faqs/">Amazon VPC 常见问题</a>  *** BYOIP<br><a href="https://aws.amazon.com/cn/blogs/networking-and-content-delivery/introducing-bring-your-own-ip-byoip-for-amazon-vpc/">Introducing Bring Your Own IP (BYOIP) for Amazon VPC</a> ***  50%<br><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-byoip.html">Bring your own IP addresses (BYOIP) in Amazon EC2</a><br>[Practice Set 1] 32题</p>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li>[SAP-1] VPC Section *** </li>
<li><a href="https://zhuanlan.zhihu.com/p/529181222">Chapter 2-Amazon Virtual Private Cloud (Amazon VPC) and Networking Fundamentals</a> *** </li>
<li><a href="https://www.bilibili.com/video/BV1CG41137bx/">【云计算】AWS高级网络.LAB1.1.vpc_peering</a></li>
<li><a href="https://jayendrapatil.com/aws-virtual-private-cloud-vpc/">VPC</a> ***  未<br><a href>UCloud 陈煌栋-UCloud VPC的技术演进之路</a></li>
</ol>
]]></content>
      <categories>
        <category>云计算</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>网络空间安全-Cyber Security</title>
    <url>/www6vHomeHexo/2022/10/23/cyberSecurity/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="综述">综述</span><a href="#综述" class="header-anchor">#</a></h2><p><a href="https://www.doc88.com/p-69916034297662.html?r=1">基于CiteSpace的国内外网络空间安全研究综述</a> ***</p>
<h2><span id="web安全">Web安全</span><a href="#web安全" class="header-anchor">#</a></h2><ul>
<li><p>Web安全[6]</p>
<img src="/www6vHomeHexo/2022/10/23/cyberSecurity/web-security.JPG" class title="Web安全">
</li>
<li><p>OWASP TOP 10[2]</p>
<ul>
<li>失效的访问控制<ul>
<li>提权-root</li>
</ul>
</li>
<li>加密失败<ul>
<li>弱随机数生成器</li>
<li>忘记加“盐”</li>
</ul>
</li>
<li>注入  <ul>
<li>SQL注入</li>
<li>命令注入</li>
<li>XSS</li>
</ul>
</li>
<li>安全配置错误</li>
</ul>
</li>
</ul>
<h2><span id="linux安全3">Linux安全[3]</span><a href="#linux安全3" class="header-anchor">#</a></h2><img src="/www6vHomeHexo/2022/10/23/cyberSecurity/linux-security.JPG" class title="linux安全">


<h2><span id="攻击模型">攻击模型</span><a href="#攻击模型" class="header-anchor">#</a></h2><p><a href="https://www.doc88.com/p-38973089899040.html">网络攻击模型研究综述</a><br>ATT&amp;CK模型</p>
<h2><span id="攻击手段-8">攻击手段 [8]</span><a href="#攻击手段-8" class="header-anchor">#</a></h2><ul>
<li>漏洞利用 <ul>
<li>SQL 注入漏洞</li>
<li>跨站漏洞 </li>
<li>授权验证绕过漏洞 </li>
<li>权限提升漏洞</li>
</ul>
</li>
<li>口令爆破 </li>
<li>钓鱼攻击 <ul>
<li>内网钓鱼</li>
<li>外网钓鱼</li>
</ul>
</li>
<li>供应链攻击 </li>
<li>VPN仿冒接入  </li>
<li>近源攻击     </li>
<li>DDoS[1] +<ul>
<li>CC攻击</li>
<li>HTTP慢速攻击</li>
</ul>
</li>
<li>MITM 中间人</li>
<li>DNS欺骗</li>
<li>勒索软件-木马</li>
</ul>
<h2><span id="漏洞防御与渗透测试">漏洞防御与渗透测试</span><a href="#漏洞防御与渗透测试" class="header-anchor">#</a></h2><h2><span id="安全防御工具">安全防御工具</span><a href="#安全防御工具" class="header-anchor">#</a></h2><a href="/www6vHomeHexo/2022/03/12/cyberSecurityTool/" title="安全产品">安全产品</a>



<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li><p><a href="https://wenku.baidu.com/view/7f2c9810c8aedd3383c4bb4cf7ec4afe05a1b14c?fr=xueshu">基于Web应用层的DDoS攻击模型研究</a> *</p>
</li>
<li><p>《Web 漏洞挖掘实战》  王昊天</p>
</li>
<li><p>《13 | Linux系统安全：多人共用服务器，如何防止别人干“坏事”？》  何为舟</p>
</li>
<li><p>xxx</p>
</li>
<li><p>xxx</p>
</li>
<li><p>《模块串讲（一）丨Web安全：如何评估用户数据和资产数据面临的威胁？》 何为舟</p>
</li>
<li><p>xxx</p>
</li>
<li><p>《红蓝攻防》</p>
</li>
<li><p><a href="https://tech.meituan.com/2021/04/08/threat-modeling-security.html">实践之后，我们来谈谈如何做好威胁建模</a>  美团  未</p>
</li>
</ol>
]]></content>
      <categories>
        <category>安全</category>
        <category>网络空间安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S高可用-零停机[探针]</title>
    <url>/www6vHomeHexo/2022/10/22/k8sAvailableHealth/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5">健康检查</a><ul>
<li><a href="#liveness-probe-2">Liveness Probe [2]</a></li>
<li><a href="#readiness-probe-2">Readiness Probe  [2]</a></li>
<li><a href="#startupprobe-4">startupProbe [4]</a></li>
</ul>
</li>
<li><a href="#%E4%BC%98%E9%9B%85%E7%BB%88%E6%AD%A2-5">优雅终止 [5]</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81-6">代码 [6]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="健康检查">健康检查</span><a href="#健康检查" class="header-anchor">#</a></h1><h3><span id="liveness-probe-2">Liveness Probe [2]</span><a href="#liveness-probe-2" class="header-anchor">#</a></h3><p><strong>确定何时重启容器</strong>. 例如，当应用程序处于运行状态但无法做进一步操作，liveness探针将捕获到deadlock，重启处于该状态下的容器，使应用程序在存在bug的情况下依然能够继续运行下去。<br><strong>liveness的初始值为成功。</strong></p>
<h3><span id="readiness-probe-2">Readiness Probe  [2]</span><a href="#readiness-probe-2" class="header-anchor">#</a></h3><p><strong>确定容器是否已经就绪可以接受流量.</strong> 该信号的作用是控制哪些Pod应该作为service的后端。如果Pod处于非就绪状态，那么它们将会被从service的load balancer中移除。<br><strong>readiness的初始值为失败。</strong></p>
<h3><span id="startupprobe-4">startupProbe [4]</span><a href="#startupprobe-4" class="header-anchor">#</a></h3><p>启动检查, 使用启动探针检测容器应用程序是否已经启动<br>对于较新的（≥v1.16）Kubernetes 集群，如果是具有<strong>不可预测或可变启动时间</strong>的应用程序应使用 startup 探针。</p>
<p><strong>只运行一次。</strong></p>
<ul>
<li>探针类型<br>httpGet: 指定端口和路径执行 HTTP GET 请求<br>tcpSocket: 对容器的 IP 地址上的指定端口执行 TCP 检查<br>命令,exec: 在容器内执行指定命令</li>
</ul>
<h1><span id="优雅终止-5">优雅终止 [5]</span><a href="#优雅终止-5" class="header-anchor">#</a></h1><p>  系统底层默认会向主进程发送 SIGTERM 信号，而对剩余子进程发送 SIGKILL 信号。系统这样做的大概原因是因为大家在设计主进程脚本的时候都不会进行信号的捕获和传递，这会导致容器关闭时，多个子进程无法被正常终止，所以系统使用 SIGKILL 这个不可屏蔽信号，而是为了能够在没有任何前提条件的情况下，能够把容器中所有的进程关掉。</p>
<p>  也就是说如果主进程自身不是服务本身，可能会导致是被强制Kill的，解决的方法也很简单，也就是在主进程中对收到的信号做个转发，发送到容器中的其他子进程，这样容器中的所有进程在停止时，都会收到 SIGTERM，而不是 SIGKILL 信号了。</p>
<h1><span id="代码-6">代码 [6]</span><a href="#代码-6" class="header-anchor">#</a></h1><ul>
<li><p>Probe</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="comment"># 存活检测</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">5084</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">    <span class="comment"># 就绪检测</span></span><br><span class="line">    <span class="attr">readinessProbe:</span></span><br><span class="line">      <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">5084</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">    <span class="comment"># 优雅退出</span></span><br><span class="line">    <span class="attr">lifecycle:</span> </span><br><span class="line">      <span class="attr">preStop:</span> </span><br><span class="line">        <span class="attr">exec:</span> </span><br><span class="line">          <span class="attr">command:</span> </span><br><span class="line">          <span class="bullet">-</span> <span class="string">sleep</span></span><br><span class="line">          <span class="bullet">-</span> <span class="number">30</span></span><br><span class="line">  <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">60</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Service<br>Cluster 模式（externalTrafficPolicy: Cluster）</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">externalTrafficPolicy:</span> <span class="string">Cluster</span>  <span class="comment">###</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p>Local 模式（externalTrafficPolicy: Local）</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">externalTrafficPolicy:</span> <span class="string">Local</span>  <span class="comment">###</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br></pre></td></tr></table></figure>

<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p>健康检查</p>
<ol>
<li><a href="https://blog.51cto.com/3842834/2317986">Liveness和Readiness两种Health Check手段在Kubernetes中的使用</a>  耕耘实录</li>
<li><a href="https://github.com/rootsongjc/kubernetes-handbook/blob/master/guide/configure-liveness-readiness-probes.md">配置Pod的liveness和readiness探针</a>  宋净超</li>
<li><a href="https://www.cnblogs.com/xuxinkun/p/11785521.html">liveness与readiness的探针工作方式源码解析</a>  xinkun的博客</li>
<li><a href="https://mp.weixin.qq.com/s/wT_NQF9xYfKD3wVm6yUUMw">Kubernetes 探针详解！</a> </li>
<li>04 | 理解进程(3):为什么我在容器中的进程被强制杀死了? -  李程远 </li>
<li><a href="https://blog.csdn.net/alisystemsoftware/article/details/106520606">更新应用时，如何实现 K8s 零中断滚动更新</a> ***</li>
</ol>
]]></content>
      <categories>
        <category>云原生</category>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>数据中台</title>
    <url>/www6vHomeHexo/2022/10/16/dataMiddlePlatform/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="数据中台">数据中台</span><a href="#数据中台" class="header-anchor">#</a></h1><h3><span id="数据中台全景">数据中台全景</span><a href="#数据中台全景" class="header-anchor">#</a></h3><ul>
<li><p>数据中台全景[6]</p>
<img src="/www6vHomeHexo/2022/10/16/dataMiddlePlatform/middleStage-data.jpg" class>
</li>
<li><p>数据中台全景-阿里[7]</p>
<img src="/www6vHomeHexo/2022/10/16/dataMiddlePlatform/middleStage-data-ali.jpg" class title="数据中台全景-阿里">

</li>
<li><p>zhyt</p>
<img src="/www6vHomeHexo/2022/10/16/dataMiddlePlatform/zhyt.png" class title="中和应泰"></li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol start="6">
<li><a href="https://www.esensoft.com/industry-news/dx-24039.html">一文读懂数据中台架构体系</a> *** </li>
<li><a href="https://xie.infoq.cn/article/8147ffdb15528ce08008d8100">数据中台各种架构图</a></li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>数据中台</category>
      </categories>
      <tags>
        <tag>数据中台</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS 学习资源</title>
    <url>/www6vHomeHexo/2022/10/01/awsStudyResource/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="commons">commons</span><a href="#commons" class="header-anchor">#</a></h2><ul>
<li><p>AWS 认证云从业者 (CLF-C01)</p>
</li>
<li><p>Devops</p>
<ul>
<li>AWS 认证开发人员 – 助理 (DVA-C01) </li>
<li>AWS 认证 SysOps 管理员 – 助理 (SOA-C02)<br> <a href="https://www.bilibili.com/video/BV15U4y1S73s/">2022 终极 AWS 认证 - SysOps 管理员助理-上</a> 大量实操 中文<br><a href="https://www.bilibili.com/video/BV1F3411N7TJ/">2022 终极 AWS 认证 - SysOps 管理员助理-下</a> 大量实操 中文</li>
<li>AWS 认证 DevOps 工程师 – 专业 (DOP-C01)</li>
</ul>
</li>
<li><p>Solution</p>
<ul>
<li>AWS 认证解决方案架构师 – 助理 (SAA-C02)<br><a href="https://www.bilibili.com/video/BV1wR4y1F7YM/">Ultimate AWS Certified Solutions Architect Associate 2022（P1）-上</a> hand-on 中文 200<br><a href="https://www.bilibili.com/video/BV16L4y177kj/">Ultimate AWS Certified Solutions Architect Associate 2022（P2）- 下</a> hand-on 中文 156<br><a href="https://www.bilibili.com/video/BV12K411p7uy/">[AWS Certified Solutions Architect - Associate][2020][机翻字幕]</a> 269个<br><a href="https://www.bilibili.com/video/BV1K7411H7xm/">YOUTUBE上播放量超过16万人次的AWS SAA认证视频</a> 不全</li>
<li>AWS 认证解决方案架构师 – 专业 (SAP-C01)<br><a href="https://www.bilibili.com/video/BV1nR4y1N72u/">Amazon ECS 和 Fargate 大师班 - AWS 上的 Docker</a> 中文<br><a href="https://www.bilibili.com/video/BV1S541187uv/">AWS Solution Architect Professional, Stephane Maarek-2020</a> 无字幕</li>
</ul>
</li>
</ul>
<h2><span id="special">special</span><a href="#special" class="header-anchor">#</a></h2><ul>
<li>AWS 认证高级网络 – 专业 (ANS-C00)<br><a href="https://space.bilibili.com/412127397/search/video?keyword=aws">乾颐堂 aws网络</a> *** bili<br><a href="https://www.bilibili.com/video/BV1CG41137bx/">【云计算】AWS高级网络.LAB1.1.vpc_peering</a> </li>
<li>AWS 认证安全 – 专业 (SCS-C01)</li>
<li>AWS 认证机器学习 – 专业 (MLS-C01)</li>
<li>AWS 认证数据库 – 专业 (DBS-C01)</li>
<li>AWS 认证数据分析 – 专业 (DAS-C01)</li>
</ul>
<h2><span id="备考">备考</span><a href="#备考" class="header-anchor">#</a></h2><ul>
<li><a href="https://www.bilibili.com/video/BV1ph411y7TQ/">AWS认证备考细则</a> *** 要重新看<br>AWS考试指导书<br>AWS产品白皮书</li>
<li>考点<br><a href="https://www.pearsonvue.com.cn/aws">Pearson VUE</a><br>PSI 抵制</li>
<li>改期和取消 <ul>
<li>改期<br>24小时之前改期，只能改期2次 </li>
<li>AWS考试券-半价</li>
</ul>
</li>
</ul>
<p>参考:<br><a href="https://www.xiaoheiwoo.com/choosing-the-right-aws-certification/">11 项 AWS 认证：哪一项适合你和你的团队？</a> *<br><a href="https://www.bilibili.com/video/BV1gU4y177TE/">AWS认证之路 - 备战 AWS Certification 考试</a> bilibili  *</p>
<h2><span id="官方">官方</span><a href="#官方" class="header-anchor">#</a></h2><p><a href="https://aws.amazon.bokecc.com/">亚马逊云科技 视频中心</a> ***<br>在线研讨会, re:Invent, Innovate,  Summit,  Transformation Day<br><a href="https://aws.amazon.com/cn/about-aws/events/">亚马逊云科技中国市场及培训活动</a> ***<br><a href="https://aws.amazon.com/cn/about-aws/events/webinar/2019/">aws 在线研讨会</a> ***  2015-2019<br><a href="https://space.bilibili.com/418158141">亚马逊云科技官方账号</a> *** bili  - INNOVATE 2020<br><a href="https://blog.csdn.net/awschina?type=blog">亚马逊云开发者</a>  亚马逊CSDN blog-会议,咨询<br><a href="https://amazonaws-china.com/cn/blogs/architecture/">AWS Architecture Blog</a> ***<br><a href="https://www.allthingsdistributed.com/">All Things Distributed</a>  aws cto</p>
<h2><span id="非官方">非官方</span><a href="#非官方" class="header-anchor">#</a></h2><p><a href="https://www.koudaizy.com/">口袋资源</a> ***<br><a href="https://www.zhihu.com/column/c_1347591909771182080">全是aws干货</a> 分享aws云经验，提供实操干货</p>
]]></content>
      <categories>
        <category>云计算</category>
        <category>AWS</category>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS 所有的Services</title>
    <url>/www6vHomeHexo/2022/10/01/awsAllServices/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="analytics">Analytics:</span><a href="#analytics" class="header-anchor">#</a></h2><p>• Amazon Athena<br> Amazon Athena is a serverless, interactive analytics service built on open-source frameworks, supporting open-table and file formats.<br>• AWS Data Exchange<br>• AWS Data Pipeline<br>• Amazon EMR<br>• AWS Glue<br>AWS Glue is a serverless data integration service that makes it easier to discover, prepare, move, and integrate data from multiple sources for analytics, machine learning (ML), and application development.<br>[ETL]<br>• Amazon Kinesis Data Analytics<br>• Amazon Kinesis Data Firehose<br>• Amazon Kinesis Data Streams<br>• AWS Lake Formation<br>• Amazon Managed Streaming for Apache Kafka (Amazon MSK)<br>• Amazon OpenSearch Service<br>• Amazon QuickSight<br> BI tool</p>
<h2><span id="application-integration">Application Integration:</span><a href="#application-integration" class="header-anchor">#</a></h2><p>• Amazon AppFlow<br>• AWS AppSync<br>• Amazon EventBridge (Amazon CloudWatch Events)  @<br>• Amazon MQ  @<br>• Amazon Simple Notification Service (Amazon SNS)  @<br>• Amazon Simple Queue Service (Amazon SQS)  @<br>• AWS Step Functions  @</p>
<h2><span id="business-applications">Business Applications:</span><a href="#business-applications" class="header-anchor">#</a></h2><p>• Alexa for Business<br>• Amazon Simple Email Service (Amazon SES)</p>
<h2><span id="blockchain">Blockchain:</span><a href="#blockchain" class="header-anchor">#</a></h2><p>• Amazon Managed Blockchain</p>
<h2><span id="cloud-financial-management">Cloud Financial Management:</span><a href="#cloud-financial-management" class="header-anchor">#</a></h2><p>• AWS Budgets<br>• AWS Cost and Usage Report<br>• AWS Cost Explorer<br>• Savings Plans</p>
<h2><span id="compute">Compute:</span><a href="#compute" class="header-anchor">#</a></h2><p>• AWS App Runner<br>• AWS Auto Scaling<br>• AWS Batch  @<br>  AWS Batch enables you to easily and efficiently run batch computing workloads of any scale on AWS using Amazon EC2 and Amazon EC2 Spot.<br>• Amazon EC2  @<br>• Amazon EC2 Auto Scaling  @<br>• AWS Elastic Beanstalk<br>  Amazon Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and IIS.<br>• Amazon Elastic Kubernetes Service (Amazon EKS)<br>• Elastic Load Balancing  @<br>• AWS Fargate  @<br>  AWS Fargate 是一种无服务器、随用随付的计算引擎，可让您专注于构建应用程序，而无需管理服务器。AWS Fargate 与 Amazon Elastic Container Service (ECS) 和 Amazon Elastic Kubernetes Service (EKS) 兼容。<br>• AWS Lambda  @<br>• Amazon Lightsail<br>  Amazon Lightsail 以经济实惠的月度价格提供易于使用的虚拟专用服务器 (VPS) 实例、容器、存储、数据库等。<br>  Lightsail 是由 AWS 推出的面向开发人员、小型企业、学生等人员的轻量级 VPS 云计算服务。(非官方)<br>• AWS Outposts  @<br>  AWS Outposts brings native AWS services, infrastructure, and operating models to virtually any data center, co-location space, or on-premises facility.<br>• AWS Wavelength</p>
<h2><span id="containers">Containers:</span><a href="#containers" class="header-anchor">#</a></h2><p>• Amazon Elastic Container Registry (Amazon ECR)<br>• Amazon Elastic Container Service (Amazon ECS)  @<br>  Amazon ECS is a fully managed container orchestration service that helps you easily deploy, manage, and scale containerized applications. It deeply integrates with the rest of the AWS platform to provide a secure and easy-to-use solution for running container workloads in the cloud and now on your infrastructure with Amazon ECS Anywhere.<br>• Amazon ECS Anywhere<br>• Amazon Elastic Kubernetes Service (Amazon EKS)  @<br>  Amazon EKS is a managed service that makes it easy for you to use Kubernetes on AWS without needing to install and operate your own Kubernetes control plane.<br>• Amazon EKS Anywhere<br>• Amazon EKS Distro</p>
<h2><span id="database">Database:</span><a href="#database" class="header-anchor">#</a></h2><p>• Amazon Aurora  @<br>  Designed for unparalleled high performance and availability at global scale with full MySQL and PostgreSQL compatibility<br>  Amazon Aurora provides built-in security, continuous backups, serverless compute, up to 15 read replicas, automated multi-Region replication, and integrations with other AWS services.<br>• Amazon Aurora Serverless  @<br>• Amazon DocumentDB (with MongoDB compatibility)<br>  Scale JSON workloads with ease using a fully managed document database service<br>  (with MongoDB compatibility)<br>  [Free]<br>• Amazon DynamoDB  @<br>  Fast, flexible NoSQL database service for single-digit millisecond performance at any scale<br>  [Free]<br>• Amazon ElastiCache  @<br>  Unlock microsecond latency and scale with in-memory caching<br>  [Free]<br>• Amazon Keyspaces (for Apache Cassandra)<br>• Amazon Neptune<br>  Amazon Neptune is a fast, reliable, fully-managed graph database service that makes it easy to build and run applications that work with highly connected datasets.<br>• Amazon RDS  @<br>• Amazon Redshift<br>• Amazon Timestream</p>
<h2><span id="developer-tools">Developer Tools:</span><a href="#developer-tools" class="header-anchor">#</a></h2><p>• AWS Cloud9<br>• AWS CodeArtifact<br>• AWS CodeBuild<br>• AWS CodeCommit<br>• AWS CodeDeploy<br>• Amazon CodeGuru<br>• AWS CodePipeline<br>• AWS CodeStar<br>• AWS X-Ray</p>
<h2><span id="end-user-computing">End User Computing:</span><a href="#end-user-computing" class="header-anchor">#</a></h2><p>• Amazon AppStream 2.0<br>• Amazon WorkSpaces</p>
<h2><span id="frontend-web-and-mobile">Frontend Web and Mobile:</span><a href="#frontend-web-and-mobile" class="header-anchor">#</a></h2><p>• AWS Amplify<br>• Amazon API Gateway<br>• AWS Device Farm<br>• Amazon Pinpoint</p>
<h2><span id="internet-of-things">Internet of Things:</span><a href="#internet-of-things" class="header-anchor">#</a></h2><p>• AWS IoT Analytics<br>• AWS IoT Core<br>• AWS IoT Device Defender<br>• AWS IoT Device Management<br>• AWS IoT Events<br>• AWS IoT Greengrass<br>• AWS IoT SiteWise<br>• AWS IoT Things Graph<br>• AWS IoT 1-Click</p>
<h2><span id="machine-learning">Machine Learning:</span><a href="#machine-learning" class="header-anchor">#</a></h2><p>• Amazon Comprehend<br>• Amazon Forecast<br>• Amazon Fraud Detector<br>• Amazon Kendra<br>• Amazon Lex<br>  Build chatbots with conversational AI<br>• Amazon Personalize<br>• Amazon Polly<br>  Amazon Polly uses deep learning technologies to synthesize natural-sounding human speech, so you can convert articles to speech.<br>• Amazon Rekognition<br>  Automate your image and video analysis with machine learning<br>• Amazon SageMaker<br>  Build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows<br>• Amazon Textract<br>• Amazon Transcribe<br>• Amazon Translate</p>
<h2><span id="management-and-governance">Management and Governance:</span><a href="#management-and-governance" class="header-anchor">#</a></h2><p>• AWS CloudFormation  @<br>• AWS CloudTrail<br>  AWS CloudTrail monitors and records account activity across your AWS infrastructure, giving you control over storage, analysis, and remediation actions.<br>• Amazon CloudWatch  @<br>• Amazon CloudWatch Logs  @<br>• AWS Command Line Interface (AWS CLI)<br>• AWS Compute Optimizer<br>• AWS Config<br>• AWS Control Tower<br>• AWS License Manager<br>• Amazon Managed Grafana<br>• Amazon Managed Service for Prometheus<br>• AWS Management Console<br>• AWS Organizations  @<br>• AWS Personal Health Dashboard<br>• AWS Proton<br>• AWS Service Catalog<br>• Service Quotas<br>• AWS Systems Manager<br>• AWS Trusted Advisor<br>• AWS Well-Architected Tool</p>
<h2><span id="media-services">Media Services:</span><a href="#media-services" class="header-anchor">#</a></h2><p>• Amazon Elastic Transcoder<br>• Amazon Kinesis Video Streams</p>
<h2><span id="migration-and-transfer">Migration and Transfer:</span><a href="#migration-and-transfer" class="header-anchor">#</a></h2><p>• AWS Application Discovery Service<br>• AWS Application Migration Service (CloudEndure Migration)<br>• AWS Database Migration Service (AWS DMS)<br>  Homogeneous Database Migrations<br>  Heterogeneous Database Migrations<br>• AWS DataSync<br>  Simplify and accelerate secure data migrations<br>• AWS Migration Hub<br>  Discover the tools that you need to simplify your migration and modernization<br>  AWS Migration Hub provides a central location to collect server and application inventory data for the assessment, planning, and tracking of migrations to AWS. Migration Hub can also help accelerate application modernization following migration.<br>• AWS Schema Conversion Tool (AWS SCT)<br>• AWS Snow Family  @<br>• AWS Transfer Family<br>  AWS Transfer Family securely scales your recurring business-to-business file transfers to AWS Storage services using SFTP, FTPS, FTP, and AS2 protocols. </p>
<h2><span id="networking-and-content-delivery">Networking and Content Delivery:</span><a href="#networking-and-content-delivery" class="header-anchor">#</a></h2><p>• Amazon CloudFront  @<br>• AWS Direct Connect  @<br>• Elastic Load Balancing (ELB)  @<br>• AWS Global Accelerator  @<br>  <a href="https://kebingzao.com/2020/08/13/aws-ga/">使用 AWS Global Accelerator 加速你的服务</a><br>• AWS PrivateLink  @<br>• Amazon Route 53  @<br>• AWS Transit Gateway  @<br>• Amazon VPC  @<br>• AWS VPN  @</p>
<h2><span id="security-identity-and-compliance">Security, Identity, and Compliance:</span><a href="#security-identity-and-compliance" class="header-anchor">#</a></h2><p>• AWS Artifact<br>• AWS Audit Manager<br>• AWS Certificate Manager (ACM)<br> Provision and manage SSL&#x2F;TLS certificates with AWS services and connected resources<br>• AWS CloudHSM<br> Manage single-tenant hardware security modules (HSMs) on AWS<br>• Amazon Cognito<br>• Amazon Detective<br>• AWS Directory Service<br>• AWS Firewall Manager @<br> Centrally configure and manage firewall rules across your accounts<br>• Amazon GuardDuty<br>• AWS Identity and Access Management (IAM)  @<br>• Amazon Inspector<br>• AWS Key Management Service (AWS KMS)  @<br>• Amazon Macie<br>• AWS Network Firewall  @<br>• AWS Resource Access Manager (AWS RAM)<br>• AWS Secrets Manager<br>• AWS Security Hub<br>• AWS Security Token Service (AWS STS)<br>• AWS Shield<br>• AWS Single Sign-On  @<br>• AWS WAF  @</p>
<h2><span id="storage">Storage:</span><a href="#storage" class="header-anchor">#</a></h2><p>• AWS Backup<br>  Centrally manage and automate data protection<br>• Amazon Elastic Block Store (Amazon EBS)  @<br>  Easy to use, high performance block storage at any scale<br>• AWS Elastic Disaster Recovery (CloudEndure Disaster Recovery)<br>• Amazon Elastic File System (Amazon EFS)  @<br>  Simple, serverless, set-and-forget, elastic file system<br>• Amazon FSx (for all types)<br>  Launch, run, and scale feature-rich and highly-performant file systems with just a few clicks<br>• Amazon S3  @<br>• Amazon S3 Glacier  @<br>  Long-term, secure, durable storage classes for data archiving at the lowest cost and milliseconds access<br>• AWS Storage Gateway  @<br>  Provide on-premises applications with access to virtually unlimited cloud storage</p>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><p><a href="https://us-east-1.console.aws.amazon.com/console/services?region=us-east-1">AWS所有服务</a></p>
]]></content>
      <categories>
        <category>云计算</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Storage-S3</title>
    <url>/www6vHomeHexo/2022/10/01/awsStorageS3/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="s3">S3</span><a href="#s3" class="header-anchor">#</a></h2><ul>
<li><p>基本特性[5]</p>
<ul>
<li>S3的文件存储在存储桶（Buckets）内，可以理解为文件夹</li>
<li>存储桶创建之后会生成一个URL<br>S3是以HTTPS的形式展现的，而非HTTP</li>
<li>S3的存储桶创建的时候可以选择所在区域（Region），但不能选择可用区（AZ），AWS会负责S3的高可用、容灾问题 *<ul>
<li>S3创建的时候可以选择某个AWS区域，一旦选择了就不能更改</li>
<li>如果要在其他区域使用该S3的内容，可以使用跨区域复制  #2</li>
</ul>
</li>
<li>S3拥有不同的等级（Standard, Stantard-IA, Onezone-IA, RRS, Glacier） #1</li>
<li>启用了版本控制（Version Control）你可以恢复S3内的文件到之前的版本  #4</li>
<li>S3可以开启生命周期管理 #3<ul>
<li>要启用生命周期管理需要先启用版本控制功能</li>
</ul>
</li>
<li>支持加密功能  </li>
<li>使用访问控制列表（Access Control Lists）和桶策略（Bucket Policy）可以控制S3的访问安全</li>
</ul>
</li>
<li><p>S3[2]</p>
<ul>
<li>Static content</li>
<li>serverless</li>
<li>pay-as-you-go</li>
</ul>
</li>
<li><p>Type #1</p>
<img src="/www6vHomeHexo/2022/10/01/awsStorageS3/s3-type.JPG" class title="S3 Type">
</li>
<li><p>S3 – Replication [2][4] #2</p>
<ul>
<li>Cross Region Replication (CRR)</li>
<li>Same Region Replication (SRR)</li>
<li>Combine with Lifecycle Policies</li>
</ul>
</li>
<li><p>S3 Select &amp; Glacier Select[3]</p>
<ul>
<li>S3 Select<br>server side filtering</li>
<li>Glacier Select</li>
</ul>
</li>
<li><p>Lifecycle Management #3</p>
<ul>
<li>Transition actions</li>
<li>Expiration actions</li>
</ul>
</li>
<li><p>访问S3</p>
<ul>
<li>S3访问策略[1]  <img src="/www6vHomeHexo/2022/10/01/awsStorageS3/s3-accessPolicy.JPG" class title="s3访问策略"></li>
<li>访问方式[4]<ul>
<li>private Address</li>
<li>public Address</li>
</ul>
</li>
</ul>
</li>
<li><p>Versioning #4</p>
<ul>
<li>preserve, retrieve, and restore</li>
</ul>
</li>
<li><p>Access Points [2]</p>
<ul>
<li>Access Point gets its own DNS and policy to limit who can access it<br>One policy per Access Point<br><a href="https://aws.amazon.com/s3/features/access-points/">Amazon S3 Access Points</a><br><a href="https://aws.amazon.com/s3/features/multi-region-access-points/">Amazon S3 Multi-Region Access Points</a><br><a href="../../../../2022/06/17/awsNetworkVPCendpoint/">AWS Network-VPC Endpoint</a> self</li>
</ul>
</li>
</ul>
<h2><span id="aws-storage-gateway46">AWS Storage Gateway[4][6]</span><a href="#aws-storage-gateway46" class="header-anchor">#</a></h2><ul>
<li>File Gateway<br>SMB or NFS-based access</li>
<li>Volume Gateway<br>Block storage – iSCSI protocol<ul>
<li>Cached volumes<br>provides low-latency access to your frequently accessed data but not to the entire data.</li>
<li>Stored volumes<br>store your primary data locally, while asynchronously back up that data to AWS.</li>
</ul>
</li>
<li>Tape Gateway<br><a href="https://docs.aws.amazon.com/storagegateway/index.html">AWS Storage Gateway Documentation</a></li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li><a href="https://www.bilibili.com/video/BV1hJ411U7vd">AWS解决方案架构师认证 Professional(SAP)中文视频培训课程2022</a>  P10</li>
<li>[SAP-2] Storage Section *** </li>
<li><a href="https://aws.amazon.com/blogs/aws/s3-glacier-select/">S3 Select and Glacier Select – Retrieving Subsets of Objects</a></li>
<li>[SAP-1] *** </li>
<li><a href="http://www.cloudbin.cn/?p=1968">AWS学习笔记（十） Amazon Simple Storage Service (S3)</a> </li>
<li><a href>Practice Set 1</a> Question 13</li>
</ol>
<p>Series<br>10. <a href="https://www.iloveaws.cn/1238.html">08-S3存储桶策略（S3 Bucket Policies）</a><br>11. <a href="https://www.iloveaws.cn/1361.html">09-配置跨账户S3存储桶的访问（Cross Account S3 Bucket Configuration）</a><br>12. <a href="https://www.iloveaws.cn/1426.html">10-S3标准 ACL（Canned ACL）</a><br>13. <a href="https://www.iloveaws.cn/2428.html">39-S3存储桶跨区域复制 (CRR)</a></p>
<p><a href="https://www.bilibili.com/video/BV14a4y1W77S/">海量数据云归档最佳实践</a> bili ucloud</p>
]]></content>
      <categories>
        <category>云计算</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Database</title>
    <url>/www6vHomeHexo/2022/10/01/awsDatabase/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="rds2">RDS[2]</span><a href="#rds2" class="header-anchor">#</a></h2><ul>
<li>database engines<ul>
<li>Amazon Aurora</li>
<li>MySQL</li>
<li>MariaDB</li>
<li>Oracle</li>
<li>Microsoft SQL Server</li>
<li>PostgreSQ</li>
</ul>
</li>
<li>Backup and Recovery<ul>
<li>Automated Backups</li>
<li>Manual Backups (Snapshot)</li>
</ul>
</li>
<li>RDS Replication<ul>
<li>RPO &#x3D; 10 minutes, RTO &#x3D; 5 minutes</li>
</ul>
</li>
<li><strong>Amazon RDS Multi-AZ and Read Replicas</strong></li>
</ul>
<table>
<thead>
<tr>
<th><strong>Multi-AZ Deployments</strong></th>
<th><strong>Read Replicas</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Synchronous replication – highly durable</td>
<td>Asynchronous replication – highly scalable</td>
</tr>
<tr>
<td>Only database engine on primary instance is active</td>
<td>All read replicas are accessible and can be used for read scaling</td>
</tr>
<tr>
<td>Automated backups are taken from standby</td>
<td>No backups configured by default</td>
</tr>
<tr>
<td>Always span two Availability Zones within a single Region</td>
<td>Can be within an Availability Zone, Cross-AZ, or Cross-Region</td>
</tr>
<tr>
<td>Database engine version upgrades happen on primary</td>
<td>Database engine version upgrade is independent from source instance</td>
</tr>
<tr>
<td>Automatic failover to standby when a problem is detected</td>
<td>Can be manually promoted to a standalone database instance</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">注：</span><br><span class="line">RPO = Recovery Point Objective</span><br><span class="line">RT0 - Recovery Time Objective</span><br></pre></td></tr></table></figure>



<h2><span id="aurora-2">Aurora [2]</span><a href="#aurora-2" class="header-anchor">#</a></h2><ul>
<li><p>Replicas  </p>
<ul>
<li>Aurora Replicas are within a region</li>
<li>Replicas scale-out read requests</li>
<li>Can promote Aurora Replica to be a new primary or create new primary</li>
<li>Can use Auto Scaling to add replicas</li>
</ul>
</li>
<li><p>Cross-Region Replica with Aurora MySQL</p>
<ul>
<li>Asynchronous replication<br><strong>Replication uses the MySQL database engine</strong></li>
</ul>
</li>
<li><p>Global Database</p>
<ul>
<li><strong>Replication uses the Aurora storage layer</strong></li>
<li>Applications can connect to the cluster Reader Endpoint [3]</li>
</ul>
</li>
<li><p>Fault Tolerance</p>
<ul>
<li>Fault tolerance across 3 AZs</li>
</ul>
</li>
<li><p>Multi-Master</p>
<ul>
<li>All nodes allow reads&#x2F;writes</li>
<li>Available for MySQL only</li>
<li>Up to four read&#x2F;write nodes</li>
<li>Single Region only</li>
</ul>
</li>
</ul>
<p>参考:<br><a href="https://zhuanlan.zhihu.com/p/159304158">在 Amazon Aurora Global Database 中使用全球分布式 MySQL 程序</a>  未<br><a href="https://aws.amazon.com/cn/getting-started/hands-on/aurora-global-database/">使用 Amazon Aurora Global Database 进行快速的跨区域灾难恢复和低延迟全球读取</a> 未<br><a href="https://www.bilibili.com/video/BV1P64y1M7fu/">力从地起 - 揭秘 Aurora 底层存储 (Level 300)</a>  *** global database，snapshot</p>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li><a href="https://aws.amazon.com/rds/features/multi-az/">Amazon RDS Multi-AZ</a></li>
<li>SAP-1  Database</li>
<li><a href="https://aws.amazon.com/cn/blogs/aws/new-reader-endpoint-for-amazon-aurora-load-balancing-higher-availability/">New Reader Endpoint for Amazon Aurora – Load Balancing &amp; Higher Availability</a></li>
</ol>
]]></content>
      <categories>
        <category>云计算</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Network-Overview</title>
    <url>/www6vHomeHexo/2022/10/01/awsNetwork/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="overview13">Overview[1][3]</span><a href="#overview13" class="header-anchor">#</a></h2><img src="/www6vHomeHexo/2022/10/01/awsNetwork/awsNetwork.jpg" class title="AWS网路产品">


<h5><span id="云上网络场景">云上网络[场景]</span><a href="#云上网络场景" class="header-anchor">#</a></h5><ul>
<li>vpc</li>
<li>vpc peering ***<ul>
<li>[劣势：没有transitive 特性]</li>
</ul>
</li>
<li>private link<ul>
<li>vpc上打个洞，用的比较少</li>
</ul>
</li>
<li>ELB</li>
</ul>
<h5><span id="跨地域网络场景">跨地域网络[场景]</span><a href="#跨地域网络场景" class="header-anchor">#</a></h5><ul>
<li>sd-wan    <ul>
<li>cloudwan</li>
</ul>
</li>
</ul>
<h5><span id="混合云网络场景">混合云网络[场景]</span><a href="#混合云网络场景" class="header-anchor">#</a></h5><ul>
<li>vpn<ul>
<li>client vpn ***</li>
<li>vpn gateway  </li>
<li>vpn site-to-site ***<br><a href="https://zhuanlan.zhihu.com/p/395805857">AWS Site-to-Site VPN</a><br><a href="https://docs.aws.amazon.com/zh_cn/vpn/latest/s2svpn/how_it_works.html">AWS Site-to-Site VPN 的工作原理</a></li>
</ul>
</li>
<li>专线<ul>
<li>direct connect ***</li>
</ul>
</li>
<li>transit gateway ***<ul>
<li>[劣势： 不能跨region. 如果要跨region, 需要TGW之间做peering]</li>
</ul>
</li>
</ul>
<h5><span id="解决方案">(解决方案)</span><a href="#解决方案" class="header-anchor">#</a></h5><ul>
<li>transit vpc</li>
</ul>
<h5><span id="vpc-peering-vs-transit-vpc-vs-transit-gateway">VPC Peering vs. Transit VPC vs. Transit Gateway</span><a href="#vpc-peering-vs-transit-vpc-vs-transit-gateway" class="header-anchor">#</a></h5><img src="/www6vHomeHexo/2022/10/01/awsNetwork/aws-network-compare.JPG" class title="VPC Peering vs. Transit VPC vs. Transit Gateway">


<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><p>1.<a href="https://www.bilibili.com/video/BV1gQ4y1k7LH/">亚马逊云科技企业组网解决方案 | 一期一会</a><br>3. <a href="https://www.bilibili.com/video/BV1CG41137bx/">【云计算】AWS高级网络.LAB1.1.vpc_peering</a><br>7. <a href="https://www.zhihu.com/column/c_1520366118765621248">AWS networking</a> *** 笔记  未</p>
<h3><span id="white-paper">white paper</span><a href="#white-paper" class="header-anchor">#</a></h3><p><a href="https://d1.awsstatic.com/whitepapers/building-a-scalable-and-secure-multi-vpc-aws-network-infrastructure.pdf">Building a Scalable and Secure Multi-VPC AWS Network Infrastructure-AWS Whitepaper</a> ***  未<br><a href="https://www.bilibili.com/video/BV1Cd4y1377m/">教主技术进化论2022第24期 AWS网络白皮书.1.vpc_peering</a> </p>
<p><a href="https://d1.awsstatic.com/whitepapers/building-a-scalable-and-secure-multi-vpc-aws-network-infrastructure.pdf">https://d1.awsstatic.com/whitepapers/building-a-scalable-and-secure-multi-vpc-aws-network-infrastructure.pdf</a></p>
]]></content>
      <categories>
        <category>云计算</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Security</title>
    <url>/www6vHomeHexo/2022/10/01/awssecurity/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="landing-zone1">Landing Zone[1]</span><a href="#landing-zone1" class="header-anchor">#</a></h2><ul>
<li>Control Tower</li>
</ul>
<h2><span id="wafweb-application-firewall-13">WAF(Web Application Firewall) [1][3]</span><a href="#wafweb-application-firewall-13" class="header-anchor">#</a></h2><ul>
<li>计费方式</li>
<li>部署方式<ul>
<li>传统WAF<br>部署在ELB之后，部署在EC2之上</li>
<li>AWS WAF<br>部署在CloudFront之上</li>
</ul>
</li>
</ul>
<img src="/www6vHomeHexo/2022/10/01/awssecurity/waf-security-automations-architecture.png" class title="Security Automations for AWS WAF">    
<h2><span id="firewall-manager1">Firewall Manager[1]</span><a href="#firewall-manager1" class="header-anchor">#</a></h2><p>以规模化方式管理AWS WAF规则</p>
<h2><span id="kms-1todo">KMS [1][todo]</span><a href="#kms-1todo" class="header-anchor">#</a></h2><h2><span id="kms-4">KMS [4]</span><a href="#kms-4" class="header-anchor">#</a></h2><ul>
<li><p>KMS Key Types</p>
<ul>
<li>Symmetric (AES-256 keys)</li>
<li>Asymmetric (RSA &amp; ECC key pairs)</li>
</ul>
</li>
<li><p>Types of KMS Keys</p>
<img src="/www6vHomeHexo/2022/10/01/awssecurity/kms-keyType.JPG" class title="Types of KMS Keys">
</li>
<li><p>KMS Key Material Origin</p>
<ul>
<li>KMS (AWS_KMS) – default</li>
<li>External (EXTERNAL)<br>BYOK， 外部的key导入KMS</li>
<li>Custom Key Store (AWS_CLOUDHSM)<br>用户自定义的Key Store  [感觉类似加密机，硬件加密]</li>
</ul>
</li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><p>bilibili</p>
<ol>
<li><a href="https://www.bilibili.com/video/BV1ka4y1v7ZN/">AWS 常见安全参考架构 (Level 200)</a></li>
<li>亚马逊云科技 安全架构连连看</li>
<li><a href="https://aws.amazon.com/cn/solutions/implementations/security-automations-for-aws-waf/">Security Automations for AWS WAF</a></li>
<li>[SAP-2]  Security Section</li>
</ol>
]]></content>
      <categories>
        <category>云计算</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang内置类型-Map</title>
    <url>/www6vHomeHexo/2022/09/22/golangMap/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#map-%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0">Map 内部实现</a><br>- <a href="#map%E7%9A%84%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84">map的内部结构</a><br>- <a href="#map%E7%9A%84%E5%86%85%E9%83%A8%E5%87%BD%E6%95%B0-4">map的内部函数 [4]</a><br>- <a href="#%E6%89%A9%E5%AE%B9-2">扩容 [2]</a><br>- <a href="#%E6%89%A9%E5%AE%B9-4">扩容 [4]</a><br>- <a href="#map-%E8%A7%A3%E5%86%B3-hash-%E5%86%B2%E7%AA%81-3">map 解决 hash 冲突 [3]</a><br>- <a href="#%E7%BC%BA%E9%99%B7-4">缺陷 [4]</a></li>
<li><a href="#map%E7%9A%84%E4%BD%BF%E7%94%A8">map的使用</a><br>- <a href="#map%E7%9A%84%E4%BD%BF%E7%94%A8-1">map的使用</a><br>- <a href="#%E5%B9%B6%E5%8F%91">并发</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h2><span id="map-内部实现">Map 内部实现</span><a href="#map-内部实现" class="header-anchor">#</a></h2><img src="/www6vHomeHexo/2022/09/22/golangMap/golang-map.jpg" class title="Golang Map">

<h5><span id="map的内部结构">map的内部结构</span><a href="#map的内部结构" class="header-anchor">#</a></h5><ul>
<li>hmap<ul>
<li>bucket<ul>
<li>topHash<br><strong>快速定位key,以空间换时间</strong><br>每个 bucket 的 tophash 区域其实是用来快速定位 key 位置的. 这是一种以空间换时间的思路。</li>
<li>key</li>
<li>value<br>Go 运行时采用了<strong>把 key 和 value 分开存储的方式，而不是采用一个 kv 接着一个 kv 的 kv 紧邻方式存储</strong>，这带来的其实是算法上的复杂性，但却减少了因内存对齐带来的内存浪费。</li>
<li>overflow</li>
</ul>
</li>
</ul>
</li>
<li>bmap</li>
</ul>
<h5><span id="map的内部函数-4">map的内部函数 [4]</span><a href="#map的内部函数-4" class="header-anchor">#</a></h5><ul>
<li>mapassign 写</li>
<li>mapdelete 删</li>
<li>mapaccess 读</li>
</ul>
<h5><span id="扩容-2">扩容 [2]</span><a href="#扩容-2" class="header-anchor">#</a></h5><ul>
<li>buckets &amp;&amp; oldbuckets </li>
<li><strong>两种扩容方式 [渐进式扩容, 类似redis rehash]</strong><ul>
<li>因为 overflow bucket 过多导致的“扩容”，实际上运行时会新建一个和现有规模一样的 bucket 数组，然后在 assign 和 delete 时做排空和迁移。</li>
<li>因为当前数据数量超出 LoadFactor 指定水位而进行的扩容，那么运行时会建立一个两倍于现有规模的 bucket 数组，但真正的排空和迁移工作也是在 assign 和 delete 时逐步进行的。</li>
</ul>
</li>
</ul>
<h5><span id="扩容-4">扩容 [4]</span><a href="#扩容-4" class="header-anchor">#</a></h5><p>触发:  mapassign<br>时机: load factor 过大  OR overflow bucket 过多<br>搬运过程:  渐进式</p>
<ul>
<li>mapassign<ul>
<li>elem cout &gt; bucket*6.5  -&gt; bigger size grow</li>
<li>overflow too many  –&gt; same size grow <ul>
<li>noverflow &gt;&#x3D;2^15</li>
<li>nvoerflow &lt; 2^15 &amp;&amp; nvoerflow &gt; bucket count</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><span id="map-解决-hash-冲突-3">map 解决 hash 冲突 [3]</span><a href="#map-解决-hash-冲突-3" class="header-anchor">#</a></h5><p>在 map 解决 hash &#x2F;分桶 冲突问题时，实际上结合了拉链法和开放寻址法两种思路. 以 map 的插入写流程为例，进行思路阐述：<br>（1）桶数组中的每个桶，严格意义上是一个单向桶链表，以桶为节点进行串联；<br>（2）每个桶固定可以存放 8 个 key-value 对；<br>（3）当 key 命中一个桶时，首先根据开放寻址法，在桶的 8 个位置中寻找空位进行插入；<br>（4）倘若桶的 8 个位置都已被占满，则基于桶的溢出桶指针，找到下一个桶，重复第（3）步；<br>（5）倘若遍历到链表尾部，仍未找到空位，则基于拉链法，在桶链表尾部续接新桶，并插入 key-value 对.</p>
<h5><span id="缺陷-4">缺陷 [4]</span><a href="#缺陷-4" class="header-anchor">#</a></h5><ul>
<li>已经扩容的map, 无法 缩容</li>
<li>保证并发安全时, 要手动读写锁，易出错</li>
<li>多核心下表现差</li>
</ul>
<h2><span id="map的使用">map的使用</span><a href="#map的使用" class="header-anchor">#</a></h2><h5><span id="map的使用">map的使用</span><a href="#map的使用" class="header-anchor">#</a></h5><p>  value没有任何的限制, key有严格的限制</p>
<h5><span id="并发">并发</span><a href="#并发" class="header-anchor">#</a></h5><ul>
<li>不可以并发读写<br>可以并发读</li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li><a href="https://www.bilibili.com/video/BV1194y1o77s/?spm_id_from=pageDriver&vd_source=f6e8c1128f9f264c5ab8d9411a644036">Go面试题系列：Go map的底层实现原理</a></li>
<li>《16|复合数据类型：原始map类型的实现机制是这样的？》 TonyBai</li>
<li><a href="https://zhuanlan.zhihu.com/p/597483155">Golang map 实现原理</a></li>
<li>《09 神奇的内置数据结构》 V</li>
</ol>
]]></content>
      <categories>
        <category>Golang</category>
        <category>基础</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>用户画像</title>
    <url>/www6vHomeHexo/2022/09/21/personProflie/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F-3">用户画像 [3]</a></li>
<li><a href="#%E6%9E%B6%E6%9E%84-1">架构 [1]</a></li>
<li><a href="#%E7%94%A8%E6%88%B7%E6%A0%87%E7%AD%BE-2">用户标签 [2]</a><ul>
<li><a href="#%E5%9F%BA%E7%A1%80%E6%A0%87%E7%AD%BE-3">基础标签 [3]</a></li>
<li><a href="#%E8%A1%8C%E4%B8%BA%E6%A0%87%E7%AD%BE">行为标签</a></li>
<li><a href="#%E5%81%8F%E5%A5%BD%E6%A0%87%E7%AD%BE-3">偏好标签 [3]</a></li>
<li><a href="#%E9%A2%84%E6%B5%8B%E6%A0%87%E7%AD%BE">预测标签</a></li>
</ul>
</li>
<li><a href="#%E5%85%B3%E6%B3%A8%E7%82%B9">关注点</a><ul>
<li><a href="#%E6%A0%87%E7%AD%BE%E7%9A%84%E7%B2%92%E5%BA%A6-3">标签的粒度 [3]</a></li>
<li><a href="#%E9%9D%99%E6%80%81%E5%8A%A8%E6%80%81%E6%A0%87%E7%AD%BE-3">静态&#x2F;动态标签 [3]</a></li>
</ul>
</li>
<li><a href="#%E5%9C%88%E4%BA%BA-%E5%9F%BA%E4%BA%8E%E6%A0%87%E7%AD%BE%E8%81%9A%E7%B1%BB%E7%9A%84%E4%BA%BA%E7%BE%A4%E7%94%9F%E6%88%90-3">圈人-基于标签聚类的人群生成 [3]</a><ul>
<li><a href="#%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F">实现方式</a></li>
</ul>
</li>
<li><a href="#%E5%85%B3%E7%B3%BB%E5%BA%93-id-mapping-2">关系库 ID-Mapping [2]</a></li>
<li><a href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF3">应用场景[3]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="用户画像-3">用户画像 [3]</span><a href="#用户画像-3" class="header-anchor">#</a></h1><p>用户画像就是与该用户相关联的数据的可视化的展现，一句话来总结就是<strong>用户信息标签化</strong>.</p>
<p>这些标签的来源就是一些<strong>用户的行为</strong>.</p>
<h1><span id="架构-1">架构 [1]</span><a href="#架构-1" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/09/21/personProflie/process.jpg" class>

<img src="/www6vHomeHexo/2022/09/21/personProflie/arch.jpg" class>


<h1><span id="用户标签-2">用户标签 [2]</span><a href="#用户标签-2" class="header-anchor">#</a></h1><h3><span id="基础标签-3">基础标签 [3]</span><a href="#基础标签-3" class="header-anchor">#</a></h3><ul>
<li>人口属性<br>性别 年龄 职业 等</li>
<li>购买能力<br>收入及购买能力、购买频次和渠道</li>
<li>用户等级<br>高级会员<br>VIP会员</li>
<li>上课情况<ul>
<li>下粉批次</li>
<li>直播间类型</li>
<li>完课率</li>
<li>听课阶段</li>
</ul>
</li>
</ul>
<h3><span id="行为标签">行为标签</span><a href="#行为标签" class="header-anchor">#</a></h3><ul>
<li><p>绑定手机号</p>
</li>
<li><p>添加微信</p>
</li>
<li><p>删除微信</p>
</li>
<li><p>回复问候</p>
</li>
<li><p>下载软件</p>
</li>
<li><p>购买课程</p>
<ul>
<li>购买9.9直播</li>
<li>接听dayN直播报名电话</li>
<li>报名dayN直播</li>
<li>进入dayN直播间</li>
<li>观看dayN预习视频</li>
<li>回复dayN预习作业</li>
<li>回复dayN作业</li>
<li>购买高级会员</li>
<li>购买VIP</li>
</ul>
</li>
</ul>
<h3><span id="偏好标签-3">偏好标签 [3]</span><a href="#偏好标签-3" class="header-anchor">#</a></h3><ul>
<li><p>时间偏好<br>PC端活跃时间<br>App端活跃时间<br>Web端活跃时间</p>
</li>
<li><p>渠道偏好<br>常用PC端<br>常用App端<br>常用Web端</p>
</li>
<li><p>板块关注偏好<br>科技类<br>汽车类<br>电力能源</p>
</li>
<li><p>消费需求<br>消费习惯和消费偏好</p>
</li>
<li><p>风险偏好</p>
</li>
</ul>
<h3><span id="预测标签">预测标签</span><a href="#预测标签" class="header-anchor">#</a></h3><h1><span id="关注点">关注点</span><a href="#关注点" class="header-anchor">#</a></h1><h3><span id="标签的粒度-3">标签的粒度 [3]</span><a href="#标签的粒度-3" class="header-anchor">#</a></h3><p>比如年龄标签是20-30岁和21岁，就是明显不同粒度的标签<br>比如活跃时间是白天或者晚上和下午3点，就是明显不同粒度的标签</p>
<h3><span id="静态x2f动态标签-3">静态&#x2F;动态标签 [3]</span><a href="#静态x2f动态标签-3" class="header-anchor">#</a></h3><ul>
<li><p>静态标签<br>性别、年龄、地域、收入 相对是静态标签</p>
</li>
<li><p>动态标签<br>用户访问设备、用户的48小时是否活跃、内容访问偏好、消费偏好等属于时常在发生变动的，这些动态特征可以变成动态标签</p>
</li>
</ul>
<h1><span id="圈人-基于标签聚类的人群生成-3">圈人-基于标签聚类的人群生成 [3]</span><a href="#圈人-基于标签聚类的人群生成-3" class="header-anchor">#</a></h1><h3><span id="实现方式">实现方式</span><a href="#实现方式" class="header-anchor">#</a></h3><ul>
<li>按维度(n天内)加权汇总某类主题和实体(买家)在某种对象(课程)上的相关行为(点击 买课)，然后归一化到[0,1]之间，取TopN或全部输出。</li>
<li>调整的可以是维度（天数）, 实体（买家），对象（课程）， 行为(点击 买课)，权重等。</li>
</ul>
<h1><span id="关系库-id-mapping-2">关系库 ID-Mapping [2]</span><a href="#关系库-id-mapping-2" class="header-anchor">#</a></h1><ul>
<li><p>关系库主要是 IDMapping<br>IDMapping主要指用户设备的打通，用于识别用户的唯一性</p>
</li>
<li><p>ID-Mapping的存储<br>JanusGraph</p>
</li>
</ul>
<h1><span id="应用场景3">应用场景[3]</span><a href="#应用场景3" class="header-anchor">#</a></h1><ul>
<li>精细化运营</li>
<li>商业分析</li>
<li>搜索</li>
<li>精准广告营销<br>人群圈选，做定向投放</li>
<li>个性化推荐<br>千人千面</li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&mid=2247499260&idx=2&sn=5c6f1fb40cd90edd63ea7974284af09b">日处理数据量超10亿：友信金服基于Flink构建实时用户画像系统的实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/jyiDWiK0zczEaZKY5Hy5xg">网易大数据用户画像实践 </a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247500642&idx=1&sn=15b22586962cee5c58bb58d898c9a465">用户画像技术及方法论</a> ***</li>
<li><a href="https://zhuanlan.zhihu.com/p/466822319">实战案例：手把手教你构建电商用户画像(附代码）</a> 未</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>用户画像</category>
      </categories>
      <tags>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title>用户行为分析</title>
    <url>/www6vHomeHexo/2022/09/15/userBehaviorAnalysis/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%9E%B6%E6%9E%84-5">架构 [5]</a></li>
<li><a href="#%E5%AE%8C%E6%95%B4%E9%93%BE%E8%B7%AF-4">完整链路 [4]</a></li>
<li><a href="#%E6%8C%87%E6%A0%87-2">指标 [2]</a><ul>
<li><a href="#%E7%B2%98%E6%80%A7%E6%8C%87%E6%A0%87">粘性指标</a></li>
<li><a href="#%E6%B4%BB%E8%B7%83%E6%8C%87%E6%A0%87">活跃指标</a></li>
<li><a href="#%E4%BA%A7%E5%87%BA%E6%8C%87%E6%A0%87">产出指标</a></li>
</ul>
</li>
<li><a href="#%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90">用户行为分析</a><ul>
<li><a href="#%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95-1-2-4-6">常用方法 [1] [2] [4] [6]</a></li>
</ul>
</li>
<li><a href="#%E6%BC%8F%E6%96%97%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90">漏斗模型分析</a><ul>
<li><a href="#%E9%9C%80%E6%B1%82%E5%9C%BA%E6%99%AF-9">需求场景 [9]</a></li>
<li><a href="#%E6%BC%8F%E6%96%97%E7%B1%BB%E5%9E%8B">漏斗类型</a></li>
<li><a href="#%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B">整体流程</a></li>
<li><a href="#aarrr%E6%BC%8F%E6%96%97%E6%A8%A1%E5%9E%8B-1-3">AARRR漏斗模型 [1] [3]</a></li>
</ul>
</li>
<li><a href="#%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90">路径分析</a><ul>
<li><a href="#%E8%BD%AC%E5%8C%96%E7%8E%87%E8%AE%A1%E7%AE%97">转化率计算</a></li>
</ul>
</li>
<li><a href="#%E9%87%87%E9%9B%86%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE-2">采集用户行为数据 [2]</a><ul>
<li><a href="#%E5%B9%B3%E5%8F%B0%E8%AE%BE%E7%BD%AE%E5%9F%8B%E7%82%B9-6-10">平台设置埋点 [6] [10]</a></li>
<li><a href="#%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BB%9F%E8%AE%A1%E5%B7%A5%E5%85%B7">第三方统计工具</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>



<h1><span id="架构-5">架构 [5]</span><a href="#架构-5" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/09/15/userBehaviorAnalysis/arch.jpg" class>

<p>图中底层蓝色的部分是数据处理计算部分，依托于存储与计算分离的特性以及预计算能力， 很好地满足在海量数据场景下的数据高效计算能力。同时提供了完善的企业级平台运维处理能力，支持多种架构满足各类客户的场景需求。</p>
<p>往上，通过多维数据模型框架，对用户基础数据进行语义分类和转化，提供多种维度分类的数据主题模型。基于这些数据主题模型，就可以直接对接应用分析端进行常用的事件分析，漏斗分析，留存分析。</p>
<h1><span id="完整链路-4">完整链路 [4]</span><a href="#完整链路-4" class="header-anchor">#</a></h1><img src="/www6vHomeHexo/2022/09/15/userBehaviorAnalysis/flow.jpg" class>

<p>埋点 -&gt; 使用app -&gt; 数据上报 -&gt; 数据模型 -&gt; 行为分析 </p>
<h1><span id="指标-2">指标 [2]</span><a href="#指标-2" class="header-anchor">#</a></h1><h3><span id="粘性指标">粘性指标</span><a href="#粘性指标" class="header-anchor">#</a></h3><ul>
<li>关注用户周期内持续访问的情况<br>新用户数与比例、活跃用户数与比例、用户转化率、用户留存率、用户流失率、用户访问率</li>
</ul>
<h3><span id="活跃指标">活跃指标</span><a href="#活跃指标" class="header-anchor">#</a></h3><ul>
<li>用户访问的参与度<br>活跃用户、新增用户、回访用户、流失用户、平均停留时长、使用频率</li>
</ul>
<h3><span id="产出指标">产出指标</span><a href="#产出指标" class="header-anchor">#</a></h3><ul>
<li>用户创造的直接价值输出<br>页面浏览数PV、独立访客数UV、点击次数、消费频次、消费金额</li>
</ul>
<h1><span id="用户行为分析">用户行为分析</span><a href="#用户行为分析" class="header-anchor">#</a></h1><h3><span id="常用方法-1-2-4-6">常用方法 [1] [2] [4] [6]</span><a href="#常用方法-1-2-4-6" class="header-anchor">#</a></h3><ul>
<li><p>动作分析</p>
<ul>
<li>行为事件分析</li>
<li>页面点击分析</li>
</ul>
</li>
<li><p>转化分析</p>
<ul>
<li><strong>漏斗模型分析</strong> [7] [9]</li>
<li><strong>用户行为路径分析</strong> [7][11]</li>
</ul>
</li>
<li><p>用户分析</p>
<ul>
<li><strong>用户留存分析</strong> [7] [8]</li>
<li><strong>用户分群分析</strong><br>用户画像（基本属性、用户偏好、生活习惯、用户行为等）的标签信息将用户分群</li>
</ul>
</li>
<li><p>福格模型分析</p>
</li>
</ul>
<img src="/www6vHomeHexo/2022/09/15/userBehaviorAnalysis/application.jpg" class>


<h1><span id="漏斗模型分析">漏斗模型分析</span><a href="#漏斗模型分析" class="header-anchor">#</a></h1><h3><span id="需求场景-9">需求场景 [9]</span><a href="#需求场景-9" class="header-anchor">#</a></h3><p>定位用户流失具体原因</p>
<p>针对不同版本，转化率情况对比</p>
<p>检测某个专题活动效果</p>
<h3><span id="漏斗类型">漏斗类型</span><a href="#漏斗类型" class="header-anchor">#</a></h3><p>无序漏斗：在漏斗的周期内，不限定漏斗多个步骤之间事件发生的顺序。<br>有序漏斗：在漏斗的周期内，严格限定漏斗每个步骤之间的发生顺序。</p>
<h3><span id="整体流程">整体流程</span><a href="#整体流程" class="header-anchor">#</a></h3><ul>
<li>确定转化路径</li>
<li>分析流失原因</li>
<li>优化关键因子</li>
</ul>
<h3><span id="aarrr漏斗模型-1-3">AARRR漏斗模型 [1] [3]</span><a href="#aarrr漏斗模型-1-3" class="header-anchor">#</a></h3><ul>
<li>实现用户增长的5个指标<ul>
<li>Acquisition（获取）：指的是用户从各种渠道进入产品的过程。</li>
<li>Activation（激活）：指的是用户开始使用产品，并完成核心操作的过程。</li>
<li>Retention（留存）：指的是用户在完成激活后，继续使用产品，并形成一定程度的用户粘性。</li>
<li>Revenue（收入）：指的是用户在使用产品后，产生的实际收益。</li>
<li>Referral（自传播）：指的是用户在使用产品后，愿意将产品推荐给他人，形成口碑和自然增长。</li>
</ul>
</li>
</ul>
<h1><span id="路径分析">路径分析</span><a href="#路径分析" class="header-anchor">#</a></h1><h3><span id="转化率计算">转化率计算</span><a href="#转化率计算" class="header-anchor">#</a></h3><p>页面转化率<br>路径转化率</p>
<h1><span id="采集用户行为数据-2">采集用户行为数据 [2]</span><a href="#采集用户行为数据-2" class="header-anchor">#</a></h1><h3><span id="平台设置埋点-6-10">平台设置埋点 [6] [10]</span><a href="#平台设置埋点-6-10" class="header-anchor">#</a></h3><h3><span id="第三方统计工具">第三方统计工具</span><a href="#第三方统计工具" class="header-anchor">#</a></h3><p>国内： 百度统计,  CNZZ统计,  GrowingIO,  诸葛IO,  神策IO,  友盟<br>国外：Google Analytics,   Thinking Analytics, Mixpanel, Heap </p>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><a href="https://blog.csdn.net/Sake360/article/details/120350080">用户行为分析</a></li>
<li><a href="https://baijiahao.baidu.com/s?id=1653670195355016641&wfr=spider&for=pc">用户研究：如何做用户行为分析？</a></li>
<li><a href="https://blog.csdn.net/WindyQCF/article/details/123911538">万字详解用户行为分析</a></li>
<li><a href="https://baijiahao.baidu.com/s?id=1663323869315685791&wfr=spider&for=pc">用户行为分析是什么？怎么做？</a></li>
<li><a href="https://www.infoq.cn/article/xZYe1DUopNA9CzLwau3O">数十亿用户数据，上千个用户标签维度，用户分析怎么做？</a> ***<br><a href="https://mp.weixin.qq.com/s?__biz=MzIyNTIyNTYwOA==&mid=2651010996&idx=1&sn=f7ba207a991d595036a11fc3b6797bac">活动回顾 | 数十亿用户数据，上千个用户标签维度，用户分析怎么做？</a>  kylin</li>
<li><a href="https://www.infoq.cn/article/yGOh38XjpYdTKMJjzjoH">如何实现用户行为的动态采集与分析</a></li>
<li><a href="https://www.infoq.cn/article/ecmRgdfrjFl1U3hAd59b">如何基于 Apache Doris 构建简易高效的用户行为分析平台？</a><br><a href="https://www.infoq.cn/article/SoCIclCLD8f4vSzLB4dX">如何基于 Apache Doris 构建简易高效的用户行为分析平台？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI4NjY4MTU5Nw==&mid=2247490504&idx=1&sn=9827b136fa5cfc81467cb1b795f7bc41">用户行为分析模型实践（一）—— 路径分析模型</a>  vivo</li>
<li><a href="https://xie.infoq.cn/article/f305ea8be1935540432aca0d0">用户行为分析模型实践（二）—— 漏斗分析模型</a>  vivo</li>
<li><a href="https://xie.infoq.cn/article/1163e5781f37b4e55a2c43c70">用户行为分析模型实践（三）——H5 通用分析模型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&mid=2247486360&idx=1&sn=85504543498dfc82e5e720b77faa602d">基于Spark的用户行为路径分析的产品化实践</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/146639831">【分析框架】用户行为分析</a> *** 未</li>
<li><a href="https://zhuanlan.zhihu.com/p/133962465">淘宝用户行为分析（附Python源码）</a> *** 未</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>用户行为分析</category>
      </categories>
      <tags>
        <tag>用户行为分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang 学习资源</title>
    <url>/www6vHomeHexo/2022/09/09/golangStudy/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="golang">Golang</span><a href="#golang" class="header-anchor">#</a></h2><ul>
<li><p>基础</p>
<ul>
<li>极客时间 《Go 并发编程实战课》  鸟窝  ***</li>
<li>极客时间 《Go语言从入门到实战》 好像看过 ***</li>
<li>极客时间 《Go 语言核心 36 讲》 郝林 **</li>
<li>《Effective Go》<br><a href="https://golang.google.cn/doc/effective_go">Effective Go</a>  英文<br><a href="https://learnku.com/docs/effective-go/2020">高效的 Go 编程 Effective Go</a> 中文<br><a href="https://makeoptim.com/golang/effective-go">golang 编程规范 - Effective Go 中文</a> 中文</li>
<li>50 Shades of Go<br><a href="http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/">50 Shades of Go: Traps, Gotchas, and Common Mistakes for New Golang Devs</a><br><a href="https://github.com/wuYin/blog/blob/master/golang/50-shades-of-golang-traps-gotchas-mistakes.md">Golang 新手可能会踩的 50 个坑</a></li>
</ul>
</li>
<li><p>项目&amp;进阶       </p>
<ul>
<li>极客时间 《Go 语言项目开发实战》  孔令飞@腾讯  ***</li>
<li>极客训练营 《go进阶训练营 第4期》 bili V 毛剑  ***</li>
</ul>
</li>
<li><p><a href="https://talkgo.org/">gotalk</a></p>
<ul>
<li><a href="https://github.com/talkgo/night">talkgo @github</a></li>
</ul>
</li>
<li><p>Mix<br> <a href="https://github.com/0voice/Introduction-to-Golang/tree/main/Golang%20PPT">0voice&#x2F;Introduction-to-Golang</a>  *** </p>
</li>
<li><p>Go 源码分析<br><a href="https://github.com/cch123/golang-notes">Go source code analysis(zh-cn) </a>  曹大 滴滴 *** </p>
</li>
<li><p>book<br><a href="https://github.com/gopl-zh/gopl-zh.github.com">Go语言圣经中文版</a><br><a href="https://gopl-zh.github.io/">Go语言圣经（中文版）</a><br><a href="https://chai2010.cn/advanced-go-programming-book/">Go语言高级编程(Advanced Go Programming)</a></p>
</li>
</ul>
<h2><span id="golang-个人blog">Golang 个人blog</span><a href="#golang-个人blog" class="header-anchor">#</a></h2><ul>
<li><a href="https://tonybai.com/">Tony Bai</a> golang大神 ***</li>
<li><a href>鸟窝</a> Java， golang  微博架构师 ***</li>
<li><a href="http://luodw.cc/">罗道文</a>  golang python NSQ 有深度  * 2017 停更</li>
<li><a href="https://www.jianshu.com/u/1381dc29fed9">张晓龙</a>  golang *</li>
</ul>
<h2><span id="学习路线">学习路线</span><a href="#学习路线" class="header-anchor">#</a></h2><ul>
<li>学习路线<ul>
<li><a href="https://www.bilibili.com/video/BV1YY4y1g7RU?vd_source=f6e8c1128f9f264c5ab8d9411a644036">【上集】2022 年 Go 语言最全学习路线：十分钟带你过思维导图！</a></li>
<li><a href="https://www.bilibili.com/video/BV1DZ4y1q78E/?vd_source=f6e8c1128f9f264c5ab8d9411a644036">【下集】2022 年 Go 语言最全学习路线：十分钟带你过思维导图！爆肝几天几夜整理的超详细 Go 学习</a></li>
<li><a href="https://maiyang.me/">作者blog</a></li>
</ul>
</li>
<li><a href="https://www.golangroadmap.com/class/gointerview/">GOLANG ROADMAP</a> ***<br><a href="https://www.golangroadmap.com/">GOLANG ROADMAP</a><br>邀请码：caspar</li>
</ul>
]]></content>
      <categories>
        <category>Golang</category>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据 调度</title>
    <url>/www6vHomeHexo/2022/09/08/bigDataSchedule/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<ul>
<li><p>Airflow</p>
</li>
<li><p>DolphinScheduler</p>
</li>
<li><p>Azkaban</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>计算</category>
        <category>调度</category>
      </categories>
      <tags>
        <tag>调度</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据 元数据管理</title>
    <url>/www6vHomeHexo/2022/09/08/bigDataMetaMgt/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<ul>
<li><p>Apache  Atlas<br>HortonWorks<br>管理Hadoop项目里面的元数据</p>
</li>
<li><p>datahub<br>Linkedin开源<br>The Metadata Platform for the Modern Data Stack</p>
</li>
<li><p>Amundsen<br>Lyft 开源<br>致力于成为现代数据栈中的数据目录产品</p>
</li>
<li><p>Metacat<br>Netflix开源</p>
</li>
<li><p>OpenMetadata</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>存储</category>
        <category>元数据</category>
      </categories>
      <tags>
        <tag>元数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Clickhouse</title>
    <url>/www6vHomeHexo/2022/09/07/clickhouse/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%89%B9%E6%80%A7">特性</a></li>
<li><a href="#%E9%99%90%E5%88%B6">限制</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%95%E6%93%8E">数据库引擎</a></li>
<li><a href="#%E8%A1%A8%E5%BC%95%E6%93%8E">表引擎</a><ul>
<li><a href="#mergetree">MergeTree</a></li>
<li><a href="#%E6%97%A5%E5%BF%97">日志</a></li>
<li><a href="#%E9%9B%86%E6%88%90%E5%BC%95%E6%93%8E">集成引擎</a></li>
<li><a href="#%E7%94%A8%E4%BA%8E%E5%85%B6%E4%BB%96%E7%89%B9%E5%AE%9A%E5%8A%9F%E8%83%BD%E7%9A%84%E5%BC%95%E6%93%8E">用于其他特定功能的引擎</a></li>
</ul>
</li>
<li><a href="#%E7%B4%A2%E5%BC%95">索引</a><ul>
<li><a href="#%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95-3">主键索引 [3]</a></li>
<li><a href="#%E7%A8%80%E7%96%8F%E7%B4%A2%E5%BC%95-4">稀疏索引 [4]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="特性">特性</span><a href="#特性" class="header-anchor">#</a></h1><ul>
<li>列式数据库</li>
<li>数据压缩</li>
<li>支持SQL</li>
<li>向量引擎</li>
<li>实时的数据更新<br>使查询能够快速在主键中进行范围查找, 以增量的方式有序的存储在MergeTree中</li>
<li>索引<br>按照主键对数据进行排序，对数据特定值或范围的查找。</li>
<li>支持近似计算</li>
<li>支持数据复制和数据完整性<br>副本， 故障后自动恢复</li>
</ul>
<h1><span id="限制">限制</span><a href="#限制" class="header-anchor">#</a></h1><ul>
<li>没有完整的事务支持。</li>
<li>稀疏索引使得ClickHouse不适合通过其键检索单行的点查询</li>
</ul>
<h1><span id="数据库引擎">数据库引擎</span><a href="#数据库引擎" class="header-anchor">#</a></h1><p>默认情况下，ClickHouse使用<strong>Atomic</strong>数据库引擎</p>
<ul>
<li><a href="https://clickhouse.com/docs/zh/engines/database-engines/mysql">MySQL</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/database-engines/materialized-mysql">MaterializeMySQL</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/database-engines/lazy">Lazy</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/database-engines/atomic">Atomic</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/database-engines/postgresql">PostgreSQL</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/database-engines/materialized-postgresql">MaterializedPostgreSQL</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/database-engines/replicated">Replicated</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/database-engines/sqlite">SQLite</a></li>
</ul>
<h1><span id="表引擎">表引擎</span><a href="#表引擎" class="header-anchor">#</a></h1><h2><span id="mergetree">MergeTree</span><a href="#mergetree" class="header-anchor">#</a></h2><ul>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/mergetree#mergetree">MergeTree</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/replacingmergetree#replacingmergetree">ReplacingMergeTree</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/summingmergetree#summingmergetree">SummingMergeTree</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/aggregatingmergetree#aggregatingmergetree">AggregatingMergeTree</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/collapsingmergetree#table_engine-collapsingmergetree">CollapsingMergeTree</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/versionedcollapsingmergetree#versionedcollapsingmergetree">VersionedCollapsingMergeTree</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/graphitemergetree#graphitemergetree">GraphiteMergeTree</a></li>
</ul>
<h2><span id="日志">日志</span><a href="#日志" class="header-anchor">#</a></h2><ul>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/log-family/tinylog#tinylog">TinyLog</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/log-family/stripelog#stripelog">StripeLog</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/log-family/log#log">Log</a></li>
</ul>
<h2><span id="集成引擎">集成引擎</span><a href="#集成引擎" class="header-anchor">#</a></h2><ul>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/integrations/kafka#kafka">Kafka</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/integrations/mysql#mysql">MySQL</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/integrations/odbc#table-engine-odbc">ODBC</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/integrations/jdbc#table-engine-jdbc">JDBC</a></li>
<li><a href="https://clickhouse.com/docs/zh/engines/table-engines/integrations/hdfs#hdfs">HDFS</a></li>
</ul>
<h2><span id="用于其他特定功能的引擎">用于其他特定功能的引擎</span><a href="#用于其他特定功能的引擎" class="header-anchor">#</a></h2><ul>
<li><p><a href="https://clickhouse.com/docs/zh/engines/table-engines/special/distributed#distributed">Distributed</a></p>
</li>
<li><p><a href="https://clickhouse.com/docs/zh/engines/table-engines/special/materializedview#materializedview">MaterializedView</a></p>
</li>
</ul>
<h1><span id="索引">索引</span><a href="#索引" class="header-anchor">#</a></h1><h2><span id="主键索引-3">主键索引 [3]</span><a href="#主键索引-3" class="header-anchor">#</a></h2><h2><span id="稀疏索引-4">稀疏索引 [4]</span><a href="#稀疏索引-4" class="header-anchor">#</a></h2><h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://clickhouse.com/docs/zh/engines/database-engines">数据库引擎</a></p>
</li>
<li><p><a href="https://clickhouse.com/docs/zh/engines/table-engines">表引擎</a></p>
</li>
<li><p><a href="https://clickhouse.com/docs/zh/guides/best-practices">ClickHouse主键索引最佳实践</a></p>
</li>
<li><p><a href="https://clickhouse.com/docs/zh/guides/improving-query-performance/skipping-indexes">深入理解ClickHouse跳数索引</a></p>
</li>
<li><p><a href="https://blog.csdn.net/wmq880204/article/details/124224992">ClickHouse 深度解析第二篇</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/98135840">ClickHouse深度揭秘</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>存储</category>
        <category>Clickhouse</category>
      </categories>
      <tags>
        <tag>Clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>Iceberg</title>
    <url>/www6vHomeHexo/2022/09/01/iceberg/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="特性-1-2">特性 [1] [2]</span><a href="#特性-1-2" class="header-anchor">#</a></h2><ul>
<li><p>基于快照的读写分离和回溯</p>
<ul>
<li><strong>快照控制</strong>：可实现使用完全相同的表快照的可重复查询，或者使用户轻松检查更改</li>
<li><strong>Time Travel</strong> </li>
<li><strong>行级更新</strong>  [4]<br>V1版本-Copy On Write（COW）模式<br>V2版本-Copy On Write，还增加了Merge On Read（MOR）</li>
</ul>
</li>
<li><p>流批统一的写入和读取</p>
<ul>
<li>兼容性好：可以存储在任意的云存储系统和HDFS中</li>
<li>快速扫描数据：无需使用分布式SQL引擎即可读取表或查找文件</li>
<li>数据修剪优化：使用表元数据使用分区和列级统计信息修剪数据文件</li>
</ul>
</li>
<li><p>ACID 语义及数据多版本</p>
<ul>
<li>支持<strong>事务</strong>：序列化隔离,表更改是原子性的，读者永远不会看到部分更改或未提交的更改</li>
<li>高并发：<strong>高并发写入</strong>器使用乐观并发，即使写入冲突，也会重试以确保兼容更新成功</li>
<li><strong>版本回滚 Version rollback</strong>：使用户可以通过将表重置为良好状态来快速纠正问题</li>
</ul>
</li>
<li><p>表, 模式及分区的变更</p>
<ul>
<li><strong>模式演化 Schema evolution</strong>：支持添加，删除，更新或重命名，并且没有副作用</li>
<li><strong>隐藏分区 Hidden Partition</strong>：可以防止导致错误提示或非常慢查询的用户错误</li>
<li><strong>分区布局演变 Partition layout evolution</strong>：可以随着数据量或查询模式的变化而更新表的布局</li>
</ul>
</li>
<li><p>不强绑定计算存储引擎</p>
</li>
</ul>
<h2><span id="整体架构-3">整体架构 [3]</span><a href="#整体架构-3" class="header-anchor">#</a></h2><ul>
<li>数据<br>普通的 Parquet 文件</li>
<li>元数据<ul>
<li>catalog<br>version-hint.txt 文件 	</li>
<li>metadata file<br>json 文件</li>
<li>manifestlist file  [snapshot]<br>以 snap- 开头的 avro 文件	</li>
<li>manifest file<br>16db143c,18ce4c4a 开头的 avro 文件</li>
</ul>
</li>
</ul>
<h2><span id="读写过程">读写过程</span><a href="#读写过程" class="header-anchor">#</a></h2><ul>
<li>读写</li>
<li>增量读</li>
<li>实时小文件合并</li>
</ul>
<h2><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/347660549">Flink + Iceberg 全场景实时数仓的建设实践</a>  腾讯数据平台</li>
<li><a href="https://cloud.tencent.com/developer/article/2290397">5分钟入门数据湖IceBerg</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/488467438">Iceberg 原理分析</a></li>
<li><a href="https://z.itpub.net/article/detail/7B5B8C89CC5244F94A0C5FDF7DC83DFB">数据湖Iceberg技术在小米的落地与场景应用</a></li>
</ol>
<p><a href="https://zhuanlan.zhihu.com/p/636273850">Iceberg实时湖仓数据分析性能优化</a><br><a href="https://blog.csdn.net/weixin_46399686/article/details/131308217">火山引擎 Iceberg 数据湖的应用与实践</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&mid=2247562593&idx=2&sn=a41a5202c21118b1f17619a80eff651f">陈梁：腾讯数据湖查询优化实践 </a></p>
<p><a href="https://zhuanlan.zhihu.com/p/110748218">深度对比delta、iceberg和hudi三大开源数据湖方案</a>  ***<br><a href="https://baijiahao.baidu.com/s?id=1776240000826938540&wfr=spider&for=pc">Apache Iceberg 在严选批流一体的实践</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>存储</category>
        <category>Iceberg</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>语言 学习资源</title>
    <url>/www6vHomeHexo/2022/08/25/languageStudy/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="rust">Rust</span><a href="#rust" class="header-anchor">#</a></h2><ul>
<li>极客时间 《Rust 编程第一课》  陈天</li>
<li>极客时间 《张汉东的Rust实战课》 视频课</li>
</ul>
<h2><span id="python">Python</span><a href="#python" class="header-anchor">#</a></h2><ul>
<li>极客时间 《零基础学Python》  视频课</li>
<li>极客时间 《Python 自动化办公实战课》</li>
<li>极客时间 《Python核心技术与实战》</li>
<li>极客训练营  《Python进阶训练营 第5期》</li>
</ul>
]]></content>
      <categories>
        <category>语言</category>
        <category>学习资源</category>
      </categories>
      <tags>
        <tag>学习资源</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 主从延迟</title>
    <url>/www6vHomeHexo/2022/08/16/mysqlMasterSlaveDelay/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%A1%88%E4%BE%8B-1">案例 [1]</a><ul>
<li><a href="#%E6%A1%88%E4%BE%8B%E4%B8%80%E4%B8%BB%E5%BA%93dml%E8%AF%B7%E6%B1%82%E9%A2%91%E7%B9%81">案例一：主库DML请求频繁</a></li>
<li><a href="#%E6%A1%88%E4%BE%8B%E4%BA%8C%E4%B8%BB%E5%BA%93%E6%89%A7%E8%A1%8C%E5%A4%A7%E4%BA%8B%E5%8A%A1">案例二：主库执行大事务</a></li>
<li><a href="#%E6%A1%88%E4%BE%8B%E4%B8%89%E4%B8%BB%E5%BA%93%E5%AF%B9%E5%A4%A7%E8%A1%A8%E6%89%A7%E8%A1%8Cddl%E8%AF%AD%E5%8F%A5">案例三：主库对大表执行DDL语句</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="案例-1">案例 [1]</span><a href="#案例-1" class="header-anchor">#</a></h1><h3><span id="案例一主库dml请求频繁">案例一：主库DML请求频繁</span><a href="#案例一主库dml请求频繁" class="header-anchor">#</a></h3><ul>
<li>解决思路<ul>
<li>如果是MySQL 5.7以下的版本，可以做**分片(sharding)**，通过水平扩展(scale out)的方法打散写请求，提升写请求写入binlog的并行度。</li>
<li>MySQL 5.7以上的版本，<ul>
<li>在MySQL 5.7，使用了<strong>基于逻辑时钟(Group Commit)的并行复制</strong>。</li>
<li>而在MySQL 8.0，使用了<strong>基于Write Set的并行复制</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="案例二主库执行大事务">案例二：主库执行大事务</span><a href="#案例二主库执行大事务" class="header-anchor">#</a></h3><ul>
<li>解决思路<br><strong>拆分大事务语句到若干小事务中</strong>，这样能够进行及时提交，减小主从复制延时。</li>
</u