<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AI åº”ç”¨åœºæ™¯</title>
    <url>/www6vHomeAIGC/2021/08/11/ai/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#overview-1">Overview [1]</a></li>
<li><a href="#%E5%BA%94%E7%94%A8%E4%B8%8E%E8%A1%8C%E4%B8%9A-2">åº”ç”¨ä¸è¡Œä¸š [2]</a></li>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-4">è®¡ç®—æœºè§†è§‰ [4]</a><br>- <a href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF">åº”ç”¨åœºæ™¯</a></li>
<li><a href="#%E8%AF%AD%E9%9F%B3%E6%8A%80%E6%9C%AF-4">è¯­éŸ³æŠ€æœ¯ [4]</a><br>- <a href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-1">åº”ç”¨åœºæ™¯</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-4">è‡ªç„¶è¯­è¨€å¤„ç† [4]</a><br>- <a href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-2">åº”ç”¨åœºæ™¯</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">æ€»ç»“</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h2><span id="overview-1">Overview [1]</span><a href="#overview-1" class="header-anchor">#</a></h2><img src="/www6vHomeAIGC/2021/08/11/ai/ai.png" class title="AI">

<ul>
<li>äººå·¥æ™ºèƒ½çš„ä¸‰ä¸ªå±‚é¢<ul>
<li>è®¡ç®—æ™ºèƒ½<br>èƒ½ç®—èƒ½å­˜</li>
<li>æ„ŸçŸ¥æ™ºèƒ½<br>èƒ½å¬ä¼šè¯´ï¼Œ èƒ½çœ‹ä¼šè®¤</li>
<li>è®¤çŸ¥æ™ºèƒ½<br>èƒ½ç†è§£ï¼Œä¼šæ€è€ƒ</li>
</ul>
</li>
</ul>
<h2><span id="åº”ç”¨ä¸è¡Œä¸š-2">åº”ç”¨ä¸è¡Œä¸š [2]</span><a href="#åº”ç”¨ä¸è¡Œä¸š-2" class="header-anchor">#</a></h2><ul>
<li>å¥åº·ç <img src="/www6vHomeAIGC/2021/08/11/ai/ai-hangye.png" class title="è¡Œä¸š"></li>
</ul>
<h2><span id="è®¡ç®—æœºè§†è§‰-4">è®¡ç®—æœºè§†è§‰ [4]</span><a href="#è®¡ç®—æœºè§†è§‰-4" class="header-anchor">#</a></h2><h5><span id="åº”ç”¨åœºæ™¯">åº”ç”¨åœºæ™¯</span><a href="#åº”ç”¨åœºæ™¯" class="header-anchor">#</a></h5><ul>
<li>å›¾åƒåˆ†ç±»<ul>
<li>è®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒé—®é¢˜<ul>
<li>ç»†ç²’åº¦å›¾åƒåˆ†ç±»</li>
</ul>
</li>
<li>äººè„¸è¯†åˆ«<ul>
<li>èº«ä»½ç¡®è®¤</li>
<li>èº«ä»½æŸ¥æ‰¾</li>
</ul>
</li>
</ul>
</li>
<li>å›¾åƒé‡å»º</li>
<li>ç›®æ ‡æ£€æµ‹<ul>
<li>ç‰©ä½“å®šä½</li>
<li>çƒ­é—¨æ–¹å‘ï¼Œé¢†åŸŸ<ul>
<li>åœ¨æ— äººé©¾é©¶é¢†åŸŸå¾ˆé‡è¦</li>
<li>æœºå™¨äººå¯¼èˆª</li>
<li>æ™ºèƒ½è§†é¢‘ç›‘æ§</li>
<li>å·¥ä¸šæ£€æŸ¥</li>
</ul>
</li>
<li>å…³é”®é—®é¢˜<ul>
<li>å°ç›®æ ‡ é«˜ç²¾åº¦æ£€æµ‹</li>
<li>å¤šç±»åˆ«ç‰©ä½“æ£€æµ‹</li>
</ul>
</li>
</ul>
</li>
<li>å›¾åƒæœç´¢</li>
<li>å›¾åƒåˆ†å‰²<ul>
<li>æ ¸å¿ƒé—®é¢˜</li>
<li>ä¸‰ç±»(é€å±‚é€’è¿›)<ul>
<li>è¯­ä¹‰åˆ†å‰²</li>
<li>å®ä¾‹åˆ†å‰²</li>
<li>å…¨æ™¯åˆ†å‰²</li>
</ul>
</li>
<li>åº”ç”¨åœºæ™¯</li>
</ul>
</li>
<li>ç›®æ ‡è·Ÿè¸ª</li>
</ul>
<h2><span id="è¯­éŸ³æŠ€æœ¯-4">è¯­éŸ³æŠ€æœ¯ [4]</span><a href="#è¯­éŸ³æŠ€æœ¯-4" class="header-anchor">#</a></h2><h5><span id="åº”ç”¨åœºæ™¯">åº”ç”¨åœºæ™¯</span><a href="#åº”ç”¨åœºæ™¯" class="header-anchor">#</a></h5><ul>
<li>è¯­éŸ³è¯†åˆ«<ul>
<li>è¯­éŸ³è½¬æ–‡å­—</li>
<li>åº”ç”¨<ul>
<li>æ™ºèƒ½éŸ³å“</li>
<li>è¯­éŸ³è¾“å…¥å‘</li>
</ul>
</li>
</ul>
</li>
<li>è¯­éŸ³åˆæˆ <ul>
<li>æ–‡å­—è½¬è¯­éŸ³ TTS</li>
<li>åº”ç”¨<ul>
<li>äººæœºäº¤äº’</li>
<li>è¯­éŸ³å®¢æœ</li>
<li>è™šæ‹Ÿå¶åƒ-è…¾è®¯AIä¸»æ’­ è‰¾çµ</li>
</ul>
</li>
</ul>
</li>
<li>å£°çº¹è¯†åˆ«<ul>
<li>å¾®ä¿¡çš„å£°éŸ³é”åŠŸèƒ½</li>
</ul>
</li>
</ul>
<h2><span id="è‡ªç„¶è¯­è¨€å¤„ç†-4">è‡ªç„¶è¯­è¨€å¤„ç† [4]</span><a href="#è‡ªç„¶è¯­è¨€å¤„ç†-4" class="header-anchor">#</a></h2><ul>
<li>äººå·¥æ™ºèƒ½çš„æœ€é«˜å¢ƒç•Œ</li>
</ul>
<h5><span id="åº”ç”¨åœºæ™¯">åº”ç”¨åœºæ™¯</span><a href="#åº”ç”¨åœºæ™¯" class="header-anchor">#</a></h5><ul>
<li>æ–‡æœ¬åˆ†ç±»<ul>
<li>æ–°é—»åˆ†ç±»  </li>
<li>é‚®ä»¶è‡ªåŠ¨å›å¤ï¼Œåƒåœ¾é‚®ä»¶</li>
<li>å®¢æœèŠå¤©æƒ…æ„Ÿåˆ†æ</li>
<li>å†…å®¹å®¡æ ¸</li>
</ul>
</li>
<li>æœºå™¨ç¿»è¯‘<ul>
<li>åœ¨çº¿å¤šè¯­è¨€ç¿»è¯‘</li>
<li>ä¼šè®®ä¸­çš„è¯­éŸ³åŒä¼ </li>
<li>ç¿»è¯‘æœº</li>
<li>è·¨è¯­è¨€æ£€ç´¢</li>
</ul>
</li>
<li>çŸ¥è¯†å›¾è°±<ul>
<li>è®¤çŸ¥æ™ºèƒ½</li>
</ul>
</li>
<li>å¯¹è¯ç³»ç»Ÿ<ul>
<li>ä»»åŠ¡å¯¼å‘ - é—®ç­”ç³»ç»Ÿ</li>
<li>éä»»åŠ¡å¯¼å‘ - èŠå¤©æœºå™¨äºº</li>
</ul>
</li>
<li>ä¿¡æ¯æ£€ç´¢</li>
<li>æ–‡æœ¬ç”Ÿæˆ<ul>
<li>å†™ä½œæœºå™¨äºº</li>
</ul>
</li>
</ul>
<h2><span id="æ€»ç»“">æ€»ç»“</span><a href="#æ€»ç»“" class="header-anchor">#</a></h2><ul>
<li>æœºå™¨å¯ä»¥çœ‹   -  è®¡ç®—æœºè§†è§‰ </li>
<li>æœºå™¨å¯ä»¥å¬   -  è¯­éŸ³æŠ€æœ¯</li>
<li>æœºå™¨å¯ä»¥ç†è§£ -  è‡ªç„¶è¯­è¨€å¤„ç†</li>
</ul>
<h2><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h2><p><a href="https://cloud.tencent.com/edu/learning/course-3460-61199">è…¾è®¯äº‘äººå·¥æ™ºèƒ½ä»ä¸šè€…è®¤è¯çº¿ä¸ŠåŸ¹è®­è¯¾ç¨‹</a> </p>
<ol>
<li>1.1  </li>
<li>1.2 </li>
<li>1.4 æœª</li>
<li>1.5</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>åº”ç”¨åœºæ™¯</category>
      </categories>
      <tags>
        <tag>åº”ç”¨åœºæ™¯</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning</title>
    <url>/www6vHomeAIGC/2022/06/11/aiDeepLearning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#deeplearning-1">DeepLearning [1]</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%832">æ¨¡å‹è®­ç»ƒ[2]</a></li>
<li><a href="#%E6%B1%82%E8%A7%A3%E5%99%A82">æ±‚è§£å™¨[2]</a></li>
<li><a href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B02">å¸¸ç”¨çš„æŸå¤±å‡½æ•°[2]</a></li>
<li><a href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E8%B6%85%E5%8F%822">å¸¸ç”¨çš„è¶…å‚[2]</a><ul>
<li><a href="#%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88">è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ</a></li>
<li><a href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E6%95%B4%E7%AD%96%E7%95%A5">å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥</a></li>
</ul>
</li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%843">è‡ªç„¶è¯­è¨€å¤„ç†å¸¸è§çš„ç½‘ç»œç»“æ„[3]</a><ul>
<li><a href="#%E6%96%87%E6%9C%AC%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-textcnn">æ–‡æœ¬å·ç§¯ç¥ç»ç½‘ç»œ TextCNN</a></li>
<li><a href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-rnn">å¾ªç¯ç¥ç»ç½‘ç»œ RNN</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="deeplearning-1">DeepLearning [1]</span><a href="#deeplearning-1" class="header-anchor">#</a></h1><ul>
<li><p>Feedforward å‰å‘ä¼ æ’­</p>
<ul>
<li>training<br>Get some â€œground truthâ€ labeled data, a set of   (ğ’™, ğ’š)    i.e. training data</li>
<li>Feedforward:   ğ’šâ€²&#x3D; ğ’‡(ğ’™),  calculate loss: ğ‘³(ğ’šâ€², ğ’š)</li>
<li>Gradient Descent</li>
</ul>
</li>
<li><p>Backward</p>
<ul>
<li>Backpropagation åå‘ä¼ æ’­<br>ç®—å‡ºæ¯ä¸ªæƒé‡çš„æ¢¯åº¦</li>
</ul>
</li>
<li><p>parameters learning<br>å½“æˆ‘ä»¬è¦å»è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œçš„æ—¶å€™æˆ‘ä»¬è¦åšçš„äº‹æƒ…å°±æ˜¯å…ˆfeedforwardçš„å‰å‘ä¼ æ’­,<br>ç„¶åæ ¹æ®è¿™ä¸ªå‰å‘ä¼ æ’­çš„ç»“æœç®—å‡ºæ‰€æœ‰æƒé‡çš„æ¢¯åº¦ï¼Œç„¶åå†æŠŠè¿™ä¸ªæ¢¯åº¦å‘¢ è½¬æ¢æˆä¸€ä¸ªupdateçš„å€¼ï¼Œå»updateæ¯ä¸ªæƒé‡ã€‚</p>
</li>
</ul>
<h1><span id="æ¨¡å‹è®­ç»ƒ2">æ¨¡å‹è®­ç»ƒ[2]</span><a href="#æ¨¡å‹è®­ç»ƒ2" class="header-anchor">#</a></h1><ul>
<li><p>ä¸¤ä¸ªè¦ç´ </p>
<ul>
<li>ä¸€ä¸ª<strong>æ•°æ®é›†</strong></li>
<li>ä¸€ä¸ª<strong>æŸå¤±å‡½æ•°</strong></li>
</ul>
</li>
<li><p>æ¨¡å‹è®­ç»ƒ</p>
<ul>
<li>æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªæ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜çš„è¿‡ç¨‹</li>
<li>æ€ä¹ˆæ±‚è§£<ul>
<li>æ¢¯åº¦ä¸‹é™ä¸å‡¸é—®é¢˜<br>æ¢¯åº¦å†³å®šäº†å‡½æ•°å˜åŒ–çš„æ–¹å‘ï¼Œæ¯æ¬¡è¿­ä»£æ›´æ–°æˆ‘ä»¬ä¼š<strong>æ”¶æ•›åˆ°ä¸€ä¸ªæå€¼</strong></li>
<li>mini-batchæ¢¯åº¦ä¸‹é™<br>æ¡ä»¶å…è®¸çš„æƒ…å†µä¸‹ï¼Œ<strong>Batch Sizeå°½é‡å¤§äº›</strong>      </li>
<li><strong>å­¦ä¹ ç‡</strong><ul>
<li>å­¦ä¹ ç‡ä¹Ÿå¾ˆå…³é”®ï¼Œç”šè‡³éœ€è¦<strong>åŠ¨æ€è°ƒæ•´</strong><br>é€‚å½“è°ƒæ•´å­¦ä¹ ç‡ï¼ˆLearning Rateï¼‰ï¼Œ<strong>é¿å…é™·å…¥å¾ˆå·®çš„å±€éƒ¨è§£æˆ–è€…è·³è¿‡äº†å¥½çš„è§£</strong>  </li>
<li>å­¦ä¹ ç‡ï¼Œå®ƒå’Œæ¢¯åº¦çš„æ¨¡æ•°å…±åŒå†³å®šäº†<strong>æ¯æ­¥èµ°å¤šè¿œ</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="æ±‚è§£å™¨2">æ±‚è§£å™¨[2]</span><a href="#æ±‚è§£å™¨2" class="header-anchor">#</a></h1><ul>
<li>æœ€å¸¸ç”¨çš„å°±æ˜¯ <strong>Adam</strong> æˆ–è€… <strong>AdamW</strong></li>
</ul>
<h1><span id="å¸¸ç”¨çš„æŸå¤±å‡½æ•°2">å¸¸ç”¨çš„æŸå¤±å‡½æ•°[2]</span><a href="#å¸¸ç”¨çš„æŸå¤±å‡½æ•°2" class="header-anchor">#</a></h1><ul>
<li>ä¸¤ä¸ªæ•°å€¼çš„å·®è·</li>
<li>ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ï¼ˆæ¬§å¼ï¼‰è·ç¦»</li>
<li>ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„å¤¹è§’ï¼ˆä½™å¼¦è·ç¦»ï¼‰</li>
<li>ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œ<strong>äº¤å‰ç†µ</strong></li>
</ul>
<h1><span id="å¸¸ç”¨çš„è¶…å‚2">å¸¸ç”¨çš„è¶…å‚[2]</span><a href="#å¸¸ç”¨çš„è¶…å‚2" class="header-anchor">#</a></h1><h3><span id="è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ">è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ</span><a href="#è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ" class="header-anchor">#</a></h3><ul>
<li>é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼ˆ1ï¼‰ï¼š<strong>Weight Decay</strong><br>æƒ©ç½šå‚æ•°çš„å¤æ‚æ€§</li>
<li>é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼ˆ2ï¼‰ï¼š<strong>Dropout</strong><br> åœ¨å‰å‘ä¼ æ’­çš„æ—¶å€™ï¼Œæ¦‚ç‡æ€§çš„ï¼ˆä¸´æ—¶ï¼‰åˆ é™¤ä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼Œè¿™æ ·å¯ä»¥ä½¿æ¨¡å‹æ³›åŒ–æ€§æ›´å¼ºï¼Œå› ä¸ºå®ƒä¸ä¼šå¤ªä¾èµ–æŸäº›å±€éƒ¨çš„ç‰¹å¾</li>
</ul>
<h3><span id="å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥">å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥</span><a href="#å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥" class="header-anchor">#</a></h3><ul>
<li><p>å¼€å§‹æ—¶å­¦ä¹ ç‡<strong>å¤§</strong>äº›ï¼šå¿«é€Ÿåˆ°è¾¾æœ€ä¼˜è§£é™„è¿‘</p>
</li>
<li><p>é€æ¸<strong>å‡å°</strong>å­¦ä¹ ç‡ï¼šé¿å…è·³è¿‡æœ€ä¼˜è§£</p>
</li>
<li><p>NLP ä»»åŠ¡çš„æŸå¤±å‡½æ•°æœ‰å¾ˆå¤šâ€œæ‚¬å´–å³­å£â€ï¼Œè‡ªé€‚åº”å­¦ä¹ ç‡æ›´èƒ½å¤„ç†è¿™ç§æç«¯æƒ…å†µï¼Œ<strong>é¿å…æ¢¯åº¦çˆ†ç‚¸</strong>ã€‚</p>
</li>
<li><p><strong>é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼ˆ3ï¼‰</strong>ï¼š<strong>å­¦ä¹ ç‡ Warm Up</strong></p>
<ul>
<li>å…ˆä»ä¸€ä¸ªå¾ˆå°çš„å­¦ä¹ ç‡é€æ¸ä¸Šå‡åˆ°æ­£å¸¸å­¦ä¹ ç‡ï¼Œåœ¨ç¨³æ­¥å‡å°å­¦ä¹ ç‡</li>
</ul>
</li>
</ul>
<h1><span id="è‡ªç„¶è¯­è¨€å¤„ç†å¸¸è§çš„ç½‘ç»œç»“æ„3">è‡ªç„¶è¯­è¨€å¤„ç†å¸¸è§çš„ç½‘ç»œç»“æ„[3]</span><a href="#è‡ªç„¶è¯­è¨€å¤„ç†å¸¸è§çš„ç½‘ç»œç»“æ„3" class="header-anchor">#</a></h1><h3><span id="æ–‡æœ¬å·ç§¯ç¥ç»ç½‘ç»œ-textcnn">æ–‡æœ¬å·ç§¯ç¥ç»ç½‘ç»œ TextCNN</span><a href="#æ–‡æœ¬å·ç§¯ç¥ç»ç½‘ç»œ-textcnn" class="header-anchor">#</a></h3><ul>
<li><p>how</p>
<ul>
<li>ä¸€ä¸ªçª—å£çš„å·ç§¯å’ŒPoolingè¿‡ç¨‹</li>
</ul>
</li>
<li><p>why</p>
<ul>
<li>å‚æ•°é‡è¾ƒå°‘ã€å¥½è®­ç»ƒã€ç®—åŠ›è¦æ±‚ä½</li>
<li>é€‚åˆ<strong>æ–‡æœ¬åˆ†ç±»</strong>é—®é¢˜</li>
<li>å–„äºè¡¨ç¤º<strong>å±€éƒ¨ç‰¹å¾ï¼ˆå·ç§¯çª—å£ï¼‰</strong>ï¼Œä¸æ“…é•¿è¡¨ç¤ºé•¿ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»</li>
</ul>
</li>
</ul>
<h3><span id="å¾ªç¯ç¥ç»ç½‘ç»œ-rnn">å¾ªç¯ç¥ç»ç½‘ç»œ RNN</span><a href="#å¾ªç¯ç¥ç»ç½‘ç»œ-rnn" class="header-anchor">#</a></h3><ul>
<li>ç®€æ˜“ RNN<br>æœ€å¤§é—®é¢˜æ˜¯éšç€åºåˆ—é•¿åº¦å¢åŠ ï¼Œ<strong>æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸</strong></li>
<li>LSTM å’Œ GRU<br>é€šè¿‡ã€Œé—¨ã€æ¥æ§åˆ¶ä¸Šæ–‡çš„çŠ¶æ€è¢«è®°ä½è¿˜æ˜¯é—å¿˜ï¼ŒåŒæ—¶é˜²æ­¢æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://www.bilibili.com/video/BV1GA41157mJ/">ç³»ç»Ÿè®ºæ–‡é˜…è¯»ç ”è®¨ä¼šweek9ï¼šæœºå™¨å­¦ä¹ ç³»ç»Ÿï¼ˆä¸€ï¼‰</a> V ***<br> <a href="https://learn-sys.github.io/cn/reading/">W9ï¼šæœºå™¨å­¦ä¹ ç³»ç»Ÿï¼ˆä¸€ï¼‰</a> ***  å¯¹åº”çš„PPT</p>
</li>
<li><p>ã€Š11-æœºå™¨å­¦ä¹ åŸºç¡€-ä¸Šã€‹AI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆåŸ¹å…»è®¡åˆ’_2<br><a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/index.ipynb">è¯¾ä»¶</a> </p>
</li>
<li><p>ã€Š12-æœºå™¨å­¦ä¹ åŸºç¡€-ä¸‹ã€‹AI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆåŸ¹å…»è®¡åˆ’_2<br> <a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/index.ipynb">è¯¾ä»¶</a></p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/461925341">å´æ©è¾¾ï¼š28å¼ å›¾å…¨è§£æ·±åº¦å­¦ä¹ çŸ¥è¯†</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning</title>
    <url>/www6vHomeAIGC/2022/06/07/aiMachineLearning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="æœºå™¨å­¦ä¹ ç®—æ³•">æœºå™¨å­¦ä¹ ç®—æ³•</span><a href="#æœºå™¨å­¦ä¹ ç®—æ³•" class="header-anchor">#</a></h2><ul>
<li><p>ç›‘ç£å¼å­¦ä¹ </p>
<ul>
<li><p>Linear Models</p>
<ul>
<li>é€»è¾‘å›å½’ (Logistic Regression)<br><strong>ç¦»æ•£</strong><br>é€»è¾‘å›å½’å…¶å®æ˜¯ä¸€ä¸ªåˆ†ç±»ç®—æ³•è€Œä¸æ˜¯å›å½’ç®—æ³•ã€‚</li>
<li>çº¿æ€§å›å½’ (Linear Regression)<br><strong>è¿ç»­</strong></li>
</ul>
</li>
<li><p>Nearest Neighbors</p>
<ul>
<li>Ké‚»è¿‘ç®—æ³•ï¼ŒKNN</li>
</ul>
</li>
<li><p>å†³ç­–æ ‘ Decision Trees</p>
</li>
<li><p>Support Vector Machines, SVM [2]</p>
<ul>
<li>å¯åˆ† <ul>
<li>çº¿æ€§å¯åˆ†</li>
<li>çº¿æ€§ä¸å¯åˆ†</li>
</ul>
</li>
<li>è¶…å¹³é¢<ul>
<li>ä½çº¬å‡åˆ°é«˜çº¬</li>
</ul>
</li>
</ul>
</li>
<li><p>Naive Bayes</p>
</li>
<li><p>éšæœºæ£®æ—</p>
</li>
</ul>
</li>
<li><p>æ— ç›‘ç£å¼å­¦ä¹ </p>
<ul>
<li>å…³è”è§„åˆ™ </li>
<li>K-meansèšç±»ç®—æ³•<br>è´¨å¿ƒï¼ˆcentroidsï¼‰ï¼Œè·ç¦»</li>
</ul>
</li>
<li><p>å¼ºåŒ–å­¦ä¹ </p>
</li>
</ul>
<h2><span id="æœºå™¨å­¦ä¹ ">æœºå™¨å­¦ä¹ </span><a href="#æœºå™¨å­¦ä¹ " class="header-anchor">#</a></h2><ul>
<li>Classification<br>Identifying which category an object belongs to.</li>
<li>Regression<br>  Predicting a continuous-valued attribute associated with an object.</li>
<li>Clustering<br>  Automatic grouping of similar objects into sets.  </li>
<li>Dimensionality reduction<br>  Reducing the number of random variables to consider.</li>
</ul>
<img src="/www6vHomeAIGC/2022/06/07/aiMachineLearning/scikit-learn.png" class title="scikit-learn overview">



<h2><span id="æŒ‰å­¦ä¹ æ¨¡å‹åˆ’åˆ†-4">æŒ‰å­¦ä¹ æ¨¡å‹åˆ’åˆ† [4]</span><a href="#æŒ‰å­¦ä¹ æ¨¡å‹åˆ’åˆ†-4" class="header-anchor">#</a></h2><h2><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h2><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/479973669">ã€æœºå™¨å­¦ä¹ ç®—æ³•ã€‘10ç§å¸¸è§æœºå™¨å­¦ä¹ ç®—æ³•+Pythonä»£ç </a></p>
</li>
<li><p><a href="https://www.jianshu.com/p/b8227eac1fa6">æœºå™¨å­¦ä¹ â€“æœ‰ç›‘ç£â€“æ”¯æŒå‘é‡æœºSVM</a></p>
</li>
<li><p><a href="https://scikit-learn.org/stable/supervised_learning.html">Supervised learning</a></p>
</li>
<li><p><a href="https://blog.csdn.net/hustlei/article/details/121803226">äººå·¥æ™ºèƒ½å¯¼è®º(6)â€”â€”æœºå™¨å­¦ä¹ (Machine Learning)</a> ***</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>MachineLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>äººå·¥æ™ºèƒ½ çŸ¥è¯†ç‚¹</title>
    <url>/www6vHomeAIGC/2022/01/22/aiOverview/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="äººå·¥æ™ºèƒ½å¼•è®ºçŸ¥è¯†ç‚¹">äººå·¥æ™ºèƒ½å¼•è®ºçŸ¥è¯†ç‚¹</span><a href="#äººå·¥æ™ºèƒ½å¼•è®ºçŸ¥è¯†ç‚¹" class="header-anchor">#</a></h2><img src="/www6vHomeAIGC/2022/01/22/aiOverview/ai-overview.png" class>

<blockquote>
<p>62ä¸ªçŸ¥è¯†ç‚¹ï¼Œ9ä¸ªé«˜é˜¶çŸ¥è¯†ç‚¹(ç ”ç©¶ç”Ÿè¯¾ç¨‹)</p>
</blockquote>
<h2><span id="ç¾å›½k12-aiçŸ¥è¯†ç‚¹">ç¾å›½K12 AIçŸ¥è¯†ç‚¹</span><a href="#ç¾å›½k12-aiçŸ¥è¯†ç‚¹" class="header-anchor">#</a></h2><ul>
<li>æ™ºèƒ½æ„ŸçŸ¥</li>
<li>è¡¨ç¤ºå’Œæ¨ç†</li>
<li>æœºå™¨å­¦ä¹ </li>
<li>è‡ªç„¶äº¤äº’èƒ½åŠ›</li>
<li>å¯¹ç¤¾ä¼šçš„å½±å“</li>
</ul>
<h2><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h2><p><a href="https://www.bilibili.com/video/BV1Wa41157U4?spm_id_from=333.880.my_history.page.click&vd_source=f6e8c1128f9f264c5ab8d9411a644036">å´é£æ•™æˆè§£è¯»ï¼šäººå·¥æ™ºèƒ½çŸ¥è¯†ç‚¹å…¨æ™¯å›¾ï¼šè¿ˆå‘æ™ºèƒ½+æ—¶ä»£è“çš®ä¹¦</a> video<br><a href="https://www.163.com/dy/article/HFAFUJPM051193U6.html">äººå·¥æ™ºèƒ½çŸ¥è¯†ç‚¹å…¨æ™¯å›¾ï¼šè¿ˆå‘æ™ºèƒ½+æ—¶ä»£è“çš®ä¹¦</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>basic</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>äººå·¥æ™ºèƒ½-å­¦ä¹ èµ„æº</title>
    <url>/www6vHomeAIGC/2022/01/22/aiStudyResouce/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ä¹¦ç±">ä¹¦ç±</span><a href="#ä¹¦ç±" class="header-anchor">#</a></h2><ul>
<li>ç†è®º<ul>
<li>ã€Šäººå·¥æ™ºèƒ½çš„æ•°æ®åŸºç¡€ã€‹</li>
<li>ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ v2</li>
<li>The Hundred-Page Machine Learning Book - å…¥é—¨</li>
<li>è¥¿ç“œä¹¦ ***</li>
<li>èŠ±ä¹¦</li>
</ul>
</li>
<li>æ¡†æ¶<ul>
<li>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, v3 - å…¥é—¨</li>
<li>Deep Learning with PyTorch - å…¥é—¨</li>
<li>Deep Learning with Python - v2 - kerasåº“</li>
</ul>
</li>
</ul>
<h2><span id="æœºå™¨å­¦ä¹ ">æœºå™¨å­¦ä¹ </span><a href="#æœºå™¨å­¦ä¹ " class="header-anchor">#</a></h2><ul>
<li>æµ™å¤§ - å´æµ©åŸº   ***</li>
<li>å‘¨å¿—å ã€Šæœºå™¨å­¦ä¹ åˆæ­¥ã€‹ *** </li>
<li>Courseraå´æ©è¾¾- ã€Šmachine learningã€‹+ ç¬”è®°  å…¥é—¨  *** </li>
<li><a href="https://www.bilibili.com/video/av79340208/">Machine Learning A-Z Hands-On Python &amp; R In Data Science</a>  Udemy å…¥é—¨  ***</li>
<li><a href="https://www.bilibili.com/video/BV1KB4y1E73v">ã€äººå·¥æ™ºèƒ½ç³»åˆ—ã€‘ã€ä¸­æ–‡ã€‘æœºå™¨å­¦ä¹ A-Z Machine Learning in Chinese(å‰7éƒ¨åˆ†)</a></li>
<li><a href="https://www.bilibili.com/video/BV1jF411A7VF/">[Courseraå…¬å¼€è¯¾] [æœºå™¨å­¦ä¹ ä¸“é¡¹è¯¾ç¨‹1&#x2F;4] æœºå™¨å­¦ä¹ åŸºç¡€ï¼šæ¡ˆä¾‹ç ”ç©¶</a>  ***</li>
<li><a href="https://www.bilibili.com/video/BV1Bg411Z77N">èšç±»ç®—æ³•ï¼šå±‚æ¬¡èšç±»ã€k-means èšç±»ã€k-medoids èšç±»ã€å¯†åº¦èšç±»</a>  ***</li>
</ul>
<h2><span id="æ·±åº¦å­¦ä¹ ">æ·±åº¦å­¦ä¹ </span><a href="#æ·±åº¦å­¦ä¹ " class="header-anchor">#</a></h2><ul>
<li>ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ - ç¬¬äºŒç‰ˆ -pyTorchã€‹  ***<br>bç«™æœ‰è§†é¢‘è¯¾<br><a href="http://zh.d2l.ai/index.html">ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹</a> åœ¨çº¿<br>ç”µå­ä¹¦+jupternoteä»£ç </li>
<li>ã€Šç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹  ã€‹ å¤æ—¦  </li>
<li>Courseraå´æ©è¾¾ã€Šæ·±åº¦å­¦ä¹ ã€‹ + ç¬”è®°  ***</li>
<li>è€å” ***</li>
<li>è«çƒ¦Python </li>
<li>åŒ—äº¬å¤§å­¦ TensorFlow 2.0</li>
<li>ç®—æ³•å¯è§†åŒ–  ***</li>
<li>æå®æ¯… å°æ¹¾</li>
</ul>
<h2><span id="nlp-amp-å¤§æ¨¡å‹">NLP &amp; å¤§æ¨¡å‹</span><a href="#nlp-amp-å¤§æ¨¡å‹" class="header-anchor">#</a></h2><ul>
<li><p><a href="https://www.zhihu.com/education/video-course/1546509363711614976">æ²ˆå‘æ´‹å¸¦ä½ è¯»è®ºæ–‡â€”â€”CV &amp; NLP ä¸“é¢˜</a> V </p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1C14y147dp">2022å¹´é¦–å‘ï¼Bç«™è®²çš„æœ€å¥½çš„ã€NLPè‡ªç„¶è¯­è¨€å¤„ç†ã€‘ä¿å§†çº§æ•™ç¨‹ï¼</a>  V  æœ‰å®è·µ  *** </p>
</li>
<li><p>MLNLPç¬¬å…­æœŸå­¦æœ¯ç ”è®¨ä¼šå¼€å§‹æŠ¥å</p>
</li>
</ul>
<h2><span id="çŸ¥è¯†å›¾è°±">çŸ¥è¯†å›¾è°±</span><a href="#çŸ¥è¯†å›¾è°±" class="header-anchor">#</a></h2><ul>
<li><a href="https://www.bilibili.com/video/BV1VT411G7Y6?p=6">ã€å›½å®¶çº§ç²¾å“è¯¾ã€‘æµ™æ±Ÿå¤§å­¦æ•™æˆï¼ˆæ–°å…¨44é›†ï¼‰çŸ¥è¯†å›¾è°±å…¬å¼€è¯¾åˆ†äº«</a>  ***</li>
</ul>
<h2><span id="æå®¢æ—¶é—´">æå®¢æ—¶é—´</span><a href="#æå®¢æ—¶é—´" class="header-anchor">#</a></h2><ul>
<li>æå®¢æ—¶é—´<ul>
<li>ã€ŠAI æŠ€æœ¯å†…å‚ã€‹  æ´ªäº®åŠ¼   å…¨ ***</li>
<li>ã€Šæœºå™¨å­¦ä¹  40 è®²ã€‹  ç‹å¤©ä¸€ </li>
<li>ã€Šäººå·¥æ™ºèƒ½åŸºç¡€è¯¾ã€‹  ç‹å¤©ä¸€<br> æœºå™¨å­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ </li>
<li>ã€Šæˆä¸ºAIäº§å“ç»ç†ã€‹  åˆ˜æµ·ä¸° äº¬ä¸œ   </li>
<li>ã€Šé›¶åŸºç¡€å®æˆ˜æœºå™¨å­¦ä¹ ã€‹ é»„ä½³  ***</li>
<li>ã€ŠPyTorchæ·±åº¦å­¦ä¹ å®æˆ˜ã€‹æ–¹è¿œ å¤§å‚</li>
<li><a href="https://time.geekbang.org/course/intro/100023001?tab=catalog">TensorFlow å¿«é€Ÿå…¥é—¨ä¸å®æˆ˜</a></li>
<li><a href="https://time.geekbang.org/course/intro/315">TensorFlow 2 é¡¹ç›®è¿›é˜¶å®æˆ˜</a></li>
<li><a href="https://time.geekbang.org/course/intro/100046401">NLP å®æˆ˜é«˜æ‰‹è¯¾</a></li>
</ul>
</li>
<li><a href="https://time.geekbang.org/course/detail/100005001-3090">æ·±åº¦å­¦ä¹ åº”ç”¨å®è·µ 60 è®²</a><ul>
<li>æ·±åº¦å­¦ä¹ åœ¨CTRé¢„ä¼°çš„åº”ç”¨   å¼ ä¿Šæ—</li>
<li>æ·±åº¦å­¦ä¹ åœ¨å›¾åƒç†è§£ä¸­çš„åº”ç”¨  ç†Šé¹é£</li>
</ul>
</li>
<li><a href="https://time.geekbang.org/course/detail/100005001-3090">æ·±åº¦å­¦ä¹ åº”ç”¨å®è·µ 60 è®²</a><ul>
<li>çŸ¥è¯†å›¾è°±æŠ€æœ¯å®è·µ  é‚µè“¥ä¾ </li>
</ul>
</li>
<li>æå®¢è®­ç»ƒè¥<br>-ã€Šæœºå™¨å­¦ä¹ è®­ç»ƒè¥1æœŸã€‹  è§†é¢‘è¯¾</li>
</ul>
<h2><span id="ä¸­å›½å¤§å­¦mooc">ä¸­å›½å¤§å­¦MOOC</span><a href="#ä¸­å›½å¤§å­¦mooc" class="header-anchor">#</a></h2><ul>
<li>ä¸­å›½å¤§å­¦MOOC <a href="https://www.icourse163.org/learn/HIT-1206320802?tid=1468208513#/learn/announce">æ·±åº¦å­¦ä¹ åŸºç¡€</a>   å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦</li>
<li>ä¸­å›½å¤§å­¦MOOC <a href="https://www.icourse163.org/course/FUDAN-1205806833">æ·±åº¦å­¦ä¹ åŠå…¶åº”ç”¨</a>   å¤æ—¦</li>
<li>ä¸­å›½å¤§å­¦MOOC <a href="https://www.icourse163.org/course/ZUCC-1206146808">æ·±åº¦å­¦ä¹ åº”ç”¨å¼€å‘-TensorFlowå®è·µ</a>  æµ™å¤§åŸå¸‚å­¦é™¢</li>
</ul>
<h2><span id="åŸ¹è®­">åŸ¹è®­</span><a href="#åŸ¹è®­" class="header-anchor">#</a></h2><ul>
<li><a href="http://bit.baidu.com/">ç™¾åº¦æŠ€æœ¯åŸ¹è®­ä¸­å¿ƒ</a>  *** è®¤è¯ï¼Œ è‡ªåŠ¨é©¾é©¶ï¼Œäººå·¥æ™ºèƒ½åŸ¹è®­  </li>
<li><a href="http://bit.baidu.com/courseRouteDetail?id=111">äººå·¥æ™ºèƒ½å­¦ä¹ è·¯çº¿</a>  ç™¾åº¦æŠ€æœ¯åŸ¹è®­ä¸­å¿ƒ</li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>å­¦ä¹ èµ„æº</category>
      </categories>
      <tags>
        <tag>å­¦ä¹ èµ„æº</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT-å·¥å…·å’Œåº”ç”¨</title>
    <url>/www6vHomeAIGC/2022/05/09/gpt/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#platform">Platform</a></li>
<li><a href="#tools-mix">Tools &amp; Mix</a></li>
<li><a href="#%E5%BA%94%E7%94%A8">åº”ç”¨</a><ul>
<li><a href="#%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE">æ€ç»´å¯¼å›¾</a></li>
<li><a href="#%E8%A7%86%E9%A2%91">è§†é¢‘</a></li>
<li><a href="#%E8%8B%B1%E8%AF%AD">è‹±è¯­</a></li>
</ul>
</li>
<li><a href="#%E5%AE%A2%E6%88%B7%E7%AB%AF">å®¢æˆ·ç«¯</a></li>
<li><a href="#chrome-plugin">Chrome plugin</a></li>
<li><a href="#%E5%88%9B%E4%B8%9A">åˆ›ä¸š</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="platform">Platform</span><a href="#platform" class="header-anchor">#</a></h1><ul>
<li>å›½å¤–<br><a href="https://poe.com/ChatGPT">Poe</a> ***</li>
<li>å›½å†…<br><a href="https://saas.edu360.cn/system/chatgpt">å®æˆ˜äº‘</a> gpt3.5  gpt4<br><a href="https://www.feijix.com/n/y0BnXI">ChatGPTä½¿ç”¨æŒ‡å—ï¼</a>   ***<br><a href="https://www.1888ai.com/base/chat">çµçŠ€ç™¾é€š</a>  gpt3.5<br><a href="https://gpt.91chat-ai.cn/chat">ChatGpt PLUS</a><br><a href="https://yiyan.baidu.com/">æ–‡å¿ƒä¸€è¨€</a></li>
</ul>
<h1><span id="tools-amp-mix">Tools &amp; Mix</span><a href="#tools-amp-mix" class="header-anchor">#</a></h1><ul>
<li><p>GPTå­¦ä¹ å®å…¸</p>
<ul>
<li>èšåˆ<ul>
<li><a href="https://gpt.candobear.com/toolbox">GPT  å·¥å…·ç®±</a></li>
</ul>
</li>
<li>æ•™ç¨‹<ul>
<li><a href="https://gpt.candobear.com/courses">å­¦ä¹ èµ„æ–™</a></li>
</ul>
</li>
</ul>
</li>
<li><p><a href="https://gp477l8icq.feishu.cn/wiki/JUXnwzSuviL5E9kh6jUc8FRinHe">æå®¢æ—¶é—´ AIGC çŸ¥è¯†åº“</a> *** </p>
<ul>
<li>èšåˆ<ul>
<li><a href="https://gp477l8icq.feishu.cn/wiki/M1uCwFNjkiAGC7k30TaclZqknPh">AIå·¥å…·å¤§å…¨</a></li>
<li><a href="https://gp477l8icq.feishu.cn/wiki/RpabwPG9niFEu9kwJAQcAGxenDg">AIä¸»æµå·¥å…·ç²¾é€‰</a></li>
<li><a href="https://gp477l8icq.feishu.cn/wiki/VJ9ewqfOgiyrbQksbyLcrODtnkb">AIç»å…¸é¡¹ç›®</a></li>
<li><a href="https://gp477l8icq.feishu.cn/wiki/QVV6w3XstiR7hlkK53Bc8f9DnMf">AIå¯¼èˆªç«™</a></li>
</ul>
</li>
<li><a href="https://longalong.feishu.cn/wiki/wikcneAKpN3u473N7J9EAC4Ga0b">åº”ç”¨ä¸å˜ç°æ¡ˆä¾‹</a></li>
</ul>
</li>
<li><p><a href="https://www.ailookme.com/">AI å·¥å…·ç®±</a>  *** </p>
</li>
<li><p><a href="https://gptdoc.sparkai.chat/">ChatGPT Tutorial 101</a></p>
</li>
</ul>
<h1><span id="åº”ç”¨">åº”ç”¨</span><a href="#åº”ç”¨" class="header-anchor">#</a></h1><h3><span id="æ€ç»´å¯¼å›¾">æ€ç»´å¯¼å›¾</span><a href="#æ€ç»´å¯¼å›¾" class="header-anchor">#</a></h3><p><a href="https://albus.org/">albus</a></p>
<h3><span id="è§†é¢‘">è§†é¢‘</span><a href="#è§†é¢‘" class="header-anchor">#</a></h3><p><a href="https://b.jimmylv.cn/">BibiGPT</a><br><a href="https://crucible.docnavigator.in/">Youtube tools</a></p>
<h3><span id="è‹±è¯­">è‹±è¯­</span><a href="#è‹±è¯­" class="header-anchor">#</a></h3><p><a href="https://callannie.ai/signin">callannie</a></p>
<h1><span id="å®¢æˆ·ç«¯">å®¢æˆ·ç«¯</span><a href="#å®¢æˆ·ç«¯" class="header-anchor">#</a></h1><ul>
<li>ChatGPT å®¢æˆ·ç«¯<br> windowsï¼Œ mac</li>
</ul>
<h1><span id="chrome-plugin">Chrome plugin</span><a href="#chrome-plugin" class="header-anchor">#</a></h1><ul>
<li><p>WebChatGPT[instatlled]</p>
</li>
<li><p>AIPRM for ChatGPT[instatlled]</p>
</li>
<li><p>ChatGPT Sidebar<br>è¦æ³¨å†Œè´¦å·, éœ€è¦api token</p>
</li>
<li><p>ChatHub  [instatlled]<br> chatgpt + new bing<br><a href="https://github.com/chathub-dev/chathub">ChatHub </a></p>
</li>
<li><p>OpenAI Translator<br><a href="https://github.com/yetone/openai-translator">openai-translator</a><br>è¦æ³¨å†Œè´¦å·, éœ€è¦api token</p>
</li>
</ul>
<h1><span id="åˆ›ä¸š">åˆ›ä¸š</span><a href="#åˆ›ä¸š" class="header-anchor">#</a></h1><ul>
<li><a href="https://gpt3demo.com/map">GPT-3 Demo</a><ul>
<li>èŠå¤©æœºå™¨äºº</li>
<li>ä»£ç è¾…åŠ©</li>
<li>å†™ä½œåº”ç”¨</li>
<li>æ¸¸æˆ</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>gpt</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Agent Challenge</title>
    <url>/www6vHomeAIGC/2023/05/13/gptAgentChallenge/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>





<h1><span id="é—®é¢˜å’Œå±€é™æ€§-4">é—®é¢˜å’Œå±€é™æ€§ [4]</span><a href="#é—®é¢˜å’Œå±€é™æ€§-4" class="header-anchor">#</a></h1><ul>
<li><p>è®°å¿†å¬å›é—®é¢˜<br>åªæ˜¯åšç®€å•çš„ embedding ç›¸ä¼¼æ€§å¬å›ï¼Œå¾ˆå®¹æ˜“å‘ç°å¬å›çš„ç»“æœä¸æ˜¯å¾ˆå¥½</p>
</li>
<li><p>é”™è¯¯ç´¯ç§¯é—®é¢˜</p>
</li>
<li><p>æ¢ç´¢æ•ˆç‡é—®é¢˜<br>ä¸­é€”å¼•å…¥äººå·¥çš„åˆ¤æ–­å¹²é¢„å’Œåé¦ˆè¾“å…¥</p>
</li>
<li><p>ä»»åŠ¡ç»ˆæ­¢ä¸ç»“æœéªŒè¯<br>æ¨¡å‹ agent çš„å·¥ä½œå¦‚ä½•ç»ˆæ­¢ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜</p>
</li>
</ul>
<h1><span id="æŒ‘æˆ˜-8">æŒ‘æˆ˜ [8]</span><a href="#æŒ‘æˆ˜-8" class="header-anchor">#</a></h1><h3><span id="å¦‚ä½•è®©-agent-é€‰æ‹©åˆé€‚çš„å·¥å…·">å¦‚ä½•è®© agent é€‰æ‹©åˆé€‚çš„å·¥å…·</span><a href="#å¦‚ä½•è®©-agent-é€‰æ‹©åˆé€‚çš„å·¥å…·" class="header-anchor">#</a></h3><ul>
<li>Toolformer - fine tune</li>
<li>Gorilla - retrievalï¼Œfine tune</li>
</ul>
<h3><span id="ä¸å¿…è¦çš„å·¥å…·ä½¿ç”¨">ä¸å¿…è¦çš„å·¥å…·ä½¿ç”¨</span><a href="#ä¸å¿…è¦çš„å·¥å…·ä½¿ç”¨" class="header-anchor">#</a></h3><p>â€œHuman Inputâ€ä¹Ÿå†™æˆä¸€ç§å·¥å…·ï¼Œè®©æ¨¡å‹æ¥ä¸»åŠ¨å‘èµ·å¯¹äººç±»çš„æé—®<br><a href="https://python.langchain.com/docs/integrations/tools/human_tools">Human as a tool</a></p>
<h3><span id="agent-è¿”å›çš„æ ¼å¼ä¸ç¨³å®š">Agent è¿”å›çš„æ ¼å¼ä¸ç¨³å®š</span><a href="#agent-è¿”å›çš„æ ¼å¼ä¸ç¨³å®š" class="header-anchor">#</a></h3><p>è¿™é‡Œå¸¸è§çš„åšæ³•æ˜¯è®© LLM <strong>æŒ‰ç…§ json è¿™ç±»å¸¸è§çš„ schema æ¥è¿”å›</strong>ï¼Œä¸€èˆ¬ç¨³å®šæ€§ä¼šé«˜ä¸€äº›ï¼ˆç›¸æ¯”â€œAction:â€è¿™ç§ï¼‰ã€‚<br>æ­¤å¤–è‡ªåŠ¨ä¿®å¤é‡è¯•ä¹Ÿå¾ˆå®ç”¨ï¼Œå¯ä»¥åˆ©ç”¨ LangChain é‡Œçš„ <strong>output parsers</strong> æ¥å¸®åŠ©å®Œæˆã€‚</p>
<h3><span id="è®°ä½ä¹‹å‰çš„æ“ä½œé¿å…é‡å¤">è®°ä½ä¹‹å‰çš„æ“ä½œï¼Œé¿å…é‡å¤</span><a href="#è®°ä½ä¹‹å‰çš„æ“ä½œé¿å…é‡å¤" class="header-anchor">#</a></h3><p>AutoGPT - retrieval ç»“åˆè¿‘æœŸæ“ä½œè®°å½•</p>
<h3><span id="å¤„ç†è¶…é•¿çš„-observation">å¤„ç†è¶…é•¿çš„ observation</span><a href="#å¤„ç†è¶…é•¿çš„-observation" class="header-anchor">#</a></h3><p>éœ€è¦ç”¨ä¸€äº›å·¥å…·ä»ä¸­<strong>æå–æœ‰ç”¨ä¿¡æ¯</strong>ï¼Œæˆ–è€…<strong>æ”¾åˆ°å¤–éƒ¨å­˜å‚¨ä¸­å†å€ŸåŠ© retrieval æ¥ä½¿ç”¨</strong>ã€‚</p>
<h3><span id="ä¸“æ³¨äºç›®æ ‡">ä¸“æ³¨äºç›®æ ‡</span><a href="#ä¸“æ³¨äºç›®æ ‡" class="header-anchor">#</a></h3><p>ç®€å•çš„åšæ³•æ˜¯<strong>åœ¨ prompt ç»“å°¾å¤„å†æŠŠç›®æ ‡åŠ ä¸Š</strong>ï¼Œå¼•èµ· agent çš„æ³¨æ„ã€‚<br>å¦å¤–åƒ BabyAGIï¼ŒHuggingGPT è¿™ç§æŠŠ <strong>planning å’Œ execution åˆ†å¼€</strong>çš„åšæ³•ä¹Ÿæ˜¯å¾ˆæœ‰ç”¨ã€‚<strong>æ‹†åˆ†çš„æ¯”è¾ƒç»†</strong>çš„ä»»åŠ¡å¾€å¾€æ­¥éª¤æ¯”è¾ƒçŸ­ï¼Œä¹Ÿä¸å®¹æ˜“ä¸¢å¤±ç›®æ ‡ã€‚</p>
<h3><span id="ç»“æœè¯„ä¼°">ç»“æœè¯„ä¼°</span><a href="#ç»“æœè¯„ä¼°" class="header-anchor">#</a></h3><ul>
<li><strong>è¯„ä¼°æœ€ç»ˆç»“æœ</strong>æ˜¯å¦æ­£ç¡®</li>
<li><strong>è¿‡ç¨‹çš„ç»†åŒ–è¯„ä¼°</strong><ul>
<li>é€‰æ‹©çš„ä¸­é—´æ­¥éª¤æ˜¯å¦æ­£ç¡®ã€‚</li>
<li>ç”Ÿæˆ action çš„ input æ˜¯å¦æ­£ç¡®ã€‚</li>
<li>ç”Ÿæˆçš„æ­¥éª¤åºåˆ—æ˜¯å¦åˆç†é«˜æ•ˆã€‚</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="4">
<li><a href="https://zhuanlan.zhihu.com/p/622947810">AutoGPTä¸LLM Agentè§£æ</a> *** </li>
<li><a href="https://zhuanlan.zhihu.com/p/633033220">LLM å…¨æ ˆå¼€å‘æŒ‡å—è¡¥é—</a>  Agents  ***<br><a href="https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/chase-agents/">Harrison Chase: Agents</a>  ***</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/679032270">LLM Agent ç°çŠ¶å’Œä¸€äº›æ€è€ƒ ï¼ˆ202401ï¼‰</a><br>   å½“å‰ Agent çš„ç¼ºé™·å’ŒæŒ‘æˆ˜</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>Agent</tag>
      </tags>
  </entry>
  <entry>
    <title>(Survey)Agent List</title>
    <url>/www6vHomeAIGC/2023/03/05/gptAgentList/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#agentgeneral">Agentï¼ˆGeneralï¼‰</a></li>
<li><a href="#agenttoolassistant">Agent(tool&#x2F;assistant)</a></li>
<li><a href="#agentsimulation">Agent(simulation)</a></li>
<li><a href="#agent">Agent</a></li>
<li><a href="#%E5%BA%94%E7%94%A8">åº”ç”¨</a><ul>
<li><a href="#%E5%88%86%E7%B1%BB-101112">åˆ†ç±» [10][11][12]</a></li>
<li><a href="#hugginggpt">HuggingGPT</a></li>
<li><a href="#babyagi-aigc">BabyAGI [AIGC]</a></li>
<li><a href="#autogpt10">AutoGPT[10]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#xxx">xxx</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="agentgeneral">Agentï¼ˆGeneralï¼‰</span><a href="#agentgeneral" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>Agentï¼ˆGeneralï¼‰</th>
<th>ç±»å‹</th>
<th>æè¿°</th>
<th>Code</th>
</tr>
</thead>
<tbody><tr>
<td><strong>AutoGen</strong> <a href="https://www.bilibili.com/video/BV1DH4y1Z7Ep">video</a> paper ***</td>
<td>Multi Agent</td>
<td>customizable, <strong>conversable</strong>,  <strong>seamlessly allow human participation</strong> [å¾®è½¯]</td>
<td><a href="https://github.com/microsoft/autogen">code</a><img src="https://img.shields.io/github/stars/microsoft/autogen.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td><strong>MetaGPT</strong> paper***</td>
<td>Multi Agent-role base</td>
<td>è¦†ç›–è½¯ä»¶å…¬å¸å…¨ç”Ÿå‘½æµç¨‹</td>
<td><a href="https://github.com/geekan/MetaGPT">code</a><img src="https://img.shields.io/github/stars/geekan/MetaGPT.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td><strong>CrewAI</strong><a href="https://www.bilibili.com/video/BV12C4y1Y7xm">video</a></td>
<td>Multi Agent</td>
<td>æµç¨‹å®šä¹‰æ›´çµæ´»</td>
<td><a href="https://github.com/joaomdmoura/CrewAI">code</a><img src="https://img.shields.io/github/stars/joaomdmoura/CrewAI.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td><strong>BabyAGI</strong></td>
<td><strong>plan and execute</strong></td>
<td></td>
<td><a href="https://github.com/yoheinakajima/babyagi">code</a><img src="https://img.shields.io/github/stars/yoheinakajima/babyagi.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td><strong>AutoGPT</strong></td>
<td>General</td>
<td></td>
<td><a href="https://github.com/Torantulino/Auto-GPT">code</a><img src="https://img.shields.io/github/stars/Torantulino/Auto-GPT.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td><strong>LangGraph</strong> <a href="https://www.bilibili.com/video/BV1VN4y1n7bt/">video</a> ***</td>
<td>flow engineering</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>XAgent</strong> <a href="https://www.bilibili.com/video/BV1D34y1M74F">video</a></td>
<td><strong>åŒå¾ªç¯ï¼Œäººå¯å‚ä¸</strong></td>
<td>autogptï¼Œbabyagi - æ²¡æ³•æ”¶æ•›ï¼Œæœ‰æ—¶å€™ä¼šä¸å¯æ§<br>metagptï¼Œchatdev sopä¼˜åŒ–- æœ‰ä¸€å®šçš„å±€é™æ€§ï¼Œé€šç”¨æ€§ä¸å¤Ÿå¥½[é¢å£æ™ºèƒ½]</td>
<td><a href="https://github.com/OpenBMB/XAgent">code</a><img src="https://img.shields.io/github/stars/OpenBMB/XAgent.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td>Agents <a href="https://www.bilibili.com/video/BV1C8411k7UL">video</a> paper</td>
<td>single agent|multi agent</td>
<td>åŸºäºSOP</td>
<td><a href="https://github.com/aiwaves-cn/agents">code</a></td>
</tr>
<tr>
<td>phidata</td>
<td></td>
<td>Memory, knowledge and tools for LLMs</td>
<td><a href="https://github.com/phidatahq/phidata">code</a></td>
</tr>
<tr>
<td>MiniAGI <a href="https://www.bilibili.com/video/BV1Hh4y1k7Jz">video</a></td>
<td></td>
<td>simple general-purpose autonomous agent based on the OpenAI API</td>
<td><a href="https://github.com/muellerberndt/mini-agi">code</a></td>
</tr>
<tr>
<td>AL Legion</td>
<td></td>
<td>An LLM-powered autonomous agent platform</td>
<td><a href="https://github.com/eumemic/ai-legion">code</a></td>
</tr>
</tbody></table>
<h1><span id="agenttoolx2fassistant">Agent(tool&#x2F;assistant)</span><a href="#agenttoolx2fassistant" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>Agent(tool&#x2F;assistant)</th>
<th>ç±»å‹</th>
<th>æè¿°</th>
<th>Code</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ResearchGPT</strong> ***</td>
<td>plan and execute</td>
<td>èåˆè®ºæ–‡æ‹†è§£+ç½‘ç»œçˆ¬è™«</td>
<td><a href="https://github.com/assafelovic/gpt-researcher">code</a><img src="https://img.shields.io/github/stars/assafelovic/gpt-researcher.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td>WorkGPT</td>
<td>tools</td>
<td>A GPT agent framework for invoking APIs</td>
<td><a href="https://github.com/team-openpm/workgpt">code</a></td>
</tr>
<tr>
<td><strong>AgentTuning</strong><a href="https://www.bilibili.com/video/BV1E84y197Cj/">video</a>  paper</td>
<td>æŒ‡ä»¤å¾®è°ƒAgent</td>
<td>[æ¸…å]</td>
<td><a href="https://github.com/THUDM/AgentTuning">code</a></td>
</tr>
<tr>
<td><strong>ModelScope-Agent</strong> <a href="https://www.bilibili.com/video/BV1u34y137if">video</a></td>
<td>tools, MSAgent-Bench è®­ç»ƒagent</td>
<td>[é˜¿é‡Œé­”å¡”]</td>
<td><a href="https://github.com/modelscope/modelscope-agent">code</a></td>
</tr>
<tr>
<td>open-interpreter</td>
<td>os agent</td>
<td>A natural language interface for computers</td>
<td><a href="https://github.com/KillianLucas/open-interpreter">code</a></td>
</tr>
<tr>
<td>Qwen-Agent <a href="https://www.bilibili.com/video/BV1c34y1P7Yg">video</a></td>
<td></td>
<td>Agent framework and applications built upon Qwen, featuring Function Calling, Code Interpreter, RAG, and Chrome extension</td>
<td><a href="https://github.com/QwenLM/Qwen-Agent">code</a></td>
</tr>
<tr>
<td>AutoGPT-Plugins</td>
<td></td>
<td>Auo-GPTæ’ä»¶</td>
<td><a href="https://github.com/Significant-Gravitas/Auto-GPT-Plugins">code</a></td>
</tr>
<tr>
<td>GPTEngineer</td>
<td>code  assistant</td>
<td><strong>è‡ªåŠ¨</strong>å·¥å…·æ„å»ºå’Œä»£ç ç”Ÿæˆ</td>
<td><a href="https://github.com/AntonOsika/gpt-engineer">code</a><img src="https://img.shields.io/github/stars/AntonOsika/gpt-engineer.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td>Aider</td>
<td>code  assistant</td>
<td><strong>äº¤äº’å¼</strong></td>
<td><a href="https://github.com/paul-gauthier/aider">code</a></td>
</tr>
</tbody></table>
<h1><span id="agentsimulation">Agent(simulation)</span><a href="#agentsimulation" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>Agent(simulation)</th>
<th>ç±»å‹</th>
<th>æè¿°</th>
<th>Code</th>
</tr>
</thead>
<tbody><tr>
<td>Hyperwriteai <a href="https://www.bilibili.com/video/BV1BZ421B7ar/">video</a><a href="https://www.hyperwriteai.com/personal-assistant">website</a>***</td>
<td>web agent, os agent</td>
<td></td>
<td><a href="https://github.com/OthersideAI/self-operating-computer">code</a></td>
</tr>
<tr>
<td><strong>MultiON</strong> <a href="https://www.bilibili.com/video/BV1mt421W7sw/">video</a>***</td>
<td>web agent</td>
<td></td>
<td></td>
</tr>
<tr>
<td>webarena paper</td>
<td>web agent</td>
<td>WebArena: A Realistic Web Environment for Building Autonomous Agents  ç½‘ç»œæ‹ŸçœŸç¯å¢ƒï¼Œå¯ç”¨äºè‡ªä¸»æ™ºèƒ½ä½“çš„æµ‹è¯•ï¼Œæ”¯æŒåœ¨çº¿è´­ç‰©ï¼Œè®ºå›ï¼Œä»£ç ä»“åº“etc</td>
<td><a href="https://github.com/web-arena-x/webarena">code</a></td>
</tr>
<tr>
<td>MiniWoB++ï¼š</td>
<td>web agent</td>
<td>a web interaction benchmark for reinforcement learning</td>
<td><a href="https://github.com/Farama-Foundation/miniwob-plusplus">code</a></td>
</tr>
<tr>
<td><strong>OpenAgents</strong> <a href="https://www.bilibili.com/video/BV1wM41197N7/">video</a> paper***</td>
<td>web agent</td>
<td>[æ¸¯å¤§]</td>
<td><a href="https://github.com/xlang-ai/OpenAgents">code</a></td>
</tr>
<tr>
<td>Mobile-Agent <a href="https://www.bilibili.com/video/BV1Xv42117hh/">video</a></td>
<td>app agent</td>
<td>[é˜¿é‡Œ]</td>
<td></td>
</tr>
<tr>
<td><strong>AppAgent</strong> <a href="https://www.bilibili.com/video/BV1De411S7ka">video</a> [paper]</td>
<td>app agent</td>
<td>[è…¾è®¯]</td>
<td></td>
</tr>
<tr>
<td>CAMEL</td>
<td></td>
<td>CAMEL: Communicative Agents for â€œMindâ€ Exploration of Large Language Model Society</td>
<td><a href="https://github.com/camel-ai/camel">code</a></td>
</tr>
<tr>
<td><strong>Generative Agents</strong></td>
<td></td>
<td>æ–¯å¦ç¦AIå°é•‡</td>
<td><a href="https://github.com/joonspk-research/generative_agents">code</a><img src="https://img.shields.io/github/stars/joonspk-research/generative_agents.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td>AgentVerse</td>
<td></td>
<td>å¤šæ¨¡å‹äº¤äº’ç¯å¢ƒ</td>
<td><a href="https://github.com/OpenBMB/AgentVerse">code</a><img src="https://img.shields.io/github/stars/OpenBMB/AgentVerse.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td>GPTeam</td>
<td>Multi Agent</td>
<td>å¤šæ™ºèƒ½ä½“äº¤äº’</td>
<td><a href="https://github.com/101dotxyz/GPTeam">code</a></td>
</tr>
<tr>
<td><strong>ChatDev</strong><a href="https://www.bilibili.com/video/BV1334y1T7K5/">video</a></td>
<td>Multi Agent</td>
<td>è™šæ‹Ÿè½¯ä»¶å…¬å¸[é¢å£æ™ºèƒ½]</td>
<td><a href="https://github.com/OpenBMB/ChatDev">code</a><img src="https://img.shields.io/github/stars/OpenBMB/ChatDev.svg?style=flat-square" alt="GitHub Badge"></td>
</tr>
<tr>
<td>GPT PILOT</td>
<td></td>
<td><strong>äº¤äº’å¼</strong></td>
<td></td>
</tr>
<tr>
<td>DevOpsGPT</td>
<td></td>
<td>è‡ªåŠ¨</td>
<td></td>
</tr>
</tbody></table>
<h1><span id="agent">Agent</span><a href="#agent" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>Agent</th>
<th>ç±»å‹</th>
<th>æè¿°</th>
<th>Code</th>
</tr>
</thead>
<tbody><tr>
<td>TaskingAI <a href="https://www.bilibili.com/video/BV1gp4y1m75S/">video</a></td>
<td>LLMOps</td>
<td></td>
<td><a href="https://github.com/TaskingAI/TaskingAI">code</a></td>
</tr>
<tr>
<td>DIFY <a href="https://www.bilibili.com/video/BV14V411Q7wP/">video</a></td>
<td>LLMOps</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>AutoGen Studio</strong> <a href="https://www.bilibili.com/video/BV1fi4y1i7g7/">video</a> ***</td>
<td>LLMOps</td>
<td></td>
<td></td>
</tr>
<tr>
<td>L3AGI <a href="https://www.bilibili.com/video/BV1s94y1K7fP">video</a></td>
<td>LLMOps</td>
<td></td>
<td></td>
</tr>
<tr>
<td>agenta</td>
<td>LLMOps</td>
<td>The all-in-one LLM developer platform: prompt management, evaluation, human feedback, and deployment all in one place.</td>
<td><a href="https://github.com/Agenta-AI/agenta">code</a></td>
</tr>
<tr>
<td>SuperAGI</td>
<td>LLMOps</td>
<td></td>
<td></td>
</tr>
<tr>
<td>N8N <a href="https://www.bilibili.com/video/BV1vT4y1h7UM/">video</a></td>
<td>work flow</td>
<td></td>
<td></td>
</tr>
<tr>
<td>TaskWeaver <a href="https://www.bilibili.com/video/BV16C4y1c7rd">video</a></td>
<td></td>
<td>ä»¥ä»£ç ä¸ºä¸­å¿ƒ[å¾®è½¯]</td>
<td></td>
</tr>
<tr>
<td>ProAgent <a href="https://www.bilibili.com/video/BV1eu4y1b7DN">video</a></td>
<td>work flow</td>
<td>[æ¸…å]</td>
<td></td>
</tr>
<tr>
<td>Prompt flow <a href="https://www.bilibili.com/video/BV1aG411m7A4/">video</a></td>
<td></td>
<td>[å¾®è½¯]</td>
<td></td>
</tr>
<tr>
<td>AgentGPT <a href="https://www.bilibili.com/video/BV1V94y1s7uT">video</a></td>
<td>agent store, agent template</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Bisheng *</td>
<td></td>
<td>dify+flowiseçš„ç»“åˆä½“</td>
<td></td>
</tr>
</tbody></table>
<h1><span id="åº”ç”¨">åº”ç”¨</span><a href="#åº”ç”¨" class="header-anchor">#</a></h1><h3><span id="åˆ†ç±»-101112">åˆ†ç±» [10][11][12]</span><a href="#åˆ†ç±»-101112" class="header-anchor">#</a></h3><ul>
<li><p>Action agents  </p>
<ul>
<li>Function Call</li>
<li>ReACT</li>
</ul>
</li>
<li><p>Simulation agents<br>  ç”Ÿæˆå¼æ™ºèƒ½ä½“ï¼Œ CAMELï¼Œ  Generative Agents</p>
</li>
<li><p>Automomous Agent<br>  <strong>AutoGPT</strong>ï¼Œ <strong>BabyAGI</strong>,  <strong>AutoGen</strong><br>  <strong>MetaGPT</strong>     ChatDev</p>
</li>
<li><p>è·¨æ¨¡æ€Agents<br>  HuggingGPT</p>
</li>
</ul>
<h3><span id="hugginggpt">HuggingGPT</span><a href="#hugginggpt" class="header-anchor">#</a></h3><h3><span id="babyagi-aigc">BabyAGI  [AIGC]</span><a href="#babyagi-aigc" class="header-anchor">#</a></h3><p>Plan-and-execute agents<br>The <strong>planning</strong> is almost always done <strong>by an LLM</strong>.<br>The <strong>execution</strong> is usually done by a <strong>separate agent (equipped with tools)</strong>.</p>
<h3><span id="autogpt10">AutoGPT[10]</span><a href="#autogpt10" class="header-anchor">#</a></h3><p>AutoGPT çš„æ ¸å¿ƒé€»è¾‘æ˜¯ä¸€ä¸ª Prompt Loopï¼Œæ­¥éª¤å¦‚ä¸‹</p>
<ol>
<li>AutoGPT ä¼šåŸºäºä¸€å®šç­–ç•¥è‡ªåŠ¨ç»„è£… Command Promptï¼Œè¿™äº›é¦–æ¬¡ä¼šåŒ…å«ç”¨æˆ·è¾“å…¥çš„ Name, Roleå’ŒGoals </li>
<li>Command Prompt çš„ç›®æ ‡ä¸æ˜¯ä¸ºäº†æ‹¿åˆ°æœ€ç»ˆç»“æœï¼Œè€Œæ˜¯é€šè¿‡ GPT Chat API(Thinking çš„è¿‡ç¨‹)è¿”å›ä¸‹ä¸€æ­¥çš„ Command (åŒ…å«nameå’Œarguments, å¦‚<code>browser_website(url = &quot;www.baidu.com&quot;)</code> )</li>
<li>è¿™äº› Command éƒ½æ˜¯å¯æ‰©å±•çš„ï¼Œæ¯ä¸€ç§å‘½ä»¤ä»£è¡¨ä¸€ç§å¤–éƒ¨èƒ½åŠ›(æ¯”å¦‚çˆ¬è™«ã€Googleæœç´¢ï¼Œä¹ŸåŒ…æ‹¬GPTçš„èƒ½åŠ›)ï¼Œé€šè¿‡è¿™äº› Command è°ƒç”¨è¿”å›çš„ Result åˆä¼šæˆä¸ºåˆ° Command Prompt çš„ç»„æˆå…ƒç´ ï¼Œ</li>
<li>å›åˆ°ç¬¬ 1 æ­¥å¾€å¤å¾ªç¯ï¼Œç›´åˆ°æ‹¿åˆ°æœ€ç»ˆç»“æœç»“æœï¼ˆçŠ¶æ€ä¸ºâ€œcompeleteâ€ï¼‰</li>
</ol>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://github.com/www6v/awesome-ai-agents">awesome-ai-agents</a> git list</li>
<li><a href="https://github.com/www6v/DecryptPrompt">DecryptPrompt</a>  ***  git list</li>
<li><a href="https://space.bilibili.com/471000665/video?tid=0&pn=1&keyword=&order=pubdate">AIGCLINK</a> V</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/664281311">ã€ŒAgentã€é€šä¿—æ˜“æ‡‚åœ°èŠèŠAI Agentï¼ˆé™„66ä¸ªå¼€æº+44ä¸ªé—­æºAgenté¡¹ç›®ï¼‰</a></p>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://zhuanlan.zhihu.com/p/642357544">2023å¹´æ–°ç”Ÿä»£å¤§æ¨¡å‹AgentsæŠ€æœ¯,ReAct,Self-Ask,Plan-and-execute,ä»¥åŠAutoGPT, HuggingGPTç­‰åº”ç”¨</a> ***  è®ºæ–‡+ä»£ç </li>
<li>å…¬å¼€è¯¾</li>
<li>å…¬å¼€è¯¾</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>Agent</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Agent</title>
    <url>/www6vHomeAIGC/2022/11/02/gptAgent/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%9E%B6%E6%9E%84%E5%9B%BE">æ¶æ„å›¾</a><ul>
<li><a href="#%E7%BB%84%E4%BB%B6-1">ç»„ä»¶ [1]</a></li>
<li><a href="#planning-1">Planning [1]</a></li>
<li><a href="#memory-1">Memory [1]</a></li>
<li><a href="#tool-use-1">Tool Use [1]</a></li>
</ul>
</li>
<li><a href="#agentic-reasoning-design-patterns10">Agentic Reasoning Design Patterns[10]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#xxx">xxx</a></li>
<li><a href="#xxx-1">xxx</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="æ¶æ„å›¾">æ¶æ„å›¾</span><a href="#æ¶æ„å›¾" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/11/02/gptAgent/agent-overview.jpg" class>

<h3><span id="ç»„ä»¶-1">ç»„ä»¶  [1]</span><a href="#ç»„ä»¶-1" class="header-anchor">#</a></h3><p>Agent &#x3D; LLM + plan[è§„åˆ’èƒ½åŠ›] + memory[è®°å¿†èƒ½åŠ›] +Tools[å·¥å…·ä½¿ç”¨èƒ½åŠ›] </p>
<h3><span id="planning-1">Planning [1]</span><a href="#planning-1" class="header-anchor">#</a></h3><ul>
<li><p>Task Decomposition</p>
<ul>
<li>CoT </li>
<li>ToT</li>
</ul>
</li>
<li><p>Self-Reflection</p>
<ul>
<li>ReAct </li>
<li>Reflexion </li>
<li>Chain of Hindsight</li>
</ul>
</li>
</ul>
<h3><span id="memory-1">Memory [1]</span><a href="#memory-1" class="header-anchor">#</a></h3><ul>
<li>Types of Memory<ul>
<li><strong>Sensory memory</strong> as learning <strong>embedding representations for raw inputs, including text, image or other modalities</strong>;</li>
<li><strong>Short-term memory</strong> as <strong>in-context learning</strong>. It is short and finite, as it is restricted by the finite context window length of Transformer.</li>
<li><strong>Long-term memory</strong> as the external <strong>vector store</strong> that the agent can attend to at query time, accessible via fast retrieval.</li>
</ul>
</li>
</ul>
<h3><span id="tool-use-1">Tool Use [1]</span><a href="#tool-use-1" class="header-anchor">#</a></h3><ul>
<li><p>è®© agent é€‰æ‹©åˆé€‚çš„å·¥å…· [2]</p>
<ul>
<li>å¯ä»¥ retrieve ç›¸å…³ç¤ºä¾‹æ¥åš <strong>few-shot prompt</strong>ã€‚</li>
<li>ä¹Ÿå¯ä»¥è¿›ä¸€æ­¥ <strong>fine tune ç‰¹å®šæ¨¡å‹</strong>ï¼Œä¾‹å¦‚ä¹‹å‰çš„ Toolformerã€‚</li>
</ul>
</li>
<li><p>Research</p>
<ul>
<li><strong>TALM</strong> (Tool Augmented Language Models; Parisi et al. 2022) [1]</li>
<li><strong>Toolformer</strong> (Schick et al. 2023)   [1]</li>
<li><strong>Gorilla</strong> [2]</li>
</ul>
</li>
<li><p>Production  [1]</p>
<ul>
<li>ChatGPT <strong>Plugins</strong> </li>
<li>OpenAI API <strong>function calling</strong></li>
</ul>
</li>
</ul>
<h1><span id="agentic-reasoning-design-patterns10">Agentic Reasoning Design Patterns[10]</span><a href="#agentic-reasoning-design-patterns10" class="header-anchor">#</a></h1><ul>
<li>robust technology<ul>
<li>Reflectionï¼šè®© Agent å®¡è§†å’Œä¿®æ­£è‡ªå·±ç”Ÿæˆçš„è¾“å‡ºï¼›</li>
<li>Tool Useï¼šLLM ç”Ÿæˆä»£ç ã€è°ƒç”¨ API ç­‰è¿›è¡Œå®é™…æ“ä½œï¼›</li>
</ul>
</li>
<li>emerging technology<ul>
<li>Planningï¼šè®© Agent åˆ†è§£å¤æ‚ä»»åŠ¡å¹¶æŒ‰è®¡åˆ’æ‰§è¡Œï¼›</li>
<li>Multiagent Collaborationï¼šå¤šä¸ª Agent æ‰®æ¼”ä¸åŒè§’è‰²åˆä½œå®Œæˆä»»åŠ¡ï¼›</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h3><ol>
<li><a href="https://lilianweng.github.io/posts/2023-06-23-agent/">LLM Powered Autonomous Agents </a> paper</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/656676717">ã€Šç»¼è¿°ï¼šå…¨æ–°å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„Agentã€‹</a>  ***</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/648376562">LLM-based Agents survey åŸºäºå¤§è¯­è¨€æ¨¡å‹å¤šæ™ºèƒ½ä»£ç†ç®€å•ç»¼è¿°åŠå±•æœ›</a> ***</p>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><ol start="2">
<li><a href="https://zhuanlan.zhihu.com/p/633033220">LLM å…¨æ ˆå¼€å‘æŒ‡å—è¡¥é—</a>  Agents  ***<br><a href="https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/chase-agents/">Harrison Chase: Agents</a>  ***</li>
</ol>
<p>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/135868163?spm=1001.2014.3001.5502">æ™ºèƒ½ä½“AI Agentçš„æé€Ÿå…¥é—¨ï¼šä»ReActã€AutoGPTåˆ°AutoGenã€QwenAgentã€XAgentã€MetaGPT</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/679032270">LLM Agent ç°çŠ¶å’Œä¸€äº›æ€è€ƒ ï¼ˆ202401ï¼‰</a><br>   agentçš„ä¸‰ç§è§†è§’</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/622947810">AutoGPTä¸LLM Agentè§£æ</a> *** </p>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://mp.weixin.qq.com/s/4ky_OSLrHh2MxdT3AjqW1Q">å´æ©è¾¾çº¢æ‰ç¾å›½ AI å³°ä¼šè°ˆ Agent Workflow ä»¥åŠ 4 ç§ä¸»æµè®¾è®¡æ¨¡å¼ï¼Œç›¸æ¯” LLM æ›´å¼ºè°ƒè¿­ä»£ä¸å¯¹è¯ </a><br>1xx. <a href="https://mp.weixin.qq.com/s/DyXv9nxFQJYUrAFr22BCCA">æ·±åº¦ï½œç›˜ç‚¹ 3 ç§ OpenAI ç­‰ç¡…è°· AI å¤§å‚åœ¨ç ” Agent ç±»å‹</a><br>1xx. <a href="https://mp.weixin.qq.com/s/8k2Qo5vIJ2Gvm9QLFtZA4Q">Agentè½åœ°èŒƒå¼æœ¬è´¨ä¸Šæ˜¯å·¥ç¨‹åŠäº§å“è®¾è®¡ä¸Šçš„èŠ±æ´»ï¼šå…¼çœ‹æ–‡æ¡£å›¾è¡¨ç†è§£çš„å‡ ä¸ªå…³é”®é—®é¢˜</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent å¤šæ¨¡æ€</title>
    <url>/www6vHomeAIGC/2023/02/21/gptAgentMultimodal/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h3><span id="ç»¼è¿°">ç»¼è¿°</span><a href="#ç»¼è¿°" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=Mzg5NTc2OTcyOQ==&mid=2247488499&idx=1&sn=ac8c5092ddc8fd724965d12aff3f9392">2024å¹´å¤§å‹å¤šæ¨¡æ€æ™ºèƒ½ä½“(Large Multimodal Agents)ç»¼è¿°ï¼šç»„ä»¶, åˆ†ç±»ï¼Œåä½œï¼Œè¯„ä¼°ï¼Œåº”ç”¨ï¼Œå±•æœ›</a> ***</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/678238642">ä¸ªäººLLMæ™ºä½“çš„ç»¼è¿°</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/678203245">æ™ºä½“AIåœ¨å¤šæ¨¡æ€äº¤äº’é¢†åŸŸçš„ç»¼è¿°ï¼ˆä¸Šï¼‰</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/678222381">æ™ºä½“AIåœ¨å¤šæ¨¡æ€äº¤äº’é¢†åŸŸçš„ç»¼è¿°ï¼ˆä¸‹ï¼‰</a></p>
<h3><span id="app-agent">App Agent</span><a href="#app-agent" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/677071947">AppAgentæºç åˆ†æ&amp;æ€è€ƒ</a><br><a href="https://github.com/mnotgod96/AppAgent">https://github.com/mnotgod96/AppAgent</a><br><a href="https://icoz69.github.io/">https://icoz69.github.io/</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/681424409">ã€LLM-agentã€‘MOBILE-AGENT: å…·æœ‰è§†è§‰æ„ŸçŸ¥èƒ½åŠ›çš„è‡ªæ²»å¤šæ¨¡ç§»åŠ¨è®¾å¤‡agent</a><br>   <a href="https://github.com/X-PLUG/MobileAgent">https://github.com/X-PLUG/MobileAgent</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper-Agent</title>
    <url>/www6vHomeAIGC/2023/03/04/gptAgentPaper/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<p>1xx. <a href="https://github.com/zjunlp/LLMAgentPapers">LLM Agents Papers</a> ***</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/662506575">28 ç¯‡æœ€æ–°è®ºæ–‡è§£è¯» LLMs-based Agents</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/661741663">ICLRâ€™24 Agentè®ºæ–‡åˆé›†ï¼šRL-basedã€LLM-based å‰æ²¿ç ”ç©¶æ±‡æ€»</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/665282216">ICLRâ€™24 å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æœ€æ–°ç ”ç©¶è¿›å±•ä¸¨æ™ºèƒ½ä½“åº”ç”¨ç¯‡</a><br>1xx. <a href="https://mp.weixin.qq.com/s/GGRWQJ-eBvHerB9H9JPCjg">ICLRâ€™24 å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æœ€æ–°ç ”ç©¶è¿›å±•ä¸¨æ™ºèƒ½ä½“èƒ½åŠ›ç¯‡ </a><br>   <a href="https://mp.weixin.qq.com/s/eYnZY1GFWMKdU_Z57iSEJg">ICLRâ€™24 å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æœ€æ–°ç ”ç©¶è¿›å±• </a><br>1xx. <a href="https://github.com/www6v/LLM-Agents-Papers"> LLM-Agents-Papers</a></p>
<p>1xx. <a href="https://www.bilibili.com/read/cv27126779/">AGIæ–°çªç ´ï¼52ç¯‡è®ºæ–‡å°½è§ˆå¤§æ¨¡å‹Agentæœ€æ–°ç ”ç©¶è¿›å±•ï¼</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/673788545">AI Agent &amp; å¤§æ¨¡å‹ç»å…¸è®ºæ–‡æ¨è</a>  ***</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>Agent</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†|å®æˆ˜)Plan&amp;Execute,ReWOO</title>
    <url>/www6vHomeAIGC/2023/03/02/gptAgentPlanAndExecute/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="plan-and-execute-0">Plan-and-execute [0]</span><a href="#plan-and-execute-0" class="header-anchor">#</a></h1><ul>
<li><p>åŸç†</p>
<ul>
<li>Figure 2 - åŸºäºprompt [1]</li>
</ul>
</li>
<li><p>ä»£ç </p>
<ul>
<li>plan [2]<ul>
<li>Planning Step</li>
<li>Re-Plan Step</li>
</ul>
</li>
</ul>
</li>
<li><p>é—®é¢˜</p>
<ul>
<li>å†—ä½™çš„æç¤ºå’Œé‡å¤çš„æ‰§è¡Œ -&gt; ReWOO</li>
</ul>
</li>
</ul>
<h1><span id="rewoo-0">ReWOO [0]</span><a href="#rewoo-0" class="header-anchor">#</a></h1><ul>
<li><p>åŸç†</p>
<ul>
<li>Abstract [10]<br>å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆALMï¼‰å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ä¸å…è®¸çŸ¥è¯†æ£€ç´¢å’Œæ‰§è¡Œæ“ä½œçš„å·¥å…·ç›¸ç»“åˆã€‚ç°æœ‰çš„ALMç³»ç»Ÿä»¥äº¤é”™çš„æ–¹å¼è§¦å‘LLMçš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒæ—¶ä»è¿™äº›å·¥å…·ä¸­è·å–è§‚å¯Ÿç»“æœã€‚<strong>å…·ä½“è€Œè¨€ï¼ŒLLMæ¨ç†è¿‡ç¨‹ä¸­ä¼šè°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œç„¶ååœ¨è·å–å·¥å…·å“åº”ååœæ­¢ï¼ŒåŸºäºä¹‹å‰çš„å“åº”ä»¤ç‰Œæ¥å†³å®šä¸‹ä¸€æ­¥çš„æ“ä½œã€‚è¿™ç§èŒƒå¼è™½ç„¶ç›´è§‚ä¸”æ˜“äºå®ç°ï¼Œä½†å¸¸å¸¸ç”±äºå†—ä½™çš„æç¤ºå’Œé‡å¤çš„æ‰§è¡Œè€Œå¯¼è‡´è®¡ç®—å¤æ‚åº¦æé«˜</strong>ã€‚æœ¬ç ”ç©¶é¦–æ¬¡è§£å†³äº†è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ¨¡å—åŒ–çš„èŒƒå¼ReWOOï¼ˆæ— è§‚å¯Ÿæ¨ç†ï¼‰ï¼Œ<strong>å°†æ¨ç†è¿‡ç¨‹ä¸å¤–éƒ¨è§‚å¯Ÿç»“æœåˆ†ç¦»ï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†ä»¤ç‰Œçš„æ¶ˆè€—</strong>ã€‚</li>
<li>Figure 1 [10]<br>Planneré‡Œæœ‰æ ¼å¼åŒ–çš„#E</li>
<li>Figure 2  [10]</li>
</ul>
</li>
<li><p>ä»£ç  [11]</p>
<ul>
<li>Executor-tool_execution() -&gt; çŠ¶æ€æœº</li>
</ul>
</li>
<li><p>é—®é¢˜</p>
<ul>
<li>æ˜¯å¦å¯ä»¥å¹¶è¡Œï¼Ÿ-&gt; LLMCompiler</li>
</ul>
</li>
</ul>
<h1><span id="llmcompiler">LLMCompiler</span><a href="#llmcompiler" class="header-anchor">#</a></h1><ul>
<li><p>åŸç†</p>
<ul>
<li>Abstract [20]<br>LLMçš„å¤šå‡½æ•°è°ƒç”¨èƒ½åŠ›å‚¬ç”Ÿäº†åŸºäºLLMçš„è½¯ä»¶å¼€å‘ï¼Œä½¿å…¶èƒ½å¤Ÿè§£å†³æ›´å¤æ‚çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œå½“å‰çš„å¤šå‡½æ•°è°ƒç”¨æ–¹æ³•é€šå¸¸éœ€è¦<strong>é’ˆå¯¹æ¯ä¸ªå‡½æ•°è¿›è¡Œé¡ºåºæ¨ç†å’Œæ‰§è¡Œï¼Œè¿™å¯èƒ½å¯¼è‡´è¾ƒé«˜çš„å»¶è¿Ÿã€æˆæœ¬ä»¥åŠä¸å‡†ç¡®çš„è¡Œä¸º</strong>ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†LLMCompilerï¼Œå®ƒå¯ä»¥<strong>å¹¶è¡Œæ‰§è¡Œå‡½æ•°ï¼Œä»¥é«˜æ•ˆåœ°ç¼–æ’å¤šå‡½æ•°è°ƒç”¨</strong>ã€‚LLMCompiler<strong>å€Ÿé‰´äº†ç»å…¸ç¼–è¯‘å™¨çš„åŸç†</strong>ï¼Œåœ¨LLMä¸­ä½¿ç”¨<strong>ä¸‰ä¸ªç»„ä»¶</strong>æ¥ç®€åŒ–å¹¶è¡Œå‡½æ•°è°ƒç”¨ï¼šï¼ˆiï¼‰LLMè§„åˆ’å™¨ï¼Œåˆ¶å®šæ‰§è¡Œç­–ç•¥å’Œä¾èµ–å…³ç³»ï¼›ï¼ˆiiï¼‰ä»»åŠ¡è·å–å•å…ƒï¼Œåˆ†æ´¾å’Œæ›´æ–°å‡½æ•°è°ƒç”¨ä»»åŠ¡ï¼›ï¼ˆiiiï¼‰æ‰§è¡Œå™¨ï¼Œä»¥å¹¶è¡Œæ–¹å¼æ‰§è¡Œè¿™äº›ä»»åŠ¡ã€‚é€šè¿‡LLMCompilerï¼Œç”¨æˆ·å¯ä»¥æŒ‡å®šå·¥å…·ä»¥åŠå¯é€‰çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼ŒLLMCompilerä¼šè‡ªåŠ¨è®¡ç®—å‡½æ•°è°ƒç”¨çš„ä¼˜åŒ–ç¼–æ’ã€‚é‡è¦çš„æ˜¯ï¼ŒLLMCompilerå¯ä»¥ä¸LLaMA-2ç­‰å¼€æºæ¨¡å‹ä»¥åŠOpenAIçš„GPTæ¨¡å‹ä¸€èµ·ä½¿ç”¨ã€‚</li>
<li>Figure 2  [20]</li>
</ul>
</li>
<li><p>ä»£ç  [21]</p>
<ul>
<li>Planner</li>
<li>Task Fetching Unit </li>
<li>Joiner</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="plan-and-execute">Plan-and-execute</span><a href="#plan-and-execute" class="header-anchor">#</a></h3><ol start="0">
<li><a href="https://www.bilibili.com/video/BV1vJ4m1s7Zn/">LangGraphï¼šPlan-Execute Agents å®æˆ˜</a> V<br><a href="https://blog.langchain.dev/planning-agents/">Plan-and-Execute Agents</a> ***</li>
<li><a href="https://arxiv.org/pdf/2305.04091.pdf">Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought<br>Reasoning by Large Language Models</a>  Figure 2</li>
<li><a href="https://github.com/langchain-ai/langgraph/blob/main/examples/plan-and-execute/plan-and-execute.ipynb">plan-and-execute</a>    git</li>
</ol>
<h3><span id="rewoo">ReWOO</span><a href="#rewoo" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://arxiv.org/pdf/2305.18323.pdf">ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models</a></li>
<li><a href="https://github.com/langchain-ai/langgraph/blob/main/examples/rewoo/rewoo.ipynb">Reasoning without Observation</a> git<br><a href="https://www.bilibili.com/video/BV1Au4m1N7ix/">ReWoo Agentæ¡†æ¶ä»£ç å®ç°</a> V<br>1xx.  <a href="https://zhuanlan.zhihu.com/p/671491031">ReWOO: é«˜æ•ˆå¢å¼ºè¯­è¨€æ¨¡å‹ä¸­è§£å¶è§‚æµ‹å’Œæ¨ç†</a></li>
</ol>
<h3><span id="llmcompiler">LLMCompiler</span><a href="#llmcompiler" class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://arxiv.org/pdf/2312.04511v1.pdf">An LLM Compiler for Parallel Function Calling</a></li>
<li><a href="https://github.com/langchain-ai/langgraph/blob/main/examples/llm-compiler/LLMCompiler.ipynb">LLMCompiler</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>Agent</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent Planning</title>
    <url>/www6vHomeAIGC/2023/05/13/gptAgentPlanning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="types1">Types[1]</span><a href="#types1" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/05/13/gptAgentPlanning/plans.webp" class>

<ul>
<li><p><strong>ä»»åŠ¡åˆ†è§£</strong> </p>
</li>
<li><p>å¤šè®¡åˆ’é€‰æ‹©</p>
</li>
<li><p>å¤–éƒ¨è§„åˆ’å™¨è¾…åŠ©è§„åˆ’</p>
</li>
<li><p><strong>åæ€å’Œæç‚¼</strong>[20] </p>
</li>
<li><p>è®°å¿†å¢å¼ºè§„åˆ’</p>
</li>
</ul>
<h1><span id="ä»»åŠ¡åˆ†è§£">ä»»åŠ¡åˆ†è§£</span><a href="#ä»»åŠ¡åˆ†è§£" class="header-anchor">#</a></h1><ul>
<li><p>ReACT èŒƒå¼ [2]<br>æŠŠ<strong>èåˆäº†Reasoningå’ŒActing</strong>çš„ä¸€ç§èŒƒå¼ï¼Œæ¨ç†è¿‡ç¨‹æ˜¯æµ…æ˜¾æ˜“æ‡‚ï¼Œä»…ä»…<strong>åŒ…å«thought-action-observationæ­¥éª¤</strong>ï¼Œå¾ˆå®¹æ˜“åˆ¤æ–­æ¨ç†çš„è¿‡ç¨‹çš„æ­£ç¡®æ€§ï¼Œä½¿ç”¨ReActåšå†³ç­–ç”šè‡³è¶…è¿‡äº†å¼ºåŒ–å­¦ä¹ .  </p>
<ul>
<li>chain-of-thoughtæ¨ç†-é—®é¢˜<br> äº‹å®å¹»æƒ³ï¼ˆfact hallucinationï¼‰å’Œé”™è¯¯ä¼ é€’ï¼ˆerror propagationï¼‰</li>
</ul>
</li>
<li><p>Plan-and-execute agents [2]<br>æœ¬è´¨ä¸Šæ˜¯å…ˆè®¡åˆ’å†æ‰§è¡Œï¼Œå³å…ˆæŠŠç”¨æˆ·çš„é—®é¢˜åˆ†è§£æˆä¸€ä¸ªä¸ªçš„å­ä»»åŠ¡ï¼Œç„¶åå†æ‰§è¡Œå„ä¸ªå­ä»»åŠ¡ï¼Œæœ€ååˆå¹¶è¾“å‡ºå¾—åˆ°ç»“æœ</p>
</li>
</ul>
<h1><span id="patterns">Patterns</span><a href="#patterns" class="header-anchor">#</a></h1><ul>
<li>Self-ask [2]<br>Self-askæ˜¯ä¸€ç§follow-upçš„ä½¿ç”¨èŒƒå¼ï¼Œä»…ä»…åŒ…å«follow-up, immediate answeræ­¥éª¤ï¼Œè‡³äºfollow-upå¤šå°‘ä¸ªstepï¼Œå®Œå…¨ç”±å®ƒè‡ªå·±å†³å®šï¼Œä¼°è®¡è¿™å°±æ˜¯Self-askçš„åå­—çš„ç”±æ¥ã€‚</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://mp.weixin.qq.com/s/1POXDVJDv3ob1HqpKjb3Mg">å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è§„åˆ’èƒ½åŠ›ç»¼è¿°: åˆ†ç±»ã€ä»»åŠ¡åˆ†è§£ã€é€‰æ‹©ã€åæ€ã€è®°å¿†å¢å¼º </a> ç¿»è¯‘</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/642357544">2023å¹´æ–°ç”Ÿä»£å¤§æ¨¡å‹AgentsæŠ€æœ¯,ReAct,Self-Ask,Plan-and-execute,ä»¥åŠAutoGPT, HuggingGPTç­‰åº”ç”¨</a> ***  è®ºæ–‡+ä»£ç </p>
</li>
<li><a href="/www6vHomeAIGC/2023/04/07/gptAgentReflection/" title="Reflection Agent">Reflection Agent</a> self</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s/NhpJMmIcnF57qEuUkxD4kQ">AI Agentè§„åˆ’èƒ½åŠ›å…¨é¢æ‹†è§£</a></p>
<p>1xx. <a href="https://baoyu.io/translations/ai-paper/2311.11797-igniting-language-intelligence-the-hitchhikers-guide-from-chain-of-thought-reasoning-to-language-agents">å¼•é¢†è¯­è¨€æ™ºèƒ½ï¼šä»æ€ç»´é“¾æ¨ç†åˆ°è¯­è¨€æ™ºèƒ½ä½“çš„æ¢ç´¢æŒ‡å— [è¯‘]</a> paper</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=Mzg5NTc2OTcyOQ==&mid=2247488040&idx=1&sn=f404a5fc2b0380eac00564046abc77d5">2023å¹´å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è§„åˆ’æŠ€æœ¯(LLM Agent Planning)ç ”ç©¶è¿›å±•æ±‡æ€»</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)Agent</title>
    <url>/www6vHomeAIGC/2023/01/01/gptAgentPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%BE%AE%E8%B0%83%E7%9A%84agent-function-call12">åŸºäºå¾®è°ƒçš„Agent-function call[1][2]</a></li>
<li><a href="#assistant-api-3">Assistant API [3]</a><ul>
<li><a href="#assistant-api%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D">Assistant APIåŠŸèƒ½ä»‹ç»</a></li>
<li><a href="#%E5%AE%9E%E6%88%98">å®æˆ˜</a></li>
</ul>
</li>
<li><a href="#lagent-agentlego4">Lagent &amp; AgentLego[4]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="åŸºäºå¾®è°ƒçš„agent-function-call12">åŸºäºå¾®è°ƒçš„Agent-function call[1][2]</span><a href="#åŸºäºå¾®è°ƒçš„agent-function-call12" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/01/gptAgentPractice/dirs.JPG" class>

<img src="/www6vHomeAIGC/2023/01/01/gptAgentPractice/xtuner-agent.png" class>

<h1><span id="assistant-api-3">Assistant API [3]</span><a href="#assistant-api-3" class="header-anchor">#</a></h1><h3><span id="assistant-apiåŠŸèƒ½ä»‹ç»">Assistant APIåŠŸèƒ½ä»‹ç»</span><a href="#assistant-apiåŠŸèƒ½ä»‹ç»" class="header-anchor">#</a></h3><p>ä»åŠŸèƒ½å®ç°å±‚é¢æ¥è¯´ï¼ŒAssistant APIæ˜¯æˆªè‡³ç›®å‰æœ€å®Œæ•´ã€æ€§èƒ½æœ€å¼ºå¤§çš„AIåº”ç”¨å¼€å‘APIï¼Œå…·ä½“åŠŸèƒ½å¦‚ä¸‹ï¼š</p>
<ul>
<li>é¦–å…ˆï¼ŒAssistant APIå‰æ‰€æœªæœ‰çš„èƒ½å¤Ÿ<strong>è°ƒç”¨OpenAIå„æ¨¡å‹çš„å„é¡¹èƒ½åŠ›</strong>ï¼ŒåŒ…æ‹¬å¯ä»¥è°ƒç”¨Chatç³»åˆ—æ¨¡å‹ï¼ˆå³GPTç³»åˆ—æ¨¡å‹ï¼‰å®Œæˆæ–‡æœ¬å¯¹è¯ã€è°ƒç”¨DALLÂ·E 3è¿›è¡Œç»˜å›¾ã€è°ƒç”¨GPT-4-visionè¿›è¡Œå›¾åƒè¯†åˆ«ã€ä»¥åŠè°ƒç”¨Text-to-Speechæ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ç­‰ï¼Œå¹¶ä¸”æ”¯æŒåœ¨ä¸€è½®å¯¹è¯ä¸­è°ƒç”¨ä¸åŒæ¨¡å‹ï¼›</li>
<li>å…¶æ¬¡ï¼ŒAssistant APIè¿˜<strong>å†…ç½®äº†ä»£ç è§£é‡Šå™¨åŠŸèƒ½ï¼ˆCode interpreterï¼‰å’Œæµ·é‡æ–‡æœ¬ä¿¡æ¯æå–åŠŸèƒ½ï¼ˆKnowledge retrievalï¼‰</strong>åŒæ—¶ä¹Ÿä¸€å¦‚æ—¢å¾€æ”¯æŒå€ŸåŠ©<strong>Function calling</strong>è¿›è¡Œæ¨¡å‹åŠŸèƒ½å±‚é¢æ‹“å±•ï¼Œæ­¤å¤–ï¼Œéå¸¸é‡è¦çš„æ˜¯ï¼ŒAssistant APIè¿˜æ”¯æŒåœ¨ä¸€è½®å¯¹è¯ä¸­è°ƒç”¨å¤šä¸ªå·¥å…·ï¼›</li>
<li>å…¶ä¸‰ï¼Œæ­¤å¤–å¯¹äºå¼€å‘è€…éå¸¸å‹å¥½çš„ä¸€ç‚¹æ˜¯ï¼ŒAssistant APIæœ€å°è¿è¡Œå•å…ƒä¸ºæŒä¹…åŒ–çš„çº¿ç¨‹å¯¹è±¡ï¼ˆpersistent Threadsï¼‰ï¼Œå› æ­¤åœ¨å®é™…è¿è¡ŒAssistant APIæ—¶ï¼Œä¸ä»…èƒ½å¯ä»¥ç²¾ç¡®æ§åˆ¶æ¯ä¸€æ­¥çš„æ‰§è¡Œè¿‡ç¨‹ï¼ŒåŒæ—¶persistent Threadsä¹Ÿä¼šä¿ç•™æ¯è½®å¯¹è¯çš„æ ¸å¿ƒä¿¡æ¯ï¼Œå¹¶ä¸”å½“è¶…å‡ºæ¨¡å‹æ¥æ”¶ä¿¡æ¯æœ€å¤§ä¸Šä¸‹æ–‡é™åˆ¶æ—¶èƒ½å¤Ÿè‡ªåŠ¨åˆ é™¤æ—©æœŸä¿¡æ¯ï¼Œä»è€Œå®ç°å¯¹æ¨¡å‹çŸ­æœŸè®°å¿†çš„åˆç†ç®¡ç†ï¼›</li>
<li>å…¶å››ï¼ŒAssistant APIè¿˜èƒ½å¤Ÿç›´<strong>æ¥è¿æ¥OpenAIåœ¨çº¿æ–‡æ¡£åº“</strong>ï¼Œå³å¦‚æœç”¨æˆ·å°†å¤–éƒ¨æ–‡æ¡£ä¿å­˜åœ¨OpenAIäº‘ç©ºé—´å†…ï¼Œåˆ™å¯ä»¥åœ¨è°ƒç”¨Assistant APIæ—¶å®æ—¶è®¿é—®æ–‡æ¡£åº“ä¸­çš„ä»»æ„æ–‡ä»¶ï¼Œç”šè‡³å¯ä»¥åœ¨ä¸åŒçº¿ç¨‹ä¸­è°ƒç”¨ä¸åŒçš„æ–‡æ¡£ã€‚è€Œåœ¨å€ŸåŠ©Assistant APIçš„Knowledge retrievalåŠŸèƒ½ï¼Œåˆ™å¯ä»¥è®©å¤§æ¨¡å‹å®æ—¶è·å–è¿™äº›æ–‡ä»¶ä¿¡æ¯ï¼Œå¹¶ä¸”åˆç†ç®¡ç†çŸ­æœŸè®°å¿†ï¼›</li>
</ul>
<h3><span id="å®æˆ˜">å®æˆ˜</span><a href="#å®æˆ˜" class="header-anchor">#</a></h3><h1><span id="lagent-amp-agentlego4">Lagent &amp; AgentLego[4]</span><a href="#lagent-amp-agentlego4" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://github.com/InternLM/tutorial/blob/main/xtuner/README.md">xtuner å®æˆ˜</a><br>4ã€è¡¥å……ã€‘ç”¨ MS-Agent æ•°æ®é›† èµ‹äºˆ LLM ä»¥ Agent èƒ½åŠ›</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1yK4y1B75J/">(4)XTuner å¤§æ¨¡å‹å•å¡ä½æˆæœ¬å¾®è°ƒå®æˆ˜</a> V</p>
</li>
<li><p><a href="https://github.com/www6v/AIGC/tree/master/basic/%E4%B9%9D%E5%A4%A9Hector/Assistant%20API%E8%AF%A6%E8%A7%A3%E4%B8%8EAgent%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98">Assistant APIè¯¦è§£ä¸Agentå¼€å‘å®æˆ˜-ä¹å¤©Hector</a></p>
</li>
<li><p><a href="https://github.com/InternLM/Tutorial/tree/camp2/agent">Lagent &amp; AgentLego æ™ºèƒ½ä½“åº”ç”¨æ­å»º</a><br><a href="https://github.com/InternLM/Tutorial/blob/camp2/agent/lagent.md">Lagentï¼šè½»é‡çº§æ™ºèƒ½ä½“æ¡†æ¶</a><br><a href="https://github.com/InternLM/Tutorial/blob/camp2/agent/agentlego.md">AgentLegoï¼šç»„è£…æ™ºèƒ½ä½“â€œä¹é«˜â€</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>Reflection Agent</title>
    <url>/www6vHomeAIGC/2023/04/07/gptAgentReflection/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="react">ReAct</span><a href="#react" class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://react-lm.github.io/">ReAct: Synergizing Reasoning and Acting in Language Models</a> paper</li>
</ol>
<h3><span id="reflexion">Reflexion</span><a href="#reflexion" class="header-anchor">#</a></h3><ol start="21">
<li><a href="https://zhuanlan.zhihu.com/p/639254455">ã€è®ºæ–‡é˜…è¯»ã€‘Reflexion: å¤§æ¨¡å‹å¦‚ä½•ä»é”™è¯¯ç»éªŒä¸­å­¦ä¹ ï¼Ÿ</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/671508578">Reflexion: å¸¦è¨€è¯­å¼ºåŒ–å­¦ä¹ çš„è¯­è¨€æ™ºä½“</a><br>   1xx. <a href="https://blog.langchain.dev/reflection-agents/">Reflection Agents</a><br>  <a href="https://www.bilibili.com/video/BV1KJ4m1a7rZ/">LangGraphï¼šReflection Agents å®æˆ˜</a> V</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>Agent</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Agent-Tools</title>
    <url>/www6vHomeAIGC/2023/01/27/gptAgentTool/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E8%AE%BA%E6%96%87">è®ºæ–‡</a></li>
<li><a href="#%E5%88%86%E7%B1%BB1">åˆ†ç±»[1]</a><ul>
<li><a href="#tool-augmented-vs-tool-oriented-kimi-%E6%80%BB%E7%BB%93">Tool-augmented vs. Tool-oriented [kimi æ€»ç»“]</a></li>
<li><a href="#tool-augmented-learning">Tool-augmented Learning</a></li>
<li><a href="#tool-oriented-learning">Tool-oriented Learning</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#xxx">xxx</a></li>
<li><a href="#others">Others</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="è®ºæ–‡">è®ºæ–‡</span><a href="#è®ºæ–‡" class="header-anchor">#</a></h1><ul>
<li><p>è®ºæ–‡åœ°å€<br><a href="https://arxiv.org/pdf/2304.08354.pdf">Tool Learning with Foundation Models</a> </p>
</li>
<li><p>å¼€æºåœ°å€<br> <a href="https://github.com/thunlp/ToolLearningPapers">ToolLearningPapers</a> git</p>
</li>
</ul>
<h1><span id="åˆ†ç±»1">åˆ†ç±»[1]</span><a href="#åˆ†ç±»1" class="header-anchor">#</a></h1><h3><span id="tool-augmented-vs-tool-oriented-kimi-æ€»ç»“">Tool-augmented vs. Tool-oriented [kimi æ€»ç»“]</span><a href="#tool-augmented-vs-tool-oriented-kimi-æ€»ç»“" class="header-anchor">#</a></h3><ol>
<li><p>Tool-augmented Learningï¼ˆå·¥å…·å¢å¼ºå­¦ä¹ ï¼‰:</p>
<ul>
<li>è¿™ç§å­¦ä¹ æ–¹å¼æŒ‡çš„æ˜¯åœ¨åŸºç¡€æ¨¡å‹ï¼ˆå¦‚å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼‰çš„åŸºç¡€ä¸Šï¼Œ<strong>é€šè¿‡å¼•å…¥å¤–éƒ¨å·¥å…·æ¥å¢å¼ºæ¨¡å‹çš„èƒ½åŠ›</strong>ã€‚è¿™äº›å·¥å…·å¯ä»¥æ˜¯ä»»ä½•å¯ä»¥è¢«æ¨¡å‹é€šè¿‡æŸç§æ¥å£è°ƒç”¨çš„ç³»ç»Ÿæˆ–æœåŠ¡ï¼Œä¾‹å¦‚æœç´¢å¼•æ“ã€æ•°æ®åº“ã€APIç­‰ã€‚</li>
<li>å·¥å…·å¢å¼ºå­¦ä¹ çš„æ ¸å¿ƒåœ¨äºæ¨¡å‹åˆ©ç”¨è¿™äº›å·¥å…·æ¥è·å–é¢å¤–çš„ä¿¡æ¯æˆ–æ‰§è¡Œç‰¹å®šçš„ä»»åŠ¡ï¼Œä»è€Œå¼¥è¡¥æ¨¡å‹è‡ªèº«çŸ¥è¯†å’Œèƒ½åŠ›çš„ä¸è¶³ã€‚</li>
<li>ä¾‹å¦‚ï¼Œ<strong>ä¸€ä¸ªè¯­è¨€æ¨¡å‹å¯èƒ½é€šè¿‡è°ƒç”¨å¤©æ°”APIæ¥è·å–æœ€æ–°çš„å¤©æ°”ä¿¡æ¯ï¼Œæˆ–è€…é€šè¿‡æœç´¢å¼•æ“æ¥æ‰¾åˆ°ç›¸å…³é—®é¢˜çš„ç­”æ¡ˆ</strong>ã€‚</li>
</ul>
</li>
<li><p>Tool-oriented Learningï¼ˆé¢å‘å·¥å…·çš„å­¦ä¹ ï¼‰:</p>
<ul>
<li>é¢å‘å·¥å…·çš„å­¦ä¹ åˆ™æ›´å¤šåœ°å…³æ³¨äºæ¨¡å‹å¦‚ä½•å­¦ä¹ å’Œç†è§£å¦‚ä½•ä½¿ç”¨è¿™äº›å·¥å…·ã€‚è¿™ä¸ä»…ä»…æ˜¯è°ƒç”¨å·¥å…·APIé‚£ä¹ˆç®€å•ï¼Œè€Œæ˜¯<strong>æ¶‰åŠåˆ°æ¨¡å‹å¯¹å·¥å…·çš„æ·±å…¥ç†è§£å’Œç­–ç•¥æ€§ä½¿ç”¨</strong>ã€‚</li>
<li>åœ¨è¿™ç§å­¦ä¹ æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹å¯èƒ½éœ€è¦<strong>å­¦ä¹ å¦‚ä½•ç»„åˆä½¿ç”¨å¤šä¸ªå·¥å…·</strong>ï¼Œæˆ–è€…åœ¨å¤æ‚ä»»åŠ¡ä¸­åŠ¨æ€è°ƒæ•´å¯¹å·¥å…·çš„ä½¿ç”¨ç­–ç•¥ï¼Œä»¥å®ç°æ›´é«˜æ•ˆçš„é—®é¢˜è§£å†³ã€‚</li>
<li>ä¾‹å¦‚ï¼Œæ¨¡å‹å¯èƒ½éœ€è¦å­¦ä¹ å¦‚ä½•åœ¨<strong>è§„åˆ’ä¸€æ¬¡æ—…è¡Œ</strong>æ—¶ï¼Œå…ˆåè°ƒç”¨åœ°å›¾APIã€èˆªç­æœç´¢APIå’Œé…’åº—é¢„è®¢APIï¼ŒåŒæ—¶è¿˜è¦æ ¹æ®ç”¨æˆ·åé¦ˆå’Œç¯å¢ƒå˜åŒ–åŠ¨æ€è°ƒæ•´è®¡åˆ’ã€‚</li>
</ul>
</li>
</ol>
<p>æ€»çš„æ¥è¯´ï¼ŒTool-augmented Learning å¼ºè°ƒçš„æ˜¯é€šè¿‡å¤–éƒ¨å·¥å…·æ¥æ‰©å±•æ¨¡å‹çš„èƒ½åŠ›ï¼Œè€Œ Tool-oriented Learning åˆ™æ›´ä¾§é‡äºæ¨¡å‹å¯¹å·¥å…·ä½¿ç”¨çš„å­¦ä¹ å’Œä¼˜åŒ–ã€‚ä¸¤è€…éƒ½æ˜¯å·¥å…·å­¦ä¹ ï¼ˆTool Learningï¼‰çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½ä¼šæœ‰ä¸åŒçš„å®ç°æ–¹å¼å’Œå…³æ³¨ç‚¹ã€‚</p>
<h3><span id="tool-augmented-learning">Tool-augmented Learning</span><a href="#tool-augmented-learning" class="header-anchor">#</a></h3><ul>
<li>Toolformer   <a href="/www6vHomeAIGC/2023/02/03/gptAgentToolformer/" title="(åŸç†)Toolformer">(åŸç†)Toolformer</a></li>
</ul>
<h3><span id="tool-oriented-learning">Tool-oriented Learning</span><a href="#tool-oriented-learning" class="header-anchor">#</a></h3><ul>
<li>ToolMaker[10]</li>
<li>CREATOR[11]</li>
<li>ToolLLM [12]</li>
<li>Visual ChatGPT[13]</li>
<li>HuggingGPT[14]</li>
<li>Gorilla <a href="/www6vHomeAIGC/2023/04/08/gptAgentToolGorilla/" title="(åŸç†)Gorilla">(åŸç†)Gorilla</a></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/624459759">å¤§æ¨¡å‹å·¥å…·å­¦ä¹ æƒå¨ç»¼è¿°ï¼ŒBMTools èƒŒåçš„è®ºæ–‡ï¼</a></li>
</ol>
<p>1xx. <a href="https://blog.csdn.net/xixiaoyaoww/article/details/130278978">æ¸…åå‘å¸ƒå·¥å…·å­¦ä¹ æ¡†æ¶ï¼Œè®©ChatGPTæ“æ§åœ°å›¾ã€è‚¡ç¥¨æŸ¥è¯¢ï¼Œè´¾ç»´æ–¯å·²æ¥ï¼Ÿ</a></p>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><ol start="10">
<li><p><a href="https://zhuanlan.zhihu.com/p/633654195">LLMèƒ½å¤Ÿè‡ªå·±åˆ¶ä½œå·¥å…·äº†ï¼šè¯¦è§£Large Language Models as Tool Makers</a>  </p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1EN4y1q7Zn/">THUNLPæˆå‘˜é¢†è¯»EMNLPå¤§æ¨¡å‹å·¥å…·åˆ›é€ æ–°æ¡†æ¶â€œCREATORâ€</a> V æœ‰æ€ç»´å¯¼å›¾ </p>
</li>
<li><p>ã€ŠTOOLLLM: FACILITATING LARGE LANGUAGE MODELS TO MASTER 16000+ REAL-WORLD APISã€‹<br><a href="https://zhuanlan.zhihu.com/p/647899563">TOOLLLMï¼šè®©å¤§å‹è¯­è¨€æ¨¡å‹æŒæ¡çœŸå®ä¸–ç•Œçš„API</a><br><a href="https://github.com/OpenBMB/ToolBench">ToolBench </a> git<br><a href="https://blog.csdn.net/Dbox_boom/article/details/134815624">è®ºæ–‡é˜…è¯»ï¼šToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</a></p>
</li>
<li><p>ã€ŠVisual ChatGPT: Talking, Drawing and Editing with Visual Foundation Modelsã€‹<br><a href="https://github.com/chenfei-wu/TaskMatrix">TaskMatrix</a></p>
</li>
<li><p><a href="https://nakaizura.blog.csdn.net/article/details/130856470">LLMsçš„è‡ªåŠ¨åŒ–å·¥å…·ç³»ç»Ÿï¼ˆHuggingGPTã€AutoGPTã€WebGPTã€WebCPMï¼‰</a></p>
</li>
</ol>
<h3><span id="others">Others</span><a href="#others" class="header-anchor">#</a></h3><p>ã€ŠAugmented Language Modelsã€‹<br>1xx. <a href="https://blog.csdn.net/qq_39388410/article/details/130798125">Augmented Language Modelsï¼ˆå¢å¼ºè¯­è¨€æ¨¡å‹ï¼‰</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/611492200">å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆALMï¼‰ä¹‹ç»¼è¿°ç¯‡</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>agent</category>
      </categories>
      <tags>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Gorilla</title>
    <url>/www6vHomeAIGC/2023/04/08/gptAgentToolGorilla/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E8%AE%BA%E6%96%87">è®ºæ–‡</a></li>
<li><a href="#%E6%96%B9%E6%B3%95%E8%AE%BA1">æ–¹æ³•è®º[1]</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%94%B6%E9%9B%86">æ•°æ®é›†æ”¶é›†</a></li>
<li><a href="#gorilla">Gorilla</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="è®ºæ–‡">è®ºæ–‡</span><a href="#è®ºæ–‡" class="header-anchor">#</a></h1><ul>
<li><p>è®ºæ–‡åœ°å€<br> <a href="https://ar5iv.labs.arxiv.org/html/2305.15334">Gorilla: Large Language Model Connected with Massive APIs</a> </p>
</li>
<li><p>å¼€æºåœ°å€<br> <a href="https://github.com/ShishirPatil/gorilla">gorilla</a> git</p>
</li>
</ul>
<h1><span id="æ–¹æ³•è®º1">æ–¹æ³•è®º[1]</span><a href="#æ–¹æ³•è®º1" class="header-anchor">#</a></h1><h3><span id="æ•°æ®é›†æ”¶é›†">æ•°æ®é›†æ”¶é›†</span><a href="#æ•°æ®é›†æ”¶é›†" class="header-anchor">#</a></h3><p><strong>APIæ–‡æ¡£</strong></p>
<ul>
<li>HuggingFaceå¹³å°æ‰˜ç®¡å’Œæä¾›äº†çº¦203,681ä¸ªæ¨¡å‹ã€‚ç„¶è€Œï¼Œå…¶ä¸­è®¸å¤šæ¨¡å‹çš„æ–‡æ¡£è´¨é‡è¾ƒå·®ï¼Œç¼ºä¹ä¾èµ–é¡¹ï¼Œæ¨¡å‹å¡ä¸­æ²¡æœ‰ä¿¡æ¯ç­‰é—®é¢˜ã€‚</li>
<li>ä¸ºäº†ç­›é€‰å‡ºè´¨é‡è¾ƒå¥½çš„æ¨¡å‹ï¼Œä»æ¯ä¸ªé¢†åŸŸé€‰æ‹©äº†å‰20ä¸ªæ¨¡å‹ã€‚è€ƒè™‘äº†å¤šæ¨¡æ€æ•°æ®é¢†åŸŸçš„7ä¸ªé¢†åŸŸï¼ŒCVé¢†åŸŸçš„8ä¸ªé¢†åŸŸï¼ŒNLPé¢†åŸŸçš„12ä¸ªé¢†åŸŸï¼ŒéŸ³é¢‘é¢†åŸŸçš„5ä¸ªé¢†åŸŸï¼Œè¡¨æ ¼æ•°æ®é¢†åŸŸçš„2ä¸ªé¢†åŸŸå’Œå¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„2ä¸ªé¢†åŸŸã€‚</li>
<li>ç»è¿‡ç­›é€‰ï¼Œä»HuggingFaceè·å¾—äº†æ€»å…±925ä¸ªæ¨¡å‹ã€‚ä»TensorFlow Hubè·å¾—äº†801ä¸ªæ¨¡å‹ï¼Œå¹¶ä»Torch Hubè·å¾—äº†95ä¸ªæ¨¡å‹ã€‚</li>
<li>è¿™äº›æ¨¡å‹çš„ä¿¡æ¯è¢«è½¬æ¢ä¸º<strong>JSONå¯¹è±¡</strong>ï¼Œå…¶ä¸­åŒ…å«äº†é¢†åŸŸï¼ˆdomainï¼‰ã€æ¡†æ¶ï¼ˆframeworkï¼‰ã€åŠŸèƒ½ï¼ˆfunctionalityï¼‰ã€APIåç§°ï¼ˆapi_nameï¼‰ã€APIè°ƒç”¨ï¼ˆapi_callï¼‰ã€APIå‚æ•°ï¼ˆapi_argumentsï¼‰ã€ç¯å¢ƒè¦æ±‚ï¼ˆenvironment_requirementsï¼‰ã€ç¤ºä¾‹ä»£ç ï¼ˆexample_codeï¼‰ã€æ€§èƒ½ï¼ˆperformanceï¼‰å’Œæè¿°ï¼ˆdescriptionï¼‰ç­‰å­—æ®µã€‚</li>
<li>é€‰æ‹©è¿™äº›å­—æ®µæ˜¯ä¸ºäº†å°†å…¶æ³›åŒ–åˆ°æœºå™¨å­¦ä¹ é¢†åŸŸä¹‹å¤–çš„å…¶ä»–é¢†åŸŸï¼ŒåŒ…æ‹¬RESTful APIè°ƒç”¨ã€‚<br><strong>æ€»è€Œè¨€ä¹‹</strong>ï¼Œé€šè¿‡ç­›é€‰å’Œæ•´ç†ï¼Œä»HuggingFaceã€TensorFlow Hubå’ŒTorch Hubç­‰å¹³å°è·å–äº†<strong>æ€»å…±1,645ä¸ªæ¨¡å‹</strong>çš„ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä»¥<strong>JSONå¯¹è±¡</strong>çš„å½¢å¼è¿›è¡Œäº†è®°å½•å’Œæè¿°ã€‚è¿™äº›ä¿¡æ¯åŒ…æ‹¬æ¨¡å‹çš„é¢†åŸŸã€æ¡†æ¶ã€åŠŸèƒ½ã€APIè°ƒç”¨ç¤ºä¾‹ã€æ€§èƒ½ç­‰ï¼Œä»¥ä¾¿åœ¨æœºå™¨å­¦ä¹ å’Œå…¶ä»–é¢†åŸŸä¸­ä½¿ç”¨å’Œå‚è€ƒã€‚</li>
</ul>
<p><strong>æŒ‡ä»¤ç”Ÿæˆ ï¼ˆInstruction Generation ï¼‰</strong></p>
<ul>
<li>åœ¨<strong>self-instruct</strong>èŒƒä¾‹[42]çš„æŒ‡å¯¼ä¸‹ï¼Œä½¿ç”¨GPT-4ç”Ÿæˆäº†åˆæˆæŒ‡ä»¤æ•°æ®ã€‚</li>
<li>æä¾›äº†ä¸‰ä¸ªä¸Šä¸‹æ–‡ç¤ºä¾‹å’Œä¸€ä¸ªå‚è€ƒAPIæ–‡æ¡£ï¼Œè¦æ±‚æ¨¡å‹ç”Ÿæˆè°ƒç”¨APIçš„çœŸå®ä¸–ç•Œç”¨ä¾‹ã€‚</li>
<li>æ˜ç¡®æŒ‡ç¤ºæ¨¡å‹åœ¨åˆ›å»ºæŒ‡ä»¤æ—¶ä¸è¦ä½¿ç”¨ä»»ä½•APIåç§°æˆ–æç¤ºã€‚</li>
<li>ä¸ºæ¯ä¸ªä¸‰ä¸ªæ¨¡å‹ä¸­å¿ƒæ„å»ºäº†å…­ä¸ªç¤ºä¾‹ï¼ˆ<strong>æŒ‡ä»¤-APIå¯¹</strong>ï¼‰ï¼Œå…±è®¡18ä¸ªç‚¹ï¼Œè¿™äº›æ•°æ®æ˜¯æ‰‹åŠ¨ç”Ÿæˆæˆ–ä¿®æ”¹çš„ã€‚</li>
<li>å¯¹äº<strong>1,645ä¸ª</strong>APIæ•°æ®ç‚¹ä¸­çš„æ¯ä¸€ä¸ªï¼Œä»ç›¸åº”çš„å…­ä¸ªæŒ‡ä»¤ç¤ºä¾‹ä¸­éšæœºé€‰æ‹©3ä¸ªï¼Œç”Ÿæˆ<strong>æ€»å…±10ä¸ªæŒ‡ä»¤-APIå¯¹</strong>ã€‚</li>
<li>å¼ºè°ƒåªéœ€è¦ä½¿ç”¨GPT-4ç”ŸæˆæŒ‡ä»¤ï¼Œå¯ä»¥ä¸å¼€æºæ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚LLaMAã€Alpacaç­‰ï¼‰è¿›è¡Œäº¤æ¢ã€‚<br><strong>æ€»è€Œè¨€ä¹‹</strong>ï¼Œé€šè¿‡ä½¿ç”¨GPT-4ç”ŸæˆæŒ‡ä»¤ï¼Œå¹¶ç»“åˆä¸Šä¸‹æ–‡ç¤ºä¾‹å’Œå‚è€ƒAPIæ–‡æ¡£ï¼Œåœ¨æ¯ä¸ªæ¨¡å‹ä¸­å¿ƒæ„å»ºäº†å…­ä¸ªç¤ºä¾‹ï¼Œå…±è®¡18ä¸ªç‚¹ã€‚è¿™äº›ç¤ºä¾‹è¢«ç”¨äº<strong>ç”Ÿæˆ1,645ä¸ªAPIæ•°æ®ç‚¹ä¸­çš„æ¯ä¸€ä¸ªçš„æŒ‡ä»¤-APIå¯¹ï¼Œç”Ÿæˆæ€»å…±10ä¸ªå¯¹åº”å…³ç³»</strong>ã€‚ä¸å¼€æºæ›¿ä»£æ–¹æ¡ˆç›¸æ¯”ï¼ŒGPT-4çš„æŒ‡ä»¤ç”ŸæˆåŠŸèƒ½è¢«åº”ç”¨åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ã€‚</li>
</ul>
<h3><span id="gorilla">Gorilla</span><a href="#gorilla" class="header-anchor">#</a></h3><p><strong>å¸¦æœ‰çº¦æŸçš„APIè°ƒç”¨ï¼ˆAPI Call with Constraintsï¼‰</strong></p>
<ul>
<li>APIè°ƒç”¨é€šå¸¸å…·æœ‰å›ºæœ‰çš„<strong>çº¦æŸ</strong>ï¼Œè¿™äº›çº¦æŸè¦æ±‚LLMä¸ä»…ç†è§£APIè°ƒç”¨çš„åŠŸèƒ½ï¼Œè¿˜è¦<strong>æ ¹æ®ä¸åŒçš„çº¦æŸå‚æ•°å¯¹è°ƒç”¨è¿›è¡Œåˆ†ç±»</strong>ã€‚</li>
<li>æœºå™¨å­¦ä¹ APIè°ƒç”¨ä¸­å¸¸è§çš„çº¦æŸé›†æ˜¯å‚æ•°å¤§å°å’Œå‡†ç¡®æ€§çš„ä¸‹é™ã€‚è¿™äº›çº¦æŸè¦æ±‚LLMèƒ½å¤Ÿæ ¹æ®æç¤ºç†è§£å’Œå›ç­”é—®é¢˜ï¼Œä¾‹å¦‚æ ¹æ®æç¤ºé€‰æ‹©å‚æ•°å°‘äº10Mçš„å›¾åƒåˆ†ç±»æ¨¡å‹ï¼Œå¹¶ä¸”è‡³å°‘ä¿æŒ70%çš„ImageNetå‡†ç¡®ç‡ã€‚</li>
<li><strong>å¯¹LLMæ¥è¯´ï¼Œç†è§£å’Œæ¨ç†å‡ºè¯·æ±‚ä¸­åµŒå…¥çš„å„ç§çº¦æŸæ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜</strong>ã€‚LLMéœ€è¦ç»†è‡´åœ°ç†è§£ç”¨æˆ·çš„åŠŸèƒ½æè¿°ï¼Œå¹¶èƒ½å¤Ÿæ­£ç¡®åœ°å¤„ç†ä¼´éšè¿™äº›è°ƒç”¨çš„å¤æ‚çº¦æŸã€‚</li>
<li>è¿™ä¸ªæŒ‘æˆ˜å‡¸æ˜¾äº†åœ¨å®é™…APIè°ƒç”¨ä¸­å¯¹LLMçš„å¤æ‚è¦æ±‚ã€‚ä»…ä»…ç†è§£APIè°ƒç”¨çš„åŸºæœ¬åŠŸèƒ½æ˜¯ä¸å¤Ÿçš„ï¼Œ<strong>æ¨¡å‹è¿˜å¿…é¡»èƒ½å¤Ÿåº”å¯¹ä¼´éšè¿™äº›è°ƒç”¨çš„çº¦æŸï¼Œå¦‚å‚æ•°å¤§å°å’Œå‡†ç¡®æ€§è¦æ±‚</strong>ã€‚<br>æ€»è€Œè¨€ä¹‹ï¼Œåœ¨æœºå™¨å­¦ä¹ APIè°ƒç”¨ä¸­ï¼ŒLLMé¢ä¸´ç€ç†è§£å’Œå¤„ç†çº¦æŸçš„æŒ‘æˆ˜ã€‚é™¤äº†ç†è§£APIè°ƒç”¨çš„åŸºæœ¬åŠŸèƒ½å¤–ï¼ŒLLMè¿˜éœ€è¦èƒ½å¤Ÿè¯†åˆ«å’Œæ»¡è¶³ä¼´éšè°ƒç”¨çš„çº¦æŸè¦æ±‚ï¼Œå¦‚å‚æ•°å¤§å°å’Œå‡†ç¡®æ€§çš„ä¸‹é™ã€‚è¿™éœ€è¦æ¨¡å‹å…·å¤‡æ›´ç»†è‡´çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œä»¥æ»¡è¶³å®é™…APIè°ƒç”¨çš„å¤æ‚éœ€æ±‚ã€‚</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/640697382">Gorillaï¼šä¸å¤§è§„æ¨¡APIç›¸è¿çš„å¤§å‹è¯­è¨€æ¨¡å‹</a> ***</li>
</ol>
<p>1xx. <a href="https://apposcmf8kb5033.pc.xiaoe-tech.com/live_pc/l_64a7d5afe4b09d7237a04b5b">Gorillaï¼šé“¾æ¥æµ·é‡APIçš„å¤§å‹è¯­è¨€æ¨¡å‹</a> V<br>1xx. <a href="https://zhuanlan.zhihu.com/p/632583909">å¤§çŒ©çŒ©ï¼ˆGorillaï¼‰ğŸ¦ï¼Œè¿æ¥å¤§é‡ API çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œèƒ½æˆä¸ºæœªæ¥AIåº”ç”¨çš„æ ¸å¿ƒä¹ˆï¼Ÿ</a> ***</p>
<p>1xx. <a href="https://gorilla.cs.berkeley.edu/">Gorilla: Large Language Model Connected with Massive APIs</a><br>1xx. <a href="https://gorilla.cs.berkeley.edu/blog.html">Gorilla blog</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>agent</category>
      </categories>
      <tags>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Toolformer</title>
    <url>/www6vHomeAIGC/2023/02/03/gptAgentToolformer/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="è®ºæ–‡">è®ºæ–‡</span><a href="#è®ºæ–‡" class="header-anchor">#</a></h1><ul>
<li><p>è®ºæ–‡åœ°å€<br> <a href="https://arxiv.org/abs/2302.04761">Toolformer: Language Models Can Teach Themselves to Use Tools</a>  </p>
</li>
<li><p>å¼€æºåœ°å€<br><a href="https://github.com/lucidrains/toolformer-pytorch">Implementation of Toolformer</a>  git</p>
</li>
</ul>
<h1><span id="toolformer1">Toolformer[1]</span><a href="#toolformer1" class="header-anchor">#</a></h1><ul>
<li>ğŸ”‘å…³é”®è¯å’Œæ‘˜è¦<ul>
<li>Keywords: Large-scale PLMs,  Tool Learning</li>
<li>xxx<ul>
<li>é©±åŠ¨è¯­è¨€æ¨¡å‹å»ä½¿ç”¨ç®€å•çš„æ¨¡å‹æ¥è°ƒç”¨å¤–éƒ¨çš„å·¥å…·</li>
<li>Toolformeré€šè¿‡è¯­è¨€æ¨¡å‹çš„æ–¹æ³•å»å†³å®šå»è°ƒç”¨å“ªäº›APIï¼Œä¼ å…¥å“ªäº›å‚æ•°</li>
<li>Tooformeræ˜¯åœ¨è‡ªç›‘ç£å±‚é¢æ‰§è¡Œçš„ï¼Œåªéœ€è¦å¯¹æ¯ä¸ªAPIçš„è¯­è¨€æè¿°</li>
</ul>
</li>
</ul>
</li>
<li>âš™ï¸ç ”ç©¶è®¾è®¡å’Œç»“è®º<ul>
<li>æ–¹æ³•   <ul>
<li>Toolformerè°ƒç”¨ç¤ºä¾‹ï¼šxxx</li>
<li>å…³é”®è¦ç´ ï¼š<ul>
<li>æ¨¡å‹å¯¹å·¥å…·çš„ä½¿ç”¨åº”è¯¥æ˜¯è‡ªç›‘ç£çš„ï¼Œè¿™æ ·å¯ä»¥çœå»å¾ˆå¤§çš„æ ‡æ³¨å¼€é”€</li>
<li>æ¨¡å‹åº”è¯¥è‡ªè¡Œåœ°å»å†³å®šåœ¨ä½•æ—¶é—´ï¼Œç”¨ä½•æ–¹æ³•æ¥è°ƒç”¨å·¥å…·</li>
</ul>
</li>
<li><strong>æ–¹æ³•æ¦‚è¦ï¼š</strong><ul>
<li>å—åˆ°in-context learningçš„å¯å‘ï¼Œç»™å®šå°‘é‡çš„äººå†™çš„å…³äºAPIçš„æè¿°ï¼Œè®©æ¨¡å‹å»è‡ªè¡Œç”Ÿæˆæ½œåœ¨APIè°ƒç”¨çš„è¯­è¨€å»ºæ¨¡æ•°æ®</li>
<li>æ„å»ºä¸€ä¸ªè‡ªç›‘ç£çš„Losså‡½æ•°ï¼Œè®©æ¨¡å‹æ¥å†³å®šå“ªäº›APIçš„è°ƒç”¨æœ‰åŠ©äºå®ƒçš„è¯­è¨€å»ºæ¨¡çš„é¢„æµ‹</li>
</ul>
</li>
<li><strong>æ–¹æ³•ç»†èŠ‚ï¼š</strong><ul>
<li>xxx<ul>
<li>ç»™å®šä¸€ä¸ªçº¯æ–‡æœ¬æ•°æ®é›†ï¼Œæ„å»ºå‡ºä¸€ä¸ªå¸¦æœ‰APIè°ƒç”¨çš„æ•°æ®é›†ï¼Œç„¶ååœ¨æ­¤æ•°æ®é›†ä¸Šåšå¾®è°ƒ</li>
<li>ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨in-context learningæ¥ç”Ÿæˆå¤§é‡çš„æ½œåœ¨å¯èƒ½çš„APIè°ƒç”¨</li>
<li>ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œè¿™äº›APIï¼Œè¿”å›å¾—åˆ°ç»“æœ</li>
<li>ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥è¿”å›çš„ç»“æœæ˜¯å¦æœ‰åŠ©äºè¯­è¨€æ¨¡å‹çš„é¢„æµ‹ï¼Œè¿‡æ»¤æ‰å…¶ä»–çš„API</li>
</ul>
</li>
<li>APIè°ƒç”¨é‡‡æ ·<ul>
<li>ç»™æ¯ä¸€ä¸ªAPIæ¥æ’°å†™æç¤ºæ¥é¼“åŠ±æ¨¡å‹ä½¿ç”¨è¿™äº›APIï¼Œä¾‹å¦‚QAçš„æç¤ºæ˜¯ xxx</li>
<li>å¯¹äºæ–‡æœ¬çš„æ¯ä¸€ä¸ªä½ç½®ï¼Œå¦‚æœè¿™ä¸ªä½ç½®æ˜¯<api>ï¼ˆå³APIè°ƒç”¨çš„å¼€å§‹ï¼‰çš„æ¦‚ç‡å¤§äºä¸€ä¸ªé˜ˆå€¼ï¼Œåˆ™å°†æ­¤ä½ç½®ä¿ç•™åˆ°ä¸€ä¸ªé›†åˆIä¸­</api></li>
<li>å¯¹äºé›†åˆIä¸­çš„æ¯ä¸€ä¸ªä½ç½®ï¼Œé€šè¿‡æ¨¡å‹ç”Ÿæˆæœ€å¤šmä¸ªAPIè°ƒç”¨ï¼Œå¹¶ä¸”ä»¥ç»“å°¾ï¼ˆå¦‚æœç”Ÿæˆçš„è°ƒç”¨æ²¡æœ‰ä»¥ç»“å°¾ï¼Œç›´æ¥èˆå»ï¼‰</li>
</ul>
</li>
<li>APIæ‰§è¡Œ<ul>
<li>å»æ‰§è¡Œæ‰€æœ‰çš„APIè°ƒç”¨ï¼Œè¿”å›æ–‡æœ¬åºåˆ—</li>
</ul>
</li>
<li>APIè¿‡æ»¤<ul>
<li>æ„å»ºè‡ªç›‘ç£çš„è¯­è¨€æ¨¡å‹çš„losså‡½æ•°</li>
<li>ç¬¬ä¸€ä¸ªçš„å«ä¹‰ï¼šè¿›è¡ŒAPIçš„è°ƒç”¨ï¼Œå¹¶ä¸”ä½¿ç”¨APIç»“æœçš„Loss</li>
<li>ç¬¬äºŒä¸ªçš„å«ä¹‰ï¼šç©ºå­—ç¬¦ä¸²çš„Losså’Œè°ƒç”¨APIä½†ä¸è¿”å›ç»“æœLossçš„æœ€å°å€¼</li>
<li>è¿™æ—¶æˆ‘ä»¬å¸Œæœ›æ¨¡å‹ä½¿ç”¨APIå¹¶ä¸”è¿”å›ç»“æœå¯¹è¯­è¨€å»ºæ¨¡æœ‰å¸®åŠ©ï¼Œä¸”å¸®åŠ©å¾ˆæ˜æ˜¾-&gt;å‰è€…çš„lossæ˜¾è‘—æ¯”åè€…å°</li>
</ul>
</li>
<li>å¾®è°ƒå’Œæ¨ç†<ul>
<li>åœ¨ç»è¿‡å¦‚ä¸Šæ“ä½œåï¼Œå°±å¯ä»¥å¾—åˆ°å¸¦æœ‰APIè°ƒç”¨çš„æ•°æ®é›†ï¼Œç„¶åå°†æ¨¡å‹åœ¨ä¸Šé¢è¿›è¡Œå¾®è°ƒ</li>
<li>å½“æ¨¡å‹åœ¨è§£ç é˜¶æ®µè¾“å‡ºâ€-&gt;â€ç¬¦å·æ—¶ï¼Œæ„å‘³ç€éœ€è¦è°ƒç”¨APIäº†ï¼Œè°ƒç”¨å¾—åˆ°è¿”å›ç»“æœç„¶åæ‹¼æ¥ä¸Šå»</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>å®éªŒ<ul>
<li>æ¨¡å‹ï¼šGPT-J ï¼ˆ67äº¿å‚æ•°ï¼‰</li>
<li>åŸå§‹æ•°æ®ï¼šCCNet</li>
<li>çŸ¥è¯†æ¢æµ‹ä»»åŠ¡LAMA<ul>
<li>Toolformerå¯ä»¥å¤§å¹…è¶…è¿‡ä¹‹å‰çš„æ–¹æ³•ï¼Œç”šè‡³æ˜¯GPT-3ç­‰å¤§æ¨¡å‹</li>
</ul>
</li>
<li>æ•°å­¦æ•°æ®é›†</li>
<li>é—®ç­”</li>
<li>è¿™é‡Œå³ä½¿æ˜¯Toolformerä¹Ÿæ— æ³•è¶…è¶ŠGPT-3ï¼Œå¯è§é¢„è®­ç»ƒè§„æ¨¡å¯ä»¥å›Šæ‹¬æ›´å¤šçŸ¥è¯†</li>
<li>æ¨¡å‹è§„æ¨¡çš„å½±å“</li>
<li>æ¨¡å‹çš„å‚æ•°é‡åˆ°ä¸€å®šè§„æ¨¡åæ‰æ‹¥æœ‰ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›</li>
</ul>
</li>
</ul>
</li>
<li>ğŸ“šè®ºæ–‡è´¡çŒ®<ul>
<li>ä¼˜ç‚¹<ul>
<li>å°†è¯­è¨€æ¨¡å‹ä½¿ç”¨å¤–éƒ¨å·¥å…·çš„è¿›è¡Œå¾ˆè‡ªç„¶çš„ç»“åˆ</li>
<li><strong>ä¸éœ€è¦æ ‡æ³¨å¤§é‡æ•°æ®ï¼Œä½¿ç”¨è‡ªç›‘ç£çš„æ–¹æ³•è¿›è¡Œå­¦ä¹ </strong></li>
</ul>
</li>
<li>ç¼ºç‚¹<ul>
<li><strong>å·¥å…·æ— æ³•äº¤äº’ï¼Œä¹Ÿæ— æ³•é“¾å¼ä½¿ç”¨ï¼ˆæ¯ä¸ªAPIè°ƒç”¨éƒ½æ˜¯ç‹¬ç«‹çš„ï¼‰</strong></li>
<li>å®šä¹‰çš„å·¥å…·å°šä¸”æœ‰é™ï¼Œæ‰©å±•å·¥å…·åˆ™éœ€è¦ç”¨æ¨¡å‹æ ‡æ³¨æ–°çš„æ•°æ®</li>
<li>éšç€åŸºç¡€æ¨¡å‹zero-shotèƒ½åŠ›çš„å¢å¼ºï¼Œè¿™ç§éœ€è¦æ„å»ºæ•°æ®å¹¶ä¸”fine-tuneçš„åšæ³•å¯èƒ½ä¼šæ¯”è¾ƒéº»çƒ¦</li>
</ul>
</li>
</ul>
</li>
<li>OpenBMB BMTools: <a href="https://github.com/OpenBMB/BMTools">https://github.com/OpenBMB/BMTools</a></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV18s4y1u7nJ/">æ¸…ååšå£«å¸¦ä½ ææ‡‚å¤§æ¨¡å‹è‡ªå­¦å·¥å…·ä½¿ç”¨ï¼ˆToolformer)ã€è®ºæ–‡é€Ÿè¯»ã€‘</a> V æœ‰æ€ç»´å¯¼å›¾<br>1xx. <a href="https://finisky.github.io/toolformer-summary/">ä½¿LLMå–„å‡äºç‰©: Toolformer </a><br>1xx. <a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#external-apis">Prompt Engineering </a><br>1xx. <a href="https://nakaizura.blog.csdn.net/article/details/130817902">Toolformer and Tool Learningï¼ˆLLMså¦‚ä½•ä½¿ç”¨å·¥å…·ï¼‰</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>Tool</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent Tuning</title>
    <url>/www6vHomeAIGC/2023/04/07/gptAgentTuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="tuning">Tuning</span><a href="#tuning" class="header-anchor">#</a></h1><h3><span id="agenttuning">AgentTuning</span><a href="#agenttuning" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404626&idx=1&sn=da5ac106548dd30f14a57a5ce4d90f08">åŸºäºllama7Bçš„æ–‡æœ¬åµŒå…¥æ¨¡å‹ANGLEï¼šå…¼çœ‹Agentå¾®è°ƒæ•°æ®çš„ç”Ÿæˆæ–¹æ¡ˆ</a>  AgentTuning<br>1xx. <a href="https://zhuanlan.zhihu.com/p/671295938">LLMä¹‹Agentï¼ˆäº”ï¼‰| AgentTuningï¼šæ¸…åå¤§å­¦ä¸æ™ºè°±AIæå‡ºAgentTuningæé«˜å¤§è¯­è¨€æ¨¡å‹Agentèƒ½åŠ›</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/663362992?utm_id=0">AgentTuningè§£è¯»</a></p>
<h3><span id="agenttuning-å®æˆ˜">AgentTuning å®æˆ˜</span><a href="#agenttuning-å®æˆ˜" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/678989191">å•å¡ 3 å°æ—¶è®­ç»ƒä¸“å±å¤§æ¨¡å‹ Agentï¼šåŸºäº LLaMA Factory å®æˆ˜</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/690012170">2024å¹´å¤§æ¨¡å‹Agent tuningå…³é”®æŠ€æœ¯Fireact, Agent-FLAN, AgentOhana, Agent LUMOS, STE, ETO,MoE, DebateGPTç­‰</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>agent</category>
      </categories>
      <tags>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Web Agent</title>
    <url>/www6vHomeAIGC/2023/03/05/gptAgentWeb/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="web-scenarios-1">web scenarios [1]</span><a href="#web-scenarios-1" class="header-anchor">#</a></h1><p>åœ¨ç½‘ç»œåœºæ™¯ä¸­ï¼Œä»£è¡¨ç”¨æˆ·æ‰§è¡Œç‰¹å®šä»»åŠ¡è¢«ç§°ä¸ºWebå¯¼èˆªé—®é¢˜[390]ã€‚ä»£ç†ç¨‹åºè§£é‡Šç”¨æˆ·æŒ‡ä»¤ï¼Œå°†å…¶åˆ†è§£ä¸ºå¤šä¸ªåŸºæœ¬æ“ä½œï¼Œå¹¶ä¸è®¡ç®—æœºè¿›è¡Œäº¤äº’ã€‚è¿™é€šå¸¸æ¶‰åŠåˆ°å¡«å†™è¡¨å•ã€åœ¨çº¿è´­ç‰©å’Œå‘é€ç”µå­é‚®ä»¶ç­‰ç½‘ç»œä»»åŠ¡ã€‚ä»£ç†ç¨‹åºéœ€è¦å…·å¤‡ç†è§£å¤æ‚ç½‘ç»œåœºæ™¯ä¸­çš„æŒ‡ä»¤çš„èƒ½åŠ›ï¼Œé€‚åº”å˜åŒ–ï¼ˆå¦‚å˜ˆæ‚çš„æ–‡æœ¬å’ŒåŠ¨æ€HTMLç½‘é¡µï¼‰ï¼Œå¹¶æ¨å¹¿æˆåŠŸçš„æ“ä½œ[391]ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä»£ç†ç¨‹åºå¯ä»¥åœ¨å¤„ç†æœªçŸ¥ä»»åŠ¡æ—¶å®ç°å¯è®¿é—®æ€§å’Œè‡ªåŠ¨åŒ–[435]ï¼Œæœ€ç»ˆä½¿äººç±»å…äºä¸è®¡ç®—æœºç”¨æˆ·ç•Œé¢çš„é‡å¤äº¤äº’ã€‚</p>
<p>é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„ä»£ç†ç¨‹åºå¯ä»¥æœ‰æ•ˆåœ°æ¨¡ä»¿äººç±»è¡Œä¸ºï¼Œä½¿ç”¨é¢„å®šä¹‰çš„æ“ä½œï¼Œå¦‚é”®å…¥ã€æœç´¢ã€å¯¼èˆªåˆ°ä¸‹ä¸€é¡µç­‰ã€‚å®ƒä»¬åœ¨åŸºæœ¬ä»»åŠ¡ï¼ˆå¦‚åœ¨çº¿è´­ç‰©[392]å’Œæœç´¢å¼•æ“æ£€ç´¢[90]ï¼‰ä¸­è¡¨ç°è‰¯å¥½ï¼Œè¿™äº›ä»»åŠ¡å·²ç»å¾—åˆ°å¹¿æ³›æ¢ç´¢ã€‚ç„¶è€Œï¼Œæ²¡æœ‰è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„ä»£ç†ç¨‹åºå¯èƒ½éš¾ä»¥é€‚åº”ç°å®ä¸–ç•Œäº’è”ç½‘ä¸­æ›´çœŸå®å’Œå¤æ‚çš„åœºæ™¯ã€‚åœ¨åŠ¨æ€ã€å†…å®¹ä¸°å¯Œçš„ç½‘é¡µä¸Šï¼Œå¦‚åœ¨çº¿è®ºå›æˆ–åœ¨çº¿ä¸šåŠ¡ç®¡ç†[391]ï¼Œä»£ç†ç¨‹åºå¸¸å¸¸é¢ä¸´æ€§èƒ½æ–¹é¢çš„æŒ‘æˆ˜ã€‚</p>
<p>ä¸ºäº†å®ç°ä»£ç†ç¨‹åºä¸æ›´çœŸå®çš„ç½‘é¡µä¹‹é—´çš„æˆåŠŸäº¤äº’ï¼Œä¸€äº›ç ”ç©¶äººå‘˜[393ï¼›394]å¼€å§‹åˆ©ç”¨è¯­è¨€æ¨¡å‹çš„å¼ºå¤§HTMLè¯»å–å’Œç†è§£èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡æç¤ºï¼Œä»–ä»¬è¯•å›¾ä½¿ä»£ç†ç¨‹åºç†è§£æ•´ä¸ªHTMLæºä»£ç ï¼Œå¹¶é¢„æµ‹æ›´åˆç†çš„ä¸‹ä¸€æ­¥æ“ä½œã€‚Mind2Web[389]ç»“åˆäº†ä¸ºHTMLè¿›è¡Œå¾®è°ƒçš„å¤šä¸ªè¯­è¨€æ¨¡å‹ï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿåœ¨ç°å®ä¸–ç•Œçš„åœºæ™¯ä¸­æ€»ç»“å†—é•¿çš„HTMLä»£ç [388]å¹¶æå–æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒWebGum[390]é€šè¿‡ä½¿ç”¨åŒ…å«HTMLæˆªå±çš„å¤šæ¨¡æ€è¯­æ–™åº“ï¼Œèµ‹äºˆä»£ç†ç¨‹åºè§†è§‰æ„ŸçŸ¥èƒ½åŠ›ã€‚å®ƒåŒæ—¶è¿›è¡Œäº†è¯­è¨€æ¨¡å‹å’Œè§†è§‰ç¼–ç å™¨çš„å¾®è°ƒï¼ŒåŠ æ·±äº†ä»£ç†ç¨‹åºå¯¹ç½‘é¡µçš„å…¨é¢ç†è§£ã€‚</p>
<p>Performing specific tasks on behalf of users in a web scenario is known as the web navigation problem [390]. Agents interpret user instructions, break them down into multiple basic operations, and interact with computers. This often includes web tasks such as filling out forms, online shopping, and sending emails. Agents need to possess the ability to understand instructions within complex web scenarios, adapt to changes (such as noisy text and dynamic HTML web pages), and generalize successful operations [391]. In this way, agents can achieve accessibility and automation when dealing with unseen tasks in the future [435], ultimately freeing humans from repeated interactions with computer UIs. </p>
<p>Agents trained through reinforcement learning can effectively mimic human behavior using predefined actions like typing, searching, navigating to the next page, etc. They perform well in basic tasks such as online shopping [392] and search engine retrieval [90], which have been widely explored. However, agents without LLM capabilities may struggle to adapt to the more realistic and complex scenarios in the real-world Internet. In dynamic, content-rich web pages such as online forums or online business management [391], agents often face challenges in performance. </p>
<p>In order to enable successful interactions between agents and more realistic web pages, some researchers [393; 394] have started to leverage the powerful HTML reading and understanding abilities of LLMs. By designing prompts, they attempt to make agents understand the entire HTML source code and predict more reasonable next action steps. Mind2Web [389] combines multiple LLMs fine-tuned for HTML, allowing them to summarize verbose HTML code [388] in real-world scenarios and extract valuable information. Furthermore, WebGum [390] empowers agents with visual perception abilities by employing a multimodal corpus containing HTML screenshots. It simultaneously fine-tunes the LLM and a visual encoder, deepening the agentâ€™s comprehensive understanding of web pages.</p>
<h1><span id="papers-2">papers [2]</span><a href="#papers-2" class="header-anchor">#</a></h1><p><strong>In web scenarios</strong></p>
<ul>
<li>[2023&#x2F;10] <strong>OpenAgents: An Open Platform for Language Agents in the Wild.</strong> <em>XLang Lab (The University of Hong Kong) arXiv.</em> [<a href="https://arxiv.org/abs/2310.10634">paper</a>] [<a href="https://docs.xlang.ai/">project page</a>] [<a href="https://github.com/xlang-ai/OpenAgents">code</a>] [<a href="https://chat.xlang.ai/">demo</a>]  ***</li>
<li>[2023&#x2F;07] <strong>WebArena: A Realistic Web Environment for Building Autonomous Agents.</strong> <em>Shuyan Zhou (CMU) et al. arXiv.</em> [<a href="https://arxiv.org/abs/2307.13854">paper</a>] [<a href="https://webarena.dev/">code</a>] *</li>
<li>[2023&#x2F;07] <strong>A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis.</strong> <em>Izzeddin Gur (DeepMind) et al. arXiv.</em> [<a href="https://arxiv.org/abs/2307.12856">paper</a>]</li>
<li>[2023&#x2F;06] <strong>SYNAPSE: Leveraging Few-Shot Exemplars for<br>Human-Level Computer Control.</strong> <em>Longtao Zheng (Nanyang Technological University) et al. arXiv.</em> [<a href="https://arxiv.org/abs/2306.07863">paper</a>] [<a href="https://github.com/ltzheng/synapse">code</a>] *</li>
<li>[2023&#x2F;06] <strong>Mind2Web: Towards a Generalist Agent for the Web.</strong> <em>Xiang Deng (The Ohio State University) et al. arXiv.</em> [<a href="https://arxiv.org/abs/2306.06070">paper</a>] [<a href="https://osu-nlp-group.github.io/Mind2Web/">code</a>] ***</li>
<li>[2023&#x2F;05] <strong>Multimodal Web Navigation with Instruction-Finetuned Foundation Models.</strong> <em>Hiroki Furuta (The University of Tokyo) et al. arXiv.</em> [<a href="https://arxiv.org/abs/2305.11854">paper</a>]</li>
<li>[2023&#x2F;03] <strong>Language Models can Solve Computer Tasks.</strong> <em>Geunwoo Kim (University of California) et al. arXiv.</em> [<a href="https://arxiv.org/abs/2303.17491">paper</a>] [<a href="https://github.com/posgnu/rci-agent">code</a>]</li>
<li>[2022&#x2F;07] <strong>WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents.</strong> <em>Shunyu Yao (Princeton University) et al. arXiv.</em> [<a href="https://arxiv.org/abs/2207.01206">paper</a>] [<a href="https://webshop-pnlp.github.io/">code</a>] *</li>
<li>[2021&#x2F;12] <strong>WebGPT: Browser-assisted question-answering with human feedback.</strong> <em>Reiichiro Nakano (OpenAI) et al. arXiv.</em> [<a href="https://arxiv.org/abs/2112.09332">paper</a>]</li>
<li>[2023&#x2F;05] <strong>Agents: An Open-source Framework for Autonomous Language Agents.</strong> <em>Wangchunshu Zhou (AIWaves) et al. arXiv.</em> [<a href="https://arxiv.org/pdf/2309.07870.pdf">paper</a>] [<a href="https://github.com/aiwaves-cn/agents">code</a>]  ***</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li>ã€ŠThe Rise and Potential of Large Language Model Based Agents: A Surveyã€‹ã€</li>
<li><a href="https://github.com/woooodyy/llm-agent-paper-list">The Rise and Potential of Large Language Model Based Agents: A Survey</a> git<br>1xx. <a href="https://sites.google.com/view/mm-webnav/">Multimodal Web Navigation with Instruction-Finetuned Foundation Models</a><br>1xx. <a href="https://hub.baai.ac.cn/view/28104">Google DeepMindï½œå…·å¤‡è§„åˆ’é•¿ç¨‹ä¸Šä¸‹æ–‡ç†è§£å’Œç¨‹åºåˆæˆèƒ½åŠ›çš„çœŸå®ä¸–ç•ŒWebAgent</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/662146234">LLMs-Agent è®ºæ–‡: WebAgent, 2023, Izzeddin Gur et al., Google DeepMind.</a><br>1xx. <a href="https://github.com/www6v/OpenAgents">OpenAgents</a></li>
</ol>
<h3><span id="web-agent">web  agent</span><a href="#web-agent" class="header-anchor">#</a></h3><p>1xx. <a href="https://baoyu.io/translations/ai-paper/2401.13919-webvoyager-building-an-end-to-end-web-agent-with-large-multimodal-models">WebVoyagerï¼šå€ŸåŠ©å¼ºå¤§å¤šæ¨¡æ€æ¨¡å‹ï¼Œå¼€åˆ›å…¨æ–°çš„ç½‘ç»œæ™ºèƒ½ä½“ [è¯‘]</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>agent</category>
      </categories>
      <tags>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>COT</title>
    <url>/www6vHomeAIGC/2023/02/08/gptCOT/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="cot4">CoT[4]</span><a href="#cot4" class="header-anchor">#</a></h1><ul>
<li><p>CoT(Chain of Thought)</p>
<ul>
<li>CoT-SC(Self Consistency)</li>
</ul>
</li>
<li><p>ToT(Tree of Thoughts)<br>åˆ†ä¸ºäº†Thought Decompositionï¼ŒThought Generatorï¼ŒState Evaluatorï¼ŒSearch algorithms</p>
</li>
<li><p>GoT(Graph of Thoughts)</p>
</li>
<li><p>AoT(Algorithm of Thoughts)</p>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="4">
<li><a href="https://zhuanlan.zhihu.com/p/654034193">2023å¹´èƒ½å¤Ÿè§£å†³å¤æ‚é—®é¢˜çš„æ€ç»´é“¾æŠ€æœ¯ï¼šCotï¼ŒToTï¼ŒGoTï¼ŒAoT</a></li>
</ol>
<p>1xx. <a href="https://github.com/zchuz/CoT-Reasoning-Survey">CoT-Reasoning-Survey </a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404176&idx=1&sn=2eafdf5426bfe1347869b9af268d4238">å¤§æ¨¡å‹COTæ€ç»´é“¾æ¨ç†çš„å‡ ä¸ªå…³é”®é—®é¢˜ï¼šä»è¯„æµ‹åŸºå‡†ã€ç»“æ„å˜ä½“åˆ°å¢å¼ºæ–¹æ¡ˆçš„ç³»ç»Ÿç»¼è¿° </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>COT</category>
      </categories>
      <tags>
        <tag>COT</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatGLM</title>
    <url>/www6vHomeAIGC/2023/01/06/gptChatGLM/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<p><a href="https://www.bilibili.com/video/BV1ju411T74Y/">ç¬¬åä¸€è¯¾ï¼šChatGLM</a> V<br><a href="https://blog.csdn.net/v_JULY_v/article/details/129880836">ChatGLMä¸¤ä»£çš„éƒ¨ç½²&#x2F;å¾®è°ƒ&#x2F;å®ç°ï¼šä»åŸºåº§GLMã€ChatGLMçš„LoRA&#x2F;P-Tuningå¾®è°ƒã€6Bæºç è§£è¯»åˆ°ChatGLM2çš„å¾®è°ƒä¸å®ç°</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/625468667">ã€Instruction Tuningã€‘ChatGLM å¾®è°ƒå®æˆ˜ï¼ˆé™„æºç ï¼‰</a></p>
<p><a href="https://github.com/www6v/transformers_tasks/blob/main/LLM/chatglm_finetune/readme.md">Finetune ChatGLM-6B</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401516&idx=1&sn=80b3cfecc9f4338b87fcd9bc91ef2465">ä¹Ÿçœ‹æ”¯æŒ32Kä¸Šä¸‹æ–‡çš„ChatGLM2-6Bæ¨¡å‹ï¼šä¼˜åŒ–ç‚¹ç®€è¯»åŠç°æœ‰å¼€æºæ¨¡å‹ä¸»æµè®­ç»ƒä¼˜åŒ–ç‚¹æ¦‚è¿° </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>ChatGLM</category>
      </categories>
      <tags>
        <tag>ChatGLM</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)Chinese-LLaMA PT+SFT</title>
    <url>/www6vHomeAIGC/2023/02/21/gptChineseLlama/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA">ç¯å¢ƒæ­å»º</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81-%E6%A8%A1%E5%9E%8B-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87">ä»£ç ã€æ¨¡å‹ã€æ•°æ®é›†å‡†å¤‡</a><ul>
<li><a href="#%E4%BB%A3%E7%A0%81%E5%87%86%E5%A4%87-5">ä»£ç å‡†å¤‡ [5]</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E6%9D%83%E9%87%8D-%E5%8F%8A-tokenizer-%E5%87%86%E5%A4%87-4">æ¨¡å‹æƒé‡ åŠ Tokenizer å‡†å¤‡ [4]</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87-3">æ•°æ®é›†å‡†å¤‡ [3]</a></li>
</ul>
</li>
<li><a href="#%E8%AF%8D%E8%A1%A8%E6%89%A9%E5%85%85">è¯è¡¨æ‰©å……</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82">æ¨¡å‹è®­ç»ƒç»†èŠ‚</a><ul>
<li><a href="#%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%E9%A2%84%E8%AE%AD%E7%BB%83">ç¬¬äºŒé˜¶æ®µé¢„è®­ç»ƒ</a></li>
<li><a href="#%E5%B0%86-lora-%E6%9D%83%E9%87%8D%E4%B8%8E%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6">å°† LoRA æƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶</a></li>
<li><a href="#%E6%8C%87%E4%BB%A4%E7%B2%BE%E8%B0%83">æŒ‡ä»¤ç²¾è°ƒ</a></li>
<li><a href="#%E5%B0%86%E5%A4%9A%E4%B8%AAlora%E6%9D%83%E9%87%8D%E4%B8%8E%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6">å°†å¤šä¸ªLoRAæƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶</a></li>
</ul>
</li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86">æ¨¡å‹æ¨ç†</a></li>
<li><a href="#%E7%BB%93%E8%AF%AD">ç»“è¯­</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="ç¯å¢ƒæ­å»º">ç¯å¢ƒæ­å»º</span><a href="#ç¯å¢ƒæ­å»º" class="header-anchor">#</a></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install transformers==4.28.1 sentencepiece==0.1.97 google protobuf deepspeed -i https://pypi.tuna.tsinghua.ed</span></span><br><span class="line">u.cn/simple  --trusted-host pypi.tuna.tsinghua.edu.cn</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/huggingface/peft.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git checkout 13e53fc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install . -i https://pypi.tuna.tsinghua.edu.cn/simple  --trusted-host pypi.tuna.tsinghua.edu.cn</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install torch==1.13.1</span></span><br></pre></td></tr></table></figure>
<h1><span id="ä»£ç -æ¨¡å‹-æ•°æ®é›†å‡†å¤‡">ä»£ç ã€æ¨¡å‹ã€æ•°æ®é›†å‡†å¤‡</span><a href="#ä»£ç -æ¨¡å‹-æ•°æ®é›†å‡†å¤‡" class="header-anchor">#</a></h1><h3><span id="ä»£ç å‡†å¤‡-5">ä»£ç å‡†å¤‡ [5]</span><a href="#ä»£ç å‡†å¤‡-5" class="header-anchor">#</a></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3e2f2529</span></span><br><span class="line">git clone https://github.com/ymcui/Chinese-LLaMA-Alpaca.git</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æ³¨æ„: ä¸€å®šè¦ç”¨ commitid &#x3D;3e2f2529çš„ä»£ç ï¼Œ ç”¨æœ€æ–°ä»£ç ä¼šæœ‰å¾ˆå¤šå¼‚å¸¸</p>
</blockquote>
<h3><span id="æ¨¡å‹æƒé‡-åŠ-tokenizer-å‡†å¤‡-4">æ¨¡å‹æƒé‡ åŠ Tokenizer å‡†å¤‡ [4]</span><a href="#æ¨¡å‹æƒé‡-åŠ-tokenizer-å‡†å¤‡-4" class="header-anchor">#</a></h3><h3><span id="æ•°æ®é›†å‡†å¤‡-3">æ•°æ®é›†å‡†å¤‡ [3]</span><a href="#æ•°æ®é›†å‡†å¤‡-3" class="header-anchor">#</a></h3><h1><span id="è¯è¡¨æ‰©å……">è¯è¡¨æ‰©å……</span><a href="#è¯è¡¨æ‰©å……" class="header-anchor">#</a></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python3 merge_tokenizers.py \</span></span><br><span class="line"><span class="language-bash">  --llama_tokenizer_dir /root/internLM/model/skyline2006/llama-7b \</span></span><br><span class="line"><span class="language-bash">  --chinese_sp_model_file /root/internLM/Chinese-LLaMA-Alpaca-main/scripts/merge_tokenizer/chinese_sp.model</span></span><br></pre></td></tr></table></figure>

<h1><span id="æ¨¡å‹è®­ç»ƒç»†èŠ‚">æ¨¡å‹è®­ç»ƒç»†èŠ‚</span><a href="#æ¨¡å‹è®­ç»ƒç»†èŠ‚" class="header-anchor">#</a></h1><h3><span id="ç¬¬äºŒé˜¶æ®µé¢„è®­ç»ƒ">ç¬¬äºŒé˜¶æ®µé¢„è®­ç»ƒ</span><a href="#ç¬¬äºŒé˜¶æ®µé¢„è®­ç»ƒ" class="header-anchor">#</a></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ä¿®æ”¹è¿è¡Œè„šæœ¬run_pt.sh</span><br><span class="line"></span><br><span class="line">lr=2e-4</span><br><span class="line">lora_rank=8</span><br><span class="line">lora_alpha=32</span><br><span class="line">lora_trainable=&quot;q_proj,v_proj,k_proj,o_proj,gate_proj,down_proj,up_proj&quot;</span><br><span class="line">modules_to_save=&quot;embed_tokens,lm_head&quot;</span><br><span class="line">lora_dropout=0.05</span><br><span class="line"></span><br><span class="line">pretrained_model=/root/internLM/model/skyline2006/llama-7b #</span><br><span class="line">chinese_tokenizer_path=/root/internLM/Chinese-LLaMA-Alpaca-main/scripts/merge_tokenizer/merged_tokenizer_hf  #</span><br><span class="line">dataset_dir=/root/internLM/shu-master/books  #</span><br><span class="line">data_cache=/root/cache/books #</span><br><span class="line">per_device_train_batch_size=1</span><br><span class="line">per_device_eval_batch_size=1</span><br><span class="line">training_steps=100</span><br><span class="line">gradient_accumulation_steps=1</span><br><span class="line">output_dir=/root/internLM/llamazh/output_dir #</span><br><span class="line">RANDOM=100 #</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">deepspeed_config_file=ds_zero2_no_offload.json</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>å…·ä½“æ‰§è¡Œè¿‡ç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š<br>sh run_pt.sh </p>
<img src="/www6vHomeAIGC/2023/02/21/gptChineseLlama/1.png" class>
<img src="/www6vHomeAIGC/2023/02/21/gptChineseLlama/2.png" class>
<img src="/www6vHomeAIGC/2023/02/21/gptChineseLlama/3.png" class>

<p>æ¨¡å‹è¾“å‡ºæ–‡ä»¶ï¼š</p>
<img src="/www6vHomeAIGC/2023/02/21/gptChineseLlama/result.png" class>


<h3><span id="å°†-lora-æƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶">å°† LoRA æƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶</span><a href="#å°†-lora-æƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶" class="header-anchor">#</a></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python merge_llama_with_chinese_lora.py \</span><br><span class="line">    --base_model /root/internLM/model/skyline2006/llama-7b \</span><br><span class="line">    --tokenizer_path /root/internLM/Chinese-LLaMA-Alpaca-main/scripts/merge_tokenizer/merged_tokenizer_hf  \</span><br><span class="line">    --lora_model /root/internLM/llamazh/output_dir/lora/ \</span><br><span class="line">    --output_type huggingface \</span><br><span class="line">    --output_dir /root/internLM/llamazh/pt_merged/book-merge-hf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">åˆå¹¶LLaMAå’ŒLoRAåçš„æƒé‡</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ll -h /root/internLM/llamazh/pt_merged/book-merge-hf</span></span><br><span class="line">total 13G</span><br><span class="line">drwxr-xr-x 2 root root 4.0K Feb 23 10:48 ./</span><br><span class="line">drwxr-xr-x 3 root root 4.0K Feb 23 10:47 ../</span><br><span class="line">-rw-r--r-- 1 root root  598 Feb 23 10:47 config.json</span><br><span class="line">-rw-r--r-- 1 root root  132 Feb 23 10:47 generation_config.json</span><br><span class="line">-rw-r--r-- 1 root root 9.3G Feb 23 10:48 pytorch_model-00001-of-00002.bin</span><br><span class="line">-rw-r--r-- 1 root root 3.6G Feb 23 10:48 pytorch_model-00002-of-00002.bin</span><br><span class="line">-rw-r--r-- 1 root root  27K Feb 23 10:48 pytorch_model.bin.index.json</span><br><span class="line">-rw-r--r-- 1 root root  411 Feb 23 10:47 special_tokens_map.json</span><br><span class="line">-rw-r--r-- 1 root root 741K Feb 23 10:47 tokenizer.model</span><br><span class="line">-rw-r--r-- 1 root root  727 Feb 23 10:47 tokenizer_config.json</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">åŸå§‹llamaæƒé‡</span></span><br><span class="line">ll -h /root/internLM/model/skyline2006/llama-7b</span><br><span class="line">total 13G</span><br><span class="line">drwxr-xr-x 2 root root 4.0K Feb 21 20:04 ./</span><br><span class="line">drwxr-xr-x 3 root root 4.0K Feb 21 19:38 ../</span><br><span class="line">-rw-r--r-- 1 root root   43 Feb 21 19:38 .mdl</span><br><span class="line">-rw------- 1 root root 3.6K Feb 21 20:04 .msc</span><br><span class="line">-rw-r--r-- 1 root root   36 Feb 21 20:04 .mv</span><br><span class="line">-rw------- 1 root root  11K Feb 21 19:39 LICENSE</span><br><span class="line">-rw------- 1 root root 9.0K Feb 21 20:04 README.md</span><br><span class="line">-rw------- 1 root root  22M Feb 21 19:38 alpaca_data.json</span><br><span class="line">-rw------- 1 root root  427 Feb 21 19:38 config.json</span><br><span class="line">-rw------- 1 root root  302 Feb 21 19:39 configuration.json</span><br><span class="line">-rw------- 1 root root 1.2K Feb 21 19:39 default_offload_opt_param.json</span><br><span class="line">-rw------- 1 root root  124 Feb 21 19:39 generation_config.json</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:40 pytorch_model-00001-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:42 pytorch_model-00002-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:44 pytorch_model-00003-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:47 pytorch_model-00004-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:50 pytorch_model-00005-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:51 pytorch_model-00006-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:53 pytorch_model-00007-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:55 pytorch_model-00008-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:55 pytorch_model-00009-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:56 pytorch_model-00010-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:56 pytorch_model-00011-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:56 pytorch_model-00012-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:57 pytorch_model-00013-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:57 pytorch_model-00014-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:58 pytorch_model-00015-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:59 pytorch_model-00016-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:59 pytorch_model-00017-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:59 pytorch_model-00018-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 19:59 pytorch_model-00019-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:00 pytorch_model-00020-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:00 pytorch_model-00021-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:00 pytorch_model-00022-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:01 pytorch_model-00023-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:01 pytorch_model-00024-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:01 pytorch_model-00025-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:01 pytorch_model-00026-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:02 pytorch_model-00027-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:02 pytorch_model-00028-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:02 pytorch_model-00029-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:03 pytorch_model-00030-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:03 pytorch_model-00031-of-00033.bin</span><br><span class="line">-rw------- 1 root root 387M Feb 21 20:03 pytorch_model-00032-of-00033.bin</span><br><span class="line">-rw------- 1 root root 501M Feb 21 20:04 pytorch_model-00033-of-00033.bin</span><br><span class="line">-rw------- 1 root root  25K Feb 21 20:04 pytorch_model.bin.index.json</span><br><span class="line">-rw------- 1 root root    2 Feb 21 20:04 special_tokens_map.json</span><br><span class="line">-rw------- 1 root root 489K Feb 21 20:04 tokenizer.model</span><br><span class="line">-rw------- 1 root root  141 Feb 21 20:04 tokenizer_config.json</span><br></pre></td></tr></table></figure>

<h3><span id="æŒ‡ä»¤ç²¾è°ƒ">æŒ‡ä»¤ç²¾è°ƒ</span><a href="#æŒ‡ä»¤ç²¾è°ƒ" class="header-anchor">#</a></h3><p>ä¿®æ”¹æ¨¡å‹ç²¾è°ƒè„šæœ¬run_sft.sh</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pretrained_model=/root/internLM/llamazh/pt_merged/book-merge-hf  #</span><br><span class="line">chinese_tokenizer_path=/root/internLM/Chinese-LLaMA-Alpaca-main/scripts/merge_tokenizer/merged_tokenizer_hf #</span><br><span class="line">dataset_dir=/root/internLM/Chinese-LLaMA-Alpaca-main/data #</span><br><span class="line">per_device_train_batch_size=1</span><br><span class="line">per_device_eval_batch_size=1</span><br><span class="line">training_steps=100</span><br><span class="line">gradient_accumulation_steps=1</span><br><span class="line">output_dir=/root/internLM/llamazh/sft_output  #</span><br><span class="line">#peft_model=path/to/peft/model/dir</span><br><span class="line">validation_file=/root/internLM/llm-action-main/train/chinese-llama-alpaca/alpaca_eval.json  #</span><br><span class="line">RANDOM=1000</span><br><span class="line">deepspeed_config_file=ds_zero2_no_offload.json</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; sh run_sft.sh </span><br></pre></td></tr></table></figure>
<img src="/www6vHomeAIGC/2023/02/21/gptChineseLlama/sft-1.png" class>
<img src="/www6vHomeAIGC/2023/02/21/gptChineseLlama/sft-2.png" class>
<img src="/www6vHomeAIGC/2023/02/21/gptChineseLlama/sft-result1.png" class>
<img src="/www6vHomeAIGC/2023/02/21/gptChineseLlama/sft-result2.png" class>


<p>æ¨¡å‹è¾“å‡ºæ–‡ä»¶ï¼š</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -al -h /root/internLM/llamazh/sft_output/lora</span></span><br><span class="line">total 819M</span><br><span class="line">drwxr-xr-x 2 root root 4.0K Feb 23 15:29 .</span><br><span class="line">drwxr-xr-x 3 root root 4.0K Feb 23 15:29 ..</span><br><span class="line">-rw-r--r-- 1 root root  501 Feb 23 15:29 adapter_config.json</span><br><span class="line">-rw-r--r-- 1 root root 819M Feb 23 15:29 adapter_model.bin</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3><span id="å°†å¤šä¸ªloraæƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶">å°†å¤šä¸ªLoRAæƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶</span><a href="#å°†å¤šä¸ªloraæƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶" class="header-anchor">#</a></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python merge_llama_with_chinese_lora.py \</span><br><span class="line">     --base_model /root/internLM/model/skyline2006/llama-7b \</span><br><span class="line">     --tokenizer_path /root/internLM/llamazh/output_dir,/root/internLM/llamazh/sft_output \</span><br><span class="line">     --lora_model /root/internLM/llamazh/output_dir/lora/,/root/internLM/llamazh/sft_output/lora \</span><br><span class="line">     --output_type huggingface \</span><br><span class="line">     --output_dir /root/internLM/llamazh/all_output</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ll  /root/internLM/llamazh/all_output</span><br><span class="line">total 13449132</span><br><span class="line">drwxr-xr-x 2 root root       4096 Feb 23 16:38 ./</span><br><span class="line">drwxr-xr-x 7 root root       4096 Feb 23 16:38 ../</span><br><span class="line">-rw-r--r-- 1 root root         21 Feb 23 16:38 added_tokens.json</span><br><span class="line">-rw-r--r-- 1 root root        598 Feb 23 16:38 config.json</span><br><span class="line">-rw-r--r-- 1 root root        132 Feb 23 16:38 generation_config.json</span><br><span class="line">-rw-r--r-- 1 root root 9943340890 Feb 23 16:38 pytorch_model-00001-of-00002.bin</span><br><span class="line">-rw-r--r-- 1 root root 3827767515 Feb 23 16:38 pytorch_model-00002-of-00002.bin</span><br><span class="line">-rw-r--r-- 1 root root      26788 Feb 23 16:38 pytorch_model.bin.index.json</span><br><span class="line">-rw-r--r-- 1 root root        435 Feb 23 16:38 special_tokens_map.json</span><br><span class="line">-rw-r--r-- 1 root root     757958 Feb 23 16:38 tokenizer.model</span><br><span class="line">-rw-r--r-- 1 root root        747 Feb 23 16:38 tokenizer_config.json</span><br></pre></td></tr></table></figure>

<h1><span id="æ¨¡å‹æ¨ç†">æ¨¡å‹æ¨ç†</span><a href="#æ¨¡å‹æ¨ç†" class="header-anchor">#</a></h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python inference_hf.py \</span><br><span class="line">     --base_model /root/internLM/llamazh/all_output \</span><br><span class="line">     --with_prompt \</span><br><span class="line">     --interactive</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python inference_hf.py      --base_model /root/internLM/llamazh/all_output      --with_prompt      --<span class="keyword">in</span></span><br><span class="line">teractive</span><br><span class="line">Loading checkpoint shards: <span class="number">100</span>%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| <span class="number">2</span>/<span class="number">2</span> [<span class="number">00</span>:<span class="number">26</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">13.09</span>s/it]</span><br><span class="line">Vocab of the base model: <span class="number">49954</span></span><br><span class="line">Vocab of the tokenizer: <span class="number">49954</span></span><br><span class="line">Start inference <span class="keyword">with</span> instruction mode.</span><br><span class="line">=====================================================================================</span><br><span class="line">+ è¯¥æ¨¡å¼ä¸‹ä»…æ”¯æŒå•è½®é—®ç­”ï¼Œæ— å¤šè½®å¯¹è¯èƒ½åŠ›ã€‚</span><br><span class="line">+ å¦‚è¦è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè¯·ä½¿ç”¨llama.cppæˆ–llamachatå·¥å…·ã€‚</span><br><span class="line">-------------------------------------------------------------------------------------</span><br><span class="line">+ This mode only supports single-turn QA.</span><br><span class="line">+ If you want to experience multi-turn dialogue, please use llama.cpp <span class="keyword">or</span> llamachat.</span><br><span class="line">=====================================================================================</span><br><span class="line">Input:who are youï¼Ÿ</span><br><span class="line">Response:  I am <span class="number">10</span> years old, my name <span class="keyword">is</span> Lilly.</span><br></pre></td></tr></table></figure>

<h1><span id="ç»“è¯­">ç»“è¯­</span><a href="#ç»“è¯­" class="header-anchor">#</a></h1><p>æ•´ä¸ªè®­ç»ƒæµç¨‹:<br>è¯è¡¨æ‰©å……+é¢„è®­ç»ƒ(ç»§ç»­é¢„è®­ç»ƒ)  -&gt;  è¾“å‡ºloraæ¨¡å‹<br>æŒ‡ä»¤ç²¾è°ƒsft   -&gt;  è¾“å‡ºloraæ¨¡å‹<br>åˆå¹¶2ä¸ªloraæ¨¡å‹ï¼Œåœ¨è¿›è¡Œæ¨ç†</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/631360711">ä¸­æ–‡LLaMA&amp;Alpacaå¤§è¯­è¨€æ¨¡å‹è¯è¡¨æ‰©å……+é¢„è®­ç»ƒ+æŒ‡ä»¤ç²¾è°ƒ</a></li>
<li><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/">Chinese-LLaMA-Alpaca</a><br><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki">ä¸­æ–‡æ–‡æ¡£</a><br><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%84%9A%E6%9C%AC">é¢„è®­ç»ƒè„šæœ¬</a></li>
<li><a href="https://github.com/shjwudp/shu">ç»§ç»­é¢„è®­ç»ƒ DataSet</a></li>
<li><a href="https://www.modelscope.cn/models/skyline2006/llama-7b/summary">llama-7b</a> åŸºç¡€æ¨¡å‹</li>
<li><a href="https://github.com/www6v/AIGC/tree/master/chinese-llama-alpaca">chinese-llama-alpaca</a>  git ä»£ç ä»¥è¿™ä¸ªä¸ºä¸»<br><a href="https://github.com/www6v/llm-action/tree/main/train/chinese-llama-alpaca">chinese-llama-alpaca</a> å‚è€ƒè¿™ä¸ªä»£ç ï¼Œæœ‰å¾ˆå¤šé—æ¼çš„æ–‡ä»¶ï¼Œéƒ½è¡¥é½äº†ï¼Œå·²æäº¤åˆ°AIGC</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†|å®æˆ˜)ç»§ç»­Pre-Training</title>
    <url>/www6vHomeAIGC/2023/02/03/gptContinualPretraining/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="ç»§ç»­-é¢„è®­ç»ƒ-continual-pre-training-1">ç»§ç»­-é¢„è®­ç»ƒ continual pre-training [1]</span><a href="#ç»§ç»­-é¢„è®­ç»ƒ-continual-pre-training-1" class="header-anchor">#</a></h1><ul>
<li><p>ç»§ç»­é¢„è®­ç»ƒçš„ç›®çš„<br>ä¸ºäº†å¾—åˆ°<strong>é€‚åº”ä¸åŒè¡Œä¸š&#x2F;ä»»åŠ¡é¢†åŸŸ</strong>çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œ<strong>æå‡ä¸‹æ¸¸ä»»åŠ¡çš„æ•ˆæœ</strong></p>
</li>
<li><p>ä»€ä¹ˆæ—¶å€™éœ€è¦ç»§ç»­é¢„è®­ç»ƒï¼Ÿ<br><strong>é¢„è®­ç»ƒ(pre-train)çš„è¯­æ–™ä¸ä¸‹æ¸¸ä»»åŠ¡(finetune)è¯­æ–™çš„ã€æ•°æ®åˆ†å¸ƒ&#x2F;é¢†åŸŸå·®å¼‚ã€‘å¤§æ—¶</strong></p>
</li>
</ul>
<h1><span id="åƒå¸†llama-2ä¸­æ–‡å¢å¼ºæŠ€æœ¯ä»‹ç»-postpretrain2">åƒå¸†Llama 2ä¸­æ–‡å¢å¼ºæŠ€æœ¯ä»‹ç»-Postpretrain[2]</span><a href="#åƒå¸†llama-2ä¸­æ–‡å¢å¼ºæŠ€æœ¯ä»‹ç»-postpretrain2" class="header-anchor">#</a></h1><ul>
<li><p>ä¸­æ–‡è¯è¡¨æ„å»º +Tokenizer<br>ä¸­æ–‡è¯è¡¨æ‰©å¢ 29k -&gt; 59k</p>
</li>
<li><p>Embedding<br>åœ¨åŸæœ‰EmbeddingçŸ©é˜µåè¿½åŠ ä¸­æ–‡embeddingæ˜ å°„</p>
</li>
<li><p>æ•°æ®é…æ¯”<br> ä¸­æ–‡ï¼šè‹±æ–‡çº¦1:1</p>
</li>
<li><p>pipeline</p>
<ul>
<li>åŸå§‹æ•°æ®é›†</li>
<li><strong>å¼‚å¸¸æ¸…æ´—</strong></li>
<li><strong>æ•°æ®è¿‡æ»¤</strong></li>
<li><strong>å»é‡</strong></li>
<li>éšç§åŒ¿ååŒ–</li>
</ul>
</li>
</ul>
<blockquote>
<p>å¼€æºå¤§æ¨¡å‹é¢„è®­ç»ƒè¯­æ–™é¢„å¤„ç†æµç¨‹æ€»ç»“ï¼š åŸºäºåŸºç¡€è§„åˆ™å¤„ç†ä¸ºä¸» + åŸºäºæ¨¡å‹çš„è´¨é‡è¿‡æ»¤é€æ­¥æˆä¸ºè¶‹åŠ¿</p>
</blockquote>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/545092184">æµ…è°ˆä¸€ä¸‹ã€Œç»§ç»­é¢„è®­ç»ƒã€</a></li>
<li>&lt;&lt;åƒå¸†å¢å¼ºç‰ˆ Llama 2-æå‡å¤§æ¨¡å‹å¯¹è¯æŒ‡ä»¤éµå¾ªèƒ½åŠ›&gt;&gt;<br>1xx. <a href="https://zhuanlan.zhihu.com/p/654463331">å¦‚ä½•æ›´å¥½åœ°ç»§ç»­é¢„è®­ç»ƒï¼ˆContinue PreTrainingï¼‰</a><br>warmup  +  å­¦ä¹ ç‡<br>1xx. <a href="https://blog.csdn.net/Kaiyuan_sjtu/article/details/120695507">Donâ€™t stop pretrainingï¼Œç»§ç»­é¢„è®­ç»ƒï¼</a></li>
</ol>
<p>1xx. ã€ŠInvestigating Continual Pretraining in Large Language Models: Insights and Implicationsã€‹<br>    <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648409027&idx=1&sn=4083853fd0bfb1790d8df6b4414b6583&chksm=83839096b4f41980e8277f34650c2029a45e853adfc2b412ea386952751e44d29e75f0048d12&scene=178&cur_album_id=3343133676745932807#rd">å€¼å¾—ä¸€çœ‹çš„å¤§æ¨¡å‹é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ç­–ç•¥æ€»ç»“ï¼šå…¼è¯»20240229å¤§æ¨¡å‹è¿›å±•æ—©æŠ¥</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>(Survey)Data Management</title>
    <url>/www6vHomeAIGC/2023/04/27/gptDataManagement/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%863">æ•°æ®ç®¡ç†[3]</a><ul>
<li><a href="#pretraining-of-llm">Pretraining of LLM</a></li>
<li><a href="#sft">SFT</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="æ•°æ®ç®¡ç†3">æ•°æ®ç®¡ç†[3]</span><a href="#æ•°æ®ç®¡ç†3" class="header-anchor">#</a></h1><h3><span id="pretraining-of-llm">Pretraining of LLM</span><a href="#pretraining-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Data Quantity</p>
<ul>
<li><strong>Scaling Laws</strong></li>
<li>Data Repetition</li>
</ul>
</li>
<li><p>Data Quality</p>
<ul>
<li>Deduplication<ul>
<li>N-gramå’ŒHashæŠ€æœ¯<br><strong>MinHashç®—æ³•</strong></li>
<li>ç¥ç»ç½‘ç»œæ–¹æ³•</li>
<li>è¯­ä¹‰å»é‡<br>SemDeDup</li>
</ul>
</li>
<li>Quality Filtering   <ul>
<li><strong>åˆ†ç±»å™¨</strong></li>
<li><strong>å¯å‘å¼è§„åˆ™</strong></li>
<li>é˜ˆå€¼è¿‡æ»¤<br>ä¾‹å¦‚åŸºäºå›°æƒ‘åº¦ï¼ˆPerplexityï¼‰</li>
</ul>
</li>
<li>Diversity &amp; Age<ul>
<li><strong>æ•°æ®å¤šæ ·æ€§ï¼ˆDiversityï¼‰</strong></li>
<li>æ•°æ®æ—¶æ•ˆæ€§ï¼ˆAgeï¼‰</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="sft">SFT</span><a href="#sft" class="header-anchor">#</a></h3><ul>
<li><p>Data Quantity</p>
</li>
<li><p>Data Quality</p>
<ul>
<li>Instruction Quality<br>Instruction Mining,  LIMA</li>
<li><strong>Instruction Diversity</strong><br><strong>Self-Instruct</strong>,  <strong>#InsTag</strong>ï¼Œ Alpaca</li>
<li><strong>Instruction Complexity</strong><br><strong>WizardLM</strong>,  <strong>#InsTag</strong>, <strong>Evol-Instruct</strong></li>
<li>Prompt Design</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="3">
<li>ã€ŠData Management For Large Language Models: A Surveyã€‹huawei<br> <a href="https://blog.csdn.net/weixin_60760661/article/details/136058893">å¤§æ¨¡å‹çš„æ•°æ®ç®¡ç†â€”â€”è®ºæ–‡ç²¾è¯»</a><br> <a href="https://github.com/www6v/data_management_LLM">Data Management for LLM</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>DataManagement</category>
      </categories>
      <tags>
        <tag>DataManagement</tag>
      </tags>
  </entry>
  <entry>
    <title>(Survey)æ•°æ®å¤„ç†</title>
    <url>/www6vHomeAIGC/2023/02/05/gptDataProcess/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-pipeline">æ•°æ®å¤„ç† pipeline</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%80%9A%E7%94%A8-1">æ•°æ®å¤„ç†[é€šç”¨] [1]</a><ul>
<li><a href="#%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4">è´¨é‡è¿‡æ»¤</a></li>
<li><a href="#%E5%86%97%E4%BD%99%E5%8E%BB%E9%99%A4">å†—ä½™å»é™¤</a></li>
<li><a href="#%E8%AF%8D%E5%85%83%E5%88%87%E5%88%86">è¯å…ƒåˆ‡åˆ†</a></li>
</ul>
</li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%862">æ•°æ®å¤„ç†[2]</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%A0%87%E8%AE%B0">æ•°æ®æ ‡è®°</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87">æ•°æ®å‡†å¤‡</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA">æ•°æ®å¢å¼º</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-1">æ•°æ®å¢å¼º</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F">æ•°æ®è´¨é‡</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="æ•°æ®å¤„ç†-pipeline">æ•°æ®å¤„ç† pipeline</span><a href="#æ•°æ®å¤„ç†-pipeline" class="header-anchor">#</a></h1><h2><span id="æ•°æ®å¤„ç†é€šç”¨-1">æ•°æ®å¤„ç†[é€šç”¨] [1]</span><a href="#æ•°æ®å¤„ç†é€šç”¨-1" class="header-anchor">#</a></h2><img src="/www6vHomeAIGC/2023/02/05/gptDataProcess/data_process.png" class>

<h3><span id="è´¨é‡è¿‡æ»¤">è´¨é‡è¿‡æ»¤</span><a href="#è´¨é‡è¿‡æ»¤" class="header-anchor">#</a></h3><ul>
<li>åŸºäº<strong>åˆ†ç±»å™¨</strong>çš„æ–¹æ³•</li>
<li>åŸºäº<strong>å¯å‘ å¼</strong>çš„æ–¹æ³•</li>
</ul>
<h3><span id="å†—ä½™å»é™¤">å†—ä½™å»é™¤</span><a href="#å†—ä½™å»é™¤" class="header-anchor">#</a></h3><p>å¯ä»¥åœ¨<strong>å¥å­çº§</strong>ã€<strong>æ–‡æ¡£çº§</strong>å’Œ<strong>æ•°æ®é›†çº§</strong>ç­‰ä¸åŒç²’åº¦ä¸Šå»é‡<br>åœ¨å®è·µä¸­åº”è¯¥ å…±åŒä½¿ç”¨è¿™ä¸‰ä¸ªçº§åˆ«çš„å»é‡</p>
<h3><span id="è¯å…ƒåˆ‡åˆ†">è¯å…ƒåˆ‡åˆ†</span><a href="#è¯å…ƒåˆ‡åˆ†" class="header-anchor">#</a></h3><ul>
<li>BPE</li>
<li>WordPiece</li>
<li>Unigram è¯å…ƒåˆ†æ</li>
</ul>
<h2><span id="æ•°æ®å¤„ç†2">æ•°æ®å¤„ç†[2]</span><a href="#æ•°æ®å¤„ç†2" class="header-anchor">#</a></h2><img src="/www6vHomeAIGC/2023/02/05/gptDataProcess/pipeline.webp" class>
<h3><span id="æ•°æ®æ ‡è®°">æ•°æ®æ ‡è®°</span><a href="#æ•°æ®æ ‡è®°" class="header-anchor">#</a></h3><ul>
<li>åŒ…æ ‡ç­¾</li>
<li>åŠç›‘ç£æ ‡ç­¾</li>
<li>ä¸»åŠ¨å­¦ä¹ </li>
<li>æ•°æ®ç¼–ç¨‹</li>
<li>è¿œç¨‹ç›‘ç£</li>
</ul>
<h3><span id="æ•°æ®å‡†å¤‡">æ•°æ®å‡†å¤‡</span><a href="#æ•°æ®å‡†å¤‡" class="header-anchor">#</a></h3><h3><span id="æ•°æ®å¢å¼º">æ•°æ®å¢å¼º</span><a href="#æ•°æ®å¢å¼º" class="header-anchor">#</a></h3><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li>ã€Šå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‹ </li>
<li>ã€ŠData-centric Artificial Intelligence: A Surveyã€‹ å¤§å­¦<br><a href="https://zhuanlan.zhihu.com/p/620890799">Data-centric Artificial Intelligence: A Survey</a><br> <a href="https://cloud.tencent.com/developer/article/2359824">æœºå™¨å­¦ä¹ æ•°æ®å·¥ç¨‹çš„æ¦‚è¿°</a></li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/639207933">å¤§æ¨¡å‹æ—¶ä»£ä¸‹æ•°æ®çš„é‡è¦æ€§</a> ç»¼è¿°</p>
<p>1xx. <a href="https://hub.baai.ac.cn/view/28740">å¤§æ¨¡å‹ç ”å‘æ ¸å¿ƒï¼šæ•°æ®å·¥ç¨‹ã€è‡ªåŠ¨åŒ–è¯„ä¼°åŠä¸çŸ¥è¯†å›¾è°±çš„ç»“åˆ</a><br>   <a href="https://mp.weixin.qq.com/s/SvDnQD886E3DBtw8k9asgg">å¤§æ¨¡å‹ç ”å‘æ ¸å¿ƒï¼šæ•°æ®å·¥ç¨‹ã€è‡ªåŠ¨åŒ–è¯„ä¼°åŠä¸çŸ¥è¯†å›¾è°±çš„ç»“åˆ </a></p>
<p>1xx. <a href="https://blog.csdn.net/qq_16949707/article/details/133875958">ç¬¦å°§ï¼šåˆ«å·å¤§æ¨¡å‹è®­ç»ƒäº†ï¼Œæ¥å·æ•°æ®å§ï¼ã€å¹²è´§åè¶³ã€‘</a> çœ‹æœ€åçš„5ä¸ªç»“è®º </p>
<ol start="50">
<li><a href="/www6vHomeAIGC/2023/01/06/gptInstructTuning/" title="(åŸç†)Instruct Tuning">(åŸç†)Instruct Tuning</a> self</li>
</ol>
<h3><span id="æ•°æ®å¢å¼º">æ•°æ®å¢å¼º</span><a href="#æ•°æ®å¢å¼º" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/420295576">å“ˆå·¥å¤§ï½œ15ç§NLPæ•°æ®å¢å¼ºæ–¹æ³•æ€»ç»“ä¸å¯¹æ¯”</a></p>
<h3><span id="æ•°æ®è´¨é‡">æ•°æ®è´¨é‡</span><a href="#æ•°æ®è´¨é‡" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403976&idx=1&sn=694db5e2b3085b1610e8d19daa93a474">å†çœ‹å¤§æ¨¡å‹é¢„è®­æ•°æ®è´¨é‡å¦‚ä½•è¯„ä¼°ï¼šå›°æƒ‘åº¦ã€é”™è¯¯L2èŒƒæ•°å’Œè®°å¿†åŒ–ä¸‰ç§åº¦é‡æ–¹æ³•çš„æ•ˆæœå¯¹æ¯”åˆ†æç ”ç©¶</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataProcess</category>
      </categories>
      <tags>
        <tag>dataProcess</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†|å®æˆ˜)Data  Annotation</title>
    <url>/www6vHomeAIGC/2023/04/24/gptDataProcessAnnotation/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="survey">Survey</span><a href="#survey" class="header-anchor">#</a></h3><p>1xx.  <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648408650&idx=2&sn=ef8424969be749489188ebd810800f08">å¦‚ä½•åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡Œæ•°æ®æ ‡æ³¨ä¸çŸ¥è¯†è’¸é¦ï¼šå…¼çœ‹ActiveRAGä¸Šä¸‹æ–‡å»å™ªçš„å¤§æ¨¡å‹RAGé—®ç­”èŒƒå¼</a><br>   å¤§æ¨¡å‹ç”¨äºæ•°æ®æ ‡æ³¨<br>   ã€ŠLarge Language Models for Data Annotation: A Surveyã€‹</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399919&idx=1&sn=66fc1dfdba57744a80c6869b8cf941af">ChatGPTç”¨äºæ•°æ®æ ‡æ³¨æ˜¯å¦å¯è¡Œï¼šåŸºäºæ¨ç‰¹åˆ†ç±»ã€ç”Ÿæˆå†…å®¹æ’åºä»»åŠ¡çš„ä»£è¡¨æ€§å®éªŒæŠ¥å‘Šä»‹ç» </a></p>
<h3><span id="framework">Framework</span><a href="#framework" class="header-anchor">#</a></h3><p>1xx.  AutoLabel - è‡ªåŠ©æ•°æ®æ ‡æ³¨ </p>
<p>1xx. <a href="https://opendatalab.github.io/labelU/">LabelU ä»‹ç»</a><br>   <a href="https://github.com/opendatalab/labelU">LabelU Repo</a> git ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤</p>
<p>1xx. <a href="https://developer.aliyun.com/article/1311807">InsTagï¼šå¤§è¯­è¨€æ¨¡å‹ç›‘ç£å¾®è°ƒæ•°æ®æ ‡ç­¾æ ‡æ³¨å·¥å…·</a>  æœ‰ç›¸å…³çš„paper<br>   <a href="https://www.modelscope.cn/studios/lukeminglkm/instagger_demo/summary">InsTagæŒ‡ä»¤æ‰“æ ‡å·¥å…·</a> demo</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataProcess</category>
      </categories>
      <tags>
        <tag>dataProcess</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)æ•°æ®å¤„ç†</title>
    <url>/www6vHomeAIGC/2023/03/19/gptDataProcessPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%A1%88%E4%BE%8B">æ¡ˆä¾‹</a><ul>
<li><a href="#%E5%8D%83%E5%B8%86llama-2%E4%B8%AD%E6%96%87%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D-sft30">åƒå¸†Llama 2ä¸­æ–‡å¢å¼ºæŠ€æœ¯ä»‹ç»-SFT[30]</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA">æ•°æ®å¢å¼º</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%B2%BE%E7%AE%80">æ•°æ®ç²¾ç®€</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94">æ•°æ®é…æ¯”</a></li>
</ul>
</li>
<li><a href="#%E5%BA%A6%E5%B0%8F%E6%BB%A1%E8%BD%A9%E8%BE%95%E9%87%91%E8%9E%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B31">åº¦å°æ»¡è½©è¾•é‡‘èå¤§æ¨¡å‹[31]</a><ul>
<li><a href="#%E9%80%9A%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E6%B5%81%E6%B0%B4%E7%BA%BF">é€šç”¨çš„æ•°æ®æ¸…æ´—æµæ°´çº¿</a></li>
<li><a href="#%E5%A2%9E%E9%87%8F%E9%A2%84%E8%AE%AD%E7%BB%83-%E6%9C%80%E4%BD%B3%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94">å¢é‡é¢„è®­ç»ƒ æœ€ä½³æ•°æ®é…æ¯”</a></li>
<li><a href="#%E6%9E%84%E9%80%A0%E9%80%9A%E7%94%A8%E5%92%8C%E9%87%91%E8%9E%8D%E6%8C%87%E4%BB%A4%E6%95%B0%E6%8D%AE">æ„é€ é€šç”¨å’Œé‡‘èæŒ‡ä»¤æ•°æ®</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E6%A1%88%E4%BE%8B-1">æ¡ˆä¾‹</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="æ¡ˆä¾‹">æ¡ˆä¾‹</span><a href="#æ¡ˆä¾‹" class="header-anchor">#</a></h1><h2><span id="åƒå¸†llama-2ä¸­æ–‡å¢å¼ºæŠ€æœ¯ä»‹ç»-sft30">åƒå¸†Llama 2ä¸­æ–‡å¢å¼ºæŠ€æœ¯ä»‹ç»-SFT[30]</span><a href="#åƒå¸†llama-2ä¸­æ–‡å¢å¼ºæŠ€æœ¯ä»‹ç»-sft30" class="header-anchor">#</a></h2><h3><span id="æ•°æ®å¢å¼º">æ•°æ®å¢å¼º</span><a href="#æ•°æ®å¢å¼º" class="header-anchor">#</a></h3><ul>
<li>Self-instruct</li>
<li>wizard [20]</li>
</ul>
<h3><span id="æ•°æ®ç²¾ç®€">æ•°æ®ç²¾ç®€</span><a href="#æ•°æ®ç²¾ç®€" class="header-anchor">#</a></h3><ul>
<li>ä½è´¨é‡è¿‡æ»¤</li>
<li>ç›¸ä¼¼æ•°æ®è¿‡æ»¤</li>
</ul>
<h3><span id="æ•°æ®é…æ¯”">æ•°æ®é…æ¯”</span><a href="#æ•°æ®é…æ¯”" class="header-anchor">#</a></h3><ul>
<li>é¢†åŸŸæ•°æ®</li>
<li>å¤šè¯­è¨€æ•°æ®</li>
</ul>
<h2><span id="åº¦å°æ»¡è½©è¾•é‡‘èå¤§æ¨¡å‹31">åº¦å°æ»¡è½©è¾•é‡‘èå¤§æ¨¡å‹[31]</span><a href="#åº¦å°æ»¡è½©è¾•é‡‘èå¤§æ¨¡å‹31" class="header-anchor">#</a></h2><h3><span id="é€šç”¨çš„æ•°æ®æ¸…æ´—æµæ°´çº¿">é€šç”¨çš„æ•°æ®æ¸…æ´—æµæ°´çº¿</span><a href="#é€šç”¨çš„æ•°æ®æ¸…æ´—æµæ°´çº¿" class="header-anchor">#</a></h3><ul>
<li>æ–‡æœ¬æŠ½å–<ul>
<li>å¤šæ¥æºæ•°æ®æ”¶é›†</li>
<li>æ­£æ–‡æå–</li>
</ul>
</li>
<li>æ•°æ®æ¸…æ´—<ul>
<li>è§„åˆ™è¿‡æ»¤</li>
<li>æ¨¡å‹è¿‡æ»¤</li>
</ul>
</li>
<li>å»é‡ä¸æ ¡éªŒ<ul>
<li>MinHashLSH</li>
<li>è´¨é‡æ ¡éªŒ</li>
</ul>
</li>
</ul>
<h3><span id="å¢é‡é¢„è®­ç»ƒ-æœ€ä½³æ•°æ®é…æ¯”">å¢é‡é¢„è®­ç»ƒ æœ€ä½³æ•°æ®é…æ¯”</span><a href="#å¢é‡é¢„è®­ç»ƒ-æœ€ä½³æ•°æ®é…æ¯”" class="header-anchor">#</a></h3><ul>
<li><p><strong>è‹±æ–‡æ•°æ®  vs ä¸­æ–‡æ•°æ®</strong><br><strong>1  :  3</strong></p>
</li>
<li><p>ä¸­æ–‡æ•°æ®ä¸­çš„  <strong>é€šç”¨æ•°æ® vs é‡‘èæ•°æ®</strong><br>ä» 9:1 å˜æˆ  <strong>4:1</strong></p>
<ul>
<li>é€šç”¨é¢†åŸŸæŒ‡ä»¤æ•°æ®<br> 8å¤§ç±» 50å°ç±»</li>
<li>é‡‘èé¢†åŸŸæŒ‡ä»¤æ•°æ®<br> 4å¤§ç±» 20å°ç±»</li>
</ul>
</li>
</ul>
<h3><span id="æ„é€ é€šç”¨å’Œé‡‘èæŒ‡ä»¤æ•°æ®">æ„é€ é€šç”¨å’Œé‡‘èæŒ‡ä»¤æ•°æ®</span><a href="#æ„é€ é€šç”¨å’Œé‡‘èæŒ‡ä»¤æ•°æ®" class="header-anchor">#</a></h3>
<ul>
<li>Self-Instruct</li>
<li>Evol-Instruct</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="æ¡ˆä¾‹">æ¡ˆä¾‹</span><a href="#æ¡ˆä¾‹" class="header-anchor">#</a></h3><ol start="30">
<li>ã€Šåƒå¸†å¢å¼ºç‰ˆ Llama 2ã€‹ ç™¾åº¦ æœ‰ppt</li>
<li>ã€Šé‡‘èè¡Œä¸šå®æˆ˜ï¼šåº¦å°æ»¡è½©è¾•é‡‘èå¤§æ¨¡å‹åº”ç”¨æ¢ç´¢ä¸å¼€å‘å®è·µã€‹ ç™¾åº¦  æœ‰ppt</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399885&idx=1&sn=4f49c5148715c38aa4eaee3080435f17">ä¹Ÿçœ‹å¤§æ¨¡å‹è®­ç»ƒè¯­æ–™å¦‚ä½•æ¸…æ´—ï¼šCommon Crawlæ¦‚è¿°ã€ä»£è¡¨æ€§æ¸…æ´—æ–¹æ¡ˆåŠä»£ç å®ç°          </a> ä»£ç <br>   <a href="https://zhuanlan.zhihu.com/p/610659484?utm_id=0">GPT-3 è®­ç»ƒè¯­æ–™ Common Crawl å¤„ç†æµç¨‹</a></p>
<p>1xx. <a href="https://github.com/alibaba/data-juicer/blob/main/README_ZH.md">Data-Juicer: ä¸ºå¤§è¯­è¨€æ¨¡å‹æä¾›æ›´é«˜è´¨é‡ã€æ›´ä¸°å¯Œã€æ›´æ˜“â€œæ¶ˆåŒ–â€çš„æ•°æ®</a> git</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataProcess</category>
      </categories>
      <tags>
        <tag>dataProcess</tag>
      </tags>
  </entry>
  <entry>
    <title>(è´¨é‡è¿‡æ»¤)RefinedWeb, Textbooks</title>
    <url>/www6vHomeAIGC/2024/02/27/gptDataRefinedWeb/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="åŠ¨æœº1">åŠ¨æœº[1]</span><a href="#åŠ¨æœº1" class="header-anchor">#</a></h1><ul>
<li>ä½œè€…æ‰§ç€è¯æ˜ç½‘é¡µæ•°æ®å¥½äºä¸“æœ‰æ•°æ®<ul>
<li>ç½‘é¡µæ•°æ®çš„é‡çº§æ¯”å…¬å¼€æ•°æ®å¤§çš„å¤šï¼Œä»…ç”¨ä¸“æœ‰æ•°æ®æ¨¡å‹æ¨¡å‹è®­ç»ƒä¸åˆ°æœ€ä½³æ•ˆæœ</li>
<li>ä¸“æœ‰æ•°æ®å¤„ç†èµ·æ¥å¾ˆéº»çƒ¦</li>
<li>å¤§éƒ¨åˆ†ä¸“æœ‰æ•°æ®å…¶å®åœ¨ç½‘é¡µæ•°æ®ä¸­ä¹Ÿèƒ½æ‰¾åˆ°</li>
</ul>
</li>
</ul>
<p>ä½œè€…è®¤ä¸ºè¦æƒ³æ¨¡å‹è®­ç»ƒçš„å¤§ã€è€—è´¹çš„äººåŠ›å°‘å°±ä¸å¾—ä¸é‡æ–°<strong>å°†ç½‘é¡µæ•°æ®ç²¾ç»†åŒ–</strong>åˆ©ç”¨èµ·æ¥ã€‚</p>
<h1><span id="ç»“è®º1">ç»“è®º[1]</span><a href="#ç»“è®º1" class="header-anchor">#</a></h1><ul>
<li>ä½œè€…è¯æ˜äº†ä»…ç”¨<strong>webæ•°æ®</strong>å¦‚æœç»è¿‡æ°å½“çš„<strong>æ¸…æ´—å’Œè¿‡æ»¤</strong>ï¼Œå¯ä»¥è·å¾—è¶…è¿‡ä½¿ç”¨äº†ä¸“æœ‰æ•°æ®æ¨¡å‹çš„æ•ˆæœã€‚</li>
</ul>
<h1><span id="æ–‡æœ¬å¤„ç†pipeline1">æ–‡æœ¬å¤„ç†Pipeline[1]</span><a href="#æ–‡æœ¬å¤„ç†pipeline1" class="header-anchor">#</a></h1><h3><span id="ç›®æ ‡è¯­è¨€è¯†åˆ«">ç›®æ ‡è¯­è¨€è¯†åˆ«</span><a href="#ç›®æ ‡è¯­è¨€è¯†åˆ«" class="header-anchor">#</a></h3><h3><span id="è§„åˆ™è¿‡æ»¤">è§„åˆ™è¿‡æ»¤</span><a href="#è§„åˆ™è¿‡æ»¤" class="header-anchor">#</a></h3><h3><span id="é€šè¿‡æœºå™¨å­¦ä¹ æ–¹æ³•è¿‡æ»¤å‡ºé«˜è´¨é‡è¯­æ–™åº“">é€šè¿‡æœºå™¨å­¦ä¹ æ–¹æ³•è¿‡æ»¤å‡ºé«˜è´¨é‡è¯­æ–™åº“</span><a href="#é€šè¿‡æœºå™¨å­¦ä¹ æ–¹æ³•è¿‡æ»¤å‡ºé«˜è´¨é‡è¯­æ–™åº“" class="header-anchor">#</a></h3><h3><span id="å»é‡deduplication">å»é‡ï¼ˆDeduplicationï¼‰</span><a href="#å»é‡deduplication" class="header-anchor">#</a></h3><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="refinedweb">RefinedWeb</span><a href="#refinedweb" class="header-anchor">#</a></h3><ol>
<li><a href="https://zhuanlan.zhihu.com/p/641013454">æ•°æ®ä¸ºç‹ï¼šå¤§æ¨¡å‹é¢„è®­ç»ƒä¸­çš„æ•°æ®å¤„ç†åŠæ€è€ƒâ€”The RefinedWeb Dataset for Falcon LLMè®ºæ–‡è§£è¯»</a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401484&idx=1&sn=c49b5ca5fc962ca757d3a082b74f037a">â€œè¶…è¶ŠLLama 65Bâ€çš„Falcon40Bè¯­è¨€æ¨¡å‹ä¸ºä»€ä¹ˆå¥½ï¼šå†çœ‹ç²¾ç»†åŒ–çš„æ•°æ®æ¸…æ´—çš„é‡è¦æ€§ </a><br>   RefinedWeb Dataset for Falcon,   Falconé‡‡ç”¨bloomæ¶æ„</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402104&idx=1&sn=7d4924b2a5a840e4ff3de43299248b1d">å†è°ˆå¤§æ¨¡å‹çš„é¢„è®­æ•°æ®æ¸…æ´—ä¸å¾®è°ƒæ•°æ®ç”Ÿæˆï¼šRedPajamaæ•°æ®å¤„ç†æ¡†æ¶ä¸entity-centricæŒ‡ä»¤ç”Ÿæˆæ–¹æ³•è§£è¯» </a><br>    llamaæ•°æ®çš„å¤ç°é¡¹ç›®SlimPajama</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/637996787">ã€Falcon Paperã€‘æˆ‘ä»¬æ˜¯é æ´—æ•°æ®æ´—è´¥ LLaMA çš„ï¼</a> æœª</p>
<h3><span id="textbooks-æ•°é‡-gtscaling-law">Textbooks   æ•°é‡-&gt;scaling law</span><a href="#textbooks-æ•°é‡-gtscaling-law" class="header-anchor">#</a></h3><p>1xx. <a href="https://finisky.github.io/textbooks-are-all-you-need-summary/">æ•°æ®ä¸ºç‹: Textbooks Are All You Need </a>   ä»¥å°åšå¤§  æ‰“ç ´ä¼ ç»Ÿè¯­è¨€æ¨¡å‹ç¼©æ”¾å®šå¾‹<br>1xx. <a href="https://zhuanlan.zhihu.com/p/673021932">Textbooks Are All You Need II: phi-1.5 technical report ç²¾è¯»ä¸ç¿»è¯‘</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/672066480">å°æ¨¡å‹çš„æƒŠäººèƒ½åŠ›: Phi-2</a></p>
<h3><span id="å…¶ä»–">å…¶ä»–</span><a href="#å…¶ä»–" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403821&idx=1&sn=7b96e0db09f05888078019cd20bc8390">å†çœ‹å¤šè¯­ç§å¤§æ¨¡å‹é¢„è®­æ•°æ®å¦‚ä½•æ¸…æ´—ï¼šå…¼è®ºæ–‡æ¡£ç»“æ„ä¿¡æ¯å¯¹å¤§æ¨¡å‹é—®ç­”çš„é‡è¦æ€§åŠå®ç°æ€è·¯ </a><br>äºŒã€å†çœ‹è®­ç»ƒæ•°æ®é›†å¦‚ä½•æ¸…æ´—ï¼šå¤šè¯­ç§å¼€æºè®­ç»ƒæ•°æ®é›†CulturaX</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataProcess</category>
      </categories>
      <tags>
        <tag>dataProcess</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)LIMA, LESS</title>
    <url>/www6vHomeAIGC/2023/04/27/gptDataSFTQuality/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#lima-1kimi">LIMA [1][kimi]</a></li>
<li><a href="#less-%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-10">LESS æ ¸å¿ƒæ€æƒ³ [10]</a></li>
<li><a href="#less10kimi">LESS[10][kimi]</a><ul>
<li><a href="#%E5%AE%9E%E9%AA%8C%E6%96%B9%E6%B3%95">å®éªŒæ–¹æ³•ï¼š</a></li>
<li><a href="#%E7%BB%93%E8%AE%BA">ç»“è®ºï¼š</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#lima">LIMA</a></li>
<li><a href="#less">LESS</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="lima-1kimi">LIMA [1][kimi]</span><a href="#lima-1kimi" class="header-anchor">#</a></h1><p>LIMAï¼ˆLess Is More for Alignmentï¼‰çš„å®éªŒé€šè¿‡ä¸€ç³»åˆ—è®¾è®¡ç²¾è‰¯çš„æ­¥éª¤æ¥æ¢ç©¶æ•°æ®è´¨é‡ã€å¤šæ ·æ€§ä»¥åŠæ•°é‡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä»è€Œå¾—å‡ºäº†<strong>æé«˜æ•°æ®è´¨é‡å’Œå¢åŠ æç¤ºå¤šæ ·æ€§æ¯”å•çº¯å¢åŠ æ•°æ®é‡æ›´èƒ½æå‡æ¨¡å‹æ€§èƒ½çš„ç»“è®º</strong>ã€‚ä»¥ä¸‹æ˜¯<strong>å®éªŒæ–¹æ³•</strong>çš„å…³é”®æ­¥éª¤ï¼š</p>
<ol>
<li><p><strong>ç²¾å¿ƒç­–åˆ’çš„å¾®è°ƒæ•°æ®</strong>ï¼šLIMAæ¨¡å‹åœ¨<strong>1000ä¸ª</strong>ç²¾å¿ƒç­–åˆ’çš„æç¤ºå’Œå›å¤ä¸Šè¿›è¡Œäº†<strong>å¾®è°ƒ</strong>ï¼Œè¿™äº›æ•°æ®è¢«è®¾è®¡ä¸ºæ¨¡æ‹ŸçœŸå®ç”¨æˆ·ä¸AIåŠ©æ‰‹çš„äº¤äº’ã€‚</p>
</li>
<li><p><strong>æ¶ˆèå®éªŒ</strong>ï¼šé€šè¿‡æ¶ˆèå®éªŒï¼Œç ”ç©¶è€…ä»¬è§‚å¯Ÿäº†åœ¨å¢åŠ æ•°æ®é‡çš„åŒæ—¶ä¸å¢åŠ æç¤ºå¤šæ ·æ€§æ—¶ï¼Œæ¨¡å‹æ€§èƒ½çš„æå‡æ˜¯å¦æœ‰é™ï¼›è€Œåœ¨ä¼˜åŒ–æ•°æ®è´¨é‡æ—¶ï¼Œæ€§èƒ½æ˜¯å¦æœ‰æ˜¾è‘—æå‡ã€‚</p>
</li>
<li><p><strong>æ•°æ®æ„é€ </strong>ï¼šç ”ç©¶è€…ä»Stack Exchangeã€wikiHowå’ŒPushshift Redditæ•°æ®é›†æ”¶é›†æ•°æ®ï¼Œå¹¶è¿›è¡Œäº†<strong>è´¨é‡å’Œå¤šæ ·æ€§</strong>çš„æ§åˆ¶ã€‚è¿™äº›æ•°æ®é›†è¢«ç”¨æ¥æ„é€ è®­ç»ƒæ ·æœ¬ï¼Œä»¥ç¡®ä¿è¾“å…¥çš„å¤šæ ·æ€§å’Œè¾“å‡ºçš„ä¸€è‡´æ€§ã€‚</p>
</li>
<li><p><strong>è´¨é‡ä¸å¤šæ ·æ€§çš„å¯¹æ¯”</strong>ï¼šç ”ç©¶è€…æ¯”è¾ƒäº†ç»è¿‡è´¨é‡è¿‡æ»¤çš„Stack Exchangeæ•°æ®å’ŒåŒè´¨åŒ–çš„wikiHowæ•°æ®å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ›´<strong>å¤šæ ·åŒ–çš„Stack Exchangeæ•°æ®åœ¨æ€§èƒ½ä¸Šä¼˜äºåŒè´¨åŒ–çš„wikiHowæ•°æ®</strong>ã€‚ ã€å¤šæ ·åŒ–ã€‘</p>
</li>
<li><p><strong>æ•°é‡çš„å¯¹æ¯”</strong>ï¼šç ”ç©¶è€…å¯¹ä»Stack ExchangeæŠ½å–çš„æŒ‡æ•°çº§å¢åŠ çš„è®­ç»ƒé›†è¿›è¡Œäº†æµ‹è¯•ï¼Œå‘ç°<strong>è®­ç»ƒé›†çš„ç¿»å€å¹¶æ²¡æœ‰æ”¹å–„å“åº”è´¨é‡</strong>ï¼Œä»è€Œè¯´æ˜å•çº¯å¢åŠ æ•°æ®é‡å¹¶ä¸ä¸€å®šèƒ½æå‡æ€§èƒ½ã€‚ã€æ•°é‡ã€‘</p>
</li>
<li><p><strong>è´¨é‡æ§åˆ¶çš„å®éªŒ</strong>ï¼šç ”ç©¶è€…è¿˜æ¯”è¾ƒäº†æœªç»è¿‡ä»»ä½•è´¨é‡æˆ–é£æ ¼è¿‡æ»¤çš„Stack Exchangeæ•°æ®é›†ä¸ç»è¿‡è¿‡æ»¤çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½ï¼Œå‘ç°<strong>è¿‡æ»¤å</strong>çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½<strong>æ›´ä¼˜</strong>ã€‚ã€è´¨é‡ã€‘</p>
</li>
<li><p><strong>äººç±»è¯„ä¼°</strong>ï¼šä¸ºäº†è¯„ä¼°LIMAæ¨¡å‹çš„æ€§èƒ½ï¼Œç ”ç©¶è€…è¿›è¡Œäº†äººç±»åå¥½ç ”ç©¶ï¼Œå°†LIMAçš„è¾“å‡ºä¸å…¶ä»–å‡ ä¸ªåŸºçº¿æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è®©äººç¾¤å·¥ä½œè€…é€‰æ‹©ä»–ä»¬æ›´å–œæ¬¢çš„è¾“å‡ºã€‚</p>
</li>
</ol>
<p>é€šè¿‡è¿™äº›å®éªŒæ­¥éª¤ï¼ŒLIMAçš„ç ”ç©¶å¾—å‡ºäº†<strong>æ•°æ®è´¨é‡å’Œæç¤ºå¤šæ ·æ€§å¯¹äºæå‡æ¨¡å‹æ€§èƒ½çš„é‡è¦æ€§è¿œè¶…è¿‡å•çº¯å¢åŠ æ•°æ®é‡çš„ç»“è®º</strong>ã€‚è¿™äº›å‘ç°æ”¯æŒäº†â€œæµ…å±‚å¯¹é½å‡è¯´â€ï¼Œå³æ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µå·²ç»å­¦ä¹ åˆ°äº†å‡ ä¹æ‰€æœ‰çŸ¥è¯†å’Œèƒ½åŠ›ï¼Œè€Œå¾®è°ƒè¿‡ç¨‹ä¸»è¦æ˜¯å­¦ä¹ ä¸äººç±»äº¤äº’çš„é£æ ¼å’Œæ ¼å¼ã€‚</p>
<ul>
<li><p>æ€»ç»“ [1]</p>
<p>æ¶ˆèå®éªŒæ˜¾ç¤ºï¼Œ<strong>å½“æ‰©å¤§æ•°æ®é‡è€Œä¸åŒæ—¶æ‰©å¤§æç¤ºå¤šæ ·æ€§æ—¶ï¼Œæ”¶ç›Šä¼šå¤§å¤§å‡å°‘ï¼Œè€Œåœ¨ä¼˜åŒ–æ•°æ®è´¨é‡æ—¶ï¼Œæ”¶ç›Šä¼šå¤§å¤§å¢åŠ </strong><br>ã€<strong>æ•°é‡</strong> &lt;â€“&gt; <strong>å¤šæ ·æ€§</strong>  <strong>è´¨é‡</strong>ã€‘</p>
</li>
</ul>
<h1><span id="less-æ ¸å¿ƒæ€æƒ³-10">LESS æ ¸å¿ƒæ€æƒ³ [10]</span><a href="#less-æ ¸å¿ƒæ€æƒ³-10" class="header-anchor">#</a></h1><p>é€šè¿‡ä»…ç»™å‡º<strong>å°‘æ•°ä½“ç°ç‰¹å®šèƒ½åŠ›çš„ç¤ºä¾‹</strong>ï¼Œä»å¤§é‡æŒ‡ä»¤æ•°æ®é›†ä¸­<strong>æœ‰æ•ˆåœ°é€‰æ‹©5%æœ‰å½±å“åŠ›çš„æ•°æ®</strong>ç”¨äºç›®æ ‡æŒ‡ä»¤å¾®è°ƒï¼Œç»“æœä¼˜äºå…¨é‡æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”æ‰€é€‰å­é›†åœ¨ä¸åŒæ¨¡å‹å‚æ•°è§„æ¨¡å’Œä¸åŒæ¨¡å‹ç³»åˆ—ä¸­ä»ç„¶æ™®éæœ‰æ•ˆã€‚</p>
<h1><span id="less10kimi">LESS[10][kimi]</span><a href="#less10kimi" class="header-anchor">#</a></h1><p>LESSï¼ˆSelecting Influential Data for Targeted Instruction Tuningï¼‰çš„å®éªŒæ–¹æ³•å’Œç›¸åº”çš„ç»“è®ºå¦‚ä¸‹ï¼š</p>
<h3><span id="å®éªŒæ–¹æ³•">å®éªŒæ–¹æ³•ï¼š</span><a href="#å®éªŒæ–¹æ³•" class="header-anchor">#</a></h3><ol>
<li><p><strong>çƒ­èº«è®­ç»ƒï¼ˆWarmup Trainingï¼‰</strong>ï¼šä½¿ç”¨LoRAï¼ˆLow-Rank Adaptationï¼‰æŠ€æœ¯å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œçƒ­èº«è®­ç»ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„æ•°æ®åˆ†å¸ƒã€‚</p>
</li>
<li><p><strong>æ¢¯åº¦æ•°æ®å­˜å‚¨ï¼ˆGradient Data Storeï¼‰</strong>ï¼šæ„å»ºäº†ä¸€ä¸ªå…·æœ‰æŠ•å½±ä½ç»´æ¢¯åº¦ç‰¹å¾çš„æ¢¯åº¦æ•°æ®å­˜å‚¨ï¼Œè¯¥å­˜å‚¨å¯ä»¥é‡å¤ç”¨äºä¸åŒçš„ç›®æ ‡ä»»åŠ¡ã€‚</p>
</li>
<li><p><strong>æ•°æ®é€‰æ‹©ç®—æ³•</strong>ï¼šåˆ©ç”¨æ•°æ®å­˜å‚¨å’Œç®—æ³•é€‰æ‹©ä¸ä½“ç°ç‰¹å®šèƒ½åŠ›çš„å°‘æ•°ç¤ºä¾‹æœ€ç›¸ä¼¼çš„è®­ç»ƒæ•°æ®ç‚¹ã€‚?</p>
</li>
<li><p><strong>æ¨¡å‹è®­ç»ƒ</strong>ï¼šä½¿ç”¨é€‰æ‹©çš„æ•°æ®å­é›†æ¥è®­ç»ƒç›®æ ‡æ¨¡å‹ã€‚</p>
</li>
<li><p><strong>è¯„ä¼°</strong>ï¼šåœ¨ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¯„ä¼°LESSé€‰æ‹©çš„æ•°æ®å­é›†çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬MMLUã€TYDIQAå’ŒBBHæ•°æ®é›†ã€‚</p>
</li>
</ol>
<h3><span id="ç»“è®º">ç»“è®ºï¼š</span><a href="#ç»“è®º" class="header-anchor">#</a></h3><ol>
<li><p><strong>LESSçš„æœ‰æ•ˆæ€§</strong>ï¼šLESS<strong>åœ¨ä¸åŒçš„æ¨¡å‹ä¸­éƒ½æ˜¯æœ‰æ•ˆçš„</strong>ï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªè¯„ä¼°æ•°æ®é›†ä¸Šæé«˜æ€§èƒ½ã€‚</p>
</li>
<li><p><strong>æ•°æ®å­é›†çš„æ€§èƒ½</strong>ï¼š<strong>ä½¿ç”¨LESSé€‰æ‹©çš„5%çš„æ•°æ®é€šå¸¸ä¼˜äºä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œè®­ç»ƒçš„ç»“æœ</strong>ã€‚è¿™è¡¨æ˜å®Œæ•´æ•°æ®é›†å¯èƒ½åŒ…å«ä¸ç‰¹å®šç›®æ ‡ä»»åŠ¡æ— å…³æˆ–æœ‰å®³çš„æ•°æ®ç‚¹ã€‚</p>
</li>
<li><p><strong>æ•°æ®çš„å¯è½¬ç§»æ€§</strong>ï¼šä½¿ç”¨è¾ƒå°æ¨¡å‹é€‰æ‹©çš„æ•°æ®å¯ä»¥æé«˜è¾ƒå¤§æ¨¡å‹å’Œä¸åŒæ¨¡å‹ç³»åˆ—çš„æ€§èƒ½ï¼Œè¯æ˜äº†LESSé€‰æ‹©çš„æ•°æ®å…·æœ‰é«˜åº¦çš„å¯è½¬ç§»æ€§ã€‚</p>
</li>
<li><p><strong>ä¸å…¶ä»–æ–¹æ³•çš„æ¯”è¾ƒ</strong>ï¼šLESSæ˜¯å”¯ä¸€ä¸€è‡´æœ‰æ•ˆçš„æ–¹æ³•ï¼Œç›¸è¾ƒäºå…¶ä»–åŸºçº¿æ–¹æ³•ï¼ˆå¦‚éšæœºé€‰æ‹©ã€BM25ã€DSIRã€RDSï¼‰è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</p>
</li>
<li><p><strong>è®¡ç®—æˆæœ¬</strong>ï¼šLESSçš„è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼Œä½†ç”±äºå…¶æœ‰æ•ˆæ€§ï¼Œè¿™ä¸€æˆæœ¬æ˜¯åˆç†çš„ã€‚</p>
</li>
<li><p><strong>å®šæ€§åˆ†æ</strong>ï¼šLESSé€‰æ‹©çš„æ•°æ®èƒ½å¤Ÿä½“ç°é¢„æœŸä¸‹æ¸¸åº”ç”¨æ‰€éœ€çš„æ¨ç†æŠ€èƒ½ï¼Œè€Œä¸æ˜¯ä»…ä»…åŸºäºè¡¨é¢å½¢å¼çº¿ç´¢ã€‚</p>
</li>
<li><p><strong>å±€é™æ€§</strong>ï¼šLESSéœ€è¦çƒ­èº«è®­ç»ƒé˜¶æ®µï¼Œè¿™å¢åŠ äº†è®¡ç®—è´Ÿè½½ã€‚æ­¤å¤–ï¼Œä½¿ç”¨è¡¥å…¨Tokençš„å¹³å‡æ¢¯åº¦å¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜ã€‚è¿˜æœ‰ï¼Œæœ€å°åŒ–éªŒè¯æŸå¤±å¹¶ä¸æ€»èƒ½æé«˜ä»»åŠ¡æ€§èƒ½ï¼Œä¸”æ•°æ®é€‰æ‹©ä¸­çš„çº¿æ€§åº¦å‡è®¾æ˜¯LESSçš„ä¸€ä¸ªé™åˆ¶ã€‚</p>
</li>
</ol>
<p>æ€»ä½“è€Œè¨€ï¼ŒLESSé€šè¿‡é€‰æ‹©ä¸ç›®æ ‡ä»»åŠ¡é«˜åº¦ç›¸å…³çš„æ•°æ®ç‚¹ï¼Œèƒ½å¤Ÿåœ¨æŒ‡ä»¤å¾®è°ƒä¸­å®ç°é«˜æ•ˆçš„æ€§èƒ½æå‡ï¼Œå°½ç®¡å­˜åœ¨ä¸€äº›å±€é™æ€§å’Œè®¡ç®—æˆæœ¬ã€‚</p>
<p>ã€æ€»ç»“:  å°‘é‡æœ‰<strong>è´¨é‡</strong>çš„æ•°æ®  ä¼˜äº  å…¨é‡æ•°æ® ã€‘ ã€æ•°æ®é€‰æ‹©ç®—æ³•ã€‘</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="lima">LIMA</span><a href="#lima" class="header-anchor">#</a></h3><ol>
<li><a href="https://mp.weixin.qq.com/s/c50HrOfKOqgqGPVRHf6EpA">å¤§æ¨¡å‹å¾®è°ƒç©¶ç«Ÿéœ€è¦å¤šå°‘æ•°æ®ï¼šä»ä¸‰ä¸ªç°æœ‰ä»£è¡¨å·¥ä½œçœ‹å‡ ç»„ç»“è®ºåŠä¸€ç‚¹æ€è€ƒ </a><br>  <strong>æŒ‡ä»¤æ ¼å¼çš„å¤šæ ·æ€§</strong><br>  ã€ŠLIMA: Less Is More for Alignmentã€‹<br>  ã€ŠMAYBE ONLY 0.5% DATA IS NEEDEDã€‹</li>
</ol>
<p>1xx. <a href="https://blog.csdn.net/jinniulema/article/details/133915276">ã€è®ºæ–‡ç¬”è®°ã€‘LIMA: Less Is More for Alignment</a></p>
<h3><span id="less">LESS</span><a href="#less" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://zhuanlan.zhihu.com/p/686007325">LESSï¼šä»…é€‰æ‹©5%æœ‰å½±å“åŠ›çš„æ•°æ®ä¼˜äºå…¨é‡æ•°æ®é›†è¿›è¡Œç›®æ ‡æŒ‡ä»¤å¾®è°ƒ</a></li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/686687923">LESS å®è·µï¼šç”¨å°‘é‡çš„æ•°æ®è¿›è¡Œç›®æ ‡æŒ‡ä»¤å¾®è°ƒ</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataset</category>
      </categories>
      <tags>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)SFT Scaling</title>
    <url>/www6vHomeAIGC/2023/04/26/gptDataSFTScaling/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="è®ºæ–‡">è®ºæ–‡</span><a href="#è®ºæ–‡" class="header-anchor">#</a></h1><ul>
<li>è®ºæ–‡åœ°å€<br> ã€ŠWhen Scaling Meets LLM Fine-tuning: The Effect of Data, Model and Fine-tuning Methodã€‹</li>
</ul>
<h1><span id="æ‘˜è¦1">æ‘˜è¦[1]</span><a href="#æ‘˜è¦1" class="header-anchor">#</a></h1><p>è¿™ç¯‡è®ºæ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¾®è°ƒï¼ˆfinetuningï¼‰é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒè§„æ¨¡å› ç´ ä¸‹çš„å¾®è°ƒæ€§èƒ½ã€‚ä½œè€…æ¢è®¨äº†åŒ…æ‹¬LLMæ¨¡å‹å¤§å°ã€é¢„è®­ç»ƒæ•°æ®å¤§å°ã€æ–°å¾®è°ƒå‚æ•°å¤§å°å’Œå¾®è°ƒæ•°æ®å¤§å°åœ¨å†…çš„å¤šä¸ªå› ç´ ï¼Œå¹¶è€ƒè™‘äº†ä¸¤ç§å¾®è°ƒæ–¹æ³•ï¼šå…¨æ¨¡å‹å¾®è°ƒï¼ˆFMTï¼‰å’Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPETï¼ŒåŒ…æ‹¬prompt tuningå’ŒLoRAï¼‰ã€‚ç ”ç©¶å‘ç°LLMå¾®è°ƒéµå¾ªåŸºäº<strong>åŠŸç‡çš„ä¹˜æ³•è”åˆè§„æ¨¡æ³•åˆ™</strong>ï¼Œ<strong>LLMæ¨¡å‹è§„æ¨¡çš„å¢åŠ å¯¹å¾®è°ƒæ€§èƒ½çš„æå‡å¤§äºé¢„è®­ç»ƒæ•°æ®è§„æ¨¡çš„å¢åŠ ï¼Œè€ŒPETå‚æ•°è§„æ¨¡çš„å¢åŠ é€šå¸¸æ•ˆæœä¸ä½³</strong>ã€‚æ­¤å¤–ï¼Œ<strong>å¾®è°ƒæ–¹æ³•çš„é€‰æ‹©é«˜åº¦ä¾èµ–äºå…·ä½“ä»»åŠ¡å’Œå¾®è°ƒæ•°æ®</strong>ã€‚</p>
<p>ã€ åŠŸç‡çš„ä¹˜æ³•è”åˆè§„æ¨¡æ³•åˆ™: å¾®è°ƒæ•°æ®æ•°é‡ &lt;â€“&gt; xxxã€‘<br>ã€æ¨¡å‹å¤§å°(æ ‡é¢˜é‡Œçš„Model ) &gt; é¢„è®­ç»ƒæ•°æ®(æ ‡é¢˜é‡Œçš„Data),   PETå‚æ•°(æ ‡é¢˜é‡Œçš„Fine-tuning Method) æ— æ•ˆã€‘<br>ã€å¾®è°ƒæ–¹æ³•çš„é€‰æ‹©é«˜åº¦ä¾èµ–äºå…·ä½“ä»»åŠ¡å’Œå¾®è°ƒæ•°æ®ã€‘</p>
<h1><span id="å®éªŒæ–¹æ³•1">å®éªŒæ–¹æ³•[1]</span><a href="#å®éªŒæ–¹æ³•1" class="header-anchor">#</a></h1><p>å®éªŒåŸºäºä¸¤ç»„é¢„è®­ç»ƒçš„åŒè¯­LLMsï¼ˆè‹±è¯­&amp;å¾·è¯­ï¼Œè‹±è¯­&amp;ä¸­æ–‡ï¼‰ï¼Œæ¨¡å‹å¤§å°ä»1Båˆ°16Bã€‚ä½œè€…åœ¨WMTæœºå™¨ç¿»è¯‘ï¼ˆè‹±è¯­-å¾·è¯­ã€è‹±è¯­-ä¸­æ–‡ï¼‰å’Œå¤šè¯­è¨€æ‘˜è¦ï¼ˆè‹±è¯­ã€å¾·è¯­ã€æ³•è¯­å’Œè¥¿ç­ç‰™è¯­ï¼‰ä»»åŠ¡ä¸Šè¿›è¡Œäº†å¤§è§„æ¨¡ç ”ç©¶ï¼Œæœ€å¤šä½¿ç”¨20Må¾®è°ƒç¤ºä¾‹ã€‚å®éªŒè®¾ç½®åŒ…æ‹¬ï¼š</p>
<ul>
<li><strong>ä¸‹æ¸¸ä»»åŠ¡</strong>ï¼šé€‰æ‹©æœºå™¨ç¿»è¯‘å’Œå¤šè¯­è¨€æ‘˜è¦ä½œä¸ºå¾®è°ƒçš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</li>
<li><strong>LLMså’Œé¢„è®­ç»ƒ</strong>ï¼šé‡‡ç”¨è§£ç å™¨ä»…Transformeræ¨¡å‹ï¼Œä½¿ç”¨ä¿®æ”¹åçš„UL2ç›®æ ‡è¿›è¡Œè®­ç»ƒã€‚</li>
<li><strong>å¾®è°ƒè®¾ç½®</strong>ï¼šç ”ç©¶äº†ä¸‰ç§å¾®è°ƒæ–¹æ³•ï¼ˆFMTã€Promptå’ŒLoRAï¼‰ï¼Œå¹¶æ¢ç´¢äº†å››ç§ä¸åŒçš„è§„æ¨¡å› ç´ ã€‚</li>
<li><strong>è¯„ä¼°</strong>ï¼šä½¿ç”¨åŸºäºtokençº§åˆ«çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰é€‰æ‹©æœ€ä½³æ£€æŸ¥ç‚¹è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä½¿ç”¨BLEURTå’ŒRougeLè¯„ä¼°ç”Ÿæˆè´¨é‡ã€‚</li>
</ul>
<h1><span id="ç»“è®º1">ç»“è®º[1]</span><a href="#ç»“è®º1" class="header-anchor">#</a></h1><ul>
<li>æå‡ºäº†ä¸€ä¸ªä¹˜æ³•è”åˆè§„æ¨¡æ³•åˆ™æ¥æè¿°å¾®è°ƒæ•°æ®å¤§å°å’Œå…¶ä»–è§„æ¨¡å› ç´ ä¹‹é—´çš„è§„æ¨¡å…³ç³»ã€‚</li>
<li>LLMæ¨¡å‹è§„æ¨¡çš„å¢åŠ å¯¹å¾®è°ƒæ€§èƒ½çš„æå‡å¤§äºé¢„è®­ç»ƒæ•°æ®è§„æ¨¡çš„å¢åŠ ã€‚</li>
<li>PETå‚æ•°è§„æ¨¡çš„å¢åŠ å¯¹äºLoRAå’ŒPromptçš„æ•ˆæœæœ‰é™ï¼Œä¸”æœ‰æ—¶ç”šè‡³ä¼šå¯¼è‡´åå‘è§„æ¨¡æ•ˆåº”ã€‚</li>
<li>å¾®è°ƒæ–¹æ³•çš„é€‰æ‹©å¯¹äºä¸‹æ¸¸ä»»åŠ¡æ¥è¯´å¹¶ä¸ç®€å•ï¼Œéœ€è¦æ ¹æ®ä»»åŠ¡ç‰¹æ€§å’Œå¾®è°ƒæ•°æ®çš„å¯ç”¨æ€§æ¥å†³å®šã€‚</li>
<li>å¾®è°ƒå¯èƒ½ä¼šæé«˜æ¨¡å‹å¯¹ç›¸å…³ä»»åŠ¡çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯å½“åŸºç¡€LLMè¾ƒå¤§æ—¶ï¼ŒPromptå’ŒLoRAé€šå¸¸æ¯”FMTè¡¨ç°å¾—æ›´å¥½ã€‚</li>
</ul>
<p>ä½œè€…æŒ‡å‡ºï¼Œå°½ç®¡ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œä½†ä¹Ÿå­˜åœ¨ä¸€äº›å±€é™æ€§ï¼Œå¦‚è”åˆè§„æ¨¡æ³•åˆ™ä¸»è¦åŸºäºå°é—­ç”Ÿæˆä»»åŠ¡çš„å®è¯ç»“æœï¼Œç¼ºä¹ç†è®ºåŸºç¡€ã€‚æœªæ¥çš„å·¥ä½œå°†æ‰©å±•åˆ°å¤šæ¨¡æ€LLMsï¼Œæ¢ç´¢å¾®è°ƒæ•°æ®è´¨é‡çš„å½±å“ï¼Œå¹¶è€ƒè™‘å¼€æ”¾å’Œåˆ›é€ æ€§çš„ç”Ÿæˆä»»åŠ¡ä»¥åŠå¾®è°ƒçš„å¤šä»»åŠ¡è®¾ç½®ã€‚</p>
<h1><span id="é‡è¦ç»“è®º2">é‡è¦ç»“è®º[2]</span><a href="#é‡è¦ç»“è®º2" class="header-anchor">#</a></h1><p>ä½œè€…ä»¬æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¾®è°ƒï¼ˆfinetuningï¼‰è¿‡ç¨‹ä¸­ä¸åŒè§„æ¨¡å› ç´ å¯¹æ€§èƒ½çš„å½±å“ã€‚ä»¥ä¸‹æ˜¯è®ºæ–‡çš„ä¸€äº›é‡è¦ç»“è®ºåŠå…¶å¯¹â€œSCALINGâ€æ¦‚å¿µçš„è§£é‡Šï¼š</p>
<ol>
<li><p><strong>ä¹˜æ³•è”åˆç¼©æ”¾æ³•åˆ™</strong>ï¼šä½œè€…æå‡ºäº†ä¸€ä¸ªåŸºäº<strong>ä¹˜æ³•çš„è”åˆç¼©æ”¾æ³•åˆ™ï¼ˆmultiplicative joint scaling lawï¼‰</strong>ï¼Œç”¨äºæè¿°å¾®è°ƒæ•°æ®å¤§å°ä¸å…¶ä»–ç¼©æ”¾å› ç´ ï¼ˆå¦‚LLMæ¨¡å‹å¤§å°ã€é¢„è®­ç»ƒæ•°æ®å¤§å°ã€PETå‚æ•°å¤§å°ï¼‰ä¹‹é—´çš„å…³ç³»ã€‚è¿™ä¸ªæ³•åˆ™è¡¨æ˜ï¼Œ<strong>å¾®è°ƒæ€§èƒ½ä¸è¿™äº›å› ç´ çš„ä¹˜æ³•ç»„åˆæœ‰å…³</strong>ï¼Œè€Œä¸æ˜¯ç®€å•çš„åŠ æ³•å…³ç³»ã€‚</p>
</li>
<li><p><strong>æ¨¡å‹å¤§å°å¯¹å¾®è°ƒçš„å½±å“</strong>ï¼šç ”ç©¶å‘ç°ï¼Œ<strong>å¢åŠ LLMæ¨¡å‹çš„å¤§å°å¯¹å¾®è°ƒæ€§èƒ½çš„æå‡æ¯”å¢åŠ é¢„è®­ç»ƒæ•°æ®çš„å¤§å°æ›´ä¸ºæ˜¾è‘—</strong>ã€‚è¿™è¡¨æ˜åœ¨æœ‰é™èµ„æºä¸‹ï¼Œ<strong>ä¼˜å…ˆè€ƒè™‘æ‰©å¤§æ¨¡å‹è§„æ¨¡è€Œä¸æ˜¯æ•°æ®è§„æ¨¡</strong>ï¼Œå¯èƒ½ä¼šå¸¦æ¥æ›´å¥½çš„å¾®è°ƒæ•ˆæœã€‚</p>
</li>
<li><p><strong>å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPETï¼‰çš„å±€é™æ€§</strong>ï¼šå°½ç®¡PETæ–¹æ³•ï¼ˆå¦‚prompt tuningå’ŒLoRAï¼‰æ—¨åœ¨é€šè¿‡ä¼˜åŒ–å°‘é‡å‚æ•°æ¥æé«˜æ€§èƒ½ï¼Œä½†ç ”ç©¶å‘ç°<strong>å¢åŠ PETå‚æ•°çš„å¤§å°å¯¹äºå¾®è°ƒæ€§èƒ½çš„æå‡æ•ˆæœæœ‰é™ï¼Œæœ‰æ—¶ç”šè‡³ä¼šå‡ºç°åå‘ç¼©æ”¾ç°è±¡</strong>ã€‚</p>
</li>
<li><p><strong>ä»»åŠ¡å’Œæ•°æ®ä¾èµ–æ€§</strong>ï¼šå¾®è°ƒçš„ç¼©æ”¾ç‰¹æ€§é«˜åº¦ä¾èµ–äºå…·ä½“ä»»åŠ¡å’Œæ•°æ®ã€‚è¿™æ„å‘³ç€<strong>æ²¡æœ‰ä¸€ç§é€šç”¨çš„æœ€ä¼˜å¾®è°ƒæ–¹æ³•</strong>ï¼Œé€‰æ‹©å“ªç§å¾®è°ƒæ–¹æ³•éœ€è¦æ ¹æ®ä¸‹æ¸¸ä»»åŠ¡çš„ç‰¹æ€§å’Œå¯ç”¨çš„å¾®è°ƒæ•°æ®é‡æ¥å†³å®šã€‚</p>
</li>
<li><p><strong>å¾®è°ƒå¯¹é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›çš„å½±å“</strong>ï¼šå°½ç®¡å¾®è°ƒé€šå¸¸æ˜¯ä¸ºäº†æé«˜ç‰¹å®šä»»åŠ¡çš„æ€§èƒ½ï¼Œä½†ç ”ç©¶å‘ç°ï¼ŒåŸºäºLLMçš„å¾®è°ƒä»ç„¶å¯ä»¥ä¿ƒè¿›å¯¹ç›¸å…³ä»»åŠ¡çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚ç‰¹åˆ«æ˜¯PETæ–¹æ³•åœ¨ä¿ç•™æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´å¥½ã€‚</p>
</li>
<li><p><strong>å¾®è°ƒæ•°æ®é‡çš„ä¸´ç•Œç‚¹</strong>ï¼šè®ºæ–‡ä¸­è¿˜è®¨è®ºäº†ä¸åŒå¾®è°ƒæ–¹æ³•ä¹‹é—´çš„ä¸´ç•Œç‚¹ï¼Œå³åœ¨ç‰¹å®šçš„å¾®è°ƒæ•°æ®é‡ä¸‹ï¼Œä¸€ç§æ–¹æ³•å¯èƒ½æ¯”å¦ä¸€ç§æ–¹æ³•è¡¨ç°å¾—æ›´å¥½ã€‚è¿™ä¸ªä¸´ç•Œç‚¹ä¼šéšç€ä»»åŠ¡å’Œæ¨¡å‹å¤§å°çš„ä¸åŒè€Œå˜åŒ–ã€‚</p>
</li>
</ol>
<p>è¿™äº›ç»“è®ºå¯¹ç†è§£LLMå¾®è°ƒè¿‡ç¨‹ä¸­çš„â€œSCALINGâ€å…·æœ‰é‡è¦æ„ä¹‰ã€‚å®ƒä»¬æ­ç¤ºäº†ä¸åŒè§„æ¨¡å› ç´ å¦‚ä½•ç›¸äº’ä½œç”¨ä»¥åŠå®ƒä»¬å¯¹å¾®è°ƒæ€§èƒ½çš„å…±åŒå½±å“ï¼Œä¸ºåœ¨å®é™…åº”ç”¨ä¸­é€‰æ‹©å’Œä¼˜åŒ–å¾®è°ƒç­–ç•¥æä¾›äº†ç†è®ºä¾æ®ã€‚é€šè¿‡è¿™äº›å‘ç°ï¼Œç ”ç©¶è€…å’Œå®è·µè€…å¯ä»¥æ›´å¥½åœ°ç†è§£åœ¨ç‰¹å®šæ¡ä»¶ä¸‹å¦‚ä½•æœ‰æ•ˆåœ°ç¼©æ”¾å’Œé…ç½®ä»–ä»¬çš„æ¨¡å‹ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href>è¯·å¸®æˆ‘è¯»ç¯‡è®ºæ–‡ï¼Œè¯¦ç»†çš„å†™å‡ºæ‘˜è¦ï¼Œå®éªŒæ–¹æ³•ï¼Œç»“è®º</a> kimi</li>
<li><a href>è¯·å¸®æˆ‘è¯»ç¯‡è®ºæ–‡ï¼Œè®ºæ–‡æœ‰å“ªäº›é‡è¦çš„ç»“è®ºï¼Ÿ è¿™äº›ç»“è®ºæ˜¯å¦‚ä½•è§£é‡Šé¢˜ç›®ä¸­çš„SCALINGçš„ï¼Ÿ</a> kimi</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648409027&idx=1&sn=4083853fd0bfb1790d8df6b4414b6583">å€¼å¾—ä¸€çœ‹çš„å¤§æ¨¡å‹é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ç­–ç•¥æ€»ç»“ï¼šå…¼è¯»20240229å¤§æ¨¡å‹è¿›å±•æ—©æŠ¥ </a><br>ã€ŠWhen Scaling Meets LLM Finetuning: The Effect of Dataï¼Œ Model and Finetuning MethodÂ»</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataset</category>
      </categories>
      <tags>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Data Selection</title>
    <url>/www6vHomeAIGC/2023/05/05/gptDataSelection/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#ifd1">IFD[1]</a></li>
<li><a href="#mods2">MoDS[2]</a></li>
<li><a href="#deita-3">DEITA [3]</a><ul>
<li><a href="#%E5%A4%8D%E6%9D%82%E6%80%A7%E8%AF%84%E5%88%86">å¤æ‚æ€§è¯„åˆ†</a></li>
<li><a href="#%E8%B4%A8%E9%87%8F%E8%AF%84%E5%88%86">è´¨é‡è¯„åˆ†</a></li>
<li><a href="#%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%AD%9B%E9%80%89">å¤šæ ·æ€§ç­›é€‰</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="ifd1">IFD[1]</span><a href="#ifd1" class="header-anchor">#</a></h1><ul>
<li>ä¸‰ä¸ªæ­¥éª¤<ul>
<li>Learning from Brief Experience<br>åˆ©ç”¨å°‘é‡è¿›è¡Œè¿›è¡Œ<strong>æ¨¡å‹åˆå­¦</strong> </li>
<li>Evaluating Based on Experience<br>åˆ©ç”¨åˆå­¦æ¨¡å‹è®¡ç®—åŸå§‹æ•°æ®ä¸­æ‰€æœ‰<strong>IFDæŒ‡æ ‡</strong><ul>
<li>ç®—æ³•<ul>
<li>æ¡ä»¶å›ç­”åˆ†æ•°ï¼ˆ Conditioned Answer Scoreï¼ŒCASï¼‰</li>
<li>ç›´æ¥ç­”æ¡ˆåˆ†æ•°ï¼ˆDirect Answer Scoreï¼ŒDASï¼‰</li>
<li>æŒ‡ä»¤è·Ÿéšéš¾åº¦ï¼ˆInstruction-Following Difficultyï¼ŒIFDï¼‰åˆ†æ•°</li>
</ul>
</li>
</ul>
</li>
<li>Retraining from Self-Guided Experience<br>åˆ©ç”¨<strong>æ¨±æ¡ƒæ•°æ®</strong>è¿›è¡Œæ¨¡å‹<strong>é‡è®­ç»ƒ</strong></li>
</ul>
</li>
</ul>
<h1><span id="mods2">MoDS[2]</span><a href="#mods2" class="header-anchor">#</a></h1><ul>
<li><p>è´¨é‡ç­›é€‰<br>é‡‡ç”¨OpenAssistantçš„<strong>reward-model</strong>-debertav3-large-v2æ¨¡å‹ï¼ˆä¸€ä¸ªåŸºäº<strong>DeBERTaæ¶æ„</strong>è®¾è®¡çš„å¥–åŠ±æ¨¡å‹ï¼‰å¯¹æ•°æ®è¿›è¡Œ<strong>è´¨é‡æ‰“åˆ†</strong>ã€‚</p>
</li>
<li><p>å¤šæ ·æ€§ç­›é€‰<br>ä¸ºäº†é¿å…æ‰€é€‰è´¨é‡æ•°æ®é«˜åº¦ç›¸ä¼¼ï¼Œé€šè¿‡<strong>K-Center-Greedyç®—æ³•</strong>è¿›è¡Œæ•°æ®ç­›é€‰ï¼Œåœ¨æœ€å¤§åŒ–å¤šæ ·æ€§çš„æƒ…å†µä¸‹ï¼Œä½¿æŒ‡ä»¤æ•°æ®é›†æœ€å°ã€‚<br>åœ¨è¯¥æ­¥éª¤ä¸­ï¼Œé‡‡ç”¨<strong>BERTæ¨¡å‹</strong>ä¸ºæŒ‡ä»¤æ•°æ®ç”Ÿæˆå¥å‘é‡æ¥è®¡ç®—ä¸åŒæ•°æ®ä¹‹é—´çš„è·ç¦»ã€‚</p>
</li>
<li><p>å¿…è¦æ€§ç­›é€‰</p>
</li>
</ul>
<h1><span id="deita-3">DEITA [3]</span><a href="#deita-3" class="header-anchor">#</a></h1><h3><span id="å¤æ‚æ€§è¯„åˆ†">å¤æ‚æ€§è¯„åˆ†</span><a href="#å¤æ‚æ€§è¯„åˆ†" class="header-anchor">#</a></h3><ul>
<li>å¤æ‚æ€§è¯„ä¼°çš„æ–¹æ³•  <ul>
<li>Random Selectionï¼šéšæœºé€‰æ‹©æ ·æœ¬ã€‚</li>
<li>Instruction Lengthï¼šæŒ‰ç…§æŒ‡ä»¤çš„é•¿åº¦è®¡ç®—å¤æ‚æ€§ã€‚</li>
<li><strong>Perplexity</strong>ï¼šé€šè¿‡é¢„è®­ç»ƒæ¨¡å‹è®¡ç®—å›å¤çš„å›°æƒ‘åº¦ä½œä¸ºå¤æ‚æ€§æŒ‡æ ‡ï¼Œå›°æƒ‘å€¼è¶Šå¤§æ„å‘³ç€æ•°æ®æ ·æœ¬è¶Šéš¾ã€‚</li>
<li><strong>Direct Scoring</strong>ï¼šåˆ©ç”¨ChaGPTç»™æŒ‡ä»¤çš„å¤æ‚æ€§æ‰“åˆ†ã€‚</li>
<li>Instruction Nodeï¼šåˆ©ç”¨ChatGPTå°†æŒ‡ä»¤è½¬æ¢æˆè¯­ä¹‰æ ‘ï¼Œé€šè¿‡æ ‘çš„èŠ‚ç‚¹æ•°ä½œä¸ºå¤æ‚æ€§æŒ‡æ ‡ã€‚</li>
<li><strong>Instag Complexity</strong>ï¼šåˆ©ç”¨ChatGPTå¯¹éƒ¨åˆ†æ•°æ®è¿›è¡Œæ‰“æ ‡ç­¾ï¼Œå†è®­ç»ƒä¸€ä¸ªLlamaæ¨¡å‹ï¼Œå†åˆ©ç”¨è®­ç»ƒåçš„Llamaæ¨¡å‹å¯¹å…¨é‡æ•°æ®é¢„æµ‹ï¼Œæ ‡ç­¾è¶Šå¤šè¯´æ˜æ•°æ®çº¦å¤æ‚ã€‚</li>
<li><strong>IFD</strong>ï¼šæŒ‡ä»¤è·Ÿéšéš¾åº¦ä½œä¸ºå¤æ‚æ€§æŒ‡æ ‡ã€‚</li>
</ul>
</li>
</ul>
<p>DEITAè¯„ä¼°å¤æ‚æ€§çš„æ–¹æ³•ï¼Œä¸»è¦å…ˆå¯¹ä¸€ä¸ªå°è§„æ¨¡ç§å­æ•°æ®é›†ï¼ˆ2kï¼‰è¿›è¡Œæ•°æ®å¤æ‚æ€§<strong>æ‰©å±•</strong>ï¼Œå†åˆ©<strong>ç”¨ChatGPTå¯¹æ‰©å±•æ•°æ®è¿›è¡Œæ‰“åˆ†</strong>ï¼Œå¹¶<strong>è®­ç»ƒä¸€ä¸ªLlama1-7Bçš„æ¨¡å‹</strong>ï¼Œæœ€ååˆ©ç”¨è®­ç»ƒåçš„æ¨¡å‹å¯¹æ•°æ®çš„æ‰“åˆ†ä½œä¸ºå¤æ‚æ€§è¯„ä¼°æŒ‡æ ‡ã€‚</p>
<h3><span id="è´¨é‡è¯„åˆ†">è´¨é‡è¯„åˆ†</span><a href="#è´¨é‡è¯„åˆ†" class="header-anchor">#</a></h3><ul>
<li>è´¨é‡è¯„ä¼°çš„æ–¹æ³•æœ‰<ul>
<li>Random Selectionï¼šéšæœºé€‰æ‹©æ ·æœ¬ã€‚</li>
<li>Response Lengthï¼šé‡‡ç”¨è¾“å‡ºé•¿åº¦ä½œä¸ºè´¨é‡è¯„ä¼°æŒ‡æ ‡ã€‚</li>
<li>Direct Scoringï¼šåˆ©ç”¨ChatGPTç›´æ¥è¯„ä¼°å¯¹ç‰¹å®šæŒ‡ä»¤è¾“å‡ºç»“æœçš„å‡†ç¡®æ€§ã€‚</li>
</ul>
</li>
</ul>
<p>DEITAè¯„ä¼°è´¨é‡çš„æ–¹æ³•ï¼Œ<strong>ä¸è¯„ä¼°å¤æ‚æ€§æ–¹æ³•ä¸€è‡´</strong>ã€‚å…ˆå¯¹ä¸€ä¸ªå°è§„æ¨¡ç§å­æ•°æ®é›†ï¼ˆ2kï¼Œä¸å¤æ‚æ€§æ•°æ®ä¸€è‡´ï¼‰è¿›è¡Œæ•°æ®è´¨é‡æ‰©å±•ï¼Œå†åˆ©ç”¨ChatGPTå¯¹æ‰©å±•æ•°æ®è¿›è¡Œæ‰“åˆ†å¹¶è®­ç»ƒä¸€ä¸ªLlama1-7Bçš„æ¨¡å‹ï¼Œæœ€ååˆ©ç”¨è®­ç»ƒåçš„æ¨¡å‹å¯¹æ•°æ®çš„æ‰“åˆ†ä½œä¸ºè´¨é‡è¯„ä¼°æŒ‡æ ‡ã€‚</p>
<p><strong>æ•°æ®è´¨é‡æ‰©å±•</strong>ï¼Œé€šè¿‡ç‰¹æ®Šçš„æç¤ºè¯åˆ©ç”¨ChatGPTå¯¹æ•°æ®çš„å›å¤éƒ¨åˆ†è¿›è¡Œæ”¹å†™ï¼Œä¸»è¦æ˜¯å¢å¼ºå›å¤çš„æœ‰ç”¨æ€§ã€ç›¸å…³æ€§ã€ä¸°å¯Œæ·±åº¦ã€åˆ›é€ åŠ›å’Œæä¾›é¢å¤–çš„ç»†èŠ‚æè¿°ã€‚</p>
<h3><span id="å¤šæ ·æ€§ç­›é€‰">å¤šæ ·æ€§ç­›é€‰</span><a href="#å¤šæ ·æ€§ç­›é€‰" class="header-anchor">#</a></h3><p>å¤šæ ·æ€§ç­›é€‰æ–¹æ³•ï¼Œé¦–å…ˆå°†æ•°æ®æ± ä¸­çš„æ•°æ®æŒ‰ç…§å¤æ‚æ€§å’Œè´¨é‡çš„ç»¼åˆå¾—åˆ†ï¼ˆå¤æ‚æ€§åˆ†æ•°*è´¨é‡åˆ†æ•°ï¼‰è¿›è¡Œé™åº<strong>æ’åº</strong>ï¼›<br>ç„¶åæŒ‰é¡ºåºé€ä¸ªå–å‡ºæ ·æœ¬æ•°æ®x ï¼Œ<strong>è®¡ç®—x ä¸ç­›é€‰æ± ä¸­ç›¸é‚»æœ€è¿‘çš„æ ·æœ¬ä¹‹é—´è·ç¦»å€¼</strong>ï¼Œå…¶ä¸­ï¼Œæ•°æ®åˆ©ç”¨Llama1-13Bæ¨¡å‹è¿›è¡Œå‘é‡è¡¨å¾ï¼Œè·ç¦»è®¡ç®—é‡‡ç”¨<strong>ä½™å¼¦ç›¸ä¼¼åº¦</strong>ã€‚<br>å¦‚æœ<strong>è·ç¦»å€¼å°äº ræ—¶</strong>ï¼Œè®¤ä¸ºè¯¥æ ·æœ¬ä¸ç­›é€‰æ± ä¸­æ•°æ®ç›¸ä¼¼ç¨‹åº¦ä¸é«˜ï¼Œå¯ä»¥<strong>çº³å…¥ç­›é€‰æ± </strong>ï¼›å¦åˆ™<strong>ä¸çº³å…¥ç­›é€‰æ± </strong>ã€‚å½“ç­›é€‰æ± ä¸­æ ·æœ¬æ•°è¾¾åˆ°è§„å®šæ ·æœ¬ä¸ªæ•°ï¼Œå®Œæˆå¤šæ ·æ€§ç­›é€‰ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/658128530">å¦‚ä½•ä»æ•°æ®é›†ä¸­è‡ªåŠ¨è¯†åˆ«é«˜è´¨é‡çš„æŒ‡ä»¤æ•°æ®-IFDæŒ‡æ ‡çš„ä½¿ç”¨</a><br>ã€ŠFrom Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuningã€‹<br>ChatLawå°±è¿™ä¹ˆè®­çš„</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/671183709">å¤§æ¨¡å‹å¾®è°ƒæŠ€å·§ | é«˜è´¨é‡æŒ‡ä»¤æ•°æ®ç­›é€‰æ–¹æ³•-MoDS</a><br>ã€ŠMoDS: Model-oriented Data Selection for Instruction Tuningã€‹<br> è´¨é‡ç­›é€‰ï¼Œ å¤šæ ·æ€§ç­›é€‰ï¼Œå¿…è¦æ€§ç­›é€‰   </p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/675928711">DEITA-å¤§æ¨¡å‹æŒ‡ä»¤å¾®è°ƒçš„æ•°æ®é«˜æ•ˆç­›é€‰æ–¹æ³•</a></p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/687339776">DEITAï¼šèåˆå¤æ‚åº¦ã€è´¨é‡ã€å¤šæ ·æ€§çš„é«˜æ•ˆæ•°æ®ç­›é€‰</a><br>   å¤æ‚åº¦ã€è´¨é‡ã€å¤šæ ·æ€§</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648409027&idx=1&sn=4083853fd0bfb1790d8df6b4414b6583">å€¼å¾—ä¸€çœ‹çš„å¤§æ¨¡å‹é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ç­–ç•¥æ€»ç»“ï¼šå…¼è¯»20240229å¤§æ¨¡å‹è¿›å±•æ—©æŠ¥ </a><br>ã€ŠA Survey on Data Selection for Language Modelsã€‹</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Data Selection</category>
      </categories>
      <tags>
        <tag>Data Selection</tag>
      </tags>
  </entry>
  <entry>
    <title>(list)æ•°æ®é›†</title>
    <url>/www6vHomeAIGC/2023/01/08/gptDataSet/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="dataset">DataSet</span><a href="#dataset" class="header-anchor">#</a></h1><ul>
<li><p>ç»¼åˆ[å¹³å°] </p>
<ul>
<li><a href="http://opendatalab.com/">OpenDataLab</a> [1]<br>ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤<br><strong>æ•°æ®æè¿°è¯­è¨€  DSDL</strong> + å¹³å°æ ‡å‡†æ•°æ®é›†</li>
<li><a href="https://www.luge.ai/#/">åƒè¨€æ•°æ®é›†</a><br>ç™¾åº¦</li>
</ul>
</li>
<li><p>è¯„æµ‹æ•°æ®é›†</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648405040&idx=1&sn=ad45944e78b5742337158cff80dbd9b3">å†çœ‹é¢†åŸŸå¾®è°ƒå¤§æ¨¡å‹çš„ä¸»æµåŸºåº§å’Œè¯„æµ‹æ•°æ®é›†ï¼šé¡¹ç›®åœ°å€åŠè®ºæ–‡æŒ‡å¼•</a></li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV18m4y1h7zW/">å¤§æ¨¡å‹æ—¶ä»£çš„æ•°æ®å˜é© - å¦‚ä½•è®¾è®¡å¤§æ¨¡å‹çš„æ•°æ®é…æ–¹ã€æ™ºèƒ½æ•°æ®é‡‡é›†ã€æ ‡æ³¨ã€ETL</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataset</category>
      </categories>
      <tags>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>(List) Pretrain æ•°æ®é›†</title>
    <url>/www6vHomeAIGC/2023/04/24/gptDataSetPretrainList/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="pretrainæ•°æ®é›†">Pretrainæ•°æ®é›†</span><a href="#pretrainæ•°æ®é›†" class="header-anchor">#</a></h1><ul>
<li><a href="https://zhuanlan.zhihu.com/p/641187337">LLMå¤§æ¨¡å‹æ•°æ®é›†ä¹‹è°œ</a> Pretrainæ•°æ®é›†</li>
<li><a href="https://github.com/brightmart/nlp_chinese_corpus">å¤§è§„æ¨¡ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†è¯­æ–™</a></li>
<li><a href="https://github.com/Glanvery/LLM-Travel/blob/main/LLM_Pretrain_Datasets.md">å¼€æºçš„å¯ç”¨äºLLM Pretrainæ•°æ®é›†</a> Pretrainæ•°æ®é›†</li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399359&idx=1&sn=502c65376e14b20a7dc1ceb35c62141d">å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹è®­ç»ƒå¿…å¤‡æ•°æ®é›†-The Pileï¼šæ¶µç›–22ç±»ã€800GBçš„å¤šæ ·æ€§æ–‡æœ¬æ•°æ®é›†æ¦‚è¿° </a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402424&idx=1&sn=e2d26821b6e9a5a2871e0ddbca565c30">å¤§æ¨¡å‹å†æ€»ç»“åŠChatSQLå®è·µæ¡ˆä¾‹åˆ†äº«ï¼šå¤§æ¨¡å‹è®­ç»ƒæ•°æ®åŠå·¥å…·çš„5å¼ è„‘å›¾æ€»ç»“åŠChatSQLå¼€æºé¡¹ç›®å®ç°è§£æ</a><br>3ã€RLFHå¼ºåŒ–ä¸é¢„è®­ç»ƒæ•°æ®é›† </li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403405&idx=1&sn=cb53c35efda2b771b4c1f289ae97c1d3">å¤§æ¨¡å‹ç ”å‘å¿…å¤‡ï¼šä¸¤å¤§å¼€æºå¯ç”¨ä¸”æ¸…æ´—è¿‡çš„ä¸­æ–‡æ–‡æœ¬è¯­æ–™åº“åŠå¤§æ¨¡å‹FLOPSã€å‚æ•°é‡å¿«é€Ÿä¼°è®¡å·¥å…·æ¨è </a>           ä¹¦ç”ŸÂ·ä¸‡å·1.0 ,    wudaoæ•°æ®é›†</li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataset</category>
      </categories>
      <tags>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent åˆ†ç±»[æœ‰è¶£|æœ‰ç”¨]</title>
    <url>/www6vHomeAIGC/2023/04/06/gptAgentCategory/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%9C%89%E8%B6%A3%E7%9A%84ai%E6%9B%B4%E5%83%8F%E4%BA%BA%E7%9A%84ai">æœ‰è¶£çš„AIï¼šæ›´åƒäººçš„AI</a><ul>
<li><a href="#%E5%A5%BD%E7%9C%8B%E7%9A%84%E7%9A%AE%E5%9B%8A-%E5%A4%9A%E6%A8%A1%E6%80%81">å¥½çœ‹çš„çš®å›Š å¤šæ¨¡æ€</a></li>
<li><a href="#%E6%9C%89%E8%B6%A3%E7%9A%84%E7%81%B5%E9%AD%82">æœ‰è¶£çš„çµé­‚</a></li>
</ul>
</li>
<li><a href="#%E6%9C%89%E7%94%A8%E7%9A%84ai%E6%9B%B4%E5%83%8F%E5%B7%A5%E5%85%B7%E7%9A%84ai">æœ‰ç”¨çš„AIï¼šæ›´åƒå·¥å…·çš„AI</a><ul>
<li><a href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E8%83%BD%E5%8A%9B">å¤§æ¨¡å‹åŸºç¡€èƒ½åŠ›</a></li>
<li><a href="#1p-3p-%E4%BA%A7%E5%93%81%E6%B3%95%E5%88%99">1P-3P äº§å“æ³•åˆ™</a></li>
<li><a href="#%E8%A7%A3%E5%86%B3%E5%A4%8D%E6%9D%82%E4%BB%BB%E5%8A%A1%E5%92%8C%E4%BD%BF%E7%94%A8%E5%B7%A5%E5%85%B7">è§£å†³å¤æ‚ä»»åŠ¡å’Œä½¿ç”¨å·¥å…·</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="æœ‰è¶£çš„aiæ›´åƒäººçš„ai">æœ‰è¶£çš„AIï¼šæ›´åƒäººçš„AI</span><a href="#æœ‰è¶£çš„aiæ›´åƒäººçš„ai" class="header-anchor">#</a></h1><h3><span id="å¥½çœ‹çš„çš®å›Š-å¤šæ¨¡æ€">å¥½çœ‹çš„çš®å›Š  å¤šæ¨¡æ€</span><a href="#å¥½çœ‹çš„çš®å›Š-å¤šæ¨¡æ€" class="header-anchor">#</a></h3><ul>
<li><p>å¤šæ¨¡æ€<strong>ç†è§£èƒ½åŠ›</strong></p>
<ul>
<li>å¤šæ¨¡æ€æ•°æ®ç«¯åˆ°ç«¯é¢„è®­ç»ƒçš„æ¨¡å‹<br>Gemini </li>
<li>å·¥ç¨‹åŒ–<br>  projection layer</li>
<li>ç›´æ¥ç”¨æ–‡æœ¬å»ç²˜æ¥ encoderã€decoder å’Œæ–‡æœ¬å¤§æ¨¡å‹</li>
<li>egã€è‡ªå·±åŠ¨æ‰‹åšå‡ºGeminiæ¼”ç¤ºè§†é¢‘çš„æ•ˆæœã€‘</li>
</ul>
</li>
<li><p>å¤šæ¨¡æ€<strong>ç”Ÿæˆèƒ½åŠ›</strong></p>
<ul>
<li>è§†é¢‘ç”Ÿæˆ<ul>
<li>Live2Dï¼Œ3D æ¨¡å‹</li>
<li>DeepFake<br>å½•åˆ¶ä¸€ä¸ªçœŸäººè§†é¢‘ï¼Œ æŠŠè§†é¢‘ä¸­çš„äººè„¸æ¢æˆæŒ‡å®šçš„äººè„¸ç…§ç‰‡</li>
<li>Image Animation<br>ç»™å®šä¸€å¼ ç…§ç‰‡ï¼Œéšåæ ¹æ®è¿™å¼ ç…§ç‰‡ç”Ÿæˆä¸€ç³»åˆ—çš„å¯¹åº”è§†é¢‘ </li>
<li><strong>Video Diffusion</strong><br>å¯¹ç‰©ç†ä¸–ç•Œçš„å»ºæ¨¡<br>æˆæœ¬æœ€é«˜</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="æœ‰è¶£çš„çµé­‚">æœ‰è¶£çš„çµé­‚</span><a href="#æœ‰è¶£çš„çµé­‚" class="header-anchor">#</a></h3><ul>
<li><p>ä¸ªæ€§</p>
<ul>
<li>åŸºäºprompt<br>å®Œæ•´åœ°åˆ»ç”»å‡ºä¸€ä¸ªäººç‰©çš„å†å²ã€ä¸ªæ€§ã€è®°å¿†å’Œæ€§æ ¼<br>é•¿æ–‡æœ¬</li>
<li>åŸºäºå¾®è°ƒçš„ agent<ul>
<li>æ›´å…³é”®çš„è¿˜æ˜¯æ•°æ®<ul>
<li><strong>å¯¹è¯æ€§è¯­æ–™</strong> &amp; <strong>äº‹å®æ€§è¯­æ–™</strong></li>
<li>ç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬å…ˆç”¨å¯¹è¯æ€§è¯­æ–™å»å¾®è°ƒä»–çš„ä¸ªæ€§å’Œè¯´è¯é£æ ¼</li>
<li>ç¬¬äºŒæ­¥ï¼Œå†å»æŠŠäº‹å®æ€§è¯­æ–™è¿›è¡Œæ•°æ®æ¸…æ´—åï¼ŒåŸºäºå„ç§è§’åº¦æé—®ï¼Œç”Ÿæˆè¿™ä¸ªäººç‰©ç¬¬ä¸€äººç§°å£å»çš„å›ç­”ï¼Œè¿™å«åš<strong>æ•°æ®å¢å¼º</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>æ…¢æ€è€ƒ</strong>ä¸è®°å¿†</p>
<ul>
<li>ç»„ä»¶<br><strong>è®°å¿†ã€æƒ…æ„Ÿ</strong>ã€ä»»åŠ¡è§„åˆ’ã€å·¥å…·</li>
<li>é•¿æœŸè®°å¿†<ul>
<li>äº‹å®æ€§çš„è®°å¿†<ul>
<li>æ€»ç»“<br>æ–‡æœ¬æ€»ç»“  MemGPT</li>
<li><strong>RAG å’Œä¿¡æ¯å‹ç¼©</strong></li>
<li>é•¿ä¸Šä¸‹æ–‡  <strong>é•¿ä¸Šä¸‹æ–‡</strong><br>ç»“åˆæŒä¹…åŒ– KV Cache<br>æˆæœ¬è¿˜æ˜¯å¤ªé«˜<br>ã€eg.  æ–‡æœ¬æ€»ç»“ + RAGã€‘</li>
</ul>
</li>
<li>ç¨‹åºæ€§çš„è®°å¿†<ul>
<li>few-shot</li>
<li>å¾®è°ƒ<br>çŸ­æœŸæ¥çœ‹ä»ç„¶æ˜¯æ•ˆæœæœ€å¥½çš„è·¯çº¿</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="æœ‰ç”¨çš„aiæ›´åƒå·¥å…·çš„ai">æœ‰ç”¨çš„AIï¼šæ›´åƒå·¥å…·çš„AI</span><a href="#æœ‰ç”¨çš„aiæ›´åƒå·¥å…·çš„ai" class="header-anchor">#</a></h1><h3><span id="å¤§æ¨¡å‹åŸºç¡€èƒ½åŠ›">å¤§æ¨¡å‹åŸºç¡€èƒ½åŠ›</span><a href="#å¤§æ¨¡å‹åŸºç¡€èƒ½åŠ›" class="header-anchor">#</a></h3><ul>
<li><strong>å¤æ‚ä»»åŠ¡çš„è§„åˆ’å’Œåˆ†è§£</strong></li>
<li>éµå¾ªå¤æ‚æŒ‡ä»¤</li>
<li><strong>è‡ªä¸»ä½¿ç”¨å·¥å…·</strong></li>
<li>å‡å°‘å¹»è§‰</li>
</ul>
<h3><span id="1p-3p-äº§å“æ³•åˆ™">1P-3P äº§å“æ³•åˆ™</span><a href="#1p-3p-äº§å“æ³•åˆ™" class="header-anchor">#</a></h3><ul>
<li><p>åˆ†ç±»</p>
<ul>
<li>ä¸ªäººåŠ©ç†ç±»</li>
<li>å•†ä¸šæ™ºèƒ½ç±»</li>
</ul>
</li>
<li><p>OpenAI çš„ 1P-3P äº§å“æ³•åˆ™</p>
<ul>
<li>åªè¦ä¸€ä¸¤ä¸ªäººï¼ˆ1Pï¼‰å¼€å‘çš„äº§å“å°±è‡ªå·±ï¼ˆfirst Partyï¼‰åš<ul>
<li>1P äº§å“ä¾‹å­<ul>
<li>å¯¼æ¸¸</li>
<li>ä¼ä¸š ERP åŠ©æ‰‹</li>
<li>å¤§æ¨¡å‹é‡‡é›†æ•°æ®</li>
<li><strong>æ‰‹æœºè¯­éŸ³åŠ©æ‰‹</strong><br>RPAï¼ˆæœºå™¨äººæµç¨‹è‡ªåŠ¨åŒ–ï¼‰<ul>
<li>è…¾è®¯çš„<strong>AppAgent</strong><br>è§†è§‰æ–¹æ¡ˆ</li>
</ul>
</li>
<li>ä¼šè®®å’Œç”Ÿæ´»è®°å½•å™¨</li>
</ul>
</li>
</ul>
</li>
<li>éœ€è¦ä¸‰ä¸ªäººï¼ˆ3Pï¼‰ä»¥ä¸Šå¼€å‘çš„äº§å“å°±è®©ç¬¬ä¸‰æ–¹ï¼ˆthird Partyï¼‰åš</li>
</ul>
</li>
</ul>
<h3><span id="è§£å†³å¤æ‚ä»»åŠ¡å’Œä½¿ç”¨å·¥å…·">è§£å†³å¤æ‚ä»»åŠ¡å’Œä½¿ç”¨å·¥å…·</span><a href="#è§£å†³å¤æ‚ä»»åŠ¡å’Œä½¿ç”¨å·¥å…·" class="header-anchor">#</a></h3><ul>
<li>æ…¢æ€è€ƒ<ul>
<li><strong>æ€ç»´é“¾</strong><br> æ€ç»´é“¾æ˜¯éå¸¸è‡ªç„¶çš„ä¸€ç§æ…¢æ€è€ƒçš„æ¨¡å¼</li>
<li>å¤æ‚ä»»åŠ¡çš„è§„åˆ’å’Œåˆ†è§£   <ul>
<li>ç”¨<strong>å¤šæ­¥çš„ç½‘ç»œæœç´¢</strong>å»å›ç­”éš¾é¢˜</li>
</ul>
</li>
<li>AI éœ€è¦èƒ½å¤ŸæŒ‰ç…§æµç¨‹<strong>è°ƒç”¨å·¥å…·</strong><ul>
<li>å·¥å…·ä½¿ç”¨å±äºè¿‡ç¨‹è®°å¿†ï¼Œä½¿ç”¨åœºæ™¯å’Œæ¡ä»¶ä¸æ˜¯è¯­è¨€å¯ä»¥æ˜ç¡®æè¿°çš„<br>ä½¿ç”¨ <strong>fine-tuning æ–¹æ³•</strong>å‘Šè¯‰æ¨¡å‹ä¸€äº›å·¥å…·ä½¿ç”¨çš„æ ·ä¾‹ï¼Œç”šè‡³åœ¨é¢„è®­ç»ƒæ—¶å°±åŠ å…¥</li>
<li>å·¥å…·ä½¿ç”¨å¯ä»¥ç”¨ä»£ç å½¢å¼è¡¨è¾¾ï¼Œå› æ­¤å±äº<strong>ä»£ç ç”Ÿæˆèƒ½åŠ›</strong><br>ä½¿ç”¨<strong>RAGæ–¹æ³•</strong>è·å–åˆ°å·¥å…·ä½¿ç”¨çš„ä»£ç </li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://zhuanlan.zhihu.com/p/689816790">AI Agent åº”è¯¥æ›´æœ‰è¶£è¿˜æ˜¯æ›´æœ‰ç”¨ï¼Ÿ</a>  ***</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Wizard</title>
    <url>/www6vHomeAIGC/2023/03/18/gptDataWizard/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#wizard-%E6%96%B9%E6%B3%95">Wizard æ–¹æ³•</a><ul>
<li><a href="#%E8%87%AA%E5%8A%A8%E6%8C%87%E4%BB%A4%E6%95%B0%E6%8D%AE%E8%BF%9B%E5%8C%96-1">è‡ªåŠ¨æŒ‡ä»¤æ•°æ®è¿›åŒ– [1]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E8%B4%A8%E9%87%8F-%E5%A4%9A%E6%A0%B7%E6%80%A7-%E5%A4%8D%E6%9D%82%E5%BA%A6">è´¨é‡-&gt; å¤šæ ·æ€§, å¤æ‚åº¦</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="wizard-æ–¹æ³•">Wizard æ–¹æ³•</span><a href="#wizard-æ–¹æ³•" class="header-anchor">#</a></h1><h3><span id="è‡ªåŠ¨æŒ‡ä»¤æ•°æ®è¿›åŒ–-1">è‡ªåŠ¨æŒ‡ä»¤æ•°æ®è¿›åŒ– [1]</span><a href="#è‡ªåŠ¨æŒ‡ä»¤æ•°æ®è¿›åŒ–-1" class="header-anchor">#</a></h3><p>1ï¼‰æŒ‡ä»¤è¿›åŒ–</p>
<ul>
<li>In-Depth Evolving æç¤º [æ·±åº¦]<ul>
<li>äº”ç§ç±»å‹çš„æç¤ºæ¥å¢å¼ºæŒ‡ä»¤<br>å¢åŠ çº¦æŸ + æ·±åŒ– + å…·ä½“åŒ– + å¢åŠ æ¨ç†æ­¥éª¤ + å¤æ‚åŒ–è¾“å…¥</li>
<li>æ ¸å¿ƒéƒ¨åˆ†<br><strong>In-Depth Evolvingçš„æç¤ºçš„æ ¸å¿ƒéƒ¨åˆ†æ˜¯ â€œä½ çš„ç›®æ ‡æ˜¯å°†ä¸€ä¸ªç»™å®šçš„æç¤ºæ”¹å†™æˆæ›´å¤æ‚çš„ç‰ˆæœ¬ï¼Œä½¿é‚£äº›è‘—åçš„äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼ˆå¦‚ChatGPTå’ŒGPT4ï¼‰æ›´éš¾å¤„ç†ã€‚ä½†æ”¹å†™åçš„æç¤ºå¿…é¡»æ˜¯åˆç†çš„ï¼Œèƒ½è¢«äººç†è§£ï¼Œå¹¶èƒ½è¢«äººå›åº”â€</strong></li>
</ul>
</li>
<li>In-Breadth Evolvingæç¤º [å¹¿åº¦]<ul>
<li>ç›®çš„<br>æ—¨åœ¨æé«˜<strong>ä¸»é¢˜è¦†ç›–ç‡</strong>ã€<strong>æŠ€èƒ½è¦†ç›–ç‡</strong>å’Œæ•´ä½“æ•°æ®é›†çš„<strong>å¤šæ ·æ€§</strong></li>
</ul>
</li>
</ul>
<p>2ï¼‰å“åº”ç”Ÿæˆ</p>
<p>3ï¼‰æ¶ˆé™¤è¿›åŒ–<br>   å³è¿‡æ»¤æœªèƒ½è¿›åŒ–çš„æŒ‡ä»¤</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="è´¨é‡-gt-å¤šæ ·æ€§-å¤æ‚åº¦">è´¨é‡-&gt; å¤šæ ·æ€§, å¤æ‚åº¦</span><a href="#è´¨é‡-gt-å¤šæ ·æ€§-å¤æ‚åº¦" class="header-anchor">#</a></h3><ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401462&idx=1&sn=764f0302918174cea29ae22ac5760033">å¦‚ä½•æ„é€ å¤æ‚å¤šæ ·çš„å¾®è°ƒæŒ‡ä»¤æ•°æ®ï¼šWizardLMå¤æ‚æŒ‡ä»¤æ„é€ æ€æƒ³ä¸å®éªŒåˆ†æå·¥ä½œæ€»ç»“ </a><br> <a href="https://github.com/nlpxucan/WizardLM">WizardLM</a> git</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataProcess</category>
      </categories>
      <tags>
        <tag>dataProcess</tag>
      </tags>
  </entry>
  <entry>
    <title>(list)å¤šæ¨¡æ€  æ•°æ®é›†</title>
    <url>/www6vHomeAIGC/2023/04/01/gptDatasetMulitmodal/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="pre-trainingæ•°æ®é›†">Pre-trainingæ•°æ®é›†</span><a href="#pre-trainingæ•°æ®é›†" class="header-anchor">#</a></h1><ul>
<li><p>LAION[1]<br><a href="https://laion.ai/projects/">LAION</a></p>
</li>
<li><p>wukong[1]<br><a href="https://zhuanlan.zhihu.com/p/473794131">[è®ºæ–‡]ä¸­æ–‡å¤šæ¨¡æ€æ•°æ®é›†WuKong &amp; FILIP &amp; LiT-tuning</a><br><a href="https://zhuanlan.zhihu.com/p/551622338">Wukongï¼šä¸€äº¿è§„æ¨¡çš„ä¸­æ–‡è·¨æ¨¡æ€é¢„è®­ç»ƒåŸºå‡†</a></p>
</li>
<li><p>MMDialog<br><a href="https://zhuanlan.zhihu.com/p/584894471">ç™¾ä¸‡é‡çº§çš„å¤šæ¨¡æ€å¯¹è¯æ•°æ®é›†æ¥äº†ï¼Œ153ä¸‡å¼ å›¾ç‰‡4000å¤šä¸»é¢˜</a> </p>
</li>
<li><p>OBELISC[2]</p>
</li>
<li><p>ShareGPT4V[3]<br>opensource</p>
</li>
</ul>
<h1><span id="sftæ•°æ®é›†">SFTæ•°æ®é›†</span><a href="#sftæ•°æ®é›†" class="header-anchor">#</a></h1><ul>
<li>LAMM</li>
<li>MultiIntruct</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="é¢„è®­ç»ƒæ•°æ®é›†">é¢„è®­ç»ƒæ•°æ®é›†</span><a href="#é¢„è®­ç»ƒæ•°æ®é›†" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/686757824">å¤šæ¨¡æ€æ•°æ®é›†æ”¶é›†</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/670149958">[è®ºæ–‡é˜…è¯»] å¼€æºçš„å¤šæ¨¡æ€æ–‡æ¡£æ•°æ®é›†ï¼ŒOBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents</a><br>ä»ç½‘é¡µæ–‡æ¡£é‡Œå¾—åˆ°çš„æ•°æ®é›†</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/669485001">è¶…è¶ŠåŒçº§7Bæ¨¡å‹ï¼ ä¸­å›½å›¢é˜Ÿå¼€æºå¤§è§„æ¨¡é«˜è´¨é‡å›¾æ–‡æ•°æ®é›†ShareGPT4Vï¼Œå¤§å¹…æå‡å¤šæ¨¡æ€æ€§èƒ½</a><br><a href="https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V">ShareGPT4V</a> git</p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/527182857">å¤šæ¨¡æ€é¢„è®­ç»ƒæ•°æ®é›†</a></p>
<p>1xx. <a href="https://opendatalab.org.cn/">OpenDataLab</a></p>
<h3><span id="sftæ•°æ®é›†">SFTæ•°æ®é›†</span><a href="#sftæ•°æ®é›†" class="header-anchor">#</a></h3><p>1xx. <a href="https://datac.blog.csdn.net/article/details/135434897">ã€LMM 015ã€‘LAMMï¼šå¤šæ¨¡æ€æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œæ¡†æ¶å’ŒåŸºå‡†</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/678489834">[NeurIPS2023] LAMMï¼šå¤šæ¨¡æ€æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ã€æ¡†æ¶ã€è¯„æµ‹åŸºå‡†</a></p>
<p>1xx. <a href="https://www.bilibili.com/video/BV12p4y1M7RV/">Talk | ACLâ€™23 æ°å‡ºè®ºæ–‡ï¼ŒMultiIntructï¼šé€šè¿‡å¤šæ¨¡æ€æŒ‡ä»¤é›†å¾®è°ƒæå‡VLMçš„é›¶æ ·æœ¬å­¦ä¹ </a><br>1xx. <a href="https://blog.csdn.net/qq_45978862/article/details/132008907">ã€ACL2023ã€‘MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataset</category>
      </categories>
      <tags>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)SFT æ•°æ®ç»„åˆ</title>
    <url>/www6vHomeAIGC/2023/02/06/gptDatasetSFT/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E8%AE%BA%E6%96%87">è®ºæ–‡</a></li>
<li><a href="#%E9%97%AE%E9%A2%981">é—®é¢˜[1]</a></li>
<li><a href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C1">å®éªŒç»“æœ[1]</a></li>
<li><a href="#%E9%97%AE%E9%A2%982-%E5%9C%A8sft%E4%B8%AD%E7%BB%93%E5%90%88%E4%B8%89%E7%A7%8D%E8%83%BD%E5%8A%9B%E6%97%B6%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E6%80%A7%E8%83%BD%E5%86%B2%E7%AA%81kimipaper">é—®é¢˜2 åœ¨SFTä¸­ç»“åˆä¸‰ç§èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªï¼Ÿ[kimi][paper]</a><ul>
<li><a href="#%E7%BB%93%E8%AE%BA">ç»“è®ºï¼š</a></li>
</ul>
</li>
<li><a href="#%E9%97%AE%E9%A2%983-%E5%AF%BC%E8%87%B4%E6%80%A7%E8%83%BD%E5%86%B2%E7%AA%81%E7%9A%84%E5%85%B3%E9%94%AE%E5%9B%A0%E7%B4%A0%E6%98%AF%E4%BB%80%E4%B9%88kimipaper">é—®é¢˜3 å¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿ[kimi][paper]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="è®ºæ–‡">è®ºæ–‡</span><a href="#è®ºæ–‡" class="header-anchor">#</a></h1><ul>
<li>è®ºæ–‡åœ°å€<br> ã€ŠHOW ABILITIES IN LARGE LANGUAGE MODELS ARE AFFECTED BY SUPERVISED FINE-TUNING DATA COM- POSITIONã€‹<br>keyword: SFT æ•°æ®ç»„åˆ</li>
</ul>
<h1><span id="é—®é¢˜1">é—®é¢˜[1]</span><a href="#é—®é¢˜1" class="header-anchor">#</a></h1><p>1ã€æ¨ç†ã€ç¼–ç å’Œé€šç”¨èƒ½åŠ›å¦‚ä½•éšSFTæ•°æ®é‡è€Œå˜åŒ–ï¼Ÿ<br>2ã€åœ¨SFTä¸­ç»“åˆä¸‰ç§èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªï¼Ÿ<br>3ã€å¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿ<br>4ã€ä¸åŒçš„SFTç­–ç•¥å¯¹ç»„åˆæ•°æ®æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ</p>
<h1><span id="å®éªŒç»“æœ1">å®éªŒç»“æœ[1]</span><a href="#å®éªŒç»“æœ1" class="header-anchor">#</a></h1><p>1ã€ä¸åŒçš„èƒ½åŠ›è¡¨ç°å‡ºä¸åŒçš„æ‰©å±•æ¨¡å¼ï¼Œåœ¨æ•°æ®é‡ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œ<strong>è¾ƒå¤§çš„æ¨¡å‹é€šå¸¸è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½</strong>ã€‚<br>2ã€éšç€æ•°æ®é‡çš„æŒç»­å¢åŠ ï¼Œ<strong>æ•°å­¦æ¨ç†å’Œä»£ç ç”Ÿæˆèƒ½åŠ›ä¹Ÿåœ¨ä¸æ–­æé«˜</strong>ï¼Œ<strong>ä¸€èˆ¬èƒ½åŠ›</strong>åˆ™æ˜¯åœ¨æ ·æœ¬æ•°è¾¾åˆ°<strong>ä¸€åƒå·¦å³</strong>æ—¶æ‰å¾—åˆ°æå‡ï¼Œä¸”æå‡é€Ÿåº¦è¾ƒæ…¢ã€‚<br>3ã€åœ¨<strong>æ•°æ®é‡è¾ƒä½</strong>çš„æƒ…å†µä¸‹ï¼Œæ•°æ®ç»„åˆä¼šå¸¦æ¥å„ç§èƒ½åŠ›çš„<strong>æé«˜</strong>ï¼Œè€Œåœ¨<strong>æ•°æ®é‡è¾ƒé«˜</strong>çš„æƒ…å†µä¸‹ï¼Œèƒ½åŠ›åˆ™ä¼šå‘ç”Ÿ<strong>å†²çª</strong>ã€‚<br>4ã€ç»„æˆ<strong>æ•°æ®é‡</strong>ä¼šå½±å“<strong>æ€§èƒ½</strong>ï¼Œè€Œ<strong>ç»„æˆæ¯”ä¾‹</strong>çš„å½±å“åˆ™<strong>å¾®ä¹å…¶å¾®</strong>ã€‚</p>
<p>ã€æ¨¡å‹å¤§å°ã€‘</p>
<p>ã€æ•°æ®æ•°é‡ã€‘</p>
<p>ã€æ•°æ®æ•°é‡ &lt;â€“&gt;  å¤šæ ·æ€§ã€‘ï¼Ÿ</p>
<p>ã€ç»„æˆæ¯”ä¾‹ã€‘</p>
<h1><span id="é—®é¢˜2-åœ¨sftä¸­ç»“åˆä¸‰ç§èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªkimipaper">é—®é¢˜2 åœ¨SFTä¸­ç»“åˆä¸‰ç§èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªï¼Ÿ[kimi][paper]</span><a href="#é—®é¢˜2-åœ¨sftä¸­ç»“åˆä¸‰ç§èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªkimipaper" class="header-anchor">#</a></h1><p>é—®é¢˜2 æ¢è®¨çš„æ˜¯åœ¨ç›‘ç£å¼å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰ä¸­ç»“åˆæ¨ç†ã€ç¼–ç å’Œé€šç”¨èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªã€‚</p>
<h3><span id="ç»“è®º">ç»“è®ºï¼š</span><a href="#ç»“è®º" class="header-anchor">#</a></h3><ol>
<li><p><strong>æ€§èƒ½å†²çªçš„å­˜åœ¨</strong>ï¼šåœ¨é«˜èµ„æºè®¾ç½®ä¸‹ï¼Œå³å½“SFTæ•°æ®é›†æ··åˆä½¿ç”¨æ—¶ï¼Œä¸åŒèƒ½åŠ›é¢†åŸŸï¼ˆå¦‚æ•°å­¦æ¨ç†ã€ç¼–ç å’Œé€šç”¨å¯¹é½èƒ½åŠ›ï¼‰ä¹‹é—´ä¼šå‘ç”Ÿæ€§èƒ½å†²çªã€‚ç„¶è€Œï¼Œåœ¨ä½èµ„æºè®¾ç½®ä¸‹ï¼Œæ··åˆæ•°æ®æºèƒ½å¤Ÿæå‡æ€§èƒ½ã€‚</p>
</li>
<li><p><strong>æ€§èƒ½å†²çªä¸èµ„æºé‡çš„å…³ç³»</strong>ï¼šéšç€æ•°æ®é‡çš„å¢åŠ ï¼Œç‰¹å®šä»»åŠ¡çš„æ€§èƒ½å¯èƒ½ä¼šå› ä¸ºå…¶ä»–ä»»åŠ¡çš„å­˜åœ¨è€Œä¸‹é™ã€‚è¿™è¡¨æ˜åœ¨æ•°æ®é‡è¾ƒå¤§æ—¶ï¼Œä¸åŒä»»åŠ¡ä¹‹é—´å¯èƒ½ä¼šç›¸äº’å¹²æ‰°ï¼Œå¯¼è‡´æ€§èƒ½å†²çªã€‚</p>
</li>
<li><p><strong>æ¨¡å‹å¤§å°å¯¹æ€§èƒ½çš„å½±å“</strong>ï¼šéšç€æ¨¡å‹å¤§å°çš„å¢åŠ ï¼Œåœ¨ä½èµ„æºè®¾ç½®ä¸‹ï¼Œæ•°å­¦å’Œé€šç”¨èƒ½åŠ›çš„æ€§èƒ½æå‡æ›´åŠ æ˜æ˜¾ã€‚</p>
</li>
</ol>
<h1><span id="é—®é¢˜3-å¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ æ˜¯ä»€ä¹ˆkimipaper">é—®é¢˜3 å¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿ[kimi][paper]</span><a href="#é—®é¢˜3-å¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ æ˜¯ä»€ä¹ˆkimipaper" class="header-anchor">#</a></h1><p>åœ¨SFTï¼ˆç›‘ç£å¼å¾®è°ƒï¼‰ä¸­ç»“åˆæ¨ç†ã€ç¼–ç å’Œé€šç”¨èƒ½åŠ›æ—¶ï¼Œå¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ åŒ…æ‹¬ï¼š</p>
<ol>
<li><p><strong>æ•°æ®ç»„æˆå’Œæ¯”ä¾‹</strong>ï¼šå½“ä¸åŒèƒ½åŠ›é¢†åŸŸçš„æ•°æ®æ··åˆåœ¨ä¸€èµ·è¿›è¡ŒSFTæ—¶ï¼Œå¦‚æœ<strong>æ•°æ®é‡å……è¶³</strong>ï¼Œæ¥è‡ªå…¶ä»–é¢†åŸŸçš„æ•°æ®å¯èƒ½ä¼šè¢«è§†ä¸º<strong>å™ªå£°</strong>ï¼Œä»è€Œå½±å“ç‰¹å®šé¢†åŸŸçš„æ€§èƒ½ã€‚</p>
</li>
<li><p><strong>æ¨¡å‹å¤§å°</strong>ï¼š<strong>è¾ƒå¤§çš„æ¨¡å‹</strong>åœ¨ç›¸åŒæ•°æ®é‡ä¸‹é€šå¸¸è¡¨ç°<strong>æ›´å¥½</strong>ï¼Œå¹¶ä¸”åœ¨ä½èµ„æºè®¾ç½®ä¸‹å¯¹äºæ•°å­¦å’Œé€šç”¨èƒ½åŠ›çš„æ€§èƒ½å¢ç›Šæ›´å¤§ã€‚</p>
</li>
<li><p><strong>è®­ç»ƒç­–ç•¥</strong>ï¼šå¤šä»»åŠ¡å­¦ä¹ è™½ç„¶èƒ½å¤Ÿä¿ç•™ä¸“ä¸šèƒ½åŠ›ï¼Œä½†å¯¹é€šç”¨èƒ½åŠ›çš„ä¼¤å®³æœ€å¤§ï¼›è€Œé¡ºåºè®­ç»ƒå’Œæ··åˆé¡ºåºè®­ç»ƒè™½ç„¶ä¿ç•™äº†é€šç”¨èƒ½åŠ›ï¼Œä½†ä¼šä¸¢å¤±å¤ªå¤šçš„ä¸“ä¸šèƒ½åŠ›ã€‚</p>
</li>
<li><p><strong>æ•°æ®é‡ä¸èƒ½åŠ›çš„å…³ç³»</strong>ï¼šæ•°å­¦æ¨ç†å’Œç¼–ç èƒ½åŠ›éšç€æ•°æ®é‡çš„å¢åŠ è€ŒæŒç»­æé«˜ï¼Œè€Œé€šç”¨èƒ½åŠ›åœ¨å¤§çº¦ä¸€åƒä¸ªæ ·æœ¬åè¶‹äºå¹³ç¨³ã€‚</p>
</li>
<li><p><strong>ä»»åŠ¡ç‰¹æ€§å·®å¼‚</strong>ï¼šæ¨ç†å’Œç¼–ç ä»»åŠ¡éœ€è¦å¤æ‚çš„é€»è¾‘æ¥åˆ†è§£ä»»åŠ¡æŒ‡ä»¤å’Œå¤„ç†éè¯­è¨€å’Œç¬¦å·ç‰¹å¾ï¼Œè€Œå¯¹é½äººç±»æ„å›¾åˆ™éœ€è¦å¤šæ ·æ€§å’Œç†è§£æ¨¡ç³Šçš„äººç±»æŒ‡ä»¤ã€‚</p>
</li>
</ol>
<p>ç›¸åº”çš„ç»“è®ºåŒ…æ‹¬ï¼š</p>
<ul>
<li>åœ¨<strong>ä½èµ„æºè®¾ç½®ä¸‹</strong>ï¼Œæ··åˆæ•°æ®æºå¯ä»¥<strong>æé«˜æ€§èƒ½</strong>ï¼Œä½†åœ¨<strong>é«˜èµ„æºè®¾ç½®</strong>ä¸‹ï¼Œå¯èƒ½ä¼šå¯¼è‡´<strong>æ€§èƒ½ä¸‹é™</strong>ã€‚</li>
<li><strong>æ•°æ®é‡</strong>ç›´æ¥<strong>å½±å“åŠ›èƒ½è¡¨ç°</strong>ï¼Œè€Œ<strong>æ•°æ®æ¯”ä¾‹</strong>çš„å½±å“<strong>ä¸æ˜¾è‘—</strong>ã€‚</li>
<li>æå‡ºçš„<strong>åŒé˜¶æ®µæ··åˆå¾®è°ƒï¼ˆDMTï¼‰ç­–ç•¥</strong>æœ‰æ•ˆåœ°å‡è½»äº†å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„æ€§èƒ½å†²çªå’Œé¡ºåºè®­ç»ƒä¸­çš„ç¾éš¾æ€§é—å¿˜ï¼Œå®ç°äº†é€šç”¨ä¸ä¸“ä¸šèƒ½åŠ›ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
</ul>
<p>è¿™äº›ç»“è®ºå¼ºè°ƒäº†åœ¨SFTé˜¶æ®µç†è§£å’Œè§£å†³æ•°æ®ç»„æˆé—®é¢˜å¯¹äºå…¨é¢æé«˜LLMsï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰çš„èƒ½åŠ›è‡³å…³é‡è¦ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404728&idx=2&sn=1cb2203648271720d421c963ebcc03b3">SFTå¾®è°ƒçš„æ•°æ®ç»„åˆåŠè®­ç»ƒç­–ç•¥å¦‚ä½•å½±å“å¤§æ¨¡å‹æ€§èƒ½ï¼š4ä¸ªç»å…¸é—®é¢˜åŠå®éªŒç»“è®ºåˆ†äº« </a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401381&idx=1&sn=c24d896aab990ffdf30107a7c6c1ea4f">å†çœ‹å¤§æ¨¡å‹å¾®è°ƒä¸åº”ç”¨ï¼š3å¤§è¡Œä¸š18ä¸ªå¼€æºå‚ç›´å¾®è°ƒæ¨¡å‹ã€å¾®è°ƒæ•°æ®ã€å·¥å…·èµ„æºåŠæœ‰è¶£çš„AIGCåº”ç”¨é›†åˆ</a> äºŒ ä¸‰</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400009&idx=1&sn=f72c0a9cb7c19184995156c3ef169b74">ä¹Ÿè°ˆå¤§æ¨¡å‹ç ”å‘ä¸­çš„å¾®è°ƒæ•°æ®è§„æ¨¡è¯„ä¼°ä¸è´¨é‡é—®é¢˜ï¼šæ•°æ®è§„æ¨¡å¤§å°çš„å½±å“è¯„ä¼°ã€æ•°æ®ä¸»è¦é—®é¢˜åŠæ¸…æ´—é¡¹ç›®</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400342&idx=1&sn=d344ced5035fc804f490b00469746fc8">ä¹Ÿè°ˆå¾®è°ƒæ•°æ®è´¨é‡ã€å¤šæ ·æ€§è§„æ¨¡å¯¹å¤§æ¨¡å‹æ€§èƒ½çš„å½±å“ä¸è¯„ä¼°æ–¹æ¡ˆï¼šBelleé¡¹ç›®å¼€æºå®éªŒå·¥ä½œæŠ¥å‘Šä»‹ç» </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>SFT</category>
      </categories>
      <tags>
        <tag>SFT</tag>
      </tags>
  </entry>
  <entry>
    <title>(List)SFTæ•°æ®é›†</title>
    <url>/www6vHomeAIGC/2023/04/24/gptDatasetSFTList/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="sftæ•°æ®é›†12">SFTæ•°æ®é›†[1][2]</span><a href="#sftæ•°æ®é›†12" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402424&idx=1&sn=e2d26821b6e9a5a2871e0ddbca565c30">å¤§æ¨¡å‹å†æ€»ç»“åŠChatSQLå®è·µæ¡ˆä¾‹åˆ†äº«ï¼šå¤§æ¨¡å‹è®­ç»ƒæ•°æ®åŠå·¥å…·çš„5å¼ è„‘å›¾æ€»ç»“åŠChatSQLå¼€æºé¡¹ç›®å®ç°è§£æ</a><br>1ã€é€šç”¨æŒ‡ä»¤å¾®è°ƒæ•°æ®</p>
</li>
<li><p><a href="https://github.com/chaoswork/sft_datasets">å¼€æºSFTæ•°æ®é›†æ•´ç†</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>SFT</category>
      </categories>
      <tags>
        <tag>SFT</tag>
      </tags>
  </entry>
  <entry>
    <title>(Survey)Dataset</title>
    <url>/www6vHomeAIGC/2023/04/01/gptDatasetSurvey/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="è®ºæ–‡">è®ºæ–‡</span><a href="#è®ºæ–‡" class="header-anchor">#</a></h1><ul>
<li><p>è®ºæ–‡åœ°å€<br> ã€ŠDatasets for Large Language Models: A Comprehensive Surveyã€‹</p>
</li>
<li><p>å¼€æºåœ°å€<br> <a href="https://github.com/lmmlzn/Awesome-LLMs-Datasets">Awesome-LLMs-Datasets</a> git</p>
</li>
</ul>
<h1><span id="å¾®è°ƒæ•°æ®">å¾®è°ƒæ•°æ®</span><a href="#å¾®è°ƒæ•°æ®" class="header-anchor">#</a></h1><h3><span id="å¾®è°ƒæ•°æ®çš„æ„é€ æ–¹å¼">å¾®è°ƒæ•°æ®çš„æ„é€ æ–¹å¼</span><a href="#å¾®è°ƒæ•°æ®çš„æ„é€ æ–¹å¼" class="header-anchor">#</a></h3><ul>
<li>äººå·¥ç”Ÿæˆçš„æ•°æ®é›†(HG)</li>
<li>æ¨¡å‹æ„å»ºçš„æ•°æ®é›†(MC)<ul>
<li>Alpaca</li>
<li>BELLE</li>
<li>Self-Instruct</li>
<li>ShareGPT</li>
<li>Wizard</li>
</ul>
</li>
<li>ç°æœ‰æ•°æ®é›†çš„æ”¶é›†å’Œæ”¹è¿›(CI) </li>
<li>ä½¿ç”¨å¤šç§æ–¹æ³•åˆ›å»ºçš„æ•°æ®é›†</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648409066&idx=1&sn=54e68bbbd45b4cc5bef8fd446fa187f8">å¤§æ¨¡å‹è®­ç»ƒæ•°æ®é›†(ä»é¢„è®­åˆ°å¼ºåŒ–)å…¨é¢ç»¼è¿°ï¼šå…¼çœ‹20240229å¤§æ¨¡å‹æ—©æŠ¥ </a>***</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>dataset</category>
      </categories>
      <tags>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦</title>
    <url>/www6vHomeAIGC/2023/02/18/gptDocSimilarity/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://zhuanlan.zhihu.com/p/111414376">çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦ç®—æ³•ç ”ç©¶</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/113133510">Sentence-Bertè®ºæ–‡ç¬”è®°</a><br>1xx. <a href="https://www.bilibili.com/video/BV13h4y1a7z6/">SentenceBertæ¨¡å‹ï¼šæ–‡æœ¬è¯­ä¹‰å»é‡</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/113017752">ä¼ ç»Ÿæ–¹æ³•TF-IDFè§£å†³çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦é—®é¢˜</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/113224707">ä¼ ç»Ÿæ–¹æ³•BM25è§£å†³çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦é—®é¢˜</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦</category>
      </categories>
      <tags>
        <tag>çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦</tag>
      </tags>
  </entry>
  <entry>
    <title>æ–‡æ¡£æ™ºèƒ½</title>
    <url>/www6vHomeAIGC/2023/04/19/gptDocumentAI/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="æ–‡æ¡£ç†è§£-10">æ–‡æ¡£ç†è§£ [10]</span><a href="#æ–‡æ¡£ç†è§£-10" class="header-anchor">#</a></h1><h3><span id="åŸºäºå¤§æ¨¡å‹çš„ocr-freeå¾®è°ƒæ–¹æ¡ˆ">åŸºäºå¤§æ¨¡å‹çš„OCR-FREEå¾®è°ƒæ–¹æ¡ˆ</span><a href="#åŸºäºå¤§æ¨¡å‹çš„ocr-freeå¾®è°ƒæ–¹æ¡ˆ" class="header-anchor">#</a></h3><ul>
<li>LLaVAR [12]</li>
<li>TextMonkey [11]</li>
</ul>
<h3><span id="æ–‡æ¡£ç‰ˆå¼åˆ†ææ•°æ®é›†">æ–‡æ¡£ç‰ˆå¼åˆ†ææ•°æ®é›†</span><a href="#æ–‡æ¡£ç‰ˆå¼åˆ†ææ•°æ®é›†" class="header-anchor">#</a></h3><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="10">
<li><a href="https://mp.weixin.qq.com/s/FsjoUUFssMv2UkbxM-IJ3A">å€¼å¾—ä¸€çœ‹çš„æ–‡æ¡£ç†è§£å‰æ²¿æ–¹æ¡ˆåŠç‰ˆå¼åˆ†æå¼€æºæ•°æ®ï¼šä¸‰ç§æ¨¡å¼ã€ä¹å¤§æ•°æ®é›† </a></li>
<li><a href="https://github.com/Yuliang-Liu/Monkey">Monkey</a><br><a href="http://vlrlab-monkey.xyz:7684/">Monkey Demo</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/670175648">LLaVARï¼šå¢å¼ºçš„è§†è§‰æŒ‡ä»¤å¾®è°ƒ</a><br><a href="https://llavar.github.io/">LLaVAR: Enhanced Visual Instruction Tuning for Text-rich Image Understanding</a></li>
</ol>
<p>1xx. <a href="https://huggingface.co/blog/zh/document-ai">åŠ é€Ÿ Document AI (æ–‡æ¡£æ™ºèƒ½) å‘å±•</a><br>    <a href="https://baijiahao.baidu.com/s?id=1755096032832674219&wfr=spider&for=pc">åŠ é€Ÿ Document AI (æ–‡æ¡£æ™ºèƒ½) å‘å±•</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s/d2Nns1qashMbcXPMG-4McQ">é˜¿é‡Œé¢å‘ä¼ä¸šæ•°å­—åŒ–çš„æ–‡æ¡£æ™ºèƒ½æŠ€æœ¯ä¸åº”ç”¨</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>DocumentAI</category>
      </categories>
      <tags>
        <tag>DocumentAI</tag>
      </tags>
  </entry>
  <entry>
    <title>å‚ç±»å¤§æ¨¡å‹</title>
    <url>/www6vHomeAIGC/2023/01/04/gptDomain/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#domain-specialization-0">Domain Specialization [0]</a><ul>
<li><a href="#%E6%80%BB%E7%BB%93-chatmind">æ€»ç»“ [chatmind]</a></li>
</ul>
</li>
<li><a href="#%E9%A2%86%E5%9F%9F%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B-1">é¢†åŸŸå¾®è°ƒæ¨¡å‹ [1]</a></li>
<li><a href="#%E5%85%B3%E6%B3%A8%E7%82%B9-2">å…³æ³¨ç‚¹ [2]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="domain-specialization-0">Domain Specialization [0]</span><a href="#domain-specialization-0" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/04/gptDomain/domain.JPG" class>

<p>LLMï¼ˆLarge Language Modelsï¼‰çš„é¢†åŸŸä¸“ä¸šåŒ–å¯ä»¥ç†è§£ä¸ºå°†å¹¿æ³›è®­ç»ƒçš„é€šç”¨LLMè°ƒæ•´åˆ°ç‰¹å®šé¢†åŸŸå†…ä»¥å®ç°æœ€ä½³æ“ä½œã€‚ä¸ºäº†åº”å¯¹ç¬¬1èŠ‚ä¸­æåˆ°çš„é¢†åŸŸä¸“ä¸šåŒ–çš„ä¸‰ä¸ªæŒ‘æˆ˜ï¼ŒLLMé¢†åŸŸä¸“ä¸šåŒ–çš„æ–¹æ³•å¯ä»¥åˆ†ä¸ºä¸‰ç±»ï¼šå¤–éƒ¨å¢å¼ºã€æç¤ºè®¾è®¡å’Œæ¨¡å‹å¾®è°ƒã€‚è¿™äº›ç±»åˆ«å¯¹åº”äº†å¯¹LLMçš„ä¸åŒè®¿é—®çº§åˆ«çš„å‡è®¾ï¼Œå³æ— è®¿é—®ï¼ˆé»‘ç›’ï¼‰ã€éƒ¨åˆ†è®¿é—®ï¼ˆç°ç›’ï¼‰å’Œå®Œå…¨è®¿é—®ï¼ˆç™½ç›’ï¼‰ã€‚é»‘ç›’å‡è®¾é€šå¸¸è¡¨ç¤ºæˆ‘ä»¬åªèƒ½è®¿é—®æ¨¡å‹APIï¼ˆä¾‹å¦‚ChatGPTï¼‰ï¼Œé™¤äº†ç”Ÿæˆçš„è¾“å‡ºä¹‹å¤–ä¸çŸ¥é“ä»»ä½•ä¿¡æ¯ï¼›ç°ç›’å‡è®¾è¡¨ç¤ºæˆ‘ä»¬æœ‰é™çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚GPT-3 APIä¸­ç”Ÿæˆçš„æ ‡è®°çš„æ¦‚ç‡ï¼‰ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥æŒ‡å¯¼æˆ‘ä»¬è®¾è®¡å’Œå¾®è°ƒä¸€ä¸ªåˆé€‚çš„æç¤ºï¼Œä»¥æ›´å¥½åœ°å¼•å‡ºé¢†åŸŸçŸ¥è¯†ï¼›ç™½ç›’å‡è®¾è¡¨ç¤ºæˆ‘ä»¬å®Œå…¨å¯ä»¥è®¿é—®LLMï¼ˆä¾‹å¦‚LLaMAåŠå…¶å˜ä½“ï¼‰ï¼ŒåŒ…æ‹¬å‚æ•°è®¾ç½®ã€è®­ç»ƒæ•°æ®å’Œæ¨¡å‹æ¶æ„ã€‚</p>
<p>é™¤äº†åŸºäºLLMå¯è®¿é—®æ€§çš„åˆ†ç±»æ³•ä¹‹å¤–ï¼Œæ ¹æ®ä½¿ç”¨çš„è®­ç»ƒç­–ç•¥ï¼Œå¯ä»¥å°†LLMé¢†åŸŸä¸“ä¸šåŒ–æ–¹æ³•åˆ†ç±»ä¸ºä»¥ä¸‹å‡ ç§ï¼šä½¿ç”¨é¢†åŸŸç‰¹å®šæ•°æ®å¯¹ç°æœ‰æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»å¤´å¼€å§‹ä¸ºç‰¹å®šé¢†åŸŸè®­ç»ƒæ¨¡å‹ï¼Œæˆ–è€…ä½¿ç”¨æ··åˆè®­ç»ƒç­–ç•¥ã€‚å¦ä¸€ä¸ªåˆ†ç±»æ³•å¯ä»¥åŸºäºå¹²é¢„çº§åˆ«ï¼šé¢„è®­ç»ƒå¹²é¢„æ¶‰åŠä¿®æ”¹é¢„è®­ç»ƒè¿‡ç¨‹ä»¥é¼“åŠ±é¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œå¾®è°ƒå¹²é¢„æ¶‰åŠåœ¨å¾®è°ƒé˜¶æ®µè¿›è¡Œè°ƒæ•´ï¼Œæ¨ç†æ—¶å¹²é¢„æ¶‰åŠä¿®æ”¹æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡Œä¸ºä»¥ç”Ÿæˆæ›´å¤šé¢†åŸŸç‰¹å®šçš„è¾“å‡ºã€‚æ­¤å¤–ï¼Œä¹Ÿå¯ä»¥åŸºäºè¯„ä¼°å’Œåé¦ˆæœºåˆ¶æ¥å»ºç«‹åˆ†ç±»æ³•ï¼šå›ºå®šè¯„ä¼°è®¾ç½®äº†ä¸€ä¸ªæ’å®šçš„åŸºå‡†ï¼ŒåŠ¨æ€è¯„ä¼°æ¶‰åŠä½¿ç”¨ä¸æ–­å˜åŒ–çš„åŸºå‡†è¿›è¡ŒæŒç»­æ€§èƒ½è¯„ä¼°ï¼ŒåŸºäºç”¨æˆ·åé¦ˆçš„è¯„ä¼°ä½¿ç”¨ç›´æ¥ç”¨æˆ·è¾“å…¥ä½œä¸ºè°ƒæ•´æ¨¡å‹å“åº”çš„ä¿¡å·ã€‚</p>
<p>åœ¨è¿™ä»½è°ƒæŸ¥ä¸­ï¼Œæˆ‘ä»¬æ ¹æ®LLMçš„å¯è®¿é—®æ€§å¯¹ç°æœ‰æ–¹æ³•è¿›è¡Œåˆ†ç±»ï¼Œå¹¶åœ¨å›¾2ä¸­æ¦‚è¿°äº†æ¯ç§æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œ1ï¼‰å¤–éƒ¨å¢å¼ºï¼ˆé»‘ç›’ï¼‰ä¸ä¸€å®šéœ€è¦è®¿é—®LLMçš„å†…éƒ¨å‚æ•°ç©ºé—´ï¼Œä½¿å¾—å¯¹èµ„æºæœ‰é™çš„ç”¨æˆ·ï¼ˆå¦‚è®¡ç®—èµ„æºã€é¢†åŸŸç‰¹å®šæ•°æ®ï¼‰æœ€æ˜“äºè®¿é—®ã€‚å¦‚å›¾2ï¼ˆbï¼‰æ‰€ç¤ºï¼Œé€šè¿‡ä½¿ç”¨å¤–éƒ¨èµ„æºæˆ–å·¥å…·ï¼Œå°†é¢†åŸŸç‰¹å®šçŸ¥è¯†åˆå¹¶åˆ°è¾“å…¥æç¤ºã€ç”Ÿæˆçš„è¾“å‡ºæˆ–ä¸¤è€…ä¸­ï¼Œæœ‰æ•ˆåœ°è°ƒæ•´LLMçš„æ€§èƒ½è€Œä¸ä¿®æ”¹å…¶å†…éƒ¨ç»“æ„ã€‚2ï¼‰æç¤ºè®¾è®¡ï¼ˆç°ç›’ï¼‰é€šè¿‡è®¿é—®LLMçš„æ¢¯åº¦æˆ–æŸå¤±å€¼è®¾è®¡å„ç§ç±»å‹çš„æç¤ºï¼Œä»è€Œå¯¹æ¨¡å‹çš„è¡Œä¸ºè¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶ã€‚3ï¼‰æ¨¡å‹å¾®è°ƒï¼ˆç™½ç›’ï¼‰éœ€è¦æœ€å¤šçš„è®¿é—®å’Œèµ„æºï¼Œå› ä¸ºå®ƒæ¶‰åŠæ›´æ–°LLMçš„å‚æ•°ï¼Œç›´æ¥å°†é¢†åŸŸç‰¹å®šçŸ¥è¯†çº³å…¥æ¨¡å‹ä¸­ï¼ˆå›¾2ï¼ˆdï¼‰ï¼‰ã€‚</p>
<p>ä¸åŒç±»åˆ«æ–¹æ³•ä¹‹é—´çš„å…³ç³»ï¼š<br>â€¢ ä¸åŒçš„ä¸“ä¸šåŒ–æ°´å¹³ï¼šæ¯ç§æ–¹æ³•åœ¨ä¸åŒçš„ä¸“ä¸šåŒ–æ°´å¹³ä¸Šæ“ä½œï¼ˆå³é»‘ç›’ã€ç°ç›’å’Œç™½ç›’ï¼‰ã€‚ä½¿ç”¨å¤–éƒ¨çŸ¥è¯†è¿›è¡Œå¢å¼ºæä¾›äº†é¢†åŸŸç‰¹å®šä¿¡æ¯çš„é›†ä¸­æ³¨å…¥ï¼Œè€Œæç¤ºå·¥ç¨‹åˆ™åœ¨è¾“å…¥å±‚é¢ä¸Šå¡‘é€ æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚æ¨¡å‹å¾®è°ƒä¿®æ”¹äº†LLMçš„å†…éƒ¨å‚æ•°ï¼Œå¯¼è‡´æ¨¡å‹è¡Œä¸ºå‘ç”Ÿæ›´æ·±åˆ»çš„å˜åŒ–ã€‚</p>
<p>â€¢ æƒè¡¡ï¼šè¿™äº›æ–¹æ³•åœ¨è®¡ç®—æˆæœ¬ã€å®æ–½ä¾¿åˆ©æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢å­˜åœ¨ä¸åŒçš„æƒè¡¡ã€‚ä½¿ç”¨å¤–éƒ¨ä¿¡æ¯è¿›è¡Œå¢å¼ºå’Œè®¾è®¡ç‰¹å®šä»»åŠ¡çš„æŒ‡ä»¤é€šå¸¸æ¯”LLMçš„çŸ¥è¯†æ›´æ–°è®¡ç®—æˆæœ¬ä½ï¼Œä½†å¯èƒ½æ— æ³•è¾¾åˆ°ç›¸åŒæ°´å¹³çš„æ€§èƒ½æ”¹è¿›ã€‚æ¨¡å‹å¾®è°ƒå’Œç¥ç»é€‚é…å™¨å¯ä»¥æä¾›æ›´å®è´¨æ€§çš„æ€§èƒ½æå‡ï¼Œä½†åœ¨å®æ–½ä¸Šå¯èƒ½æ›´å…·æŒ‘æˆ˜æ€§ï¼Œå¹¶ä¸”å¦‚æœå‡ºç°è¿‡æ‹Ÿåˆï¼Œå¯èƒ½ä¼šå¯¼è‡´æ³›åŒ–èƒ½åŠ›é™ä½ã€‚</p>
<p>â€¢ äº’è¡¥æ€§ï¼šè¿™ä¸‰ç§æ–¹æ³•å¯ä»¥ç‹¬ç«‹ä½¿ç”¨æˆ–ç»„åˆä½¿ç”¨ï¼Œä»¥åœ¨é¢†åŸŸç‰¹å®šä»»åŠ¡ä¸Šå®ç°æ›´å¥½çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å°†å¤–éƒ¨çŸ¥è¯†ä¸ç»è¿‡å¾®è°ƒçš„LLMç»“åˆèµ·æ¥ï¼Œå……åˆ†åˆ©ç”¨ä¸“ä¸šåŒ–çŸ¥è¯†å’Œä¼˜åŒ–çš„å‚æ•°ã€‚åŒæ ·ï¼Œç²¾å¿ƒè®¾è®¡çš„æç¤ºå¯ä»¥ä¸ç¥ç»é€‚é…å™¨ä¸€èµ·ä½¿ç”¨ï¼Œå¼•å¯¼æ¨¡å‹çš„è¾“å‡ºåŒæ—¶åˆ©ç”¨æ–°å­¦ä¹ çš„é¢†åŸŸç‰¹å®šçŸ¥è¯†ã€‚</p>
<h3><span id="æ€»ç»“-chatmind">æ€»ç»“ [chatmind]</span><a href="#æ€»ç»“-chatmind" class="header-anchor">#</a></h3><ul>
<li>LLMï¼ˆLarge Language Modelsï¼‰é¢†åŸŸä¸“ä¸šåŒ–<ul>
<li>é¢†åŸŸä¸“ä¸šåŒ–çš„å®šä¹‰<ul>
<li>å°†å¹¿æ³›è®­ç»ƒçš„é€šç”¨LLMè°ƒæ•´åˆ°ç‰¹å®šé¢†åŸŸå†…ä»¥å®ç°æœ€ä½³æ“ä½œ</li>
</ul>
</li>
<li>é¢†åŸŸä¸“ä¸šåŒ–çš„æŒ‘æˆ˜<ul>
<li>æŒ‘æˆ˜ä¸€ï¼šé¢†åŸŸä¸“ä¸šåŒ–çš„éœ€æ±‚</li>
<li>æŒ‘æˆ˜äºŒï¼šé¢†åŸŸä¸“ä¸šåŒ–çš„æ•°æ®ç¨€ç¼ºæ€§</li>
<li>æŒ‘æˆ˜ä¸‰ï¼šé¢†åŸŸä¸“ä¸šåŒ–çš„çŸ¥è¯†ç¼ºä¹</li>
</ul>
</li>
<li>LLMé¢†åŸŸä¸“ä¸šåŒ–çš„æ–¹æ³•<ul>
<li>æ–¹æ³•ä¸€ï¼š<strong>å¤–éƒ¨å¢å¼º</strong>  é»‘ç›’ <ul>
<li>åˆ©ç”¨å¤–éƒ¨èµ„æºæ¥å¢å¼ºLLMçš„é¢†åŸŸä¸“ä¸šåŒ–</li>
<li>ä¾‹å¦‚ï¼Œä½¿ç”¨ç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†è¿›è¡Œé¢„è®­ç»ƒ</li>
</ul>
</li>
<li>æ–¹æ³•äºŒï¼š<strong>æç¤ºè®¾è®¡</strong> ç°ç›’<ul>
<li>è®¾è®¡é€‚å½“çš„æç¤ºæ¥å¼•å¯¼LLMç”Ÿæˆç¬¦åˆç‰¹å®šé¢†åŸŸéœ€æ±‚çš„å†…å®¹</li>
<li>æ ¹æ®é¢†åŸŸçŸ¥è¯†å’Œéœ€æ±‚ï¼Œç²¾å¿ƒè®¾è®¡æç¤º</li>
</ul>
</li>
<li>æ–¹æ³•ä¸‰ï¼š<strong>æ¨¡å‹å¾®è°ƒ</strong> ç™½ç›’<ul>
<li>å¯¹é¢„è®­ç»ƒçš„LLMè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶æ›´é€‚åº”ç‰¹å®šé¢†åŸŸçš„ä»»åŠ¡å’Œæ•°æ®</li>
<li>é€šè¿‡åœ¨ç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œè¿­ä»£è®­ç»ƒï¼Œä¼˜åŒ–æ¨¡å‹æ€§èƒ½</li>
</ul>
</li>
</ul>
</li>
<li>LLMè®¿é—®çº§åˆ«çš„å‡è®¾<ul>
<li><strong>æ— è®¿é—®ï¼ˆé»‘ç›’ï¼‰</strong>å‡è®¾<ul>
<li>åªèƒ½è®¿é—®æ¨¡å‹APIï¼Œæ— æ³•è·å–å…¶ä»–ä¿¡æ¯</li>
<li>ä»…é€šè¿‡ç”Ÿæˆçš„è¾“å‡ºæ¥è¿›è¡Œæ“ä½œ</li>
</ul>
</li>
<li><strong>éƒ¨åˆ†è®¿é—®ï¼ˆç°ç›’ï¼‰</strong>å‡è®¾<ul>
<li>æ‹¥æœ‰æœ‰é™çš„ä¿¡æ¯ï¼Œå¦‚ç”Ÿæˆçš„æ ‡è®°æ¦‚ç‡</li>
<li>å¯æ ¹æ®è¿™äº›ä¿¡æ¯è®¾è®¡æç¤ºæ¥å¼•å¯¼LLMç”Ÿæˆç¬¦åˆé¢†åŸŸçŸ¥è¯†çš„å†…å®¹</li>
</ul>
</li>
<li><strong>å®Œå…¨è®¿é—®ï¼ˆç™½ç›’ï¼‰</strong>å‡è®¾<ul>
<li>å¯ä»¥å®Œå…¨è®¿é—®LLMï¼Œè·å–å…¶æ‰€æœ‰ä¿¡æ¯</li>
<li>å¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œä¿®æ”¹å’Œä¼˜åŒ–</li>
</ul>
</li>
<li>ä¸åŒè®¿é—®çº§åˆ«çš„å‡è®¾å¯¹åº”ä¸åŒçš„æ–¹æ³•å’Œæ“ä½œæ–¹å¼</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="é¢†åŸŸå¾®è°ƒæ¨¡å‹-1">é¢†åŸŸå¾®è°ƒæ¨¡å‹ [1]</span><a href="#é¢†åŸŸå¾®è°ƒæ¨¡å‹-1" class="header-anchor">#</a></h1><ul>
<li>æ³¨å…¥é¢†åŸŸçŸ¥è¯†ï¼Œåˆ†æˆä¸‰ç§ï¼š<ul>
<li>ç»§ç»­é¢„è®­ç»ƒæ³¨å…¥</li>
<li>å¾®è°ƒæ³¨å…¥ä»¥åŠ</li>
<li>å¤–æŒ‚æ³¨å…¥</li>
</ul>
</li>
</ul>
<h1><span id="å…³æ³¨ç‚¹-2">å…³æ³¨ç‚¹ [2]</span><a href="#å…³æ³¨ç‚¹-2" class="header-anchor">#</a></h1><ul>
<li><strong>é¢†åŸŸç›¸å…³æ•°æ®</strong>  æ˜¯Continue PreTrainçš„å…³é”®</li>
<li><strong>æ··åˆé€šç”¨æ•°æ®</strong>ä»¥<strong>ç¼“è§£æ¨¡å‹é—å¿˜é€šç”¨èƒ½åŠ›</strong></li>
<li><strong>é¢†åŸŸæ¨¡å‹Continue PreTrain</strong>æ—¶å¯ä»¥åŒæ­¥åŠ å…¥<strong>SFTæ•°æ®</strong>ï¼Œå³MIPï¼ŒMulti-Task Instruction PreTraining</li>
<li>ä»…ç”¨SFTåšé¢†åŸŸæ¨¡å‹æ—¶ï¼Œ<strong>èµ„æºæœ‰é™</strong>å°±ç”¨åœ¨<strong>Chatæ¨¡å‹åŸºç¡€ä¸Šè®­ç»ƒ</strong>ï¼Œ<strong>èµ„æºå……è¶³</strong>å°±åœ¨<strong>Baseæ¨¡å‹ä¸Šè®­ç»ƒ</strong>ã€‚ï¼ˆ<strong>èµ„æº&#x3D;æ•°æ®+æ˜¾å¡</strong>ï¼‰<br>+åœ¨Chatæ¨¡å‹ä¸Šè¿›è¡ŒSFTæ—¶ï¼Œè¯·ä¸€å®š<strong>éµå¾ªChatæ¨¡å‹åŸæœ‰çš„ç³»ç»ŸæŒ‡ä»¤&amp;æ•°æ®è¾“å…¥æ ¼å¼</strong>ã€‚</li>
<li>é¢†åŸŸè¯„æµ‹é›†æ—¶å¿…è¦å†…å®¹ï¼Œå»ºè®®æœ‰ä¸¤ä»½ï¼Œä¸€ä»½é€‰æ‹©é¢˜å½¢å¼è‡ªåŠ¨è¯„æµ‹ã€ä¸€ä»½å¼€æ”¾å½¢å¼äººå·¥è¯„æµ‹ã€‚</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="0">
<li><p>ã€ŠDomain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Surveyã€‹<br><a href="https://zhuanlan.zhihu.com/p/635480023">ç›®å‰æœ‰å“ªäº›æ–¹å¼è®­ç»ƒä¸€ä¸ªé¢†åŸŸçš„å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ Beyond One-Model-Fits-All A Survey of Domain Specialization LLM</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401405&idx=1&sn=59baf4a22d9a9abeb42599ac91e11a79">é¢†åŸŸå¾®è°ƒå¤§æ¨¡å‹å…¥å±€çš„è‡ªæˆ‘å’Œè§£ï¼šé¢†åŸŸå¾®è°ƒå¤§æ¨¡å‹è‹¥ä¸€å®šè¦åšï¼Œåˆ™åŠ¡å¿…æƒ³çš„è‹¥å¹²ä¸ªå‰ææ¡ä»¶ </a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/648798461">é¢†åŸŸå¤§æ¨¡å‹-è®­ç»ƒTrick&amp;è½åœ°æ€è€ƒ</a></p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/642611747">å‚ç›´é¢†åŸŸå¤§æ¨¡å‹çš„ä¸€äº›æ€è€ƒåŠå¼€æºæ¨¡å‹æ±‡æ€»</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403459&idx=2&sn=0219fc098c208e36cd32940e71089fd2">å±‚å‡ºä¸ç©·çš„å‚åŸŸå¾®è°ƒå¤§æ¨¡å‹éæœ€å…¨æ±‡æ€»ï¼š12å¤§é¢†åŸŸã€57ä¸ªé¢†åŸŸå¾®è°ƒæ¨¡å‹æ¦‚è¿°åŠå¯¹å‚ç›´è¡Œä¸šé—®ç­”çš„ä¸€äº›è®¨è®º </a> é¢†åŸŸæ¨¡å‹é›†åˆ<br>    <a href="https://github.com/www6v/Awesome-Domain-LLM">Awesome-Domain-LLM</a><br>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/131550529?spm=1001.2014.3001.5502">åŒ»ç–—é‡‘èæ³•å¾‹å¤§æ¨¡å‹ï¼šä»ChatDoctoråˆ°BloombergGPT&#x2F;FinGPT&#x2F;FinBERTã€ChatLaw&#x2F;LawGPT_zh</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400666&idx=1&sn=bc47e8c4eca6fc4baaded42fa3c6bd77">å†è°ˆå‚ç›´é¢†åŸŸå¤§æ¨¡å‹åŠä»Šæ—¥å‰æ²¿é€Ÿé€’ï¼šé‡‘èé¢†åŸŸFinBERTã€BloombergGPTä»¥åŠæ³•å¾‹é¢†åŸŸå¾®è°ƒæ¨¡å‹LawGPT_zh</a></p>
<p>1xx. <a href="/www6vHomeAIGC/2023/01/04/gptLeaderBoard/" title="æ’è¡Œæ¦œ">æ’è¡Œæ¦œ</a> self<br>1xx. <a href="https://github.com/www6v/Awesome-Domain-LLM">Awesome-Domain-LLM</a>  git å…¨</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s/jgyIOOzRWAgilcW4HfufNQ">è¡Œä¸šå¤§æ¨¡å‹è½åœ°çš„ä¸€äº›æœ‰è¶£è°ƒç ”æ€»ç»“ï¼šå…¼çœ‹å¤§æ¨¡å‹RAGé—®ç­”å››å¤§æŠ€æœ¯ç»¼è¿° </a>  è…¾è®¯ è¡Œä¸šå¤§æ¨¡å‹è°ƒç ”æŠ¥å‘Š ***</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>å¤§æ¨¡å‹</category>
      </categories>
      <tags>
        <tag>å¤§æ¨¡å‹</tag>
      </tags>
  </entry>
  <entry>
    <title>é‡‘èå¤§æ¨¡å‹</title>
    <url>/www6vHomeAIGC/2022/11/24/gptDomainFinance/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E9%87%91%E8%9E%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B-%E6%8A%80%E6%9C%AF1">é‡‘èå¤§æ¨¡å‹ æŠ€æœ¯[1]</a></li>
<li><a href="#%E9%87%91%E8%9E%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B">é‡‘èå¤§æ¨¡å‹</a><ul>
<li><a href="#fingpt-%E5%93%A5%E5%A4%A7-2">FinGPT å“¥å¤§ [2]</a></li>
<li><a href="#disc-finllm-4">DISC-FinLLM [4]</a></li>
<li><a href="#%E8%BD%A9%E8%BE%95%E9%87%91%E8%9E%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B-3">è½©è¾•é‡‘èå¤§æ¨¡å‹ [3]</a></li>
<li><a href="#bloomberggpt">BloombergGPT</a></li>
<li><a href="#finbert">FinBERT</a></li>
</ul>
</li>
<li><a href="#%E9%87%91%E8%9E%8D%E5%9C%BA%E6%99%AF">é‡‘èåœºæ™¯</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="é‡‘èå¤§æ¨¡å‹-æŠ€æœ¯1">é‡‘èå¤§æ¨¡å‹ æŠ€æœ¯[1]</span><a href="#é‡‘èå¤§æ¨¡å‹-æŠ€æœ¯1" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/11/24/gptDomainFinance/finance.png" class>
<p>A,B  å…ˆå¿½ç•¥<br>C - BloombergGPT<br>D - FinGPT</p>
<h1><span id="é‡‘èå¤§æ¨¡å‹">é‡‘èå¤§æ¨¡å‹</span><a href="#é‡‘èå¤§æ¨¡å‹" class="header-anchor">#</a></h1><h3><span id="fingpt-å“¥å¤§-2">FinGPT   å“¥å¤§ [2]</span><a href="#fingpt-å“¥å¤§-2" class="header-anchor">#</a></h3><ul>
<li><p>Resource</p>
<ul>
<li><a href="https://github.com/www6v/FinGPT">Github Repo</a></li>
<li><a href="https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster">FinGPT-Forecaster</a></li>
<li><a href="https://huggingface.co/FinGPT">huggingface</a></li>
<li>äº”ç¯‡paper</li>
</ul>
</li>
<li><p><a href="https://byfintech.medium.com/beginners-guide-to-fingpt-training-with-lora-chatglm2-6b-9eb5ace7fe99">Training</a></p>
</li>
</ul>
<h3><span id="disc-finllm-4">DISC-FinLLM [4]</span><a href="#disc-finllm-4" class="header-anchor">#</a></h3><h3><span id="è½©è¾•é‡‘èå¤§æ¨¡å‹-3">è½©è¾•é‡‘èå¤§æ¨¡å‹ [3]</span><a href="#è½©è¾•é‡‘èå¤§æ¨¡å‹-3" class="header-anchor">#</a></h3><ul>
<li>Resource<ul>
<li><a href="https://github.com/Duxiaoman-DI/XuanYuan">XuanYuan</a> git </li>
<li><a href="https://huggingface.co/datasets/Duxiaoman-DI/FinCorpus">æ•°æ®é›†</a></li>
</ul>
</li>
</ul>
<p>ã€å¤§æ¨¡å‹(åŸºäºBLOOM-176B)è½¬å‘å°æ¨¡å‹ï¼ˆXuanYuan-13B-Chatï¼‰ã€‘</p>
<h3><span id="bloomberggpt">BloombergGPT</span><a href="#bloomberggpt" class="header-anchor">#</a></h3><p>æœªå¼€æº</p>
<h3><span id="finbert">FinBERT</span><a href="#finbert" class="header-anchor">#</a></h3><h1><span id="é‡‘èåœºæ™¯">é‡‘èåœºæ™¯</span><a href="#é‡‘èåœºæ™¯" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li>ã€ŠA Survey of Large Language Models in Finance (FinLLMs)ã€‹<br> <a href="https://github.com/adlnlp/FinLLMs">FinLLMs</a></li>
<li><a href="https://www.bilibili.com/video/BV1R64y1j76H/">FinGPTå¼€æºé‡‘èå‚ç±»å¤§æ¨¡å‹</a> V</li>
<li>&lt;&lt;06ã€è„±æ•ç‰ˆã€‘é‡‘èè¡Œä¸šå®æˆ˜ï¼šåº¦å°æ»¡è½©è¾•é‡‘èå¤§æ¨¡å‹åº”ç”¨æ¢ç´¢ä¸å¼€å‘å®è·µ&gt;&gt;<br> <a href="https://www.bilibili.com/video/BV1G64y1j7Zj/">é‡‘èè¡Œä¸šå®æˆ˜ï¼šåº¦å°æ»¡è½©è¾•é‡‘èå¤§æ¨¡å‹åº”ç”¨æ¢ç´¢ä¸å¼€å‘å®è·µ</a> V</li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404800&idx=2&sn=9c1ad9d8aa8b0725dd6289bc15e177c9">æœ¬å‘¨å¤§æ¨¡å‹ä»£è¡¨è¿›å±•è§£æ:ChatGLM3çš„ç‰¹æ€§è®¤è¯†åŠLoRAä¸“å®¶æ¨¡ç»„å½¢å¼çš„é‡‘èé¢†åŸŸå¾®è°ƒæ¨¡å‹å®ç°ç­–ç•¥</a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400799&idx=1&sn=fb3778d1914849d3b41b047b33ce32a9">ChatGPTèƒ½å¦é¢„æµ‹è‚¡ä»·èµ°åŠ¿ï¼Ÿå¤§æ¨¡å‹åº”ç”¨äºé‡‘èé¢„æµ‹ä¸ä»Šæ—¥å¤§æ¨¡å‹å‰æ²¿é€Ÿé€’</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>é‡‘èå¤§æ¨¡å‹</category>
      </categories>
      <tags>
        <tag>é‡‘èå¤§æ¨¡å‹</tag>
      </tags>
  </entry>
  <entry>
    <title>æ³•å¾‹å¤§æ¨¡å‹</title>
    <url>/www6vHomeAIGC/2024/02/07/gptDomainLaw/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h3><span id="æ³•å¾‹å¤§æ¨¡å‹">æ³•å¾‹å¤§æ¨¡å‹</span><a href="#æ³•å¾‹å¤§æ¨¡å‹" class="header-anchor">#</a></h3><ul>
<li>ChatLaw </li>
<li>LawGPT_zh</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402872&idx=1&sn=0649e8f7490e057680cff1be16157209">å†çœ‹æ³•å¾‹é¢†åŸŸå¾®è°ƒæ¨¡å‹åŠå¤–æŒ‚çŸ¥è¯†åº“é—®ç­”ä¼˜åŒ–æ–¹æ¡ˆï¼šä»å¼•å…¥å…³é”®è¯ã€é¢†åŸŸåµŒå…¥åˆ°çŸ¥è¯†åº“ç»†åŒ–ã€æ„å›¾è¯†åˆ«åŠçŸ¥è¯†å¢å¼ºé¡¹ç›®æ¡ˆä¾‹ </a></p>
<p>1xx. <a href="https://finisky.github.io/lawyer-llama-summary/">è®­ç»ƒä¸­æ–‡å‚ç±»å¤§æ¨¡å‹ï¼šLawyer LLaMA </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>å‚ç±»å¤§æ¨¡å‹</category>
      </categories>
      <tags>
        <tag>å‚ç±»å¤§æ¨¡å‹</tag>
      </tags>
  </entry>
  <entry>
    <title>åŒ»ç–—å¤§æ¨¡å‹</title>
    <url>/www6vHomeAIGC/2023/02/07/gptDomainMed/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h3><span id="åŒ»ç–—å¤§æ¨¡å‹">åŒ»ç–—å¤§æ¨¡å‹</span><a href="#åŒ»ç–—å¤§æ¨¡å‹" class="header-anchor">#</a></h3><ul>
<li>LLaMA<ul>
<li>ChatDoctor  </li>
<li>åé©¼&#x2F;æœ¬è‰  å“ˆå·¥å¤§</li>
<li>PMC-LLaMA ä¸Šæµ·äº¤å¤§</li>
</ul>
</li>
<li>ChatGLM-6B<ul>
<li>ChatGLM-Med  å“ˆå·¥å¤§</li>
<li>DoctorGLM</li>
<li>æ˜åŒ» (MING)  MedicalGPT-zh  ä¸Šæµ·äº¤é€šå¤§å­¦</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402886&idx=1&sn=0552d60744645a84d13bb0cef57f321c">å†çœ‹23ä¸ªåŒ»ç–—é¢†åŸŸå¾®è°ƒå¤§æ¨¡å‹é›†åˆï¼šå…¼çœ‹CareLlamaåŒ»ç–—æ¨¡å‹çš„ä¸€äº›å®è·µç»éªŒä¸å¼€æ”¾åŒ»ç–—æ•°æ® </a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402589&idx=1&sn=3ba9d50fad433adeb8dd6c623b06c42d">å¤§æ¨¡å‹é‡ä¸Šå¿ƒç†å¥åº·å’¨è¯¢ï¼šMeChatã€QiaoBanã€SoulChatã€MindChatå››å¤§å¿ƒç†å¥åº·é¢†åŸŸå¾®è°ƒæ¨¡å‹æ€»ç»“ </a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402638&idx=1&sn=b9329498806e2b93b2d6817a17941bff">å¤§æ¨¡å‹å¸¸è§é”™è¯¯ã€åé¦ˆçš„æ¥æºåŠè‡ªæˆ‘ä¿®æ­£æ–¹æ³•ï¼šå…¼è®ºä¸¤ä¸ªæœ‰è¶£çš„åŒåä¸­åŒ»å¾®è°ƒå‚åŸŸæ¨¡å‹ </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>å‚ç±»å¤§æ¨¡å‹</category>
      </categories>
      <tags>
        <tag>å‚ç±»å¤§æ¨¡å‹</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Embedding</title>
    <url>/www6vHomeAIGC/2023/04/18/gptEmbedding/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#example-5">example [5]</a></li>
<li><a href="#embedding-%E4%BB%B7%E5%80%BC-6">Embedding ä»·å€¼ [6]</a></li>
<li><a href="#%E5%BA%94%E7%94%A8-6">åº”ç”¨ [6]</a></li>
<li><a href="#%E5%A4%A9%E6%A2%AF%E6%A6%9C">å¤©æ¢¯æ¦œ</a></li>
<li><a href="#example7">example[7]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

 

<h1><span id="example-5">example [5]</span><a href="#example-5" class="header-anchor">#</a></h1><ul>
<li><strong>é™ç»´</strong>:   t-SNE  </li>
<li>K-Means èšç±»</li>
<li>æ–‡æœ¬æœç´¢  ç›¸ä¼¼åº¦æœç´¢</li>
</ul>
<h1><span id="embedding-ä»·å€¼-6">Embedding ä»·å€¼ [6]</span><a href="#embedding-ä»·å€¼-6" class="header-anchor">#</a></h1><ul>
<li><strong>é™ç»´</strong><br>å°†è¿™äº›é«˜ç»´æ•°æ®æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´ç©ºé—´ï¼Œå¤§å¤§å‡å°‘äº†æ¨¡å‹çš„å¤æ‚åº¦ã€‚</li>
<li>æ•æ‰è¯­ä¹‰ä¿¡æ¯<br>Embeddingä¸ä»…ä»…æ˜¯é™ç»´ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒèƒ½å¤Ÿæ•æ‰åˆ°æ•°æ®çš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>æ³›åŒ–èƒ½åŠ›<br>ç”±äºEmbeddingèƒ½å¤Ÿæ•æ‰åˆ°æ•°æ®çš„ä¸€äº›å†…åœ¨è§„å¾‹ï¼Œå› æ­¤å¯¹äºè¿™äº›æœªè§è¿‡çš„æ•°æ®ï¼ŒEmbeddingä»ç„¶èƒ½å¤Ÿç»™å‡ºåˆç†çš„è¡¨ç¤º</li>
</ul>
<h1><span id="åº”ç”¨-6">åº”ç”¨ [6]</span><a href="#åº”ç”¨-6" class="header-anchor">#</a></h1><ul>
<li>è¯­ä¹‰è¡¨ç¤ºå’Œè¯­ä¹‰ç›¸ä¼¼åº¦</li>
<li>è¯è¯­å…³ç³»å’Œç±»æ¯”æ¨ç†</li>
<li>ä¸Šä¸‹æ–‡ç†è§£</li>
<li>æ–‡æœ¬åˆ†ç±»å’Œæƒ…æ„Ÿåˆ†æ</li>
<li>æœºå™¨ç¿»è¯‘å’Œç”Ÿæˆæ¨¡å‹</li>
</ul>
<h1><span id="å¤©æ¢¯æ¦œ">å¤©æ¢¯æ¦œ</span><a href="#å¤©æ¢¯æ¦œ" class="header-anchor">#</a></h1><p>  <a href="https://huggingface.co/spaces/mteb/leaderboard">mteb&#x2F;leaderboard</a></p>
<h1><span id="example7">example[7]</span><a href="#example7" class="header-anchor">#</a></h1><ul>
<li>m3eæ¨¡å‹</li>
<li>bgeæ¨¡å‹</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="5">
<li><p><a href="https://github.com/www6v/openai-quickstart/blob/main/openai_api/embedding.ipynb">embedding</a> git</p>
</li>
<li><p>ã€ŠAI å¤§æ¨¡å‹åº”ç”¨å¼€å‘å®æˆ˜è¥ã€‹ 03-å¤§æ¨¡å‹å¼€å‘åŸºç¡€ï¼šEmbedding</p>
</li>
<li><p><a href="https://blog.csdn.net/v_JULY_v/article/details/135311471">ä¸€æ–‡é€šé€Text Embeddingæ¨¡å‹ï¼šä»text2vecã€openai-ada-002åˆ°m3eã€bge</a></p>
</li>
</ol>
<p>1xx. <a href="https://www.bilibili.com/video/BV1Hk4y1X7aG/">å¦‚ä½•é€‰å–RAGä¸­çš„embeddingæ¨¡å‹</a><br>   <a href="https://huggingface.co/spaces/mteb/leaderboard">huggingface embeddingæ¨¡å‹æ’è¡Œæ¦œ</a><br>   <a href="https://arxiv.org/pdf/1908.10084.pdf">Sentence Bert</a><br>   <a href="https://github.com/blackinkkkxi/RAG_langchain">Demo Repo</a>  git</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s/qIh07eU8_lYL2gBVzTFzKA">å¼•å…¥ä»»åŠ¡InstructionæŒ‡ä»¤çš„å¥å­å‘é‡åŒ–æ–¹æ¡ˆï¼šInstructorçš„å®ç°æ€è·¯åŠè®­ç»ƒæ•°æ®é›†æ„é€ æ–¹æ¡ˆ</a><br>   <a href="https://github.com/xlang-ai/instructor-embedding">Repo</a> git</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648406715&idx=1&sn=a680597afdb7d5439a11302c7911795f">ä¹Ÿçœ‹åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡ŒRAGæ–‡æœ¬åµŒå…¥è®­ç»ƒæ•°æ®ç”Ÿæˆï¼šå…¼çœ‹é¢å‘NLPä»»åŠ¡çš„å¼€æºæŒ‡ä»¤å¾®è°ƒæ•°æ®é›† </a>        ã€ŠImproving Text Embeddings with Large Language Modelsã€‹</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/676589001">å¦‚ä½•æé«˜LLMsçš„æ–‡æœ¬è¡¨å¾(Text Embedding)èƒ½åŠ›?</a><br>    ã€ŠImproving Text Embeddings with Large Language Modelsã€‹</p>
<p>1xx. <a href="https://www.bilibili.com/video/BV1ex4y1S7u5/?p=2">æ–‡æœ¬è½¬å‘é‡æ•™ç¨‹s2â€”â€”è®¤è¯†æ–‡æœ¬è½¬å‘é‡æ–¹æ³•ï¼ˆsbertæœ¬è´¨å’Œæ¨ç†åŠ é€Ÿï¼‰</a>   V</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Embedding</category>
      </categories>
      <tags>
        <tag>Embedding</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)æ¶Œç°ç°è±¡</title>
    <url>/www6vHomeAIGC/2023/02/03/gptEmergent/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="emergent-abilities">Emergent Abilities</span><a href="#emergent-abilities" class="header-anchor">#</a></h1><ul>
<li>ğŸ”— æ–‡ç« ï¼šEmergent Abilities of Large Language Models  (2022.10)  (arxiv.org)</li>
<li>ğŸ”‘å…³é”®è¯å’Œæ‘˜è¦<ul>
<li>Keywords: LLMs, Emergent Ability, Scaling</li>
<li>abstract<ul>
<li>ä¸å¯é¢„æµ‹</li>
<li>ä¸èƒ½ä»å°æ¨¡å‹çš„çš„æ€§èƒ½å¤–æ¨</li>
<li>æ˜¯å¦èƒ½é€šè¿‡ç»§ç»­æ‰©å¤§æ¨¡å‹è§„æ¨¡æ¥è·å¾—æ›´å¤šæ¶Œç°èƒ½åŠ›</li>
</ul>
</li>
</ul>
</li>
<li>âš™ï¸ç ”ç©¶è®¾è®¡å’Œç»“è®º<ul>
<li>å®šä¹‰<ul>
<li>é€šå¸¸çš„æ¶Œç°ç°è±¡</li>
<li>å¤§æ¨¡å‹çš„æ¶Œç°ç°è±¡<ul>
<li>å°æ¨¡å‹æ¥è¿‘éšæœº</li>
<li><strong>å¤§æ¨¡å‹çªç„¶å‡ºç°</strong></li>
<li>ç›¸å˜</li>
</ul>
</li>
<li>å®éªŒæ¡†æ¶<ul>
<li>performance vs 1. FLOPs, model parameters</li>
<li><input checked disabled type="checkbox"> Training datasets</li>
<li>å ç”²ï¼šemergent ä¸å¾ˆå¤šå› ç´ éƒ½æœ‰å…³ï¼Œæœ¬æ–‡å¹¶ä¸æ˜¯è¯´åˆ°å“ªä¸ª scale å°±ä¼šå‡ºç° emergentï¼Œè€Œæ˜¯è¯´ emergent ç°è±¡æ™®éå­˜åœ¨ã€‚</li>
</ul>
</li>
<li>å®éªŒ1<ul>
<li>Few-shot Prompting</li>
<li>æµ‹è¯•æ•°æ®è¯´æ˜:<ul>
<li>A: ä¸‰ä½æ•°åŠ æ³•ï¼Œä¸¤ä½æ•°ä¹˜æ³•</li>
<li>B: [dÉªfÉ™rÉ™nt], å¤åŸ â€œdifferent,â€ </li>
<li>C: ä» e l h l o å¤åŸ hello</li>
<li>D: æ³¢æ–¯è¯­é—®ç­”</li>
<li>E: é’ˆå¯¹GPT-3 å¯¹æŠ—æ ‡çš„é—®ç­”</li>
<li>â€¦</li>
</ul>
</li>
<li>ç»“æœ<ul>
<li>è¿™äº› taskï¼Œä»¥ few-shot å½¢å¼å±•ç¤ºè¿‡ä»¥åï¼Œéƒ½æœ‰ emergent</li>
<li>ä¸åŒæ¨¡å‹ emergent scale ä¸ä¸€æ ·</li>
<li>æœ‰çš„ taskï¼Œåªæœ‰ 540B çš„ PaLM  emergeäº†</li>
</ul>
</li>
</ul>
</li>
<li>å®éªŒ2<ul>
<li>å¢å¼ºè¯­è¨€æ¨¡å‹èƒ½åŠ›çš„ emerge ç°è±¡</li>
<li>å·²çŸ¥çš„ä¸€äº›å¤§æ¨¡å‹æŠ€å·§åœ¨ä½•ç§è§„æ¨¡ä¸‹å‘æŒ¥ä½œç”¨ï¼Ÿ<ul>
<li>å¤§æ¨¡å‹æŠ€å·§<ul>
<li>æ€ç»´é“¾ Chain-of-thought: Letâ€™s think step by step.</li>
<li>æŒ‡ä»¤å¾®è°ƒ è¯·å†™ä¸€æ®µXXXçš„æè¿°</li>
<li>è‰ç¨¿æœ¬æ–¹æ³•ï¼š è®¡ç®— 15+16, è®©æ¨¡å‹åœ¨è‰ç¨¿æœ¬ä¸Šå†™â€œ5+6&#x3D;11ï¼Œè¿›ä½1â€</li>
</ul>
</li>
</ul>
</li>
<li>è¿™äº›å¢å¼ºè¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ–¹æ³•éƒ½æœ‰ä¸€å®šç¨‹åº¦çš„æ¶Œç°</li>
<li>è”æƒ³ï¼šä¹‹å‰çš„ prompt tuningï¼Œparameter efficient tuningï¼Œéƒ½æ˜¯æŸç§éšç€æ¨¡å‹è§„æ¨¡æ‰©å¤§çš„æ¶Œç°ï¼Ÿ</li>
</ul>
</li>
</ul>
</li>
<li>è®¨è®º<ul>
<li><strong>Emergent ç°è±¡çš„è§£é‡Š</strong><ul>
<li><strong>å¤šæ­¥èƒ½åŠ›è¯´</strong><ul>
<li>æ¯ä¸ªå­èƒ½åŠ›è¾¾åˆ° 90%  -&gt; ä¸€æ— æ˜¯å¤„</li>
<li>æ¯ä¸ªå­èƒ½åŠ›è¾¾åˆ° 95% -&gt; èƒ½å®Œæˆä¸€äº›ä»»åŠ¡äº†</li>
</ul>
</li>
<li>æŒ‡æ ‡ç¼ºé™·è¯´</li>
<li>å¥‡æ€ªçš„ç°è±¡ï¼šäº¤å‰ç†µæŸå¤±ä¸æ˜¯ emergent çš„ï¼Œè€Œæ˜¯åœ¨é€æ­¥ä¸‹é™</li>
</ul>
</li>
<li><strong>Emergent çš„é˜ˆå€¼å¯èƒ½ä¼šè¶Šæ¥è¶Šå°</strong><ul>
<li>æ›´å¹²å‡€çš„æ•°æ®ï¼Œæ›´å¥½çš„è®­ç»ƒæŠ€å·§ï¼Œæ›´ä¼˜ç§€çš„æ¨¡å‹ç»“æ„éƒ½å¯ä»¥æ˜¯  Emergenté˜ˆå€¼å˜å°</li>
</ul>
</li>
<li>æœªæ¥æ–¹å‘ï¼š<ul>
<li>ç»§ç»­æ‰©å¤§ model scaleï¼Œè¿œæœªè¾¾åˆ°ä¸Šé™</li>
<li>ä¸€äº›æ–°ç»“æ„çš„ scaling</li>
<li>æ•°æ®çš„ scaling</li>
<li>ç†è§£ prompt æœºåˆ¶</li>
<li>æ›´å‰æ²¿çš„ taskï¼Œç”¨æ¥æŒ‡å¯¼ emergent</li>
<li>ç†è§£ emergence</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>ğŸ“šè®ºæ–‡è´¡çŒ®<ul>
<li>ä¼˜ç‚¹<ul>
<li>ç¬¬ä¸€æ¬¡æ­£å¼æå‡º emergent å®éªŒ</li>
<li><strong>åšäº†å……åˆ†çš„å®éªŒè¡¨æ˜è¯¥ç°è±¡åœ¨å„ç§æ•°æ®é›†ä¸Šå¹¿æ³›å­˜åœ¨</strong></li>
<li>ç”šè‡³éªŒè¯äº†ä¸€äº›â€œæ–¹æ³•â€çš„æ¶Œç°</li>
<li>æå‡ºäº†ä¸€äº›è§£é‡Šè¯¥ç°è±¡çš„è§‚ç‚¹ï¼Œå¹¶æå‡ºè´¨ç–‘</li>
</ul>
</li>
<li>æ”¹è¿›ç‚¹<ul>
<li><strong>è¿˜æ˜¯ä¸çŸ¥é“ä¸ºå•¥ emerge</strong></li>
<li>å®éªŒé‡‡ç”¨å„ç§ä¸åŒæ¨¡å‹ï¼Œæ— æ³•å¾—å‡ºå“ªä¸ªè®¡ç®—é‡çº§å¯¹å“ªç§èƒ½åŠ›æœ‰ emerge</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://www.bilibili.com/video/BV1qX4y1i78J/">æ¸…ååšå£«å¸¦ä½ æ€è€ƒå¤§è¯­è¨€æ¨¡å‹LLMçš„æ¶Œç°ç°è±¡ï¼ˆEmergentï¼‰</a>  æœ‰è„‘å›¾<br> Emergent Abilities of Large Language Models ï¼ˆ<a href="https://arxiv.org/abs/2206.07682%EF%BC%89">https://arxiv.org/abs/2206.07682ï¼‰</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399147&idx=1&sn=6e6d416db50d9708c900ee3b5416bba3">å†è°ˆChatGPTç­‰å¤§æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›ï¼šå…³äºæ¶Œç°èƒ½åŠ›çš„å®šä¹‰ã€æµ‹è¯•æ–¹æ³•åŠåˆ†æå·¥ä½œæ€»ç»“ </a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Emergent</category>
      </categories>
      <tags>
        <tag>Emergent</tag>
      </tags>
  </entry>
  <entry>
    <title>æµ‹è¯„</title>
    <url>/www6vHomeAIGC/2023/02/07/gptEval/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402223&idx=1&sn=f2ec30cd04600129bb90bc9c81413d95">ä¸€äº›è®¨è®ºï¼šä¸‰å¼ å…³äºå¤§æ¨¡å‹å¾®è°ƒæ–¹æ¡ˆçš„è„‘å›¾åŠå‡ ç‚¹llama2ç­‰è¡Œä¸šè½åœ°çš„é—®é¢˜æ€è€ƒ </a><br>1xx. <a href="https://github.com/CLUEbenchmark/SuperCLUE-Llama2-Chinese">https://github.com/CLUEbenchmark/SuperCLUE-Llama2-Chinese</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402549&idx=1&sn=07a8af1db44df6125939c5c9e90f6267">å¦‚ä½•è®©è‡ªå·±çš„å¤§æ¨¡å‹æ¦œå•è¯„åˆ†æ›´é«˜ï¼šä¹Ÿè°ˆæ¦œå•è¯„æµ‹è¯„åˆ†çš„ä¸€äº›å¸¸è§æ–¹æ¡ˆå’Œå…¸å‹æ¡ˆä¾‹ </a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403046&idx=1&sn=0a9b612e9790c0bf49d5cede8fda365c">å¤§æ¨¡å‹è½åœ°çš„ä¸€äº›å‰æ²¿è§‚ç‚¹ï¼šå…¼çœ‹çŸ¥è¯†å›¾è°±å¢å¼ºå¤§æ¨¡å‹é—®ç­”çš„å‡ ä¸ªæ–¹æ¡ˆåŠCEVALæ¦œå•è¯„æµ‹å¯å‘ </a> äºŒã€CEVALæ¦œå•è¯„æµ‹ä¸­èƒ½å¤Ÿå¾—åˆ°ä¸€äº›å¯ç¤º<br><a href="https://github.com/hkust-nlp/ceval/blob/main/resources/tutorial.md">1. C-Eval æ•°æ®é›†è¯„æµ‹ç®€æ˜æ•™ç¨‹</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403295&idx=1&sn=126c949d0a00eb85b4a3a6b0106f55a6&poc_token=HApExGWjou7N5NVcTKmJpWt9LZ8ul6wynjV5VHnQ">å¤§æ¨¡å‹Bç«¯è½åœ°â€œç‰›åˆ€æ€é¸¡â€çš„å¥‡æ€ªæ„Ÿè§‰ï¼šå…¼çœ‹CEVAlé€šç”¨è¯„æµ‹åˆ°é‡‘èã€åŒ»ç–—ä¸¤å¤§å‚åŸŸè¯„æµ‹çš„è½¬å˜ </a>   CEVAl</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>eval</category>
      </categories>
      <tags>
        <tag>eval</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT ç³»åˆ—</title>
    <url>/www6vHomeAIGC/2022/12/11/gptFamily/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E8%BF%9B%E5%8C%96%E6%97%B6%E9%97%B4%E7%BA%BF">è¿›åŒ–æ—¶é—´çº¿</a></li>
<li><a href="#gpt1-1">GPT1 [1]</a></li>
<li><a href="#gpt2-1">GPT2 [1]</a><ul>
<li><a href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3">æ ¸å¿ƒæ€æƒ³</a></li>
<li><a href="#gpt-2-vs-gpt-1">GPT-2 vs. GPT-1</a></li>
</ul>
</li>
<li><a href="#gpt3-1">GPT3 [1]</a><ul>
<li><a href="#%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95">ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æ–¹æ³•</a></li>
<li><a href="#few-shot-vs-fine-tuning">Few-shot vs fine-tuning</a></li>
<li><a href="#gpt-3-vs-gpt-2">GPT-3 vs. GPT-2</a></li>
</ul>
</li>
<li><a href="#instructgpt-1">InstructGPT [1]</a><ul>
<li><a href="#%E6%AD%A5%E9%AA%A4">æ­¥éª¤</a></li>
<li><a href="#%E6%8A%80%E6%9C%AF%E6%96%B9%E6%A1%88">æŠ€æœ¯æ–¹æ¡ˆ</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">æ€»ç»“</a></li>
</ul>
</li>
<li><a href="#chatgpt-%E8%AE%AD%E7%BB%83-3">ChatGPT è®­ç»ƒ  [3]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="è¿›åŒ–æ—¶é—´çº¿">è¿›åŒ–æ—¶é—´çº¿</span><a href="#è¿›åŒ–æ—¶é—´çº¿" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/12/11/gptFamily/family.jpg" class>

<h1><span id="gpt1-1">GPT1 [1]</span><a href="#gpt1-1" class="header-anchor">#</a></h1><ol>
<li>å®ƒæ˜¯æœ€æ—©ä¸€æ‰¹æå‡ºåœ¨ NLP ä»»åŠ¡ä¸Šä½¿ç”¨ <strong>pre-train + fine-tuning èŒƒå¼</strong>çš„å·¥ä½œã€‚</li>
<li>GPT çš„å®éªŒè¯æ˜äº†æ¨¡å‹çš„ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ä¼šéšç€è§£ç å™¨å±‚æ•°å¢åŠ è€Œä¸æ–­æå‡ï¼Œè€Œä¸”ç›®å‰è¿˜æœ‰æå‡ç©ºé—´</li>
<li><strong>é¢„è®­ç»ƒæ¨¡å‹å…·æœ‰ zero-shot çš„èƒ½åŠ›</strong>ï¼Œå¹¶ä¸”èƒ½éšç€é¢„è®­ç»ƒçš„è¿›è¡Œä¸æ–­å¢å¼º</li>
</ol>
<h1><span id="gpt2-1">GPT2 [1]</span><a href="#gpt2-1" class="header-anchor">#</a></h1><h3><span id="æ ¸å¿ƒæ€æƒ³">æ ¸å¿ƒæ€æƒ³</span><a href="#æ ¸å¿ƒæ€æƒ³" class="header-anchor">#</a></h3><p>å½“æ¨¡å‹çš„å®¹é‡éå¸¸å¤§ä¸”æ•°æ®é‡è¶³å¤Ÿä¸°å¯Œæ—¶ï¼Œä»…ä»…é è¯­è¨€æ¨¡å‹çš„å­¦ä¹ ä¾¿å¯ä»¥å®Œæˆå…¶ä»–æœ‰ç›‘ç£å­¦ä¹ çš„ä»»åŠ¡ï¼Œ<strong>ä¸éœ€è¦åœ¨ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ</strong>ã€‚</p>
<h3><span id="gpt-2-vs-gpt-1">GPT-2 vs. GPT-1</span><a href="#gpt-2-vs-gpt-1" class="header-anchor">#</a></h3><ol>
<li><strong>ä¸»æ¨ zero-shot</strong>ï¼Œè€Œ GPT-1 ä¸º pre-train + fine-tuningï¼›</li>
<li>è®­ç»ƒæ•°æ®è§„æ¨¡æ›´å¤§ï¼ŒGPT-2 ä¸º 800w æ–‡æ¡£ 40Gï¼ŒGPT-1 ä¸º 5GBï¼›</li>
<li>æ¨¡å‹å¤§å°ï¼ŒGPT-2 æœ€å¤§ 15 äº¿å‚æ•°ï¼ŒGPT-1ä¸º 1 äº¿å‚æ•°ï¼›</li>
<li>æ¨¡å‹ç»“æ„è°ƒæ•´ï¼Œå±‚å½’ä¸€åŒ–å’Œå‚æ•°åˆå§‹åŒ–æ–¹å¼ï¼›</li>
<li>è®­ç»ƒå‚æ•°ï¼Œbatch_size ä» 64 å¢åŠ åˆ° 512ï¼Œä¸Šæ–‡çª—å£å¤§å°ä» 512 å¢åŠ åˆ° 1024ï¼Œç­‰ç­‰ï¼›</li>
</ol>
<h1><span id="gpt3-1">GPT3 [1]</span><a href="#gpt3-1" class="header-anchor">#</a></h1><h3><span id="ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æ–¹æ³•">ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æ–¹æ³•</span><a href="#ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æ–¹æ³•" class="header-anchor">#</a></h3><p>GPT-3 åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„è¯„ä¼°ä¸é¢„æµ‹æ—¶ï¼Œæä¾›äº†ä¸‰ç§ä¸åŒçš„æ–¹æ³•ï¼š<br><strong>Zero-shot</strong>ï¼šä»…ä½¿ç”¨å½“å‰ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œä¸è¿›è¡Œä»»ä½•æ¢¯åº¦æ›´æ–°ï¼›<br><strong>One-shot</strong>ï¼šå½“å‰ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°ï¼ŒåŠ ä¸Šä¸€ä¸ªç®€å•çš„è¾“å…¥è¾“å‡ºæ ·ä¾‹ï¼Œä¸è¿›è¡Œä»»ä½•æ¢¯åº¦æ›´æ–°ï¼›<br><strong>Few-shot</strong>ï¼šå½“å‰ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°ï¼ŒåŠ ä¸Šå‡ ä¸ªç®€å•çš„è¾“å…¥è¾“å‡ºæ ·ä¾‹ï¼Œä¸è¿›è¡Œä»»ä½•æ¢¯åº¦æ›´æ–°ï¼›</p>
<ul>
<li>Shot[2]<ul>
<li>One-shot</li>
<li>Few-Shot</li>
<li>Zero-Shot</li>
</ul>
</li>
</ul>
<h3><span id="few-shot-vs-fine-tuning">Few-shot vs fine-tuning</span><a href="#few-shot-vs-fine-tuning" class="header-anchor">#</a></h3><p>å…¶ä¸­ <strong>Few-shot</strong> ä¹Ÿè¢«ç§°ä¸º <strong>in-context learning</strong>ï¼Œè™½ç„¶å®ƒä¸ fine-tuning ä¸€æ ·éƒ½éœ€è¦ä¸€äº›<strong>æœ‰ç›‘ç£æ ‡æ³¨æ•°æ®</strong>ï¼Œä½†æ˜¯ä¸¤è€…çš„åŒºåˆ«æ˜¯ï¼š<br>ã€æœ¬è´¨åŒºåˆ«ã€‘<br><strong>fine-tuning</strong> åŸºäºæ ‡æ³¨æ•°æ®<strong>å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œæ›´æ–°</strong><br>è€Œ<strong>in-context learning</strong>ä½¿ç”¨æ ‡æ³¨æ•°æ®æ—¶ä¸åšä»»ä½•çš„æ¢¯åº¦å›ä¼ , <strong>æ¨¡å‹å‚æ•°ä¸æ›´æ–°</strong></p>
<h3><span id="gpt-3-vs-gpt-2">GPT-3 vs. GPT-2</span><a href="#gpt-3-vs-gpt-2" class="header-anchor">#</a></h3><ol>
<li>æ•ˆæœä¸Šï¼Œè¶…å‡º GPT-2 éå¸¸å¤šï¼Œèƒ½ç”Ÿæˆäººç±»éš¾ä»¥åŒºåˆ†çš„æ–°é—»æ–‡ç« ï¼›</li>
<li><strong>ä¸»æ¨ few-shot</strong>ï¼Œç›¸æ¯”äº GPT-2 çš„ zero-shotï¼Œå…·æœ‰å¾ˆå¼ºçš„åˆ›æ–°æ€§ï¼›</li>
<li>æ¨¡å‹ç»“æ„ç•¥å¾®å˜åŒ–ï¼Œé‡‡ç”¨ <strong>sparse attention</strong> æ¨¡å—ï¼›</li>
<li>æµ·é‡è®­ç»ƒè¯­æ–™ <strong>45TB</strong>ï¼ˆæ¸…æ´—å 570GBï¼‰ï¼Œç›¸æ¯”äº GPT-2 çš„ 40GBï¼›</li>
<li>æµ·é‡æ¨¡å‹å‚æ•°ï¼Œæœ€å¤§æ¨¡å‹ä¸º <strong>1750 äº¿</strong>ï¼ŒGPT-2 æœ€å¤§ä¸º 15 äº¿å‚æ•°ï¼›</li>
</ol>
<h1><span id="instructgpt-1">InstructGPT [1]</span><a href="#instructgpt-1" class="header-anchor">#</a></h1><h3><span id="æ­¥éª¤">æ­¥éª¤</span><a href="#æ­¥éª¤" class="header-anchor">#</a></h3><ul>
<li>æœ‰ç›‘ç£å¾®è°ƒï¼Œ</li>
<li>å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼Œ</li>
<li>å¼ºåŒ–å­¦ä¹ è®­ç»ƒ</li>
</ul>
<h3><span id="æŠ€æœ¯æ–¹æ¡ˆ">æŠ€æœ¯æ–¹æ¡ˆ</span><a href="#æŠ€æœ¯æ–¹æ¡ˆ" class="header-anchor">#</a></h3><ul>
<li><p>æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰<br>æœ¬è´¨ä¸Šæ¥è¯´ï¼Œ<strong>SFT å¯ä»¥ç†è§£ä¸ºäººå·¥æ ‡æ³¨äº†ä¸€æ‰¹æ•°æ®ï¼Œç„¶åå»å¾®è°ƒ GPT-3</strong>ã€‚ä½†æ˜¯å€¼å¾—ä¸€æçš„æ˜¯ï¼Œè¿™é‡Œ<strong>æ ‡æ³¨çš„æ•°æ®ä¸ GPT-3 ä¹‹å‰ç”¨æ¥åšä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨çš„ few-shot æ ¼å¼ï¼Œæœ‰éå¸¸æœ¬è´¨çš„åŒºåˆ«</strong>ã€‚<br>InstructGPT åœ¨ SFT ä¸­æ ‡æ³¨çš„æ•°æ®ï¼Œæ­£æ˜¯ä¸ºäº†<strong>æ¶ˆé™¤è¿™ç§æ¨¡å‹é¢„æµ‹ä¸ç”¨æˆ·è¡¨è¾¾ä¹ æƒ¯ä¹‹é—´çš„ gap</strong>ã€‚åœ¨æ ‡æ³¨è¿‡ç¨‹ä¸­ï¼Œä»–ä»¬<strong>ä» GPT-3 çš„ç”¨æˆ·çœŸå®è¯·æ±‚ä¸­é‡‡æ ·</strong>å¤§é‡ä¸‹æ¸¸ä»»åŠ¡çš„æè¿°ï¼Œç„¶åè®©<strong>æ ‡æ³¨äººå‘˜å¯¹ä»»åŠ¡æè¿°è¿›è¡Œç»­å†™</strong>ï¼Œä»è€Œå¾—åˆ°è¯¥é—®é¢˜çš„é«˜è´¨é‡å›ç­”ã€‚</p>
</li>
<li><p>åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰</p>
<img src="/www6vHomeAIGC/2022/12/11/gptFamily/instructGPT.jpg" class></li>
</ul>
<h3><span id="æ€»ç»“">æ€»ç»“</span><a href="#æ€»ç»“" class="header-anchor">#</a></h3><ol>
<li>è§£å†³ GPT-3 çš„<strong>è¾“å‡ºä¸äººç±»æ„å›¾</strong>ä¹‹é—´çš„<strong>Aligné—®é¢˜</strong>ï¼›</li>
<li>è®©å…·å¤‡ä¸°å¯Œä¸–ç•ŒçŸ¥è¯†çš„å¤§æ¨¡å‹ï¼Œ<strong>å­¦ä¹ â€œäººç±»åå¥½â€</strong>ï¼›</li>
<li>æ ‡æ³¨äººå‘˜æ˜æ˜¾æ„Ÿè§‰ InstructGPT çš„è¾“å‡ºæ¯” GPT-3 çš„è¾“å‡ºæ›´å¥½ï¼Œæ›´å¯é ï¼›</li>
<li>InstructGPT åœ¨<strong>çœŸå®æ€§</strong>ï¼Œ<strong>ä¸°å¯Œåº¦</strong>ä¸Šè¡¨ç°æ›´å¥½ï¼›</li>
<li>InstructGPT å¯¹æœ‰å®³ç»“æœçš„ç”Ÿæˆæ§åˆ¶çš„æ›´å¥½ï¼Œä½†æ˜¯å¯¹äº<strong>â€œåè§â€æ²¡æœ‰æ˜æ˜¾æ”¹å–„</strong>ï¼›</li>
</ol>
<h1><span id="chatgpt-è®­ç»ƒ-3">ChatGPT è®­ç»ƒ  [3]</span><a href="#chatgpt-è®­ç»ƒ-3" class="header-anchor">#</a></h1><ul>
<li>åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒæŠ€æœ¯ RLHF<ul>
<li>ä½¿ç”¨æœ‰ç›‘ç£å¾®è°ƒ Supervised Fine-tuningï¼ˆSFTï¼‰é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹<ul>
<li>Supervised fine-tuning (SFT)<br>&#x3D; Instruction Tuning</li>
</ul>
</li>
<li>è®­ç»ƒå¥–åŠ±æ¨¡å‹ Reward Modelï¼ˆRMï¼‰</li>
<li>ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•å¾®è°ƒè¯­è¨€æ¨¡å‹<ul>
<li>RLHF<br>[æœ¬è´¨  åŸºäºå¼ºåŒ–å­¦ä¹ , å¼ºåŒ–å­¦ä¹ ç®—æ³•]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/609716668">GPT &#x2F; GPT-2 &#x2F; GPT-3 &#x2F; InstructGPT è¿›åŒ–ä¹‹è·¯</a> ***</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/624793654">Few-Shot, Zero-Shot &amp; One-shot çš„é€šä¿—ç†è§£</a></p>
</li>
<li><p><a href="https://shimo.im/docs/KlkKv4XQDouwWRqd/read">AI å¤§æ¨¡å‹å¾®è°ƒè®­ç»ƒè¥å¤§çº²</a></p>
</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s/VYv8BRgGnp9ZTuXxaSuFwg">ä¸‡å­—æ‹†è§£ï¼è¿½æº¯ChatGPTå„é¡¹èƒ½åŠ›çš„èµ·æº </a> ç¬¦å°§</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/642282717">[Transformer 101ç³»åˆ—] ChatGPTæ˜¯æ€ä¹ˆç‚¼æˆçš„?</a> æœª</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>GPT</category>
      </categories>
      <tags>
        <tag>GPT</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)PEFT</title>
    <url>/www6vHomeAIGC/2022/11/18/gptFineTuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%88%86%E7%B1%BB">åˆ†ç±»</a></li>
<li><a href="#peft-%E5%88%86%E7%B1%BB-11">PEFT åˆ†ç±» [1.1]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E5%8E%9F%E7%90%86">åŸç†</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="åˆ†ç±»">åˆ†ç±»</span><a href="#åˆ†ç±»" class="header-anchor">#</a></h1><ul>
<li><p>å…¨é‡å¾®è°ƒ</p>
</li>
<li><p>å±€éƒ¨å¾®è°ƒ</p>
<ul>
<li>PEFT(Parameter-Efficient Fine-Tuning)  PEFT</li>
</ul>
</li>
</ul>
<h1><span id="peft-åˆ†ç±»-11">PEFT åˆ†ç±» [1.1]</span><a href="#peft-åˆ†ç±»-11" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/11/18/gptFineTuning/category.png" class>

<p>é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å¯ä»¥ç²—ç•¥åˆ†ä¸ºä»¥ä¸‹ä¸‰å¤§ç±»ï¼šå¢åŠ é¢å¤–å‚æ•°ï¼ˆAï¼‰ã€é€‰å–ä¸€éƒ¨åˆ†å‚æ•°æ›´æ–°ï¼ˆSï¼‰ã€å¼•å…¥é‡å‚æ•°åŒ–ï¼ˆRï¼‰ã€‚è€Œåœ¨å¢åŠ é¢å¤–å‚æ•°è¿™ç±»æ–¹æ³•ä¸­ï¼Œåˆä¸»è¦åˆ†ä¸ºç±»é€‚é…å™¨ï¼ˆAdapter-likeï¼‰æ–¹æ³•å’Œè½¯æç¤ºï¼ˆSoft promptsï¼‰ä¸¤ä¸ªå°ç±»ã€‚</p>
<ul>
<li><p>PEFT</p>
<ul>
<li>[æœ¬è´¨   åŸºäºæœ‰ç›‘ç£å­¦ä¹ ]</li>
</ul>
</li>
<li><p>PEFT(Parameter-Efficient Fine-Tuning)  PEFT</p>
<ul>
<li><p><strong>å¼•å…¥é‡å‚æ•°åŒ–ï¼ˆRï¼‰</strong>    </p>
<ul>
<li><strong>LoRA</strong> [2021 Microsoft]<br>Low-Rank Adaptation of LLMs<br>LoRA   ã€ å¹¶è”æ–¹å¼çš„å¤–æŒ‚ã€‘ [æ•ˆæœæ¯”è¾ƒå¥½]</li>
<li>QLoRA [2023 University of Washington]<br> Efficient Finetuning of Quantized LLMs</li>
<li>AdaLoRA [2023 Microsoft]<br> Adaptive Budget Allocation for PEFT</li>
</ul>
</li>
<li><p>å¢åŠ é¢å¤–å‚æ•°ï¼ˆAï¼‰</p>
<ul>
<li><strong>è½¯æç¤ºï¼ˆSoft promptsï¼‰</strong> <ul>
<li>Prefix Tuning[2021 Stanford]<br>å¢åŠ ä¸€ä¸ªå¯è¢«è®­ç»ƒçš„Embeddingå±‚<br>ã€éš¾å®ç°ã€‘</li>
<li><strong>Prompt Tuning</strong> [2021 Google]<br>ã€ç®€åŒ–ç‰ˆæœ¬çš„Prefix Tuningã€‘</li>
<li><strong>P-Turning v1</strong> [2021 Tsinghua]</li>
<li><strong>P-Turning v2</strong> [2022 Tsinghua]</li>
</ul>
</li>
<li>Adapter-Tuning[2019 Google]<br>ã€ ä¸²è”æ–¹å¼çš„å¤–æŒ‚ã€‘</li>
</ul>
</li>
<li><p>é€‰å–ä¸€éƒ¨åˆ†å‚æ•°æ›´æ–°ï¼ˆSï¼‰</p>
<ul>
<li>BitFit</li>
</ul>
</li>
<li><p>additive</p>
<ul>
<li>IA3</li>
</ul>
</li>
</ul>
</li>
<li><p>ç»Ÿä¸€å¾®è°ƒæ¡†æ¶<br>  UniPELT</p>
</li>
<li><p>æ€»ç»“[3]</p>
<img src="/www6vHomeAIGC/2022/11/18/gptFineTuning/overview.jpg" class></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="åŸç†">åŸç†</span><a href="#åŸç†" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://github.com/www6v/llm-action#llm%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86">llmå¾®è°ƒæŠ€æœ¯åŸç†</a>  æå›½ä¸œ<br>1.1 <a href="https://zhuanlan.zhihu.com/p/635152813">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆä¸€ï¼‰-èƒŒæ™¯ã€å‚æ•°é«˜æ•ˆå¾®è°ƒç®€ä»‹</a><br>1.2  <a href="https://zhuanlan.zhihu.com/p/649755252">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆä¸ƒï¼‰-æœ€ä½³å®è·µã€æ€»ç»“</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1t8411D7v4?p=8">å¤§æ¨¡å‹å¹²è´§æ•™ç¨‹çœ‹è¿™ä¸€ä¸ªå°±å¤Ÿäº†~2023å¹´å…¨ç½‘æœ€ç¡¬æ ¸æœ€å…¨é¢çš„å¤§æ¨¡å‹å…¬å¼€è¯¾|å¤§æ¨¡å‹å¾®è°ƒ | ChatGLM | LangChain</a> V ***</p>
</li>
<li><p><a href="https://aicarrier.feishu.cn/file/H1YvbRyacopEs6xzgZ8c9DDcnIh">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†åŠå®è·µ</a> pdf<br><a href="https://www.bilibili.com/video/BV1qw411c7Hd/">å¦‚ä½•é«˜æ•ˆå¾®è°ƒå¤§æ¨¡å‹ï¼ŸæŠ€æœ¯åŸç†ä¸æœ€ä½³å®è·µæ­ç§˜ï¼</a> V ***</p>
</li>
</ol>
<p>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/132116949">LLMé«˜æ•ˆå‚æ•°å¾®è°ƒæ–¹æ³•ï¼šä»Prefix Tuningã€Prompt Tuningã€P-Tuning V1&#x2F;V2åˆ°LoRAã€QLoRA(å«å¯¹æ¨¡å‹é‡åŒ–çš„è§£é‡Š)</a> **</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402136&idx=1&sn=554331e397015c4da95fb0d0929f5aa1">7æœˆæœ«å…³äºå¤§æ¨¡å‹å¾®è°ƒæ•°æ®å·¥ç¨‹ä¸è¯„ä¼°çš„æŠ€æœ¯ç»¼è¿°ï¼šä»æ•°æ®æ„é€ æ–¹æ¡ˆåˆ°æ¨¡å‹è¯„ä¼°èŒƒå¼çš„è®ºæ–‡æ¢³ç†æŒ‡å¼• </a> å¯¹é½-è®ºæ–‡é›†<br>   <a href="https://github.com/GaryYufei/AlignLLMHumanSurvey">AlignLLMHumanSurvey</a> git</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>Fine Tuning-Bert</title>
    <url>/www6vHomeAIGC/2024/01/26/gptFineTuningBert/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="åŸºäºbertçš„äºŒåˆ†ç±»">åŸºäºbertçš„äºŒåˆ†ç±»</span><a href="#åŸºäºbertçš„äºŒåˆ†ç±»" class="header-anchor">#</a></h1><ul>
<li>ä»£ç  - å…¨å‚FT,éPEFT<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_metric</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer</span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorWithPadding</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">SEED=<span class="number">42</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ALBERTæ˜¯ä¸€ç§å‹ç¼©è¿‡çš„BERT</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;albert-base-v2&quot;</span></span><br><span class="line">DATASET_NAME = <span class="string">&quot;glue&quot;</span> <span class="comment"># ä¸€ç»„NLPè¯„æµ‹ä»»åŠ¡</span></span><br><span class="line">DATASET_TASK = <span class="string">&quot;mrpc&quot;</span> <span class="comment"># MRPC æ˜¯å…¶ä¸­ä¸€ä¸ªå­ä»»åŠ¡ -- Microsoft Research Paraphrase Corpus</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># åœ¨Bertçš„åŸºç¡€ä¸ŠåŠ äº†ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyClassifier</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, backbone</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.bert_encoder = backbone</span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">768</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_loss</span>(<span class="params">self, logits, labels</span>):</span><br><span class="line">        loss_fct = nn.CrossEntropyLoss()</span><br><span class="line">        <span class="keyword">return</span> loss_fct(logits, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask,labels=<span class="literal">None</span></span>):</span><br><span class="line">        output = self.bert_encoder(input_ids=input_ids, attention_mask=attention_mask)</span><br><span class="line">        output = output.last_hidden_state[:, <span class="number">0</span>, :]</span><br><span class="line">        output = self.linear(output)</span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = self.compute_loss(output, labels)</span><br><span class="line">            <span class="keyword">return</span> loss, output</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½æ•°æ®é›†å¯¹åº”çš„è¯„ä¼°æ–¹æ³•</span></span><br><span class="line">glue_metric = datasets.load_metric(DATASET_NAME, DATASET_TASK)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_pred</span>):</span><br><span class="line">    logits, labels = eval_pred</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> glue_metric.compute(predictions=predictions, references=labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½æ•°æ®é›†</span></span><br><span class="line">raw_datasets = load_dataset(DATASET_NAME,DATASET_TASK)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒé›†</span></span><br><span class="line">raw_train_dataset = raw_datasets[<span class="string">&quot;train&quot;</span>]</span><br><span class="line"><span class="comment"># éªŒè¯é›†</span></span><br><span class="line">raw_valid_dataset = raw_datasets[<span class="string">&quot;validation&quot;</span>]</span><br><span class="line"></span><br><span class="line">columns = raw_train_dataset.column_names</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®éšæœºç§å­</span></span><br><span class="line">transformers.set_seed(SEED)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰tokenizer</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰æ•°æ®å¤„ç†å‡½æ•°ï¼ŒæŠŠåŸå§‹æ•°æ®è½¬æˆinput_ids, attention_mask, labels</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_fn</span>(<span class="params">examples</span>):</span><br><span class="line">    inputs = tokenizer(examples[<span class="string">&quot;sentence1&quot;</span>], examples[<span class="string">&quot;sentence2&quot;</span>], truncation=<span class="literal">True</span>, max_length=<span class="number">128</span>)</span><br><span class="line">    examples[<span class="string">&quot;input_ids&quot;</span>] = inputs[<span class="string">&quot;input_ids&quot;</span>]</span><br><span class="line">    examples[<span class="string">&quot;attention_mask&quot;</span>] = inputs[<span class="string">&quot;attention_mask&quot;</span>]</span><br><span class="line">    examples[<span class="string">&quot;labels&quot;</span>] = examples[<span class="string">&quot;label&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> examples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenized_train_dataset = raw_train_dataset.<span class="built_in">map</span>(</span><br><span class="line">    process_fn,</span><br><span class="line">    batched=<span class="literal">True</span>,</span><br><span class="line">    remove_columns=columns</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tokenized_valid_dataset = raw_valid_dataset.<span class="built_in">map</span>(</span><br><span class="line">    process_fn,</span><br><span class="line">    batched=<span class="literal">True</span>,</span><br><span class="line">    remove_columns=columns</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰æ•°æ®æ ¡å‡†å™¨ï¼ˆè‡ªåŠ¨ç”Ÿæˆbatchï¼‰</span></span><br><span class="line">collater = DataCollatorWithPadding(</span><br><span class="line">    tokenizer=tokenizer, return_tensors=<span class="string">&quot;pt&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰æ¨¡å‹ -- å…¶å®Transformerå¯ä»¥ç›´æ¥ç”¨AutoModelForSequenceClassification</span></span><br><span class="line"><span class="comment">#model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æˆ‘æ‰‹å·¥å†™äº†åˆ†ç±»å™¨å±‚ï¼Œä¸ºäº†æ–¹ä¾¿å¤§å®¶ç†è§£ä»€ä¹ˆå«åœ¨Transformerä¸Šé¢åšåˆ†ç±»ä»»åŠ¡</span></span><br><span class="line">backbone = AutoModel.from_pretrained(MODEL_NAME)</span><br><span class="line">model = MyClassifier(backbone)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰è®­ç»ƒå‚æ•°</span></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./output&quot;</span>,        <span class="comment"># checkpointä¿å­˜è·¯å¾„</span></span><br><span class="line">    evaluation_strategy=<span class="string">&quot;steps&quot;</span>,    <span class="comment"># æ¯Næ­¥åšä¸€æ¬¡eval</span></span><br><span class="line">    overwrite_output_dir=<span class="literal">True</span>,</span><br><span class="line">    num_train_epochs=<span class="number">1</span>,             <span class="comment"># è®­ç»ƒepochæ•°</span></span><br><span class="line">    per_device_train_batch_size=<span class="number">8</span>,  <span class="comment"># æ¯å¼ å¡çš„batchå¤§å°</span></span><br><span class="line">    gradient_accumulation_steps=<span class="number">4</span>,   <span class="comment"># ç´¯åŠ å‡ ä¸ªstepåšä¸€æ¬¡å‚æ•°æ›´æ–°</span></span><br><span class="line">    per_device_eval_batch_size=<span class="number">8</span>,  <span class="comment"># evaluation batch size</span></span><br><span class="line">    logging_steps=<span class="number">20</span>,             <span class="comment"># æ¯20æ­¥evalä¸€æ¬¡</span></span><br><span class="line">    save_steps=<span class="number">20</span>,                <span class="comment"># æ¯20æ­¥ä¿å­˜ä¸€ä¸ªcheckpoint</span></span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,             <span class="comment"># å­¦ä¹ ç‡</span></span><br><span class="line">    warmup_ratio=<span class="number">0.1</span>,               <span class="comment"># é¢„çƒ­ï¼ˆå¯é€‰ï¼‰</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰è®­ç»ƒå™¨</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model, <span class="comment"># å¾…è®­ç»ƒæ¨¡å‹</span></span><br><span class="line">    args=training_args, <span class="comment"># è®­ç»ƒå‚æ•°</span></span><br><span class="line">    data_collator=collater, <span class="comment"># æ•°æ®æ ¡å‡†å™¨</span></span><br><span class="line">    train_dataset=tokenized_train_dataset, <span class="comment"># è®­ç»ƒé›†</span></span><br><span class="line">    eval_dataset=tokenized_valid_dataset, <span class="comment"># éªŒè¯é›†</span></span><br><span class="line">    compute_metrics=compute_metrics, <span class="comment"># è¯„ä»·æŒ‡æ ‡</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¦ç”¨wandbï¼ˆä¸huggingface.coåŒæ­¥çš„æœºåˆ¶ï¼‰</span></span><br><span class="line">os.environ[<span class="string">&quot;WANDB_DISABLED&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å¼€å§‹è®­ç»ƒ</span></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p><a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/huggingface/index.ipynb">Bert fine-tuning äºŒåˆ†ç±»</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Fine-Tuning</category>
      </categories>
      <tags>
        <tag>Fine-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)PEFT æ¦‚è¿°</title>
    <url>/www6vHomeAIGC/2022/12/20/gptFineTuningPEFT/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="huggingface-peftä¸­çš„ä»»åŠ¡1">Huggingface  PEFTä¸­çš„ä»»åŠ¡[1]</span><a href="#huggingface-peftä¸­çš„ä»»åŠ¡1" class="header-anchor">#</a></h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class TaskType(str, enum.Enum):</span><br><span class="line">    SEQ_CLS = &quot;SEQ_CLS&quot;  # 3. åºåˆ—åˆ†ç±»ä»»åŠ¡</span><br><span class="line">    SEQ_2_SEQ_LM = &quot;SEQ_2_SEQ_LM&quot;  # 2. æ¡ä»¶ç”Ÿæˆä»»åŠ¡</span><br><span class="line">    CAUSAL_LM = &quot;CAUSAL_LM&quot;  #  1. å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡</span><br><span class="line">    TOKEN_CLS = &quot;TOKEN_CLS&quot;  #  4. Token åˆ†ç±»ä»»åŠ¡</span><br><span class="line">    QUESTION_ANS = &quot;QUESTION_ANS&quot;</span><br><span class="line">    FEATURE_EXTRACTION = &quot;FEATURE_EXTRACTION&quot;</span><br></pre></td></tr></table></figure>

<h3><span id="1-å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡causal-language-modeling">1. å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼ˆCausal Language Modelingï¼‰</span><a href="#1-å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡causal-language-modeling" class="header-anchor">#</a></h3><p>  å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼ˆCLMï¼‰ï¼Œåœ¨è¿™ç§å»ºæ¨¡æ–¹æ³•ä¸­ï¼Œæ¨¡å‹è¯•å›¾é¢„æµ‹ç»™å®šä¸Šä¸‹æ–‡ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ï¼Œè¯¥ä¸Šä¸‹æ–‡é€šå¸¸åŒ…æ‹¬åœ¨å½“å‰å•è¯ä¹‹å‰çš„æ‰€æœ‰å•è¯ã€‚</p>
<h3><span id="2-æ¡ä»¶ç”Ÿæˆä»»åŠ¡conditional-generation">2. æ¡ä»¶ç”Ÿæˆä»»åŠ¡ï¼ˆConditional Generationï¼‰</span><a href="#2-æ¡ä»¶ç”Ÿæˆä»»åŠ¡conditional-generation" class="header-anchor">#</a></h3><p>  æ¡ä»¶ç”Ÿæˆä»»åŠ¡ï¼ˆConditional Generationï¼‰ï¼Œæ ¹æ®ç»™å®šçš„è¾“å…¥ï¼ˆå¯èƒ½æ˜¯æ–‡æœ¬ã€å›¾ç‰‡ç­‰ï¼‰ç”Ÿæˆç¬¦åˆæ¡ä»¶çš„è¾“å‡ºã€‚<br>  æ¡ä»¶ç”Ÿæˆçš„åº”ç”¨åŒ…æ‹¬ä½†ä¸é™äºæœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ã€å›¾åƒæè¿°ç­‰ã€‚è¿™äº›ä»»åŠ¡é€šå¸¸éœ€è¦æ¨¡å‹åœ¨è¾“å…¥å’Œè¾“å‡ºä¹‹é—´å»ºç«‹å¤æ‚çš„æ˜ å°„å…³ç³»ã€‚</p>
<blockquote>
<p>å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡  vs.  æ¡ä»¶ç”Ÿæˆä»»åŠ¡<br>  å› æœè¯­è¨€å»ºæ¨¡ä¸»è¦å…³æ³¨äºç”Ÿæˆè¿è´¯ã€è‡ªç„¶çš„æ–‡æœ¬ï¼Œè€Œæ¡ä»¶ç”Ÿæˆå…³æ³¨äºç”Ÿæˆæ»¡è¶³ç‰¹å®šæ¡ä»¶æˆ–ä»»åŠ¡è¦æ±‚çš„æ–‡æœ¬ã€‚è¿™ä¸¤ç§å»ºæ¨¡æ–¹æ³•åœ¨æŸäº›åœºæ™¯ä¸‹å¯èƒ½ä¼šäº’ç›¸ä½¿ç”¨å’Œç»“åˆï¼Œä»¥å®ç°æ›´å¤æ‚çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚</p>
</blockquote>
<h3><span id="3-åºåˆ—åˆ†ç±»ä»»åŠ¡sequence-classification">3. åºåˆ—åˆ†ç±»ä»»åŠ¡ï¼ˆSequence Classificationï¼‰</span><a href="#3-åºåˆ—åˆ†ç±»ä»»åŠ¡sequence-classification" class="header-anchor">#</a></h3><p>  åºåˆ—åˆ†ç±»ï¼ˆSequence Classificationï¼‰ï¼Œå¯¹æ•´ä¸ªå¥å­è¿›è¡Œåˆ†ç±»ã€‚å¦‚: è·å–è¯„è®ºçš„æƒ…ç»ªï¼Œæ£€æµ‹ç”µå­é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ï¼Œç¡®å®šå¥å­åœ¨è¯­æ³•ä¸Šæ˜¯å¦æ­£ç¡®æˆ–ä¸¤ä¸ªå¥å­åœ¨é€»è¾‘ä¸Šæ˜¯å¦ç›¸å…³ç­‰</p>
<h3><span id="4-token-åˆ†ç±»ä»»åŠ¡token-classification">4. Token åˆ†ç±»ä»»åŠ¡ï¼ˆToken Classificationï¼‰</span><a href="#4-token-åˆ†ç±»ä»»åŠ¡token-classification" class="header-anchor">#</a></h3><p>  Token åˆ†ç±»ä»»åŠ¡ï¼ˆToken Classificationï¼‰ï¼Œå¯¹å¥å­ä¸­çš„æ¯ä¸ªè¯è¿›è¡Œåˆ†ç±»ã€‚å¦‚: è¯†åˆ«å¥å­çš„è¯­æ³•æˆåˆ†ï¼ˆåè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ï¼‰æˆ–å‘½åå®ä½“ï¼ˆäººã€åœ°ç‚¹ã€ç»„ç»‡ï¼‰ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/651744834">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆä¸€ï¼‰-PEFTæ¦‚è¿°</a></li>
<li><a href="https://github.com/www6v/llm-action#llm%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98">LLMå¾®è°ƒå®æˆ˜</a> æå›½ä¸œ</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Fine-Tuning æ—¶æœº</title>
    <url>/www6vHomeAIGC/2022/12/28/gptFineTuningWhen/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E4%BD%95%E6%97%B6%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%831">ä½•æ—¶è¿›è¡Œå¾®è°ƒ[1]</a></li>
<li><a href="#what-4">what [4]</a></li>
<li><a href="#common-use-cases2">Common use cases[2]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="ä½•æ—¶è¿›è¡Œå¾®è°ƒ1">ä½•æ—¶è¿›è¡Œå¾®è°ƒ[1]</span><a href="#ä½•æ—¶è¿›è¡Œå¾®è°ƒ1" class="header-anchor">#</a></h1><p>è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥é€šè¿‡è‡³å°‘ä¸¤ç§æ–¹å¼å­¦ä¹ æ–°çŸ¥è¯†ï¼šæƒé‡æ›´æ–°ï¼ˆä¾‹å¦‚é¢„è®­ç»ƒæˆ–å¾®è°ƒï¼‰æˆ–æç¤ºï¼ˆä¾‹å¦‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ŒRAGï¼‰ã€‚æ¨¡å‹çš„æƒé‡å°±åƒé•¿æœŸè®°å¿†ï¼Œè€Œæç¤ºå°±åƒçŸ­æœŸè®°å¿†ã€‚è¿™ä¸ªOpenAI Cookbookç»™å‡ºäº†ä¸€ä¸ªæœ‰ç”¨çš„æ¯”å–»ï¼šå½“ä½ å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒæ—¶ï¼Œå°±åƒæ˜¯åœ¨ç¦»è€ƒè¯•è¿˜æœ‰ä¸€å‘¨çš„æ—¶å€™å‡†å¤‡å¤ä¹ ã€‚å½“ä½ é€šè¿‡æç¤ºï¼ˆä¾‹å¦‚æ£€ç´¢ï¼‰å‘æç¤ºä¸­æ’å…¥çŸ¥è¯†æ—¶ï¼Œå°±åƒæ˜¯åœ¨æœ‰å¼€æ”¾ç¬”è®°çš„è€ƒè¯•ä¸­ã€‚</p>
<p>åŸºäºè¿™ä¸€ç‚¹ï¼Œ<strong>ä¸å»ºè®®ä½¿ç”¨å¾®è°ƒæ¥æ•™æˆLLMæ–°çš„çŸ¥è¯†æˆ–äº‹å®å›å¿†</strong>ï¼›OpenAIçš„John Schulmanåœ¨ä¸€æ¬¡è®²è¯ä¸­æŒ‡å‡ºï¼Œå¾®è°ƒå¯èƒ½ä¼š<strong>å¢åŠ è™šæ„</strong>ã€‚å¾®è°ƒ<strong>æ›´é€‚åˆæ•™æˆä¸“é—¨çš„ä»»åŠ¡</strong>ï¼Œä½†åº”ä¸æç¤ºæˆ–RAGç›¸å¯¹æ¯”ã€‚æ­£å¦‚è¿™é‡Œæ‰€è®¨è®ºçš„ï¼Œå¯¹äºå…·æœ‰ä¸°å¯Œç¤ºä¾‹å’Œ&#x2F;æˆ–ç¼ºä¹ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›çš„LLMæ¥è¯´ï¼Œå¾®è°ƒå¯¹äºå®šä¹‰æ˜ç¡®çš„ä»»åŠ¡å¯èƒ½æ˜¯æœ‰å¸®åŠ©çš„ã€‚è¿™ç¯‡Anyscaleåšå®¢å¾ˆå¥½åœ°æ€»ç»“äº†è¿™äº›è§‚ç‚¹ï¼š<strong>å¾®è°ƒæ˜¯ä¸ºå½¢å¼è€Œéäº‹å®</strong>[3]ã€‚</p>
<h1><span id="what-4">what [4]</span><a href="#what-4" class="header-anchor">#</a></h1><p>è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚æˆ‘å¤§è‡´å°†å¾®è°ƒç±»æ¯”ä¸ºäººçš„ä¸“ä¸šçŸ¥è¯†ï¼š</p>
<ul>
<li><strong>ç”¨æ–‡å­—æè¿°ä¸€ä¸ªä»»åŠ¡ ~&#x3D; é›¶æ ·æœ¬æç¤º</strong></li>
<li><strong>ç»™å‡ºè§£å†³ä»»åŠ¡çš„ç¤ºä¾‹ ~&#x3D; å°‘æ ·æœ¬æç¤º</strong></li>
<li><strong>å…è®¸äººä»¬ç»ƒä¹ ä»»åŠ¡ ~&#x3D; å¾®è°ƒ</strong></li>
</ul>
<p>è€ƒè™‘åˆ°è¿™ä¸ªæ¯”å–»ï¼Œä»¤äººæƒŠå¥‡çš„æ˜¯æˆ‘ä»¬æœ‰äº†å¯ä»¥ä»…é€šè¿‡æç¤ºå°±èƒ½åœ¨è®¸å¤šä»»åŠ¡ä¸Šè¾¾åˆ°é«˜æ°´å¹³å‡†ç¡®æ€§çš„æ¨¡å‹ï¼Œä½†æˆ‘ä¹Ÿé¢„è®¡è¾¾åˆ°é¡¶çº§æ€§èƒ½å¯èƒ½éœ€è¦å¾®è°ƒï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æ˜ç¡®å®šä¹‰çš„å…·ä½“ä»»åŠ¡çš„åº”ç”¨ä¸­ï¼Œåœ¨è¿™äº›ä»»åŠ¡ä¸­æˆ‘ä»¬å¯ä»¥æ”¶é›†å¤§é‡æ•°æ®å¹¶åœ¨å…¶ä¸Šè¿›è¡Œâ€œç»ƒä¹ â€ã€‚</p>
<p>è¿™å¯èƒ½æ˜¯ä¸€ä¸ªéœ€è¦ç‰¢è®°çš„<strong>ç²—ç•¥å›¾æ™¯</strong>ã€‚<strong>å°å‹æ¨¡å‹</strong>æ— æ³•è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œå¹¶ä¸”ä»æç¤ºå·¥ç¨‹ä¸­å—ç›Šç”šå°‘ï¼Œä½†æ ¹æ®ä»»åŠ¡çš„éš¾åº¦ï¼Œ<strong>ä»ç„¶æœ‰å¯èƒ½å°†å®ƒä»¬å¾®è°ƒä¸ºè¡¨ç°è‰¯å¥½çš„ä¸“å®¶</strong>ã€‚</p>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ‰€æœ‰è¿™äº›éƒ½è¿˜æ˜¯éå¸¸æ–°é¢–çš„ã€‚</p>


<h1><span id="common-use-cases2">Common use cases[2]</span><a href="#common-use-cases2" class="header-anchor">#</a></h1><p>å¾®è°ƒå¯ä»¥æ”¹å–„ç»“æœçš„ä¸€äº›å¸¸è§<strong>ç”¨ä¾‹</strong>åŒ…æ‹¬ï¼š</p>
<ul>
<li><strong>è®¾å®šé£æ ¼ã€è¯­æ°”ã€æ ¼å¼æˆ–å…¶ä»–å®šæ€§å› ç´ </strong></li>
<li><strong>æé«˜ç”Ÿæˆæ‰€éœ€è¾“å‡ºçš„å¯é æ€§</strong></li>
<li><strong>çº æ­£æ— æ³•æŒ‰ç…§å¤æ‚æç¤ºè¦æ±‚æ‰§è¡Œçš„é—®é¢˜</strong></li>
<li>ä»¥ç‰¹å®šæ–¹å¼å¤„ç†è®¸å¤šè¾¹ç¼˜æƒ…å†µ</li>
<li><strong>æ‰§è¡Œéš¾ä»¥ç”¨æç¤ºæ¸…æ™°è¡¨è¾¾çš„æ–°æŠ€èƒ½æˆ–ä»»åŠ¡</strong></li>
</ul>
<p>ä»è¾ƒé«˜å±‚é¢æ¥çœ‹ï¼Œè¿™äº›æƒ…å†µä¸‹å¾®è°ƒæ›´å®¹æ˜“å®ç°â€œ<strong>å±•ç¤ºè€Œéå‘Šè¯‰</strong>â€çš„æ•ˆæœã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•ä¸ºå¾®è°ƒè®¾ç½®æ•°æ®ä»¥åŠå„ç§ç¤ºä¾‹ï¼Œè¿™äº›ç¤ºä¾‹ä¸­å¾®è°ƒæ”¹å–„äº†åŸºçº¿æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://blog.langchain.dev/using-langsmith-to-support-fine-tuning-of-open-source-llms/">Using LangSmith to Support Fine-tuning</a><br>  <a href="https://colab.research.google.com/drive/1tpywvzwOS74YndNXhI8NUaEfPeqOc7ub?usp=sharing&ref=blog.langchain.dev">colab</a>   LANGCHAIN_API_KEY</p>
</li>
<li><p><a href="https://platform.openai.com/docs/guides/fine-tuning">Fine-tuning</a>  openai *** </p>
</li>
<li><p><a href="https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts">Fine tuning is for form, not facts</a> ***</p>
</li>
<li><p><a href="https://twitter.com/karpathy/status/1655994367033884672">Andrej Karpathy twitter</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Fine-Tuning</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†|å®æˆ˜) OpenAI Function Call</title>
    <url>/www6vHomeAIGC/2022/11/16/gptFunctionCall/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#function-call">Function Call</a><ul>
<li><a href="#%E8%B0%83%E7%94%A8%E9%A1%BA%E5%BA%8F-0-12">è°ƒç”¨é¡ºåº [0] [1][2]</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81-2">ä»£ç  [2]</a></li>
<li><a href="#goal">goal</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="function-call">Function Call</span><a href="#function-call" class="header-anchor">#</a></h1><h3><span id="è°ƒç”¨é¡ºåº-0-12">è°ƒç”¨é¡ºåº  [0] [1][2]</span><a href="#è°ƒç”¨é¡ºåº-0-12" class="header-anchor">#</a></h3><ul>
<li>Function Calling æ•´ä¸ªåŠŸèƒ½çš„è°ƒç”¨é¡ºåºå¤§è‡´å¦‚ä¸‹<ul>
<li>å£°æ˜å‡½æ•°ï¼šå®šä¹‰å½“å‰å‡½æ•°çš„åç§°ï¼Œæè¿°ï¼Œä»¥åŠå¯¹åº”çš„å‚æ•°ä¿¡æ¯ï¼Œå¹¶è¯·æ±‚å¯¹åº”çš„æ¥å£ï¼›</li>
<li>è§£æå‡½æ•°å‚æ•°ï¼šæ¥å—å¯¹åº”çš„æ¥å£è¿”å›ï¼Œå¹¶è§£æå¯¹åº”çš„å‡½æ•°å‚æ•°ä¿¡æ¯ï¼›</li>
<li>æ‰§è¡Œå‡½æ•°ï¼šæ ¹æ®å¯¹åº”çš„å‚æ•°ä¿¡æ¯è°ƒç”¨æœ¬åœ°å‡½æ•°ï¼›</li>
<li>ä¸ŠæŠ¥ç»“æœï¼šå°†æœ¬åœ°å‡½æ•°æ‰§è¡Œçš„ç»“æœä¸ŠæŠ¥ç»™ Chat æ¥å£ï¼›</li>
</ul>
</li>
</ul>
<img src="/www6vHomeAIGC/2022/11/16/gptFunctionCall/functioncall1.png" class>

<h3><span id="ä»£ç -2">ä»£ç  [2]</span><a href="#ä»£ç -2" class="header-anchor">#</a></h3><h3><span id="goal">goal</span><a href="#goal" class="header-anchor">#</a></h3><p> The goal of the OpenAI Function APIs is to more reliably return valid and useful function calls than a generic text completion or chat API.</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="0">
<li><p><a href="http://lihuaxi.xjx100.cn/news/1382737.html">å¤§æ¨¡å‹å¼€å‘(åä¸€)ï¼šChat Completionsæ¨¡å‹çš„Function callingåŠŸèƒ½è¯¦è§£</a> </p>
</li>
<li><p><a href="https://www.duidaima.com/Group/Topic/OtherTools/13709">å¦‚ä½•ä½¿ç”¨Chat Completionsæ¥å£çš„å‡½æ•°è°ƒç”¨åŠŸèƒ½</a></p>
</li>
<li><p><a href="https://blog.csdn.net/Lvbaby_/article/details/131892482">OpenAIå¼€å‘ç³»åˆ—ï¼ˆåä¸€ï¼‰ï¼šFunction callingåŠŸèƒ½çš„å®é™…åº”ç”¨æµç¨‹ä¸æ¡ˆä¾‹è§£æ</a>   ä»£ç   æµç¨‹å›¾<br><a href="https://github.com/www6v/AIGC/tree/master/basic/Function-calling">ä»£ç </a>  git</p>
</li>
<li><p><a href="https://blog.csdn.net/Lvbaby_/article/details/131933871">OpenAIå¼€å‘ç³»åˆ—ï¼ˆåä¸‰ï¼‰ï¼šåˆ©ç”¨Function callingåŠŸèƒ½å¼€å‘åŸºäºå¤§æ¨¡å‹çš„å®æ—¶å¤©æ°”æŸ¥è¯¢åŠ©æ‰‹</a> æœª</p>
</li>
<li><p><a href="https://blog.csdn.net/Lvbaby_/article/details/131912170">OpenAIå¼€å‘ç³»åˆ—ï¼ˆåäºŒï¼‰ï¼šFunction callingåŠŸèƒ½çš„æµç¨‹ä¼˜åŒ–ä¸å¤šè½®å¯¹è¯å®ç°</a> æœª</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Function Call</category>
      </categories>
      <tags>
        <tag>Function Call</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)å¹»è§‰é—®é¢˜</title>
    <url>/www6vHomeAIGC/2023/02/06/gptHallucination/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="å¹»è§‰-vs-äº‹å®æ€§1">å¹»è§‰ vs äº‹å®æ€§[1]</span><a href="#å¹»è§‰-vs-äº‹å®æ€§1" class="header-anchor">#</a></h1><p><strong>å¹»è§‰</strong>ä¸»è¦æ˜¯æŒ‡LLMç”Ÿæˆæ¯«æ— æ ¹æ®æˆ–æ¯«æ— æ ¹æ®çš„å†…å®¹ï¼Œå¹»è§‰å¯ä»¥ç†è§£ä¸ºæ¨¡å‹å€¾å‘äºâ€ç”Ÿæˆä¸æŸäº›æ¥æºç›¸å…³çš„æ— æ„ä¹‰æˆ–ä¸çœŸå®çš„å†…å®¹â€ã€‚è¿™ä¸<strong>äº‹å®æ€§é—®é¢˜</strong>ä¸åŒï¼Œåè€…å¼ºè°ƒæ¨¡å‹å­¦ä¹ ã€è·å–å’Œåˆ©ç”¨äº‹å®æ€§çŸ¥è¯†çš„èƒ½åŠ›ã€‚</p>
<p>ä¸¾ä¾‹è¯´æ˜ä¸¤è€…çš„<strong>åŒºåˆ«</strong>ï¼š</p>
<p>å¦‚æœä¸€ä¸ªLLMåœ¨è¢«è¦æ±‚åˆ›ä½œâ€ä¸€ä¸ªå…³äºå…”å­å’Œç‹¼äº¤æœ‹å‹çš„ç«¥è¯æ•…äº‹â€æ—¶ï¼Œåˆ›ä½œå‡ºäº†ä¸€ä¸ªå…³äºâ€å…”å­å’Œç‹—äº¤æœ‹å‹â€çš„æ•…äº‹ï¼Œé‚£ä¹ˆå®ƒå°±è¡¨ç°å‡ºäº†å¹»è§‰ã€‚ä¸è¿‡ï¼Œè¿™å¹¶ä¸ä¸€å®šæ˜¯äº‹å®æ€§é”™è¯¯ã€‚<br>å¦‚æœç”Ÿæˆçš„å†…å®¹åŒ…å«å‡†ç¡®çš„ä¿¡æ¯ï¼Œä½†ä¸æç¤ºçš„å…·ä½“å†…å®¹æœ‰å‡ºå…¥ï¼Œé‚£å°±æ˜¯<strong>å¹»è§‰</strong>ï¼Œè€Œ<strong>ä¸æ˜¯äº‹å®æ€§é—®é¢˜</strong>ã€‚<br>ä¾‹å¦‚ï¼Œå¦‚æœLLMçš„è¾“å‡ºåŒ…å«äº†æ¯”æç¤ºæŒ‡å®šæ›´å¤šçš„ç»†èŠ‚æˆ–ä¸åŒçš„å…ƒç´ ï¼Œä½†äº‹å®ä»ç„¶æ­£ç¡®ï¼Œè¿™å°±æ˜¯<strong>å¹»è§‰</strong>ã€‚</p>
<p>ç›¸åï¼Œå¦‚æœLLMé¿å…ç»™å‡ºç›´æ¥ç­”æ¡ˆï¼Œè€Œæ˜¯è¯´â€æˆ‘ä¸çŸ¥é“â€ï¼Œæˆ–è€…ç»™å‡ºäº†ä¸€ä¸ªå‡†ç¡®çš„ç­”æ¡ˆï¼Œä½†é—æ¼äº†ä¸€äº›æ­£ç¡®çš„ç»†èŠ‚ï¼Œé‚£ä¹ˆè¿™å°±æ˜¯<strong>äº‹å®æ€§é—®é¢˜</strong>ï¼Œè€Œ<strong>ä¸æ˜¯å¹»è§‰</strong>ã€‚</p>
<p>æ­¤å¤–ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ<strong>å¹»è§‰æœ‰æ—¶ä¼šäº§ç”Ÿä¸€äº›å†…å®¹ï¼Œè™½ç„¶ä¸åŸå§‹è¾“å…¥å†…å®¹æœ‰åå·®ï¼Œä½†åœ¨äº‹å®æ–¹é¢ä»ç„¶æ˜¯å‡†ç¡®çš„</strong>ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404394&idx=1&sn=d7cfcf2cd9aa6756d3cbff938f5f4cf2">å†çœ‹å¤§æ¨¡å‹äº‹å®æ€§çš„ç•Œå®šã€é”™è¯¯çš„èµ·å› ã€è¯„ä¼°åŠå‰æ²¿ç¼“è§£æ–¹æ¡ˆï¼šSurvey on Factuality in LLMS</a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403998&idx=1&sn=400cc902434bc04df508a55e192d2455">å†çœ‹å¤§æ¨¡å‹å¹»è§‰é—®é¢˜å¦‚ä½•ç¼“è§£ ï¼šChain-of-Verification-ä¸€ç§åŸºäºé“¾å¼éªŒè¯æ€æƒ³çš„è‡ªæˆ‘ä¿®æ­£å·¥ä½œè§£è¯» </a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648405983&idx=2&sn=95dc9c7a12bed99b63c775d4b90519d8">ä¹Ÿçœ‹ç¼“è§£å¤§æ¨¡å‹å¹»è§‰çš„å¤šé˜¶æ®µRAGæ¡†æ¶ï¼šåŠ å…¥æ··åˆæ£€ç´¢ã€è¿‡ç¨‹ç†ç”±ç”Ÿæˆä¸éªŒè¯çš„æ–¹æ¡ˆ </a></p>
<p>1xx. <a href="https://arxiv.org/abs/2309.01219">å¤§æ¨¡å‹å¹»è§‰ç»¼è¿°</a><br>   <a href="https://arxiv.org/abs/2309.05922">å¤§æ¨¡å‹å¹»è§‰ç»¼è¿°</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648405791&idx=2&sn=d7dada69e6d5ab5fba1333d234b947ef">ç½‘ç»œå®‰å…¨é¢†åŸŸå¾®è°ƒæ¨¡å‹SecGPTï¼šå…¼çœ‹å¤§æ¨¡å‹å¹»è§‰çš„åº¦é‡æ–¹å¼ã€è¯„ä¼°benchmarkåŠRAGå¢å¼ºä¸åŒæ–¹å¼ </a> å¤§æ¨¡å‹å¹»è§‰ç»¼è¿°</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403602&idx=1&sn=f2365b05630094f8d0de7ff784abe233">å¤§æ¨¡å‹å‰æ²¿çƒ­ç‚¹æœ€æ–°ç»¼è¿°ï¼šå¤§æ¨¡å‹å¾®è°ƒé—å¿˜ã€Agentæ™ºèƒ½ä½“ã€å¹»è§‰åŠRAGæ£€ç´¢å¢å¼ºæ¨¡å‹æ¨ä»‹</a> å¤§æ¨¡å‹å¾®è°ƒé—å¿˜</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403341&idx=1&sn=86cdaaf2c3a73439d2591a2f3dd0b9e0">å€¼å¾—ä¸€è¯»çš„å¤§æ¨¡å‹ç”Ÿæˆå¹»è§‰ç ”ç©¶ç»¼è¿°ï¼šå¤§æ¨¡å‹å¹»è§‰çš„èµ·å› ã€è¯„ä¼°ä»¥åŠå‡è½»ç­–ç•¥æ€»ç»“ </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/642648601">å¤§æ¨¡å‹çš„å¹»è§‰é—®é¢˜è°ƒç ”: LLM Hallucination Survey</a><br>   <a href="https://mp.weixin.qq.com/s?__biz=MzU5NDg2MjgxMg==&mid=2247485189&idx=1&sn=95d6eb333dde007f262a2955b90bc7ec">äººå·¥æ™ºèƒ½æµ·æ´‹ä¸­çš„å¡å£¬ä¹‹æ­Œï¼šå¤§å‹è¯­è¨€æ¨¡å‹LLMä¸­çš„å¹»è§‰ç ”ç©¶ç»¼è¿°ï¼ˆä¸€ï¼‰ </a><br>   <a href="https://mp.weixin.qq.com/s/eGMwNz0F1dQsNDnsLNYr8Q">å¤§å‹è¯­è¨€æ¨¡å‹çš„å¹»è§‰ç ”ç©¶ï½œå‡è½»åŠé¿å…å¤§æ¨¡å‹LLMå¹»è§‰ï¼ˆäºŒï¼‰</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s/N7NOsLHr8HYCMp5XGCBDjg">LLMä¹‹å¹»è§‰ï¼ˆä¸€ï¼‰ï¼šå¤§è¯­è¨€æ¨¡å‹å¹»è§‰è§£å†³æ–¹æ¡ˆç»¼è¿°</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Hallucination</category>
      </categories>
      <tags>
        <tag>Hallucination</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)ä¸å¯èƒ½ä¸‰è§’</title>
    <url>/www6vHomeAIGC/2023/01/25/gptImpossibleTriangle/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%921">ä¸å¯èƒ½ä¸‰è§’[1]</a><ul>
<li><a href="#%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%92">ä¸å¯èƒ½ä¸‰è§’</a></li>
<li><a href="#%E5%BC%A5%E8%A1%A5%E6%96%B9%E6%B3%95">å¼¥è¡¥æ–¹æ³•</a></li>
</ul>
</li>
<li><a href="#%E5%85%B6%E4%BB%96-%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%92">å…¶ä»– ä¸å¯èƒ½ä¸‰è§’</a><ul>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F">åˆ†å¸ƒå¼ç³»ç»Ÿ</a></li>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8">åˆ†å¸ƒå¼å­˜å‚¨</a></li>
</ul>
</li>
<li><a href="#%E8%8C%83%E5%BC%8F">èŒƒå¼</a><ul>
<li><a href="#pretrain-finetune-%E8%8C%83%E5%BC%8F3">pretrain, finetune èŒƒå¼[3]</a></li>
<li><a href="#pretrain-prompt-predict-%E8%8C%83%E5%BC%8F3">pretrain, prompt, predict èŒƒå¼[3]</a></li>
</ul>
</li>
<li><a href="#%E6%80%BB%E7%BB%93">æ€»ç»“</a></li>
<li><a href="#scaling-law10">Scaling Law[10]</a><ul>
<li><a href="#scaling-law">Scaling Law</a></li>
<li><a href="#%E5%8F%82%E6%95%B0%E9%87%8F-vs-%E6%95%B0%E6%8D%AE%E9%87%8F">å‚æ•°é‡ vs æ•°æ®é‡</a></li>
<li><a href="#%E5%8F%82%E6%95%B0%E9%87%8F-vs-%E6%95%B0%E6%8D%AE%E9%87%8F-1">å‚æ•°é‡ vs æ•°æ®é‡</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%92-1">ä¸å¯èƒ½ä¸‰è§’</a></li>
<li><a href="#scaling-law-1">Scaling Law</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="ä¸å¯èƒ½ä¸‰è§’1">ä¸å¯èƒ½ä¸‰è§’[1]</span><a href="#ä¸å¯èƒ½ä¸‰è§’1" class="header-anchor">#</a></h1><h3><span id="ä¸å¯èƒ½ä¸‰è§’">ä¸å¯èƒ½ä¸‰è§’</span><a href="#ä¸å¯èƒ½ä¸‰è§’" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/01/25/gptImpossibleTriangle/impossibleTriangle.JPG" class>

<ul>
<li>é¢„è®­ç»ƒæ¨¡å‹ä¹‹æ‰€ä»¥æ˜¯åˆ’æ—¶ä»£çš„è¿›å±•ï¼Œæ˜¯å®ƒå…·å¤‡äº†ä¸­ç­‰å°ºå¯¸ï¼ˆä¸€å¼ å¡å³å¯ç²¾è°ƒï¼‰å’Œå…¨ä»»åŠ¡SOTAçš„ç²¾è°ƒæ•ˆæœ</li>
<li>è€Œæœ€è¿‘ä¸¤å¹´é¢„è®­ç»ƒæ¨¡å‹éƒ½åœ¨å¾€å¤§å°ºå¯¸å‘å±•ï¼Œä¹Ÿå°±æ˜¯å…·å¤‡äº†å°‘æ ·æœ¬æ•ˆæœï¼Œä½†ä»–ä»¬çš„<strong>å°‘æ ·æœ¬æ•ˆæœä¾æ—§æ¯”ä¸è¿‡ä¸­ç­‰æ¨¡å‹çš„ç²¾è°ƒ</strong></li>
</ul>
<h3><span id="å¼¥è¡¥æ–¹æ³•">å¼¥è¡¥æ–¹æ³•</span><a href="#å¼¥è¡¥æ–¹æ³•" class="header-anchor">#</a></h3><ul>
<li><strong>ä¼˜åŒ–size</strong><ul>
<li>å¯¹äºå‡å°‘æ¨¡å‹å°ºå¯¸ï¼Œä¸€æ¡å…¸å‹çš„æ•…äº‹çº¿å°±æ˜¯è’¸é¦ã€‚ä½†å…¶ä¸­ä»å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼šä¸€æ˜¯å­¦ç”Ÿæ¨¡å‹å¾ˆéš¾è¾¾åˆ°åŸå§‹æ¨¡å‹çš„æ•ˆæœï¼ŒäºŒæ˜¯åŸå§‹çš„å¤§å°ºå¯¸æ¨¡å‹çš„æ¨ç†æ•ˆç‡å¤ªä½</li>
</ul>
</li>
<li><strong>ä¼˜åŒ–few-shot</strong><ul>
<li>å¯¹äºæå‡å°‘æ ·æœ¬è¡¨ç°ï¼Œ<strong>æ•°æ®å¢å¼º</strong>æ˜¯ä¸€ä¸ªå¥½åŠæ³•ï¼Œæ¯”å¦‚ç”¨æ— ç›‘ç£æ•°æ®åšè‡ªç›‘ç£è®­ç»ƒã€æˆ–è€…åŸºäºå…¶ä»–æ¨¡å‹ç”Ÿæˆä¸€äº›ä¼ªæ ·æœ¬ï¼Œä½†è¿™ç±»æ–¹æ³•ä¾æ—§å—é™äºç°æœ‰æ ‡æ³¨æ ·æœ¬çš„å¤šæ ·æ€§ï¼Œæ³›åŒ–æ€§èƒ½æå‡æœ‰é™</li>
</ul>
</li>
<li><strong>fine-tuning</strong><ul>
<li>å¯¹äºæå‡ç²¾è°ƒè¡¨ç°å’Œæ•ˆç‡ï¼ˆå…¶å®ä¹Ÿåå°‘æ ·æœ¬ï¼‰ï¼Œæœ€è¿‘ä¸€ä¸ªæ¯”è¾ƒç«çš„æ•…äº‹æ˜¯promptï¼Œä½†è¿™ç§æ–¹å¼å¯¹promptçš„è®¾è®¡éå¸¸æ•æ„Ÿï¼ŒåŒæ—¶æ•ˆæœä¹Ÿå¾ˆéš¾è¶…è¿‡ç›®å‰çš„æœ‰ç›‘ç£SOTA</li>
</ul>
</li>
</ul>
<h1><span id="å…¶ä»–-ä¸å¯èƒ½ä¸‰è§’">å…¶ä»– ä¸å¯èƒ½ä¸‰è§’</span><a href="#å…¶ä»–-ä¸å¯èƒ½ä¸‰è§’" class="header-anchor">#</a></h1><h3><span id="åˆ†å¸ƒå¼ç³»ç»Ÿ">åˆ†å¸ƒå¼ç³»ç»Ÿ</span><a href="#åˆ†å¸ƒå¼ç³»ç»Ÿ" class="header-anchor">#</a></h3><ul>
<li>CAPç†è®º<ul>
<li>C ä¸€è‡´æ€§</li>
<li>A å¯ç”¨æ€§</li>
<li>P åˆ†åŒº</li>
</ul>
</li>
</ul>
<h3><span id="åˆ†å¸ƒå¼å­˜å‚¨">åˆ†å¸ƒå¼å­˜å‚¨</span><a href="#åˆ†å¸ƒå¼å­˜å‚¨" class="header-anchor">#</a></h3><ul>
<li>RUMçŒœæƒ³<ul>
<li>Read-overhead </li>
<li>Update-overhead </li>
<li>Memory-overhead</li>
</ul>
</li>
</ul>
<h1><span id="èŒƒå¼">èŒƒå¼</span><a href="#èŒƒå¼" class="header-anchor">#</a></h1><h3><span id="pretrain-finetune-èŒƒå¼3">pretrain, finetune èŒƒå¼[3]</span><a href="#pretrain-finetune-èŒƒå¼3" class="header-anchor">#</a></h3><p>ç¬¬ä¸‰é˜¶æ®µèŒƒå¼</p>
<h3><span id="pretrain-prompt-predict-èŒƒå¼3">pretrain, prompt, predict èŒƒå¼[3]</span><a href="#pretrain-prompt-predict-èŒƒå¼3" class="header-anchor">#</a></h3><p>ç¬¬å››é˜¶æ®µèŒƒå¼</p>
<h1><span id="æ€»ç»“">æ€»ç»“</span><a href="#æ€»ç»“" class="header-anchor">#</a></h1><p>æ ¹æ®ä¸å¯èƒ½ä¸‰è§’å½¢ï¼Œ pretrain, finetune èŒƒå¼[3] å‘pretrain, prompt, predict èŒƒå¼[3]çš„è¿ç§»æ˜¯å—å¤§æ¨¡å‹å¤§å°çš„å½±å“</p>
<h1><span id="scaling-law10">Scaling Law[10]</span><a href="#scaling-law10" class="header-anchor">#</a></h1><h3><span id="scaling-law">Scaling Law</span><a href="#scaling-law" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/01/25/gptImpossibleTriangle/scalingLaw.jpg" class>

<h3><span id="å‚æ•°é‡-vs-æ•°æ®é‡">å‚æ•°é‡ vs æ•°æ®é‡</span><a href="#å‚æ•°é‡-vs-æ•°æ®é‡" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/01/25/gptImpossibleTriangle/paramVSdataSize.jpg" class>

<h3><span id="å‚æ•°é‡-vs-æ•°æ®é‡">å‚æ•°é‡ vs æ•°æ®é‡</span><a href="#å‚æ•°é‡-vs-æ•°æ®é‡" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/01/25/gptImpossibleTriangle/computeVSDatasize.jpg" class>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="ä¸å¯èƒ½ä¸‰è§’">ä¸å¯èƒ½ä¸‰è§’</span><a href="#ä¸å¯èƒ½ä¸‰è§’" class="header-anchor">#</a></h3><ol>
<li><a href="https://zhuanlan.zhihu.com/p/501381510">é¢„è®­ç»ƒæ¨¡å‹çš„ä¸‹ä¸€æ­¥ï¼Ÿçªç ´Impossible Triangle</a></li>
<li><a href="https://arxiv.org/pdf/2204.06130.pdf">Impossible Triangle: Whatâ€™s Next for Pre-trained Language Models?</a></li>
<li><a href="https://blog.csdn.net/zandaoguang/article/details/124395479">å¾®è½¯æœ±æ™¨å…‰ï¼šé¢„è®­ç»ƒæ¨¡å‹ä¸‹ä¸€æ­¥æ€ä¹ˆèµ°ï¼Ÿçªç ´PLMçš„ã€Œä¸å¯èƒ½ä¸‰è§’ã€</a></li>
<li><a href="/www6vHomeAIGC/2023/01/06/gptPromptTuning/" title="(åŸç†)Prompt Tuning">(åŸç†)Prompt Tuning</a> self</li>
</ol>
<h3><span id="scaling-law">Scaling Law</span><a href="#scaling-law" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://zhuanlan.zhihu.com/p/667489780">è§£æå¤§æ¨¡å‹ä¸­çš„Scaling Law</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/663296750">è®ºæ–‡é˜…è¯»ï¼Œå¤§æ¨¡å‹çš„ç¼©æ”¾å®šå¾‹ï¼ŒScaling Laws for Neural Language Models</a><br>2xx. <a href="https://finisky.github.io/training-compute-optimal-large-language-models-summary/">Training Compute-Optimal Large Language Models ç®€è¯» </a></li>
</ol>
<p>2xx. <a href="https://zhuanlan.zhihu.com/p/536053110">ã€é¢„è®­ç»ƒæ¨¡å‹ã€‘æ¨ç¿»OpenAIç»“è®º, DeepMindé‡æ–°å®šä¹‰é¢„è®­ç»ƒçš„è®­ç»ƒå‚æ•°å’Œè®­ç»ƒè§„æ¨¡çš„å…³ç³»ï¼</a><br>ã€ŠScaling Laws for Neural Language Modelsã€‹<br>ã€ŠTraining Compute-Optimal Large Language Modelsã€‹</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>AIGC</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)æ¨ç†-æ¡†æ¶</title>
    <url>/www6vHomeAIGC/2023/03/21/gptInferFramework/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%8E%A8%E7%90%86-%E6%A1%86%E6%9E%B611">æ¨ç† æ¡†æ¶[1.1]</a></li>
<li><a href="#vllm">vLLM</a><ul>
<li><a href="#key-features-5">key features [5]</a></li>
</ul>
</li>
<li><a href="#tensorrt-llm">TensorRT-LLM</a><ul>
<li><a href="#key-features-4">key features [4]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="æ¨ç†-æ¡†æ¶11">æ¨ç† æ¡†æ¶[1.1]</span><a href="#æ¨ç†-æ¡†æ¶11" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/03/21/gptInferFramework/inference.jpg" class>

<ul>
<li><p>server äº‘ç«¯<br>vLLMï¼ŒTensorRTï¼Œ deepspeed</p>
</li>
<li><p>pc&#x2F;edge ç§»åŠ¨ç«¯<br> llama.cpp<br>mlc-llm<br>ollama</p>
</li>
<li><p>æœåŠ¡ Server<br>Triton Server</p>
</li>
</ul>
<h1><span id="vllm">vLLM</span><a href="#vllm" class="header-anchor">#</a></h1><h3><span id="key-features-5">key features [5]</span><a href="#key-features-5" class="header-anchor">#</a></h3><ul>
<li><strong>page attention</strong>[2]<br> memory sharing</li>
<li>Continuous <strong>batching</strong> of incoming requests</li>
<li>Quantization: <ul>
<li><strong>GPTQ</strong></li>
<li><strong>AWQ</strong></li>
<li>SqueezeLLM</li>
<li><strong>FP8 KV Cache</strong></li>
</ul>
</li>
</ul>
<h1><span id="tensorrt-llm">TensorRT-LLM</span><a href="#tensorrt-llm" class="header-anchor">#</a></h1><h3><span id="key-features-4">key features [4]</span><a href="#key-features-4" class="header-anchor">#</a></h3><ul>
<li>Flash Attention</li>
<li>MHA&#x2F;MQA&#x2F;GQA</li>
<li><strong>Quantization</strong><ul>
<li>Weight-Only</li>
<li>SmoothQuant</li>
<li><strong>GPTQ</strong></li>
<li><strong>AWQ</strong></li>
<li>FP8</li>
</ul>
</li>
<li>Paged <strong>KV Cache</strong> for the Attention</li>
<li>Multi-GPU Multi-Node</li>
<li><strong>TP(Tensor Parallelism)&#x2F;PP(Pipeline Parallelism)</strong></li>
<li>In-flight <strong>Batching</strong></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1.1. <a href="https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzA5MTIxNTY4MQ==&scene=1&album_id=2959126655292211206">æ¢ç§˜LLMåº”ç”¨å¼€å‘</a>   8-19</p>
<ol start="2">
<li><p><a href="https://www.bilibili.com/video/BV1cP41187wY/">VLLM â€”â€”é«˜æ•ˆGPUè®­ç»ƒæ¡†æ¶</a> V</p>
</li>
<li><p>xx</p>
</li>
<li><p><a href="https://github.com/NVIDIA/TensorRT-LLM/">TensorRT-LLM</a> git</p>
</li>
<li><p><a href="https://github.com/vllm-project/vllm">vllm</a> git</p>
</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzA5MTIxNTY4MQ==&mid=2461142079&idx=1&sn=07d9033203c0064408fe0af33d1f9414">ä¸€æ–‡æ¢ç§˜LLMåº”ç”¨å¼€å‘(18)-æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†(æ¡†æ¶å·¥å…·-Triton Serverã€RayLLMã€OpenLLM)</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzA5MTIxNTY4MQ==&mid=2461142012&idx=1&sn=dafb0b676cdf6d41fd9bd54f9b6a82d3">ä¸€æ–‡æ¢ç§˜LLMåº”ç”¨å¼€å‘(16)-æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†(æ¡†æ¶å·¥å…·-TGIï¼ŒvLLMï¼ŒTensorRT-LLMï¼ŒDS-MII) </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/659792625">å¤§æ¨¡å‹æ¨ç†æ¡†æ¶æ¦‚è¿°</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Inference</category>
      </categories>
      <tags>
        <tag>Inference</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)æ¨ç†-æ¡†æ¶</title>
    <url>/www6vHomeAIGC/2023/02/02/gptInferFrameworkPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#lmdeploy-%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2-10">lmdeploy-æ¨ç†éƒ¨ç½² [10]</a><ul>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2">æ¨¡å‹è½¬æ¢</a></li>
<li><a href="#turbomind-%E6%8E%A8%E7%90%86%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%9C%AC%E5%9C%B0%E5%AF%B9%E8%AF%9D">TurboMind æ¨ç†+å‘½ä»¤è¡Œæœ¬åœ°å¯¹è¯</a></li>
<li><a href="#turbomind%E6%8E%A8%E7%90%86api%E6%9C%8D%E5%8A%A1">TurboMindæ¨ç†+APIæœåŠ¡</a></li>
</ul>
</li>
<li><a href="#vllm-%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B211">vLLM æ¨ç†éƒ¨ç½²[11]</a></li>
<li><a href="#tensorrt-llm-%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2">TensorRT-LLM æ¨ç†éƒ¨ç½²</a></li>
<li><a href="#triton-%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2">Triton æ¨ç†éƒ¨ç½²</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="lmdeploy-æ¨ç†éƒ¨ç½²-10">lmdeploy-æ¨ç†éƒ¨ç½² [10]</span><a href="#lmdeploy-æ¨ç†éƒ¨ç½²-10" class="header-anchor">#</a></h1><h3><span id="æ¨¡å‹è½¬æ¢">æ¨¡å‹è½¬æ¢</span><a href="#æ¨¡å‹è½¬æ¢" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/02/02/gptInferFrameworkPractice/convert.png" class>
<h3><span id="turbomind-æ¨ç†å‘½ä»¤è¡Œæœ¬åœ°å¯¹è¯">TurboMind æ¨ç†+å‘½ä»¤è¡Œæœ¬åœ°å¯¹è¯</span><a href="#turbomind-æ¨ç†å‘½ä»¤è¡Œæœ¬åœ°å¯¹è¯" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/02/02/gptInferFrameworkPractice/infer.png" class>
<h3><span id="turbomindæ¨ç†apiæœåŠ¡">TurboMindæ¨ç†+APIæœåŠ¡</span><a href="#turbomindæ¨ç†apiæœåŠ¡" class="header-anchor">#</a></h3><ul>
<li>å¯åŠ¨æœåŠ¡<img src="/www6vHomeAIGC/2023/02/02/gptInferFrameworkPractice/infer-api.png" class></li>
<li>Clientè®¿é—®æœåŠ¡<img src="/www6vHomeAIGC/2023/02/02/gptInferFrameworkPractice/infer-api-client.png" class></li>
</ul>
<h1><span id="vllm-æ¨ç†éƒ¨ç½²11">vLLM æ¨ç†éƒ¨ç½²[11]</span><a href="#vllm-æ¨ç†éƒ¨ç½²11" class="header-anchor">#</a></h1><h1><span id="tensorrt-llm-æ¨ç†éƒ¨ç½²">TensorRT-LLM æ¨ç†éƒ¨ç½²</span><a href="#tensorrt-llm-æ¨ç†éƒ¨ç½²" class="header-anchor">#</a></h1><p>[åŸºäºdockerçš„éƒ¨ç½²]</p>
<h1><span id="triton-æ¨ç†éƒ¨ç½²">Triton æ¨ç†éƒ¨ç½²</span><a href="#triton-æ¨ç†éƒ¨ç½²" class="header-anchor">#</a></h1><p>[åŸºäºk8sçš„éƒ¨ç½²]</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="10">
<li><p><a href="https://github.com/InternLM/tutorial/blob/main/lmdeploy/lmdeploy.md">lmdeploy é‡åŒ–éƒ¨ç½²</a><br>  <a href="https://www.bilibili.com/video/BV1iW4y1A77P/">(5)LMDeploy å¤§æ¨¡å‹é‡åŒ–éƒ¨ç½²å®è·µ</a> V</p>
</li>
<li><p><a href="https://github.com/LlamaFamily/Llama2-Chinese/blob/main/inference-speed/GPU/vllm_example/README.md">Atom-7B-Chat vllmæ¨ç†éƒ¨ç½²</a></p>
</li>
</ol>
<p>1xx. <a href="https://github.com/www6v/llm-action/tree/main/inference">llm-action  inference</a> git</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/666849728">TensorRT-LLMä¿å§†çº§æ•™ç¨‹ï¼ˆä¸€ï¼‰-å¿«é€Ÿå…¥é—¨</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/667572720">TensorRT-LLMä¿å§†çº§æ•™ç¨‹ï¼ˆäºŒï¼‰-ç¦»çº¿ç¯å¢ƒæ­å»ºã€æ¨¡å‹é‡åŒ–åŠæ¨ç†</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/669576221">TensorRT-LLMï¼ˆæŒç»­æ›´æ–°ï¼‰</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/629336492">æ¨¡å‹æ¨ç†æœåŠ¡åŒ–æ¡†æ¶Tritonä¿å§†å¼æ•™ç¨‹ï¼ˆä¸€ï¼‰ï¼šå¿«é€Ÿå…¥é—¨</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/634143650">æ¨¡å‹æ¨ç†æœåŠ¡åŒ–æ¡†æ¶Tritonä¿å§†å¼æ•™ç¨‹ï¼ˆäºŒï¼‰ï¼šæ¶æ„è§£æ</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/634444666">æ¨¡å‹æ¨ç†æœåŠ¡åŒ–æ¡†æ¶Tritonä¿å§†å¼æ•™ç¨‹ï¼ˆä¸‰ï¼‰ï¼šå¼€å‘å®è·µ</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Inference</category>
      </categories>
      <tags>
        <tag>Inference</tag>
      </tags>
  </entry>
  <entry>
    <title>(ç»¼è¿°)æ¨ç†ä¼˜åŒ–</title>
    <url>/www6vHomeAIGC/2023/01/01/gptInference/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%8E%A8%E7%90%86-%E4%BC%98%E5%8C%96">æ¨ç† ä¼˜åŒ–</a><ul>
<li><a href="#overview22">overview[2.2]</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-21">æ¨¡å‹å‹ç¼© [2.1]</a></li>
<li><a href="#kv-cache2324">KV Cache[2.3][2.4]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E7%BB%BC%E8%BF%B0">ç»¼è¿°</a></li>
<li><a href="#kv-cache">kv cache</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="æ¨ç†-ä¼˜åŒ–">æ¨ç† ä¼˜åŒ–</span><a href="#æ¨ç†-ä¼˜åŒ–" class="header-anchor">#</a></h1><h3><span id="overview22">overview[2.2]</span><a href="#overview22" class="header-anchor">#</a></h3><p>æœ‰å‡ ç§æ–¹æ³•å¯ä»¥åœ¨å†…å­˜ä¸­<strong>é™ä½æ¨ç†æˆæœ¬</strong>æˆ–&#x2F;å’Œ<strong>åŠ å¿«æ¨ç†é€Ÿåº¦</strong>ã€‚</p>
<ul>
<li>åº”ç”¨å„ç§<strong>å¹¶è¡Œå¤„ç†æ–¹å¼</strong>ï¼Œä»¥åœ¨å¤§é‡GPUä¸Šæ‰©å±•æ¨¡å‹ã€‚æ™ºèƒ½å¹¶è¡Œå¤„ç†æ¨¡å‹ç»„ä»¶å’Œæ•°æ®ä½¿å¾—è¿è¡Œæ‹¥æœ‰æ•°ä¸‡äº¿å‚æ•°çš„æ¨¡å‹æˆä¸ºå¯èƒ½ã€‚</li>
<li><strong>å†…å­˜å¸è½½</strong>ï¼Œå°†ä¸´æ—¶æœªä½¿ç”¨çš„æ•°æ®å¸è½½åˆ°CPUï¼Œå¹¶åœ¨ä»¥åéœ€è¦æ—¶å†è¯»å›ã€‚è¿™æœ‰åŠ©äºå‡å°‘å†…å­˜ä½¿ç”¨ï¼Œä½†ä¼šå¯¼è‡´æ›´é«˜çš„å»¶è¿Ÿã€‚</li>
<li><strong>æ™ºèƒ½æ‰¹å¤„ç†ç­–ç•¥</strong>ï¼›ä¾‹å¦‚ï¼ŒEffectiveTransformerå°†è¿ç»­çš„åºåˆ—æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œä»¥æ¶ˆé™¤æ‰¹å¤„ç†å†…çš„å¡«å……ã€‚</li>
<li><strong>ç½‘ç»œå‹ç¼©æŠ€æœ¯</strong>ï¼Œå¦‚<strong>ä¿®å‰ªã€é‡åŒ–ã€è’¸é¦</strong>ã€‚è¾ƒå°çš„æ¨¡å‹ï¼Œæ— è®ºæ˜¯å‚æ•°æ•°é‡è¿˜æ˜¯ä½å®½ï¼Œåº”è¯¥éœ€è¦æ›´å°‘çš„å†…å­˜å¹¶ä¸”è¿è¡Œæ›´å¿«ã€‚</li>
<li>é’ˆå¯¹ç›®æ ‡æ¨¡å‹æ¶æ„çš„ç‰¹å®šæ”¹è¿›ã€‚è®¸å¤š<strong>æ¶æ„å˜åŒ–</strong>ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æ³¨æ„åŠ›å±‚çš„å˜åŒ–ï¼Œæœ‰åŠ©äºæé«˜Transformerè§£ç é€Ÿåº¦ã€‚</li>
</ul>
<h3><span id="æ¨¡å‹å‹ç¼©-21">æ¨¡å‹å‹ç¼© [2.1]</span><a href="#æ¨¡å‹å‹ç¼©-21" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/01/01/gptInference/compress.png" class>

<ul>
<li>å‰ªæï¼ˆPruningï¼‰</li>
<li>çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼ŒKDï¼‰</li>
<li>é‡åŒ–ï¼ˆQuantizationï¼‰</li>
<li>ä½ç§©åˆ†è§£ï¼ˆLow-Rank Factorizationï¼‰</li>
</ul>
<h3><span id="kv-cache2324">KV Cache[2.3][2.4]</span><a href="#kv-cache2324" class="header-anchor">#</a></h3><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="ç»¼è¿°">ç»¼è¿°</span><a href="#ç»¼è¿°" class="header-anchor">#</a></h3><p>2.1. <a href="https://mp.weixin.qq.com/s/glPPSqHjsnDjC0DZSuuPzA">ä¸€æ–‡æ¢ç§˜LLMåº”ç”¨å¼€å‘(13)-æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†(ä¼˜åŒ–ç†è®º) </a><br>2.2   <a href="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/">Large Transformer Model Inference Optimization </a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/656485997">å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ€§èƒ½ä¼˜åŒ–ç»¼è¿°</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/642412124">NLPï¼ˆåå…«ï¼‰ï¼šLLM çš„æ¨ç†ä¼˜åŒ–æŠ€æœ¯çºµè§ˆ</a> *** </p>
<h3><span id="kv-cache">kv cache</span><a href="#kv-cache" class="header-anchor">#</a></h3><p>2.3. <a href="https://zhuanlan.zhihu.com/p/659770503">NLPï¼ˆäºŒåï¼‰ï¼šæ¼«è°ˆ KV Cache ä¼˜åŒ–æ–¹æ³•ï¼Œæ·±åº¦ç†è§£ StreamingLLM</a> ***<br>2.4. <a href="https://zhuanlan.zhihu.com/p/662498827">å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿï¼šçœ‹å›¾å­¦KV Cache</a> ***</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/669777159">[Awesome-LLM-Inference]ğŸ”¥ç¬¬ä¸‰æœŸï¼š30ç¯‡ï¼ŒLLMæ¨ç†è®ºæ–‡é›†-500é¡µPDF</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/658091768">[Awesome-LLM-Inference]ğŸ”¥ç¬¬äºŒæœŸ: 20ç¯‡ï¼ŒLLMæ¨ç†è®ºæ–‡é›†-300é¡µPDF</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Inference</category>
      </categories>
      <tags>
        <tag>Inference</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Instruct Tuning</title>
    <url>/www6vHomeAIGC/2023/01/06/gptInstructTuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#in-context-learning-icl-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0">In Context Learning ( ICL ) ä¸Šä¸‹æ–‡å­¦ä¹ </a></li>
<li><a href="#instruction-learning-1">Instruction Learning [1]</a><ul>
<li><a href="#instruct-tuning-">Instruct Tuning-</a></li>
<li><a href="#instructgpt">instructGPT</a></li>
<li><a href="#chatgpt">chatGPT</a></li>
</ul>
</li>
<li><a href="#instruction-tuning">Instruction Tuning</a></li>
<li><a href="#limitation-of-instruction-finetuning-2">Limitation of instruction finetuning [2]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="in-context-learning-icl-ä¸Šä¸‹æ–‡å­¦ä¹ ">In Context Learning ( ICL ) ä¸Šä¸‹æ–‡å­¦ä¹ </span><a href="#in-context-learning-icl-ä¸Šä¸‹æ–‡å­¦ä¹ " class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/06/gptInstructTuning/ICL.webp" class>

<ul>
<li><strong>in context learning</strong>ï¼Œå¤§æ„æ˜¯åœ¨<strong>prompt learningçš„åŸºç¡€ä¸Šï¼Œå°†å°‘é‡æœ‰æ ‡ç­¾æ ·æœ¬èå…¥prompt</strong>ã€‚</li>
<li>ä¸Šå›¾çš„ICLæ¨¡å‹å¯ä»¥ç†è§£æˆ<strong>æœ‰ç›‘ç£ã€æ— è®­ç»ƒ</strong>çš„<strong>å°æ ·æœ¬å­¦ä¹ </strong>ã€‚</li>
<li>ä½†<strong>å¹¶éæ‰€æœ‰ICLéƒ½ä¸è®­ç»ƒ</strong>ã€‚æ¯”å¦‚ä¸‹å›¾å³ä¸Šè§’çš„<strong>FLAN</strong>å°±æ˜¯ç”¨instruction tuning<strong>è®­ç»ƒå‚æ•°</strong>çš„ã€‚</li>
</ul>
<img src="/www6vHomeAIGC/2023/01/06/gptInstructTuning/ICL-tech.webp" class>
<ul>
<li><strong>FLAN</strong>ï¼Œ<strong>æ—¢å±äº in context learningï¼Œä¹Ÿå±äº instruction learning</strong></li>
</ul>
<h1><span id="instruction-learning-1">Instruction Learning [1]</span><a href="#instruction-learning-1" class="header-anchor">#</a></h1><h3><span id="instruct-tuning-">Instruct Tuning-</span><a href="#instruct-tuning-" class="header-anchor">#</a></h3><pre><code>FLANv1, FLANv2
</code></pre>
<h3><span id="instructgpt">instructGPT</span><a href="#instructgpt" class="header-anchor">#</a></h3><h3><span id="chatgpt">chatGPT</span><a href="#chatgpt" class="header-anchor">#</a></h3><h1><span id="instruction-tuning">Instruction Tuning</span><a href="#instruction-tuning" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/06/gptInstructTuning/instructTuning.webp" class>

<ul>
<li><p>å¯¹äºå·²æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç»§ç»­åœ¨å¤šé¡¹ä»»åŠ¡ï¼ˆBã€Cã€Dç­‰ï¼‰ä¸Šåšè®­ç»ƒï¼Œåœ¨å…¶ä»–ä»»åŠ¡ï¼ˆAï¼‰ä¸Šåšé¢„æµ‹ã€‚<strong>è™½ç„¶ä¾ç„¶æ²¡è§è¿‡ä»»åŠ¡Aï¼Œä½†æ˜¯æ ¹æ®å¯¹Bã€Cã€Dç­‰çš„è®­ç»ƒï¼Œå¯¹Açš„æ•ˆæœæœ‰æ‰€æå‡ï¼›</strong> [1]</p>
</li>
<li><p><strong>Instruct Tuning æœ¬è´¨ä¸Šä¹Ÿæ˜¯Prompt Tuning</strong> [2]</p>
</li>
<li><p>ç ”ç©¶äº†ç¼©æ”¾å¯¹æŒ‡ä»¤å¾®è°ƒçš„å½±å“ [3]<br>  ä¸å¾®è°ƒæŒ‡ä»¤çš„ä»»åŠ¡æ•°é‡æœ‰å…³ï¼Œ<strong>ä»»åŠ¡æ•°é‡è¶Šå¤šæ•ˆæœè¶Šå¥½</strong><br>  ä¸æ¨¡å‹çš„å¤§å°æœ‰å…³ï¼Œ<strong>æ¨¡å‹è¶Šå¤§æ•ˆæœè¶Šå¥½</strong></p>
</li>
<li><p>Prompt vs. Instruction Tuning  [4]<br>  Promptæ˜¯å»æ¿€å‘è¯­è¨€æ¨¡å‹çš„<strong>è¡¥å…¨èƒ½åŠ›</strong>ï¼Œæ¯”å¦‚ç»™å‡ºä¸ŠåŠå¥ç”Ÿæˆä¸‹åŠå¥ã€æˆ–è€…åšå®Œå½¢å¡«ç©ºï¼Œéƒ½è¿˜æ˜¯åƒåœ¨åšlanguage modelä»»åŠ¡.<br>  è€ŒInstruction Tuningåˆ™æ˜¯æ¿€å‘è¯­è¨€æ¨¡å‹çš„<strong>ç†è§£èƒ½åŠ›</strong>ï¼Œé€šè¿‡ç»™å‡ºæ›´æ˜æ˜¾çš„æŒ‡ä»¤&#x2F;æŒ‡ç¤ºï¼Œè®©æ¨¡å‹å»ç†è§£å¹¶åšå‡ºæ­£ç¡®çš„action<br>  <strong>Prompt tuning</strong>éƒ½æ˜¯é’ˆå¯¹<strong>ä¸€ä¸ªä»»åŠ¡</strong>çš„ï¼Œæ¯”å¦‚åšä¸ªæƒ…æ„Ÿåˆ†æä»»åŠ¡çš„prompt tuningï¼Œç²¾è°ƒå®Œçš„æ¨¡å‹åªèƒ½ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œè€Œç»è¿‡<strong>Instruction Tuningå¤šä»»åŠ¡</strong>ç²¾è°ƒåï¼Œå¯ä»¥ç”¨äºå…¶ä»–ä»»åŠ¡çš„zero-shot</p>
</li>
<li><p>Instruction Tuning æŒ‡ä»¤å¾®è°ƒ  [4]</p>
<ul>
<li>Self Instruction<ul>
<li>Alpaca &#x3D; LLaMA + Intruction Tuning [2]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="limitation-of-instruction-finetuning-2">Limitation of instruction finetuning [2]</span><a href="#limitation-of-instruction-finetuning-2" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/06/gptInstructTuning/limitation.JPG" class>
<p>é—®é¢˜1.  å¼€æ”¾æ€§é—®é¢˜<br>é—®é¢˜2.  çœ‹å›¾</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/619406727">å„ç§tuningçš„ç®€å•é€»è¾‘è§£é‡Š</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1cm4y1e7Cc/">ç¬¬ä¹è¯¾ï¼šInstruct Tuning</a> *** V</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/646136859">FLANv2ï¼šå¤§æ¨¡å‹æŒ‡ä»¤å¾®è°ƒå¿…çœ‹è®ºæ–‡</a> </p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/408166011">Instruction Tuningï½œè°·æ­ŒQuoc V.Leå›¢é˜Ÿæå‡ºåˆä¸€ç²¾è°ƒèŒƒå¼</a></p>
</li>
</ol>
<p>1xx. <a href="https://yaofu.notion.site/June-2023-A-Stage-Review-of-Instruction-Tuning-f59dbfc36e2d4e12a33443bd6b2012c2">June 2023, A Stage Review of Instruction Tuning</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/629461665">ã€LLMç³»åˆ—ä¹‹FLAN-T5&#x2F;PaLMã€‘Scaling Instruction-Finetuned Language Models</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/597036814">å¦‚ä½•ä¼˜åŒ–å¤§æ¨¡å‹çš„In-Context Learningæ•ˆæœï¼Ÿ</a></p>
<p>1xx. <a href="https://nakaizura.blog.csdn.net/article/details/128265846">Instruction Tuningï¼ˆFLANã€instructGPTã€chatGPTï¼‰</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Instruct-Tuning</category>
      </categories>
      <tags>
        <tag>Instruct-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>(Survey)Instruct Tuning</title>
    <url>/www6vHomeAIGC/2023/03/12/gptInstructTuningSurvey/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>



<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://arxiv.org/abs/2308.10792">å¤§è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒç»¼è¿°</a><br>    <a href="https://zhuanlan.zhihu.com/p/654054370">ä¸€ç¯‡å…³äºLLMæŒ‡ä»¤å¾®è°ƒçš„ç»¼è¿°</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/657138921">[è®ºæ–‡]å¤§è¯­è¨€æ¨¡å‹æŒ‡ä»¤è°ƒä¼˜ç»¼è¿°</a><br>1xx. <a href="https://blog.csdn.net/qq_41185868/article/details/132613338">Paperï¼šã€ŠInstruction Tuning for Large Language Models: A Surveyâ€”å¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤è°ƒä¼˜çš„ç»¼è¿°ã€‹ç¿»è¯‘ä¸è§£è¯»</a><br>1xx. <a href="https://github.com/xiaoya-li/Instruction-Tuning-Survey">Instruction Tuning for Large Language Models: A Survey</a> git</p>
<p>ã€å‰é¢å¤§éƒ¨åˆ†æ˜¯Instruct-Tuningï¼Œ ä¸­é—´ä¸€éƒ¨åˆ†æ˜¯Multi-modality Instruction Tuningã€‘</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Instruct-Tuning</category>
      </categories>
      <tags>
        <tag>Instruct-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>LLMOps</title>
    <url>/www6vHomeAIGC/2022/12/28/gptLLMOps/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<ol>
<li><a href="https://drive.google.com/file/d/1LZXTrRdrloIqAJT6xaNTl4WQd6y95o7K/view">LLMOps: Deployment and Learning in Production</a><br><a href="https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/llmops/">LLMOps: Deployment and Learning in Production</a><br><a href="https://zhuanlan.zhihu.com/p/629589593">[å¿…è¯»] LLM åº”ç”¨å¼€å‘å…¨æ ˆæŒ‡å—</a> LLMOps</li>
<li><a href="https://zhuanlan.zhihu.com/p/632026876">äº†è§£ä¸€ä¸‹æ–°é¢†åŸŸ LLMOps: å¤§æ¨¡å‹è¿ç»´</a><br><a href="https://wandb.ai/site/articles/understanding-llmops-large-language-model-operations">Understanding LLMOps: Large Language Model Operations</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>LLMOps</category>
      </categories>
      <tags>
        <tag>LLMOps</tag>
      </tags>
  </entry>
  <entry>
    <title>Langchain</title>
    <url>/www6vHomeAIGC/2022/11/02/gptLangchain/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#modules">Modules</a><ul>
<li><a href="#main-modules">main modules</a><ul>
<li><a href="#model-io">Model I&#x2F;O</a></li>
<li><a href="#retrieval">Retrieval</a></li>
<li><a href="#agent">Agent</a></li>
</ul>
</li>
<li><a href="#additional-modules">Additional modules</a><ul>
<li><a href="#chains">Chains</a></li>
<li><a href="#memory-10">Memory [10]</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#function-call">Function Call</a></li>
<li><a href="#%E5%BA%94%E7%94%A84">åº”ç”¨[4]</a></li>
<li><a href="#chains-1-89">Chains [1] [8][9]</a></li>
<li><a href="#templates7">Templates[7]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="modules">Modules</span><a href="#modules" class="header-anchor">#</a></h1><h2><span id="main-modules">main modules</span><a href="#main-modules" class="header-anchor">#</a></h2><h3><span id="model-ix2fo">Model I&#x2F;O</span><a href="#model-ix2fo" class="header-anchor">#</a></h3><ul>
<li>Language models  [10]        <ul>
<li>LLM</li>
<li>Chat Model</li>
<li><strong>Embedding</strong></li>
</ul>
</li>
<li>Prompts <ul>
<li>Prompt Template</li>
<li>Few-shot example</li>
<li>Example Selectors [ç±»æ¯”é€‰æ‹©]<br>å…³é”®å­—  ç›¸ä¼¼åº¦  é•¿åº¦</li>
</ul>
</li>
<li>Output parsers</li>
<li><strong>function call</strong>[2]</li>
</ul>
<h3><span id="retrieval">Retrieval</span><a href="#retrieval" class="header-anchor">#</a></h3><ul>
<li>Document Loaders</li>
<li>Text Splitters</li>
<li><strong>Retrievers</strong>[10]</li>
<li>VectorStores</li>
<li>index</li>
</ul>
<h3><span id="agent">Agent</span><a href="#agent" class="header-anchor">#</a></h3><ul>
<li>Plan-and-execute agents</li>
</ul>
<h2><span id="additional-modules">Additional modules</span><a href="#additional-modules" class="header-anchor">#</a></h2><h3><span id="chains">Chains</span><a href="#chains" class="header-anchor">#</a></h3><ul>
<li>2å¤§ç±»<ul>
<li>Chain interface[Legacy]</li>
<li>LangChain Expression Language (LCEL)<br>LCEL is a declarative way to compose chains.</li>
</ul>
</li>
<li>Foundational<ul>
<li>LLM</li>
<li>Sequential- SequentialChain</li>
<li><strong>Router</strong></li>
<li>Transformation</li>
</ul>
</li>
</ul>
<h3><span id="memory-10">Memory [10]</span><a href="#memory-10" class="header-anchor">#</a></h3><ul>
<li>å¸®è¯­è¨€æ¨¡å‹è¡¥å……ä¸Šä¸‹æ–‡</li>
<li>ConversationBufferMemory</li>
<li>ConversationBufferWindowMemory<br>çª—å£</li>
<li>ConversationSummaryMemory</li>
<li>VectorStoreRetrieverMemory</li>
</ul>
<h1><span id="function-call">Function Call</span><a href="#function-call" class="header-anchor">#</a></h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.base <span class="keyword">import</span> (</span><br><span class="line">    create_openai_fn_chain,</span><br><span class="line">    create_structured_output_chain,[<span class="number">2</span>]</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.citation_fuzzy_match <span class="keyword">import</span> (</span><br><span class="line">    create_citation_fuzzy_match_chain,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.extraction <span class="keyword">import</span> (</span><br><span class="line">    create_extraction_chain,</span><br><span class="line">    create_extraction_chain_pydantic,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.qa_with_structure <span class="keyword">import</span> (</span><br><span class="line">    create_qa_with_sources_chain,</span><br><span class="line">    create_qa_with_structure_chain,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.chains.openai_functions.tagging <span class="keyword">import</span> (</span><br><span class="line">    create_tagging_chain,</span><br><span class="line">    create_tagging_chain_pydantic,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<h1><span id="åº”ç”¨4">åº”ç”¨[4]</span><a href="#åº”ç”¨4" class="header-anchor">#</a></h1><ul>
<li>Question &amp; Answering Using Documents As Context[3]</li>
<li>Extraction[Kor]</li>
<li>Evaluation</li>
<li>Querying Tabular Data[sqlite]</li>
<li>Code Understanding</li>
<li>Interacting with APIs</li>
<li>Chatbots</li>
</ul>
<h1><span id="chains-1-89">Chains [1] [8][9]</span><a href="#chains-1-89" class="header-anchor">#</a></h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chain = load_summarize_chain(llm, chain_type=<span class="string">&quot;stuff&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">chain = load_summarize_chain(llm, chain_type=<span class="string">&quot;map_reduce&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">chain = load_summarize_chain(llm, chain_type=<span class="string">&quot;refine&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">chain = load_qa_chain(llm, chain_type=<span class="string">&quot;map_rerank&quot;</span>, verbose=<span class="literal">True</span>, return_intermediate_steps=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th>é“¾ç±»å‹</th>
<th>æ•´åˆæ–¹æ³•</th>
<th>ä¼˜ç¼ºç‚¹</th>
</tr>
</thead>
<tbody><tr>
<td>stuff</td>
<td>å°†æ‰€æœ‰å†…å®¹æ”¾å…¥ä¸€ä¸ªæç¤ºä¸­ï¼Œè¾“å…¥LLM</td>
<td>ç®€å•ã€å»‰ä»·ã€æ•ˆæœå¥½&#x2F; å¯¹è¾“å…¥æ–‡æœ¬æœ‰ä¸€å®štokené™åˆ¶</td>
</tr>
<tr>
<td>Map_reduce</td>
<td>æ¯ä¸ªé—®é¢˜å’Œæ–‡æœ¬å—å•ç‹¬ç»™è¯­è¨€æ¨¡å‹ï¼Œå¹¶å°†ç­”æ¡ˆæ±‡æ€»ç”Ÿæˆæœ€ç»ˆç»“æœ</td>
<td>è¾“å…¥ä»»æ„æ•°é‡æ–‡æœ¬ï¼Œä¸”å¹¶è¡Œå¤„ç†&#x2F; é€Ÿåº¦æ…¢ï¼Œè´¹token</td>
</tr>
<tr>
<td>Refine</td>
<td>è¿­ä»£å¤„ç†å¤šä¸ªæ–‡æœ¬ï¼ŒåŸºäºå‰ä¸€ä¸ªæ–‡æ¡£ç­”æ¡ˆæ„å»ºä¸‹ä¸€ä¸ªç­”æ¡ˆ</td>
<td>ç”¨äºç»„åˆä¿¡æ¯ï¼Œä¾æ¬¡æ„å»ºç­”æ¡ˆ&#x2F; é€Ÿåº¦æ…¢ï¼Œè´¹token</td>
</tr>
<tr>
<td>Map_rerank</td>
<td>æ¯ä¸ªæ–‡æ¡£å•ç‹¬è°ƒç”¨LLM,å¹¶è¦æ±‚è¿”å›ä¸€ä¸ªå¾—åˆ†ï¼Œç„¶åé€‰æ‹©æœ€é«˜çš„å¾—åˆ†</td>
<td>éœ€è¦å‘Šè¯‰æ¨¡å‹è¯„åˆ†çš„è§„åˆ™&#x2F; è´¹token</td>
</tr>
</tbody></table>
<img src="/www6vHomeAIGC/2022/11/02/gptLangchain/chains-type.jpg" class>


<h1><span id="templates7">Templates[7]</span><a href="#templates7" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://github.com/gkamradt/langchain-tutorials">https://github.com/gkamradt/langchain-tutorials</a></p>
</li>
<li><p><a href="https://github.com/www6v/pyExamples/blob/master/langchain/langchain-functioncall.py">functioncall</a></p>
</li>
<li><p><a href="https://github.com/www6v/pyExamples/blob/master/langchain/langchain-qaOnDoc.py">qaOnDoc</a></p>
</li>
<li><p><a href="https://github.com/www6v/langchain-tutorials/blob/main/LangChain%20Cookbook%20Part%202%20-%20Use%20Cases.ipynb">LangChain Cookbook Part 2: Use Cases</a><br> 10.å…¬å¼€è¯¾</p>
</li>
<li><p><a href="https://github.com/kyrolabs/awesome-langchain">https://github.com/kyrolabs/awesome-langchain</a></p>
</li>
<li><p><a href="https://github.com/Crossme0809/langchain-tutorials">https://github.com/Crossme0809/langchain-tutorials</a></p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/templates/docs/INDEX.md">Templates</a> *** docs<br><a href="https://templates.langchain.com/">templates</a> webui</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/666656208">å´æ©è¾¾çŸ­è¯¾_LangChain</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/651216604">ç²¾åç¬”è®°ï¼šå´æ©è¾¾ x LangChain ã€Šä½¿ç”¨LangChainæ„å»ºä¸æ•°æ®å¯¹è¯çš„èŠå¤©æœºå™¨äººã€‹ï¼ˆä¸‹ï¼‰</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2313918">ä¸€æ–‡å…¥é—¨æœ€çƒ­çš„LLMåº”ç”¨å¼€å‘æ¡†æ¶LangChain</a> æœª</p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2331337">å¤§æ¨¡å‹LangChainæ¡†æ¶åŸºç¡€ä¸ä½¿ç”¨ç¤ºä¾‹</a> æœª</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Langchain</category>
      </categories>
      <tags>
        <tag>GPT</tag>
      </tags>
  </entry>
  <entry>
    <title>Langchain  Agent</title>
    <url>/www6vHomeAIGC/2023/01/11/gptLangchainAgent/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h1><span id="langchain-agent">Langchain Agent</span><a href="#langchain-agent" class="header-anchor">#</a></h1><ul>
<li>Conversational</li>
<li>OpenAI assistants</li>
<li>OpenAI functions</li>
<li>OpenAI Multi Functions Agent</li>
<li>OpenAI tools<br>OpenAI parallel function calling (a.k.a. tool calling)</li>
<li>ReAct<br>ZeroShotReactAgent</li>
<li>Self-ask with search</li>
<li>Structured tool chat</li>
</ul>
<h1><span id="langchain-apps">Langchain Apps</span><a href="#langchain-apps" class="header-anchor">#</a></h1><h3><span id="rag-chroma-private-2">rag-chroma-private [2]</span><a href="#rag-chroma-private-2" class="header-anchor">#</a></h3><p><strong>æœ¬åœ° éƒ¨ç½²</strong><br>This template performs RAG with no reliance on external APIs.<br>It utilizes <strong>Ollama the LLM, GPT4All for embeddings, and Chroma for the vectorstore</strong>.</p>
<h3><span id="research-assistant-34">research-assistant [3][4]</span><a href="#research-assistant-34" class="header-anchor">#</a></h3><p>This template implements a version of<br>â€œGPT Researcherâ€ that you can use as a starting point for a <strong>research agent</strong>.</p>
<h1><span id="langgraph5">LangGraph[5]</span><a href="#langgraph5" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://github.com/www6v/langchain-app">Langchain Apps</a> Project Code</li>
<li><a href="https://www.bilibili.com/video/BV1JV411F7Yj/">LangChain Agents ä¿å§†çº§æ•™ç¨‹ | åŠ¨ç”»æ¼”ç¤º è®²æ¸… æ ¸å¿ƒæ¨¡å— Agents | Code è®²è§£ | Demo æ¼”ç¤º</a></li>
<li><a href="https://blog.langchain.dev/exploring-uxs-besides-chat-with-research-assistant/">â€œResearch Assistantâ€: Exploring UXs Besides Chat</a></li>
<li><a href="https://www.youtube.com/watch?v=DjuXACWYkkU">Building a Research Assistant from Scratch</a> </li>
<li><a href="https://blog.langchain.dev/langgraph/">LangGraph</a></li>
<li><a href="https://github.com/www6v/gpt-researcher/">gpt-researcher</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Langchain</category>
      </categories>
      <tags>
        <tag>GPT</tag>
      </tags>
  </entry>
  <entry>
    <title>å¤§æ¨¡å‹</title>
    <url>/www6vHomeAIGC/2023/02/17/gptLargeModel/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="http://arthurchiao.art/blog/llm-practical-guide-zh/">[è¯‘][è®ºæ–‡] å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»¼è¿°ä¸å®ç”¨æŒ‡å—ï¼ˆAmazonï¼Œ2023ï¼‰</a>   å®æˆ˜  æœª<br>1xx. <a href="https://zhuanlan.zhihu.com/p/597586623">é€šå‘AGIä¹‹è·¯ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯ç²¾è¦</a> *** </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/671710012">é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹ï¼šç»¼è¿°</a>  *** å¤§æ¨¡å‹å„ä¸ªç»´åº¦çš„ä¼˜åŒ–<br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403847&idx=1&sn=9af731e9f8418a2d869f5464530c8bd6">å¿…çœ‹çš„åäºŒä¸ªå¤§æ¨¡å‹å‰æ²¿ç»¼è¿°ï¼šå…¼è®ºHALOå¤§æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸ç¼“è§£æ–¹æ¡ˆåŠGoogleå°æ¨¡å‹é¢„æµ‹å¤§æ¨¡å‹è®­ç»ƒä¸ç¨³å®šçš„æ¢ç´¢ </a> 12ä¸ªç»¼è¿°</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>å¤§æ¨¡å‹</category>
      </categories>
      <tags>
        <tag>å¤§æ¨¡å‹</tag>
      </tags>
  </entry>
  <entry>
    <title>(ç»¼è¿°)å¤§æ¨¡å‹</title>
    <url>/www6vHomeAIGC/2022/10/30/gptLargeModelSurvey/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#llms%E7%9A%84%E8%83%8C%E6%99%AF1">LLMsçš„èƒŒæ™¯[1]</a><ul>
<li><a href="#scaling-law-of-llms">Scaling law of LLMs</a></li>
<li><a href="#llms%E7%9A%84%E6%B6%8C%E7%8E%B0%E8%83%BD%E5%8A%9B">LLMsçš„æ¶Œç°èƒ½åŠ›</a></li>
<li><a href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF">å¤§è¯­è¨€æ¨¡å‹çš„å…³é”®æŠ€æœ¯ ***</a></li>
</ul>
</li>
<li><a href="#pre-training1">Pre-training[1]</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86">æ•°æ®æ”¶é›†</a></li>
<li><a href="#%E6%9E%B6%E6%9E%84">æ¶æ„</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">æ¨¡å‹è®­ç»ƒ ***</a></li>
</ul>
</li>
<li><a href="#adaptation-tuning-of-llms1">Adaptation Tuning of LLMs[1]</a><ul>
<li><a href="#%E6%8C%87%E4%BB%A4%E8%B0%83%E4%BC%98">æŒ‡ä»¤è°ƒä¼˜ ***</a><ul>
<li><a href="#%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AE%9E%E4%BE%8B%E7%9A%84%E6%9E%84%E5%BB%BA">æ ¼å¼åŒ–å®ä¾‹çš„æ„å»º</a></li>
<li><a href="#%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E7%AD%96%E7%95%A5">æŒ‡ä»¤å¾®è°ƒç­–ç•¥</a></li>
<li><a href="#%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E7%9A%84%E6%95%88%E6%9E%9C">æŒ‡ä»¤å¾®è°ƒçš„æ•ˆæœ</a></li>
</ul>
</li>
<li><a href="#%E5%AF%B9%E9%BD%90%E8%B0%83%E4%BC%98">å¯¹é½è°ƒä¼˜</a></li>
<li><a href="#%E9%AB%98%E6%95%88%E8%B0%83%E4%BC%98">é«˜æ•ˆè°ƒä¼˜</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="llmsçš„èƒŒæ™¯1">LLMsçš„èƒŒæ™¯[1]</span><a href="#llmsçš„èƒŒæ™¯1" class="header-anchor">#</a></h1><h3><span id="scaling-law-of-llms">Scaling law of LLMs</span><a href="#scaling-law-of-llms" class="header-anchor">#</a></h3><ul>
<li>KM scaling law</li>
<li>Chinchilla Scaling law</li>
</ul>
<h3><span id="llmsçš„æ¶Œç°èƒ½åŠ›">LLMsçš„æ¶Œç°èƒ½åŠ›</span><a href="#llmsçš„æ¶Œç°èƒ½åŠ›" class="header-anchor">#</a></h3><ul>
<li>in-context learning</li>
<li>instruction following</li>
<li>step-by-step reasoning</li>
</ul>
<h3><span id="å¤§è¯­è¨€æ¨¡å‹çš„å…³é”®æŠ€æœ¯">å¤§è¯­è¨€æ¨¡å‹çš„å…³é”®æŠ€æœ¯ ***</span><a href="#å¤§è¯­è¨€æ¨¡å‹çš„å…³é”®æŠ€æœ¯" class="header-anchor">#</a></h3><ul>
<li>Scaling</li>
<li>Training</li>
<li>Ability Eliciting</li>
<li>Alignment Tuning</li>
<li>Tool Manipulation</li>
</ul>
<h1><span id="pre-training1">Pre-training[1]</span><a href="#pre-training1" class="header-anchor">#</a></h1><h3><span id="æ•°æ®æ”¶é›†">æ•°æ®æ”¶é›†</span><a href="#æ•°æ®æ”¶é›†" class="header-anchor">#</a></h3><h3><span id="æ¶æ„">æ¶æ„</span><a href="#æ¶æ„" class="header-anchor">#</a></h3><h3><span id="æ¨¡å‹è®­ç»ƒ">æ¨¡å‹è®­ç»ƒ ***</span><a href="#æ¨¡å‹è®­ç»ƒ" class="header-anchor">#</a></h3><ul>
<li><p>ä¼˜åŒ–è®¾ç½®</p>
<ul>
<li>Batch Training</li>
<li>Learning Rate</li>
<li>Optimizer</li>
<li>Stabilizing the Training</li>
</ul>
</li>
<li><p>å¯æ‰©å±•çš„è®­ç»ƒæŠ€å·§</p>
<ul>
<li>3Då¹¶è¡Œ<br>æ•°æ®å¹¶è¡Œ +  æµæ°´çº¿å¹¶è¡Œ + å¼ é‡å¹¶è¡Œ</li>
<li>ZeRO</li>
<li>æ··åˆç²¾åº¦è®­ç»ƒ</li>
<li>æ€»ä½“è®­ç»ƒå»ºè®®</li>
</ul>
</li>
</ul>
<h1><span id="adaptation-tuning-of-llms1">Adaptation Tuning of LLMs[1]</span><a href="#adaptation-tuning-of-llms1" class="header-anchor">#</a></h1><h3><span id="æŒ‡ä»¤è°ƒä¼˜">æŒ‡ä»¤è°ƒä¼˜ ***</span><a href="#æŒ‡ä»¤è°ƒä¼˜" class="header-anchor">#</a></h3><p>æœ¬è´¨ä¸Šï¼ŒæŒ‡ä»¤å¾®è°ƒæ˜¯åœ¨<strong>è‡ªç„¶è¯­è¨€æ ¼å¼çš„å®ä¾‹ï¼ˆinstanceï¼‰é›†åˆä¸Š</strong>å¾®è°ƒé¢„è®­ç»ƒåçš„ LLM çš„æ–¹æ³• [62]ã€‚</p>
<p>æŒ‡ä»¤å¾®è°ƒåï¼ŒLLM å¯ä»¥å±•ç°å‡º<strong>æ³›åŒ–åˆ°æœªè§è¿‡ä»»åŠ¡</strong>çš„å“è¶Šèƒ½åŠ› [28, 62, 64]ï¼Œå³ä½¿åœ¨å¤šè¯­è¨€åœºæ™¯ä¸‹ä¹Ÿèƒ½æœ‰ä¸é”™è¡¨ç° [98]ã€‚</p>
<h5><span id="æ ¼å¼åŒ–å®ä¾‹çš„æ„å»º">æ ¼å¼åŒ–å®ä¾‹çš„æ„å»º</span><a href="#æ ¼å¼åŒ–å®ä¾‹çš„æ„å»º" class="header-anchor">#</a></h5><ul>
<li>æ ¼å¼åŒ–å·²æœ‰æ•°æ®é›†</li>
<li>æ ¼å¼åŒ–äººç±»éœ€æ±‚</li>
<li>æ„å»ºå®ä¾‹çš„å…³é”®å› ç´ <ul>
<li><strong>å¢åŠ æŒ‡ä»¤</strong></li>
<li><strong>è®¾è®¡æ ¼å¼</strong></li>
</ul>
</li>
</ul>
<p>æ€»çš„æ¥è¯´ï¼ŒæŒ‡ä»¤<strong>å¤šæ ·æ€§ä¼¼ä¹æ¯”å®ä¾‹æ•°é‡æ›´é‡è¦</strong></p>
<h5><span id="æŒ‡ä»¤å¾®è°ƒç­–ç•¥">æŒ‡ä»¤å¾®è°ƒç­–ç•¥</span><a href="#æŒ‡ä»¤å¾®è°ƒç­–ç•¥" class="header-anchor">#</a></h5><ul>
<li><p><strong>å¹³è¡¡æ•°æ®åˆ†å¸ƒ</strong><br>ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æ–¹æ³•æ˜¯å®ä¾‹æ¯”ä¾‹æ··åˆç­–ç•¥ [87]ï¼Œå³å°†æ‰€æœ‰æ•°æ®é›†åˆå¹¶ï¼Œç„¶åä»æ··åˆæ•°æ®é›†ä¸­æŒ‰æ¯”ä¾‹é‡‡æ ·æ¯ç§å®ä¾‹ã€‚<br>æ­¤å¤–ï¼Œæ ¹æ®æœ€è¿‘çš„ç ”ç©¶å‘ç° [64, 99]ï¼Œ<strong>æé«˜é«˜è´¨é‡æ•°æ®é›†ï¼ˆä¾‹å¦‚ FLAN [62] å’Œ P3 [209]ï¼‰çš„é‡‡æ ·æ¯”ä¾‹</strong>é€šå¸¸å¯ä»¥å¸¦æ¥<strong>æ€§èƒ½æå‡</strong>ã€‚</p>
</li>
<li><p>ç»“åˆæŒ‡ä»¤å¾®è°ƒå’Œé¢„è®­ç»ƒ<br>ä¸ºäº†ä½¿å¾®è°ƒè¿‡ç¨‹æ›´åŠ æœ‰æ•ˆå’Œç¨³å®šï¼ŒOPT-IML [99] åœ¨<strong>æŒ‡ä»¤å¾®è°ƒæœŸé—´åŠ å…¥äº†é¢„è®­ç»ƒæ•°æ®</strong>ï¼Œè¿™å¯ä»¥çœ‹ä½œæ˜¯å¯¹æ¨¡å‹çš„æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰ã€‚</p>
</li>
</ul>
<p>å…·ä½“è€Œè¨€ï¼ŒGLM-130B [97] å’Œ Galactica [34] å°†<strong>æŒ‡ä»¤æ ¼å¼æ•°æ®é›†ä½œä¸ºé¢„è®­ç»ƒè¯­æ–™åº“çš„ä¸€å°éƒ¨åˆ†æ¥é¢„è®­ç»ƒ LLM</strong>ï¼Œè¿™æœ‰å¯èƒ½åŒæ—¶è·å¾—é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒçš„ä¼˜åŠ¿ã€‚</p>
<h5><span id="æŒ‡ä»¤å¾®è°ƒçš„æ•ˆæœ">æŒ‡ä»¤å¾®è°ƒçš„æ•ˆæœ</span><a href="#æŒ‡ä»¤å¾®è°ƒçš„æ•ˆæœ" class="header-anchor">#</a></h5><ul>
<li>æ€§èƒ½æ”¹è¿›<br>æœ€è¿‘çš„ç ”ç©¶åœ¨å¤šä¸ªè§„æ¨¡ä¸Šï¼ˆä» 7700 ç™¾ä¸‡åˆ° 5400 äº¿ä¸ç­‰ï¼‰å¯¹ LM è¿›è¡Œäº†å®éªŒï¼Œ**è¡¨æ˜ä¸åŒè§„æ¨¡çš„æ¨¡å‹éƒ½å¯ä»¥ä»æŒ‡ä»¤å¾®è°ƒä¸­å—ç›Š [64, 216]ï¼Œéšç€å‚æ•°è§„æ¨¡çš„å¢åŠ ï¼Œæ€§èƒ½ä¹Ÿå¾—åˆ°äº†æå‡ [98]**ã€‚ ã€æ™®é€‚æ€§ã€‘</li>
</ul>
<p>æ­¤å¤–ï¼Œ**ç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„è¾ƒå°æ¨¡å‹ç”šè‡³å¯ä»¥æ¯”æœªç»å¾®è°ƒçš„è¾ƒå¤§æ¨¡å‹è¡¨ç°æ›´å¥½ [28, 64]**ã€‚</p>
<ul>
<li>ä»»åŠ¡æ³›åŒ–æ€§<br>todo</li>
</ul>
<h3><span id="å¯¹é½è°ƒä¼˜">å¯¹é½è°ƒä¼˜</span><a href="#å¯¹é½è°ƒä¼˜" class="header-anchor">#</a></h3><h3><span id="é«˜æ•ˆè°ƒä¼˜">é«˜æ•ˆè°ƒä¼˜</span><a href="#é«˜æ•ˆè°ƒä¼˜" class="header-anchor">#</a></h3><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="http://aibox.ruc.edu.cn/docs/2023-08/cb9badcb213f4c8b89d00d579eed4a4c.pdf">å¤§è¯­è¨€æ¨¡å‹ç»¼è¿°</a> ä¸­æ–‡  v10<br>  <a href="https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf">å¤§è¯­è¨€æ¨¡å‹ç»¼è¿°</a> ä¸­æ–‡<br>  <a href="https://github.com/www6v/LLMSurvey">LLMSurvey Repo</a>  git<br>  <a href="https://zhuanlan.zhihu.com/p/630203554">[è®ºæ–‡]å¤§è¯­è¨€æ¨¡å‹ç»¼è¿°</a><br>  <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400817&idx=1&sn=c1ed1c9c87bf2526e02d21d84429c5cf">è¯¦è°ˆå¤§æ¨¡å‹è®­ç»ƒä¸­çš„æ•°æ®æ”¶é›†ã€å¤„ç†ä¸æ¨¡å‹å½±å“ï¼šA Survey of Large Language Modelså·¥ä½œä¸­çš„æ•°æ®æ€»ç»“</a><br>  <a href="https://zhuanlan.zhihu.com/p/662673023">å¤§æ¨¡å‹ç»¼è¿°-A Survey of Large Language Models</a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648408221&idx=1&sn=2874583ed668ae0b89889c81a4ab8d79">å€¼å¾—ä¸€çœ‹çš„å¤§æ¨¡å‹æœ€æ–°ç»¼è¿°ï¼šå…¼çœ‹å¤šè¯­ç§å¤§æ¨¡å‹å¾®è°ƒæ•°æ®é›†Aya </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/381282229">43é¡µé¢„è®­ç»ƒæ¨¡å‹ç»¼è¿°ï¼ˆæ¸…åã€å¤æ—¦ã€äººå¤§ï¼‰</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>å¤§æ¨¡å‹</category>
      </categories>
      <tags>
        <tag>å¤§æ¨¡å‹</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Training</title>
    <url>/www6vHomeAIGC/2022/11/19/gptLargeModelTraining/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#training-pipeline0">Training Pipeline[0]</a><ul>
<li><a href="#%E8%AE%BE%E7%BD%AE%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0-2">è®¾ç½®è®­ç»ƒå‚æ•° [2]</a></li>
<li><a href="#%E5%8F%82%E6%95%B0%E9%87%8F-vs-%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%87%8F-2">å‚æ•°é‡ vs è®­ç»ƒæ•°æ®é‡ [2]</a></li>
</ul>
</li>
<li><a href="#pre-training">Pre-training</a><ul>
<li><a href="#pre-training-4">Pre-training [4]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="training-pipeline0">Training Pipeline[0]</span><a href="#training-pipeline0" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/11/19/gptLargeModelTraining/bigModelTrainingPipeline.jpg" class>

<p><strong>æ¨¡å‹è®­ç»ƒåˆ†ä¸ºå››ä¸ªé˜¶æ®µ</strong> [2]</p>
<ul>
<li>é¢„è®­ç»ƒï¼ˆPretrainingï¼‰ â€“&gt;Base model  <ul>
<li>é¢„è®­ç»ƒæŠ€æœ¯<br>é¢„è®­ç»ƒæœ¬è´¨ä¸Šæ˜¯â¼€ä¸ªâ½†ç›‘ç£å­¦ä¹ è¿‡ç¨‹</li>
</ul>
</li>
<li>ç›‘ç£å¾®è°ƒï¼ˆSupervised Finetuningï¼‰ â€“&gt; SFT model<br>æ ¸â¼¼åŸå› è¿˜æ˜¯åœ¨äºéœ€è¦â€œèµ‹äºˆâ€â¼¤æ¨¡å‹æ›´åŠ å®šåˆ¶åŒ–çš„åŠŸèƒ½</li>
<li>å¥–åŠ±å»ºæ¨¡ï¼ˆReward Modelingï¼‰</li>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰</li>
</ul>
<p><strong>ä¸‰ä¸ªè§’åº¦è§£æ</strong> [2]</p>
<ul>
<li>æ•°æ®é‡ï¼š<strong>é¢„è®­ç»ƒ</strong>é˜¶æ®µæ‰€éœ€çš„<strong>æ•°æ®é‡å¾ˆå¤§</strong>ï¼Œä½†<strong>è´¨é‡è¦æ±‚ä¸é«˜</strong>ï¼›è€Œ<strong>åé¢çš„ä¸‰ä¸ªé˜¶æ®µ</strong>æ°æ°ç›¸åï¼Œéœ€è¦çš„<strong>æ•°æ®è´¨é‡è¾ƒé«˜</strong>ã€‚</li>
<li>è®­ç»ƒæ–¹æ³•ï¼š<strong>é¢„è®­ç»ƒå’Œç›‘ç£å¾®è°ƒ</strong>çš„è®­ç»ƒæ–¹æ³•ç›¸åŒï¼Œéƒ½æ˜¯<strong>é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯</strong>ã€‚å¥–åŠ±æ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒæ–¹æ³•åˆ™ä¸åŒã€‚<strong>å¥–åŠ±æ¨¡å‹</strong>æ˜¯<strong>äºŒå…ƒåˆ†ç±»å­¦ä¹ </strong>ï¼Œè€Œ<strong>å¼ºåŒ–å­¦ä¹ </strong>åˆ™é¼“åŠ±æ¨¡å‹ç”Ÿæˆå¥–åŠ±æ¨¡å‹è¯„åˆ†è¾ƒé«˜çš„å›ç­”ã€‚</li>
<li>è®­ç»ƒæ‰€éœ€èµ„æºï¼šé¢„è®­ç»ƒé˜¶æ®µçš„èµ„æºæ¶ˆè€—å·¨å¤§ï¼Œä½¿ç”¨æ•°åƒé¢—GPUï¼ŒèŠ±è´¹<strong>æ•°æœˆ</strong>æ—¶é—´ï¼Œå æ€»è®­ç»ƒæ—¶é—´çš„99%ã€‚åé¢çš„ä¸‰ä¸ªé˜¶æ®µåªéœ€ä½¿ç”¨æ•°åé¢—GPUï¼Œè®­ç»ƒæ—¶é—´çº¦<strong>æ•°å¤©</strong>ã€‚</li>
</ul>
<h3><span id="è®¾ç½®è®­ç»ƒå‚æ•°-2">è®¾ç½®è®­ç»ƒå‚æ•° [2]</span><a href="#è®¾ç½®è®­ç»ƒå‚æ•°-2" class="header-anchor">#</a></h3><p>è®¾ç½®è®­ç»ƒå‚æ•°ï¼Œå¦‚batch-sizeã€learning rateç­‰</p>
<ul>
<li>é¢„è®­ç»ƒé˜¶æ®µçš„<strong>Batch Sizeéå¸¸å¤§</strong>ï¼ŒèŒƒå›´åœ¨0.5Måˆ°4Mä¹‹é—´ã€‚</li>
<li><strong>Learning rateè®¾å®šè¾ƒå°</strong>ï¼Œä¸”éšç€ç½‘ç»œè§„æ¨¡çš„å¢å¤§ï¼ŒLearning rateè¶Šæ¥è¶Šå°ã€‚</li>
</ul>
<h3><span id="å‚æ•°é‡-vs-è®­ç»ƒæ•°æ®é‡-2">å‚æ•°é‡ vs è®­ç»ƒæ•°æ®é‡ [2]</span><a href="#å‚æ•°é‡-vs-è®­ç»ƒæ•°æ®é‡-2" class="header-anchor">#</a></h3><p><strong>å‚æ•°é‡å¹¶ä¸æ˜¯è¡¡é‡æ¨¡å‹èƒ½åŠ›çš„å”¯ä¸€æ ‡å‡†ï¼Œè®­ç»ƒæ•°æ®é‡ä¹Ÿæ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„å› ç´ ã€‚</strong><br>LLaMAæ¨¡å‹ï¼Œå°½ç®¡å®ƒçš„å‚æ•°é‡åªæœ‰650äº¿ï¼Œä½†å…¶æ€§èƒ½ä¸å‚æ•°é‡ä¸º1750äº¿çš„GPT-3æ¨¡å‹ç›¸æ¯”ä¹Ÿéå¸¸ä¼˜ç§€ã€‚ä¸»è¦åŸå› åœ¨äºï¼ŒLLaMAæ¨¡å‹çš„è®­ç»ƒæ•°æ®é‡è¾¾åˆ°äº†1.4ä¸‡äº¿ï¼Œè€ŒGPT-3åªæœ‰3000äº¿ã€‚</p>
<h1><span id="pre-training">Pre-training</span><a href="#pre-training" class="header-anchor">#</a></h1><h3><span id="pre-training-4">Pre-training [4]</span><a href="#pre-training-4" class="header-anchor">#</a></h3><ul>
<li><p>â¾ƒå›å½’ä¸â½£æˆå¼</p>
<ul>
<li><strong>â¾ƒå›å½’æ¨¡å‹</strong>æ˜¯â¼€ç§åºåˆ—æ¨¡å‹ï¼Œå®ƒåœ¨é¢„æµ‹ä¸‹â¼€ä¸ªè¾“å‡ºæ—¶ï¼Œä¼šå°†ä¹‹å‰çš„æ‰€æœ‰è¾“å‡ºä½œä¸ºè¾“â¼Šï¼Œç„¶å<strong>æ ¹æ®ç»Ÿè®¡è§„å¾‹ã€ç»“åˆå·²ç»è¾“â¼Šçš„æ ·æœ¬</strong>ï¼Œé¢„æµ‹ä¸‹ä¸ªä½ç½®å„å•è¯å‡ºç°çš„æ¦‚ç‡ï¼Œç„¶åè¾“å‡ºæ¦‚ç‡æœ€â¼¤çš„å•è¯ï¼Œç±»ä¼¼äºå®Œå½¢å¡«ç©ºï¼›</li>
<li><strong>â½£æˆå¼æ¨¡å‹</strong>çš„é¢„æµ‹è¿‡ç¨‹å’Œâ¾ƒå›å½’æ¨¡å‹ç±»ä¼¼ï¼Œéƒ½æ˜¯æ ¹æ®ç»Ÿ<br>è®¡è§„å¾‹é¢„æµ‹ä¸‹ä¸ªå•è¯çš„æ¦‚ç‡ï¼Œæ‰€ä¸åŒçš„æ˜¯ï¼Œ<strong>â½£æˆå¼æ¨¡å‹å¯ä»¥æ ¹æ®ä¹‹å‰çš„æ ·æœ¬çš„<br>æ¦‚ç‡åˆ†å¸ƒâ½£æˆä¸‹â¼€ä¸ªè¯ï¼Œâ½£æˆå¼æ¨¡å‹é¢„æµ‹æ—¶ä¼šå­˜åœ¨â¼€å®šçš„éšæœºæ€§ï¼›</strong></li>
</ul>
</li>
<li><p>GPTæ¥è¯´ï¼Œå°±æ˜¯â¼€ä¸ªâ¾ƒå›å½’â½£æˆå¼æ¨¡å‹ [4]<br>â¼€ä¸ªâ¾ƒå›å½’â½£æˆå¼æ¨¡å‹åœ¨è¿›â¾é¢„æµ‹çš„æ—¶å€™ï¼Œ<strong>ä¼šâ¾¸å…ˆæ ¹æ®â¾ƒå›å½’æ¨¡å‹ï¼Œåœ¨å‚è€ƒåˆ°â½¬å‰ä¸ºâ½Œ<br>å·²ç»â½£æˆçš„è¯çš„æƒ…å†µä¸‹ç¡®å®šä¸‹â¼€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åå†æ ¹æ®â½£æˆå¼çš„â½…å¼æ¥æ ¹æ®è¿™ä¸ª<br>åˆ†å¸ƒâ½£æˆä¸‹â¼€ä¸ªè¯</strong></p>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="0">
<li><p><a href="https://zhuanlan.zhihu.com/p/648050614">LLMå­¦ä¹ ç³»åˆ—1ï¼šå¤§æ¨¡å‹æ¶æ„è¦ç‚¹æ€»ç»“</a>  from ppt</p>
</li>
<li><p>xxx</p>
</li>
<li><p><a href="https://techdiylife.github.io/big-model-training/deepspeed/LLM-state-of-GPT.html">å¤§æ¨¡å‹è®­ç»ƒå…¥é—¨å®æˆ˜</a>  ***<br><a href="https://karpathy.ai/stateofgpt.pdf">State of GPT</a><br><a href="https://mp.weixin.qq.com/s/zmEGzm1cdXupNoqZ65h7yg">State of GPTï¼šå¤§ç¥Andrejæ­ç§˜OpenAIå¤§æ¨¡å‹åŸç†å’Œè®­ç»ƒè¿‡ç¨‹ </a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2328541">ä¸»æµå¤§è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯åŸç†ç»†èŠ‚</a> *** è…¾è®¯     æ¶æ„ + è®­ç»ƒ + å¾®è°ƒ</p>
</li>
<li><p>å¤§æ¨¡å‹å…¥é—¨å¿…çœ‹æ•™ç¨‹  ä¹å¤©Hector</p>
</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399532&idx=1&sn=31b7bc5a4f3114d8215da0edc2559e47">è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŸºç¡€çŸ¥è¯†æ€»ç»“ï¼šæ ‡å‡†æ•°æ®æµpiplelineã€tokenizerçš„è®¤è¯†ä»¥åŠå¸¸è§ç¼–ç æ¨¡å‹èŒƒå¼ </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/651316650">ä»å¤´é¢„è®­ç»ƒå¤§æ¨¡å‹å®è·µç»éªŒ</a>  ***<br><a href="https://wandb.ai/site/wp-content/uploads/2023/09/Current-Best-Practices-for-Training-LLMs-from-Scratch-Final.pdf">Current Best Practices for Training LLMs from Scratch</a>  åŸæ–‡</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)Training</title>
    <url>/www6vHomeAIGC/2023/01/15/gptLargeModelTrainingPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://zhuanlan.zhihu.com/p/636270877">ã€LLMã€‘ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹</a> ***  æœª<br>     <a href="https://www.bilibili.com/video/BV1a14y1o7fr/">ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹</a> V<br>1xx. <a href="http://arthurchiao.art/blog/how-to-train-a-gpt-assistant-zh/">[è¯‘] å¦‚ä½•è®­ç»ƒä¸€ä¸ªä¼ä¸šçº§ GPT åŠ©æ‰‹ï¼ˆOpenAIï¼Œ2023ï¼‰</a> æœª<br>1xx. <a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/huggingface/index.ipynb">chatgpt2 è®­ç»ƒ</a>  10.5   10.6</p>
<h3><span id="å°æ¨¡å‹è®­ç»ƒ-poc">å°æ¨¡å‹è®­ç»ƒ PoC</span><a href="#å°æ¨¡å‹è®­ç»ƒ-poc" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/660759033">LLMä»0å¼€å§‹é¢„è®­ç»ƒç³»åˆ—ï¼š1ã€å¤§æ¨¡å‹è®­ç»ƒè¸©å‘</a><br>1xx. <a href="http://arthurchiao.art/blog/gpt-as-a-finite-state-markov-chain-zh/">[è¯‘] GPT æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼š200 è¡Œ Python ä»£ç å®ç°ä¸€ä¸ªæç®€ GPTï¼ˆ2023ï¼‰</a>  æœª</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>æ’è¡Œæ¦œ</title>
    <url>/www6vHomeAIGC/2023/01/04/gptLeaderBoard/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B">å¤§æ¨¡å‹</a><ul>
<li><a href="#%E6%8E%92%E8%A1%8C%E6%A6%9C">æ’è¡Œæ¦œ</a></li>
<li><a href="#%E4%B8%AD%E5%9B%BD%E6%8E%92%E8%A1%8C%E6%A6%9C">ä¸­å›½æ’è¡Œæ¦œ</a></li>
</ul>
</li>
<li><a href="#%E6%98%BE%E5%8D%A1">æ˜¾å¡</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="å¤§æ¨¡å‹">å¤§æ¨¡å‹</span><a href="#å¤§æ¨¡å‹" class="header-anchor">#</a></h1><h3><span id="æ’è¡Œæ¦œ">æ’è¡Œæ¦œ</span><a href="#æ’è¡Œæ¦œ" class="header-anchor">#</a></h3><p><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">HuggingFaceH å¤§æ¨¡å‹æ’è¡Œæ¦œ</a></p>
<p><a href="https://www.promptingguide.ai/models/collection">LLM Collection</a></p>
<h3><span id="ä¸­å›½æ’è¡Œæ¦œ">ä¸­å›½æ’è¡Œæ¦œ</span><a href="#ä¸­å›½æ’è¡Œæ¦œ" class="header-anchor">#</a></h3><p><a href="https://github.com/www6v/awesome-LLMs-In-China">ä¸­å›½å¤§æ¨¡å‹ </a></p>
<ul>
<li>é€šç”¨ 39</li>
<li>é‡‘è 25</li>
<li>å¸æ³• 8</li>
<li>æ³•å¾‹ 6</li>
<li>åŒ»å­¦ 13</li>
<li>åŒ»ç–— 24</li>
<li>æ•™è‚² 13</li>
<li>ç§‘ç ” 17</li>
<li>å·¥ä¸š 23</li>
<li>æ”¿åŠ¡ 12</li>
<li>è¿ç»´ 7</li>
</ul>
<h1><span id="æ˜¾å¡">æ˜¾å¡</span><a href="#æ˜¾å¡" class="header-anchor">#</a></h1><ul>
<li><p>æ˜¾å¡å¤©æ¢¯æ¦œ<br> <a href="https://topic.expreview.com/GPU">æ˜¾å¡å¤©æ¢¯æ¦œ</a></p>
</li>
<li><p>æ˜¾å¡<br>æ˜¾å¡ &#x3D; GPU +  æ˜¾å­˜</p>
</li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>leaderBoard</category>
      </categories>
      <tags>
        <tag>leaderBoard</tag>
      </tags>
  </entry>
  <entry>
    <title>LLaMA</title>
    <url>/www6vHomeAIGC/2023/01/01/gptLlama/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#llama-%E6%9E%B6%E6%9E%84architecture1">LLaMA æ¶æ„ï¼ˆArchitectureï¼‰[1]</a><ul>
<li><a href="#%E9%A2%84%E5%BD%92%E4%B8%80%E5%8C%96pre-normalization%E5%8F%97-gpt3-%E5%90%AF%E5%8F%91">é¢„å½’ä¸€åŒ–ï¼ˆPre-normalizationï¼‰ï¼šå— GPT3 å¯å‘</a></li>
<li><a href="#swiglu-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%8F%97-palm-%E5%90%AF%E5%8F%91">SwiGLU æ¿€æ´»å‡½æ•°ï¼šå— PaLM å¯å‘</a></li>
<li><a href="#%E6%97%8B%E8%BD%AC%E5%B5%8C%E5%85%A5rotary-embeddings%E5%8F%97-gptneo-%E5%90%AF%E5%8F%91">æ—‹è½¬åµŒå…¥ï¼ˆRotary Embeddingsï¼‰ï¼šå— GPTNeo å¯å‘</a></li>
</ul>
</li>
<li><a href="#llama2">LLaMA2</a><ul>
<li><a href="#%E6%AF%94%E8%BE%83-21">æ¯”è¾ƒ [21]</a></li>
<li><a href="#%E8%AE%AD%E7%BB%83%E7%9A%84%E6%9E%B6%E6%9E%8410">è®­ç»ƒçš„æ¶æ„[10]</a></li>
<li><a href="#%E4%B8%8Ellama%E4%B8%BB%E8%A6%81%E5%8C%BA%E5%88%AB11">ä¸LLaMAä¸»è¦åŒºåˆ«ï¼š[11]</a></li>
</ul>
</li>
<li><a href="#llama3">LLaMA3</a><ul>
<li><a href="#%E6%8A%80%E6%9C%AF%E7%82%B9-20">æŠ€æœ¯ç‚¹ [20]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#llama">LLaMA</a></li>
<li><a href="#llama2-1">LLaMA2</a></li>
</ul>
</li>
<li><a href="#llama3-1">LLaMA3</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="llama-æ¶æ„architecture1">LLaMA æ¶æ„ï¼ˆArchitectureï¼‰[1]</span><a href="#llama-æ¶æ„architecture1" class="header-anchor">#</a></h1><h3><span id="é¢„å½’ä¸€åŒ–pre-normalizationå—-gpt3-å¯å‘">é¢„å½’ä¸€åŒ–ï¼ˆPre-normalizationï¼‰ï¼šå— GPT3 å¯å‘</span><a href="#é¢„å½’ä¸€åŒ–pre-normalizationå—-gpt3-å¯å‘" class="header-anchor">#</a></h3><p>ä¸ºäº†æé«˜<strong>è®­ç»ƒç¨³å®šæ€§</strong>ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ª Transformer sub-layer çš„<strong>è¾“å…¥</strong>è¿›è¡Œå½’ä¸€åŒ–ï¼Œè€Œä¸æ˜¯å¯¹<strong>è¾“å‡º</strong>è¿›è¡Œå½’ä¸€åŒ–ã€‚ è¿™é‡Œä½¿ç”¨ç”± Zhang å’Œ Sennrichï¼ˆ2019ï¼‰æå‡ºçš„ RMSNorm å½’ä¸€åŒ–å‡½æ•°ã€‚</p>
<h3><span id="swiglu-æ¿€æ´»å‡½æ•°å—-palm-å¯å‘">SwiGLU æ¿€æ´»å‡½æ•°ï¼šå— PaLM å¯å‘</span><a href="#swiglu-æ¿€æ´»å‡½æ•°å—-palm-å¯å‘" class="header-anchor">#</a></h3><p>ç”¨ SwiGLU æ¿€æ´»å‡½æ•°æ›¿æ¢ ReLU éçº¿æ€§ï¼Œè¯¥å‡½æ•°ç”± Shazeerï¼ˆ2020ï¼‰æå‡ºï¼Œç›®çš„æ˜¯<strong>æå‡æ€§èƒ½</strong>ã€‚ ä½†æˆ‘ä»¬ä½¿ç”¨çš„ç»´åº¦æ˜¯ <code>2/3 * 4d</code>ï¼Œè€Œä¸æ˜¯ PaLM ä¸­çš„ <code>4d</code>ã€‚</p>
<h3><span id="æ—‹è½¬åµŒå…¥rotary-embeddingså—-gptneo-å¯å‘">æ—‹è½¬åµŒå…¥ï¼ˆRotary Embeddingsï¼‰ï¼šå— GPTNeo å¯å‘</span><a href="#æ—‹è½¬åµŒå…¥rotary-embeddingså—-gptneo-å¯å‘" class="header-anchor">#</a></h3><p>å»æ‰äº†ç»å¯¹ä½ç½®åµŒå…¥ï¼ˆabsolute positional embeddingsï¼‰ï¼Œå¹¶åœ¨æ¯ä¸ªç½‘ç»œå±‚ä¸­æ·»åŠ æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆrotary positional embeddingsï¼ŒRoPEï¼‰ã€‚ RoPE ç”± Su ç­‰ï¼ˆ2021ï¼‰æå‡ºã€‚</p>
<h1><span id="llama2">LLaMA2</span><a href="#llama2" class="header-anchor">#</a></h1><h3><span id="æ¯”è¾ƒ-21">æ¯”è¾ƒ [21]</span><a href="#æ¯”è¾ƒ-21" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/01/01/gptLlama/llama2.png" class>

<h3><span id="è®­ç»ƒçš„æ¶æ„10">è®­ç»ƒçš„æ¶æ„[10]</span><a href="#è®­ç»ƒçš„æ¶æ„10" class="header-anchor">#</a></h3><p>Llama2é‡‡ç”¨äº†Llama 1ä¸­çš„å¤§éƒ¨åˆ†é¢„è®­ç»ƒè®¾ç½®å’Œæ¨¡å‹æ¶æ„ã€‚ä½¿ç”¨RMSNormåº”ç”¨é¢„å½’ä¸€åŒ–ï¼Œä½¿ç”¨SwiGLUæ¿€æ´»å‡½æ•°å’Œæ—‹è½¬ä½ç½®åµŒå…¥ã€‚</p>
<p>å…·ä½“çš„ï¼Œä½¿ç”¨AdamWä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡æ–¹å¼æ¥åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡ï¼Œé¢„çƒ­2000æ­¥ï¼Œå¹¶å°†æœ€ç»ˆå­¦ä¹ ç‡è¡°å‡åˆ°å³°å€¼å­¦ä¹ ç‡çš„10%ï¼Œå¹¶ä½¿ç”¨0.1çš„æƒé‡è¡°å‡å’Œ1.0çš„æ¢¯åº¦è£å‰ªã€‚</p>
<p>ä¸Llama 1çš„ä¸»è¦æ¶æ„å·®å¼‚åŒ…æ‹¬å¢åŠ äº†<strong>ä¸Šä¸‹æ–‡é•¿åº¦ã€ä¸¤å€å…³ç³»ã€‘</strong>å’Œ**åˆ†ç»„æŸ¥è¯¢å…³æ³¨(GQA)**ã€‚</p>
<p>åˆ†è¯å™¨æ–¹é¢ï¼Œä½¿ç”¨ä¸Llama 1ç›¸åŒçš„æ ‡è®°å™¨ï¼Œé‡‡ç”¨å­—èŠ‚å¯¹ç¼–ç (BPE)ç®—æ³•ï¼Œä½¿ç”¨sentencepeceçš„å®ç°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ<strong>ä¸Llama 1ä¸€æ ·ï¼Œå°†æ‰€æœ‰æ•°å­—æ‹†åˆ†ä¸ºå•ä¸ªæ•°å­—ï¼Œå¹¶ä½¿ç”¨å­—èŠ‚æ¥åˆ†è§£æœªçŸ¥çš„UTF-8å­—ç¬¦ã€‚æ€»è¯æ±‡è¡¨å¤§å°ä¸º32kã€‚</strong></p>
<h3><span id="ä¸llamaä¸»è¦åŒºåˆ«11">ä¸LLaMAä¸»è¦åŒºåˆ«ï¼š[11]</span><a href="#ä¸llamaä¸»è¦åŒºåˆ«11" class="header-anchor">#</a></h3><ul>
<li>æ›´å¤šçš„è®­ç»ƒæ•°æ®<br> 1.4T -&gt; 2T</li>
<li>æ›´â»“çš„ä¸Šä¸‹æ–‡çª—å£<br> 2k-&gt; 4k</li>
<li>GQAæŠ€æœ¯</li>
<li>å®Œæ•´çš„RLHFé“¾æ¡</li>
</ul>
<h1><span id="llama3">LLaMA3</span><a href="#llama3" class="header-anchor">#</a></h1><h3><span id="æŠ€æœ¯ç‚¹-20">æŠ€æœ¯ç‚¹ [20]</span><a href="#æŠ€æœ¯ç‚¹-20" class="header-anchor">#</a></h3><ul>
<li><p>GQA<br>  å¼•å…¥äº†<strong>Grouped Query Attention (GQA)<strong>ï¼Œè¿™å¯ä»¥</strong>å‡å°‘æ¨ç†è¿‡ç¨‹ä¸­çš„KVç¼“å­˜å¤§å°</strong>ï¼Œå¢åŠ æ¨ç†æ•ˆç‡<br>  æ€§èƒ½æå‡ä¸»è¦æ¥è‡ªäº<strong>kv cacheçš„sizeå‡å°</strong>ï¼Œé‚£ä¹ˆkv cacheå ç”¨çš„æ˜¾å­˜å°±å˜å°ï¼Œé‚£ä¹ˆæˆ‘ä»¬LLM servingå¯ä»¥å¤„ç†çš„è¯·æ±‚æ•°é‡å°±<strong>æ›´å¤š</strong>ï¼Œbatchsize<strong>æ›´å¤§</strong>ï¼Œååé‡å°±<strong>å˜å¤§</strong></p>
</li>
<li><p>ç¼–ç è¯è¡¨ BBPE<br>BBPEï¼šå°†å¥å­æ„å»ºä¸º<strong>UTF-8ç¼–ç å­—èŠ‚åº</strong>åˆ—è€Œéå­—ç¬¦åºåˆ—ï¼Œå†è¿›è¡Œ<strong>BPE</strong>è¿›è¡Œå­¦ä¹ <br>Tokenè¯å…¸ä»LLAMA-2çš„32Kæ‹“å±•åˆ°äº†<strong>128K</strong>ï¼Œä»¥å¢åŠ ç¼–ç æ•ˆç‡</p>
</li>
<li><p>æ•°æ®åˆæˆ</p>
<ul>
<li>ç”¨ llama2 <strong>åŠè‡ªåŠ¨åœ°åˆæˆ</strong>ä¸€äº›æ•°æ®<br>ä¾‹å¦‚ç”Ÿæˆç»™å®šè¯é¢˜ä¸‹é¢çš„ä¸€äº›æ ·ä¾‹æ•°æ®ï¼Œæˆ–è€…åŠ ä¸€ä¸ªç³»ç»Ÿæç¤ºè®©å®ƒå¯¹ç»™å®šçš„æ–‡æœ¬åœ¨æŸäº›ç»´åº¦ä¸Šæ‰“åˆ†, ç„¶åè®­ç»ƒä¸€äº›<strong>åˆ†ç±»&#x2F;æ‰“åˆ†å™¨</strong>ï¼Œå»è¿‡æ»¤é¢„è®­ç»ƒè¯­æ–™ã€‚</li>
</ul>
</li>
<li><p>æ¨¡å‹çš„æ¬¡ä¼˜åŒ–</p>
<ul>
<li>Sub-optimal Chinchilla Law<br>.ä¸€ä¸ªæ˜¯<strong>å›ºå®šä½æ¨¡å‹å¤§å°</strong>ï¼ŒæŒç»­å¢åŠ è®­ç»ƒæ•°æ®ï¼Œæ¨¡å‹æ•ˆæœä¼šæŒç»­å˜å¥½<br>å¦å¤–ä¸€ä¸ªæ˜¯<strong>å›ºå®šä½è®­ç»ƒæ•°æ®é‡</strong>ï¼Œé‚£ä¹ˆä½ æŒç»­æ”¾å¤§æ¨¡å‹å‚æ•°è§„æ¨¡ï¼ŒåŒæ ·çš„ï¼Œæ¨¡å‹æ•ˆæœä¹Ÿä¼šè¶Šæ¥æ„ˆå¥½</li>
</ul>
</li>
<li><p>DPOè®­ç»ƒæ–¹æ³•</p>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="llama">LLaMA</span><a href="#llama" class="header-anchor">#</a></h3><ol>
<li><a href="http://arthurchiao.art/blog/llama-paper-zh/">[è¯‘][è®ºæ–‡] LLaMAï¼šå¼€æ”¾å’Œé«˜æ•ˆçš„åŸºç¡€è¯­è¨€æ¨¡å‹é›†</a><br>1xx. <a href="https://www.bilibili.com/video/BV1nN41157a9/">ç¬¬åäº”è¯¾ï¼šLLaMA</a>  *** åä¸º  V<br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399298&idx=1&sn=dd83c4f42c68a89f8199f990e7570586">Metaæœ€æ–°è¯­è¨€æ¨¡å‹LLaMAè®ºæ–‡ç ”è¯»ï¼šå°å‚æ•°+å¤§æ•°æ®çš„å¼€æ”¾ã€é«˜æ•ˆåŸºç¡€è¯­è¨€æ¨¡å‹é˜…è¯»ç¬”è®° </a></li>
</ol>
<h3><span id="llama2">LLaMA2</span><a href="#llama2" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401927&idx=1&sn=3dddcb5c1d8b3c246a8b7529502fdcf0">ä¹Ÿè°ˆå‡Œæ™¨åˆ·å±çš„Llama2å¼€æºå¯å•†ç”¨æ¨¡å‹ï¼šä»å…¶æ•°æ®æ„é€ ã€æ¨¡å‹æ¶æ„å’Œè¯„ä¼°æ–¹å¼ç­‰æ–¹é¢çš„ä¸€äº›æ€»ç»“ä¸å‘ç° </a></li>
<li><a href="https://www.bilibili.com/video/BV1qQ4y1t7Aj/">ã€å¯¹è¯å¼•æ“åº”ç”¨ã€‘åƒå¸†ä¸­æ–‡å¢å¼ºLlama2æå‡å¤§æ¨¡å‹å¯¹è¯æŒ‡ä»¤éµå¾ªèƒ½åŠ›</a>  ç™¾åº¦<br>1xx. <a href="https://zhuanlan.zhihu.com/p/649756898">Llama 2è¯¦è§£</a>  ***<br><a href="https://www.bilibili.com/video/BV12h4y1N7C8/">Llama 2 æ¨¡å‹ç»“æ„è§£æ</a> *** V<br>1xx. <a href="https://www.bilibili.com/video/BV1Me411z7ZV/">ç¬¬åå…­è¯¾ï¼šLLaMA2</a> *** åä¸º  V<br>1xx. <a href="http://arthurchiao.art/blog/llama2-paper-zh/">[è¯‘][è®ºæ–‡] LLaMA 2ï¼šå¼€æ”¾åŸºç¡€å’Œå¾®è°ƒèŠå¤©æ¨¡å‹</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/644671690">Llama2æŠ€æœ¯ç»†èŠ‚&amp;å¼€æºå½±å“</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648401959&idx=1&sn=582fa45cd00035bac621336f47cce252">å†çœ‹Llama2çš„å®é™…ä½“éªŒä¸æ°‘é—´è¯„æµ‹ï¼šä»ç°æœ‰å…¬å¼€åœ¨çº¿æµ‹è¯•åœ°å€åˆ°å‡ ä¸ªæµ‹è¯•ä¾‹å­çœ‹åˆæ­¥æ•ˆæœåˆ†æ </a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402689&idx=1&sn=a1847ea36cde32bd386f85f41cf197b9">å…³äºå¤§æ¨¡å‹è¡Œä¸šé—®ç­”è½åœ°çš„æŠ€æœ¯æ–¹æ¡ˆå†æ€è€ƒï¼šå…¼çœ‹Llama2ä¸­æ–‡æ±‰åŒ–çš„æˆç«‹æ€§ã€å®ç°è·¯çº¿ä»¥åŠä»£è¡¨é¡¹ç›®</a></li>
</ol>
<h1><span id="llama3">LLaMA3</span><a href="#llama3" class="header-anchor">#</a></h1><ol start="20">
<li>ã€ŠLLAMA3çš„ä¸€äº›æ”¹é€ ç‚¹ã€‹ å¢è€å¸ˆ</li>
<li><a href="https://mp.weixin.qq.com/s/4FtVlX4wlRVwti7OVs3Zlg">ä»Llama-1åˆ°Llama-3 </a><br>1xx.  <a href="https://mp.weixin.qq.com/s/Qrjye1ZAe0NJzWYLFa4plA">å¤§æ¨¡å‹ä¹‹æˆ˜çš„æ–°åºå¹•-ä»Llama3ä¹‹å</a></li>
</ol>
<p>1xx. <a href="https://llama.family/">Llamaä¸­æ–‡ç¤¾åŒº</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>LLaMA</category>
      </categories>
      <tags>
        <tag>LLaMA</tag>
      </tags>
  </entry>
  <entry>
    <title>LLaMA å®¶æ—</title>
    <url>/www6vHomeAIGC/2023/02/24/gptLlamaFamily/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="llama-å®¶æ—1">LLaMA å®¶æ—[1]</span><a href="#llama-å®¶æ—1" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>é¡¹ç›®</th>
<th>æè¿°</th>
<th>æ•°æ®é›†</th>
</tr>
</thead>
<tbody><tr>
<td>LLaMa</td>
<td>åŸºåº§æ¨¡å‹</td>
<td>å…¬å¼€å¯ç”¨çš„æ•°æ®é›†(1T token)</td>
</tr>
<tr>
<td>Stanford Alpaca</td>
<td>ç»“åˆè‹±æ–‡è¯­æ–™é€šè¿‡Self Instructæ–¹å¼å¾®è°ƒLLaMA 7B</td>
<td>Self Instruct from davinci-003 API(52K)</td>
</tr>
<tr>
<td>Vicuna-13B</td>
<td>é€šè¿‡ShareGPT.comçš„7ä¸‡æ¡å¯¹è¯æ•°æ®å¾®è°ƒLLaMA(AlpacaåŸºç¡€ä¹‹ä¸Š, å¤šè½®å¯¹è¯å’Œé•¿åºåˆ—, full fine-tune)</td>
<td>ç”¨æˆ·å…±äº«å¯¹è¯(70K sample)</td>
</tr>
<tr>
<td>BELLE</td>
<td>ç»“åˆä¸­æ–‡è¯­æ–™é€šè¿‡Self Instructæ–¹å¼å¾®è°ƒBLOOMZ-7Bæˆ–LLaMA</td>
<td></td>
</tr>
<tr>
<td>Chinese-LLaMA&#x2F;Chinese-Alpaca</td>
<td>é€šè¿‡ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ&#x2F;æŒ‡ä»¤å¾®è°ƒLLaMA</td>
<td></td>
</tr>
<tr>
<td>å§œå­ç‰™ç³»åˆ—æ¨¡å‹Ziya-LLaMA-13B-v1</td>
<td>åŸºäºLLaMA-13Bçš„ä¸­è‹±æ–‡æ¨¡å‹</td>
<td></td>
</tr>
<tr>
<td>ChatLLaMA(è‹±æ–‡ç‰ˆ)</td>
<td>LLaMAçš„RLHFç‰ˆ</td>
<td></td>
</tr>
<tr>
<td>ColossalChat</td>
<td>é€šè¿‡self-instructæŠ€æœ¯æŒ‡ä»¤å¾®è°ƒLLaMAä¸”åŠ ä¸ŠRLHF</td>
<td></td>
</tr>
</tbody></table>
<img src="/www6vHomeAIGC/2023/02/24/gptLlamaFamily/llama2-famaly.jpg" class>



<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="å®¶æ—">å®¶æ—</span><a href="#å®¶æ—" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://blog.csdn.net/v_JULY_v/article/details/129709105">LLaMAçš„è§£è¯»ä¸å…¶å¾®è°ƒï¼šAlpaca-LoRA&#x2F;Vicuna&#x2F;BELLE&#x2F;ä¸­æ–‡LLaMA&#x2F;å§œå­ç‰™&#x2F;LLaMA 2</a> ***<br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzUyOTA5OTcwMg==&mid=2247485019&idx=1&sn=e3417472c0c1f98aede498fbe905e1a0&">æˆ‘æƒ³å­¦å¤§æ¨¡å‹ï¼Œåº”è¯¥ä»å“ªä¸ªæ¨¡å‹å¼€å§‹ï¼ŸLLaMAç”Ÿæ€å®¶è°±æ•´ç†å’Œåˆ†æ </a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/618695885">NLPï¼ˆä¹ï¼‰ï¼šLLaMA, Alpaca, ColossalChat ç³»åˆ—æ¨¡å‹ç ”ç©¶</a><br>1xx. <a href="https://github.com/www6v/Llama2-Chinese">https://github.com/www6v/Llama2-Chinese</a><br>1xx.  <a href="https://zhuanlan.zhihu.com/p/618321077">ä»0åˆ°1å¤ç°æ–¯å¦ç¦ç¾Šé©¼ï¼ˆStanford Alpaca 7Bï¼‰</a><br> GPUs: 8 å¡ A800 80GB GPUs<br>1xx. &lt;&lt;åƒå¸†å¢å¼ºç‰ˆ Llama 2-æå‡å¤§æ¨¡å‹å¯¹è¯æŒ‡ä»¤éµå¾ªèƒ½åŠ›&gt;&gt;    </p>
<p>1xx. <a href="https://github.com/www6v/Linly">ä¸­æ–‡ LLaMA</a><br>   <a href="https://www.bilibili.com/video/BV1Np4y1j783/">æ˜åŠ›è®¡åˆ’ 23 æœŸ-Linly-Chinese-LLaMA2 ä¸­æ–‡å¼€æºå¤§æ¨¡å‹æ–¹æ¡ˆåˆ†äº«</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>LLaMA</category>
      </categories>
      <tags>
        <tag>LLaMA</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Multi-Agents</title>
    <url>/www6vHomeAIGC/2023/01/21/gptMultiAgents/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%8D%8F%E4%BD%9C%E5%9E%8B%E7%9A%84-multi-agent-%E7%B3%BB%E7%BB%9F12">åä½œå‹çš„ multi-agent ç³»ç»Ÿ[1][2]</a><ul>
<li><a href="#%E6%97%A0%E5%BA%8F%E5%90%88%E4%BD%9C">æ— åºåˆä½œ</a></li>
<li><a href="#%E6%9C%89%E5%BA%8F%E5%90%88%E4%BD%9C">æœ‰åºåˆä½œ</a></li>
</ul>
</li>
<li><a href="#%E7%AB%9E%E4%BA%89%E5%9E%8B%E7%9A%84-multi-agent-%E7%B3%BB%E7%BB%9F12">ç«äº‰å‹çš„ multi-agent ç³»ç»Ÿ[1][2]</a></li>
<li><a href="#%E7%AB%9E%E4%BA%89%E5%9E%8B-vs-%E5%8D%8F%E4%BD%9C%E5%9E%8B">ç«äº‰å‹ vs åä½œå‹</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#survey">survey</a></li>
<li><a href="#xxx">xxx</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="åä½œå‹çš„-multi-agent-ç³»ç»Ÿ12">åä½œå‹çš„ multi-agent ç³»ç»Ÿ[1][2]</span><a href="#åä½œå‹çš„-multi-agent-ç³»ç»Ÿ12" class="header-anchor">#</a></h1><h3><span id="æ— åºåˆä½œ">æ— åºåˆä½œ</span><a href="#æ— åºåˆä½œ" class="header-anchor">#</a></h3><p>å½“ç³»ç»Ÿä¸­æœ‰ä¸‰ä¸ªæˆ–ä¸‰ä¸ªä»¥ä¸Šçš„Agentæ—¶ï¼Œæ¯ä¸ªAgentéƒ½å¯ä»¥è‡ªç”±åœ°å…¬å¼€è¡¨è¾¾è‡ªå·±çš„è§‚ç‚¹å’Œæ„è§ã€‚ä»–ä»¬å¯ä»¥æä¾›åé¦ˆå’Œå»ºè®®ï¼Œä»¥ä¿®æ”¹ä¸å½“å‰ä»»åŠ¡ç›¸å…³çš„ååº”ã€‚<strong>æ•´ä¸ªè®¨è®ºè¿‡ç¨‹ä¸å—æ§åˆ¶ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡ºåºï¼Œä¹Ÿæ²¡æœ‰å¼•å…¥æ ‡å‡†åŒ–çš„åä½œå·¥ä½œæµç¨‹</strong>ã€‚æˆ‘ä»¬æŠŠè¿™ç§å¤šAgentåˆä½œç§°ä¸º<strong>æ— åºåˆä½œ</strong>ã€‚</p>
<p>multi-Agentç³»ç»Ÿä¸­å¼•å…¥ä¸€ä¸ªä¸“é—¨çš„<strong>åè°ƒAgent</strong>ï¼Œè´Ÿè´£æ•´åˆå’Œç»„ç»‡æ‰€æœ‰Agentçš„å“åº”ï¼Œä»è€Œæ›´æ–°æœ€ç»ˆç­”æ¡ˆã€‚</p>
<blockquote>
<p><strong>ChatLLM ç½‘ç»œ</strong>æ˜¯è¿™ä¸€æ¦‚å¿µçš„å…¸èŒƒä»£è¡¨</p>
</blockquote>
<h3><span id="æœ‰åºåˆä½œ">æœ‰åºåˆä½œ</span><a href="#æœ‰åºåˆä½œ" class="header-anchor">#</a></h3><p>å½“ç³»ç»Ÿä¸­çš„Agentéµå®ˆç‰¹å®šè§„åˆ™æ—¶ï¼Œä¾‹å¦‚æŒ‰é¡ºåºé€ä¸€å‘è¡¨æ„è§ï¼Œä¸‹æ¸¸Agentåªéœ€å…³æ³¨ä¸Šæ¸¸çš„äº§å‡ºã€‚è¿™æ ·ï¼Œä»»åŠ¡å®Œæˆæ•ˆç‡å°±ä¼šå¤§å¤§æé«˜ï¼Œæ•´ä¸ªè®¨è®ºè¿‡ç¨‹ä¹Ÿä¼šå˜å¾—äº•ç„¶æœ‰åºã€‚</p>
<blockquote>
<p><strong>CAMEL</strong> æ˜¯<strong>åŒAgent</strong>åˆä½œç³»ç»Ÿçš„æˆåŠŸå®æ–½æ¡ˆä¾‹ã€‚<br><strong>MetaGPT</strong> ä»è½¯ä»¶å¼€å‘ä¸­çš„<strong>ç»å…¸ç€‘å¸ƒæ¨¡å‹</strong>ä¸­æ±²å–çµæ„Ÿï¼Œ<strong>å°†Agentçš„è¾“å…¥&#x2F;è¾“å‡ºæ ‡å‡†åŒ–ä¸ºå·¥ç¨‹æ–‡æ¡£</strong>ã€‚é€šè¿‡å°†å…ˆè¿›çš„äººç±»æµç¨‹ç®¡ç†ç»éªŒç¼–ç åˆ°Agentæç¤ºä¸­ï¼Œå¤šä¸ªAgentä¹‹é—´çš„åˆä½œå˜å¾—æ›´æœ‰æ¡ç†ã€‚ç„¶è€Œï¼Œåœ¨ MetaGPT çš„å®è·µæ¢ç´¢ä¸­ï¼Œæˆ‘ä»¬å‘ç°äº†Multi-Agentåˆä½œçš„æ½œåœ¨å¨èƒã€‚<strong>å¦‚æœä¸åˆ¶å®šç›¸åº”çš„è§„åˆ™ï¼Œå¤šä¸ªAgentä¹‹é—´çš„é¢‘ç¹äº’åŠ¨ä¼šæ— é™æ”¾å¤§è½»å¾®çš„å¹»è§‰</strong>ã€‚</p>
</blockquote>
<h1><span id="ç«äº‰å‹çš„-multi-agent-ç³»ç»Ÿ12">ç«äº‰å‹çš„ multi-agent ç³»ç»Ÿ[1][2]</span><a href="#ç«äº‰å‹çš„-multi-agent-ç³»ç»Ÿ12" class="header-anchor">#</a></h1><p>å½“å¤šä¸ªAgentåœ¨ â€œé’ˆé”‹ç›¸å¯¹â€çš„çŠ¶æ€ä¸‹è¡¨è¾¾è‡ªå·±çš„è®ºç‚¹æ—¶ï¼Œä¸€ä¸ª<strong>Agentå¯ä»¥ä»å…¶ä»–Agenté‚£é‡Œè·å¾—å¤§é‡å¤–éƒ¨åé¦ˆï¼Œä»è€Œçº æ­£è‡ªå·±æ‰­æ›²çš„æƒ³æ³•</strong>ã€‚</p>
<blockquote>
<p><strong>ChatEval</strong>å»ºç«‹äº†ä¸€ä¸ªåŸºäºè§’è‰²æ‰®æ¼”çš„å¤šAgentè£åˆ¤å›¢é˜Ÿã€‚</p>
</blockquote>
<h1><span id="ç«äº‰å‹-vs-åä½œå‹">ç«äº‰å‹ vs åä½œå‹</span><a href="#ç«äº‰å‹-vs-åä½œå‹" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th></th>
<th>åä½œå‹</th>
<th>ç«äº‰å‹</th>
</tr>
</thead>
<tbody><tr>
<td>ç³»ç»Ÿç›®æ ‡</td>
<td>æ•´ä½“</td>
<td>ä¸ªä½“</td>
</tr>
<tr>
<td>ä¸»æµç»“æ„</td>
<td>ä¸­å¿ƒåŒ–</td>
<td>å»ä¸­å¿ƒåŒ–</td>
</tr>
<tr>
<td>agent åŠŸèƒ½</td>
<td>ç›¸å¯¹åˆ†æ•£</td>
<td>ç›¸å¯¹åŒè´¨</td>
</tr>
<tr>
<td>agent å…³ç³»</td>
<td>ç›¸äº’ä¾èµ–</td>
<td>ç›¸äº’ç‹¬ç«‹</td>
</tr>
<tr>
<td>æ˜¯å¦è‡ªè¿è¡Œ</td>
<td>å¦</td>
<td>æ˜¯</td>
</tr>
<tr>
<td>ç³»ç»Ÿèµ„æº</td>
<td>é€šå¸¸ä¸å…±äº«</td>
<td>å…±äº«</td>
</tr>
</tbody></table>
<img src="/www6vHomeAIGC/2023/01/21/gptMultiAgents/multi-agents.webp" class>
<p>åŸºäº LLM çš„å¤šä¸ªä»£ç†çš„äº¤äº’åœºæ™¯ã€‚åœ¨åˆä½œäº’åŠ¨ä¸­ï¼Œä»£ç†ä»¥æ— åºæˆ–æœ‰åºçš„æ–¹å¼è¿›è¡Œåä½œï¼Œä»¥å®ç°å…±åŒç›®æ ‡ã€‚åœ¨å¯¹æŠ—å¼äº¤äº’ä¸­ï¼Œä»£ç†ä»¥é’ˆé”‹ç›¸å¯¹çš„æ–¹å¼å±•å¼€ç«äº‰ï¼Œä»¥æé«˜å„è‡ªçš„æ€§èƒ½ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="survey">survey</span><a href="#survey" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/685286305">åŸºäºå¤§è¯­è¨€æ¨¡å‹å¤šæ™ºä½“çš„ç»¼è¿°ï¼šè¿›æ­¥å’ŒæŒ‘æˆ˜</a> ç»¼è¿°<br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=Mzg5NTc2OTcyOQ==&mid=2247488353&idx=2&sn=374e8671df71ce7c60d2570aacc9fcf6">ä¸‡å­—ç»¼è¿°ï¼šå¤§è¯­è¨€æ¨¡å‹å¤šæ™ºèƒ½ä½“(LLM Multi-Agents)è¿›å±•ä¸æŒ‘æˆ˜</a></p>
<p>1xx. <a href="https://github.com/WooooDyy/LLM-Agent-Paper-List">LLM-Agent-Paper-List</a> ***  git</p>
<ol start="2">
<li><a href="https://zhuanlan.zhihu.com/p/656676717">ã€Šç»¼è¿°ï¼šå…¨æ–°å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„Agentã€‹</a>  *** 4.2</li>
</ol>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><ol>
<li><a href="https://zhuanlan.zhihu.com/p/665644399">NLPï¼ˆå»¿äºŒï¼‰ï¼šLLM æ—¶ä»£çš„ multi-agent ç³»ç»Ÿ</a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=Mzg5NTc2OTcyOQ==&mid=2247487550&idx=1&sn=28c8147920595f385bec3d3b05911ae7">MetaGPT-ICLR2024: é«˜æ•ˆäººç±»å·¥ä½œæµ(SOPs)èå…¥å¤šAgentåä½œï¼Œæ˜¾è‘—æå‡è½¯ä»¶å·¥ç¨‹æ•ˆç‡ï¼</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agents</category>
      </categories>
      <tags>
        <tag>Agents</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)LangGraph,AutoGen</title>
    <url>/www6vHomeAIGC/2023/05/07/gptMultiAgentsPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#langgraph-1">LangGraph [1]</a><ul>
<li><a href="#agent-supervisor">Agent Supervisor</a></li>
<li><a href="#multi-agent-collaboration">Multi Agent Collaboration</a></li>
<li><a href="#hierarchical-agent-teams">Hierarchical Agent Teams</a></li>
</ul>
</li>
<li><a href="#autogen10111213">AutoGen[10,11,12,13]</a><ul>
<li><a href="#autogen-studio20">AutoGen Studio[20]</a></li>
</ul>
</li>
<li><a href="#framework">Framework</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#langgraph">LangGraph</a></li>
<li><a href="#autogen">AutoGen</a></li>
<li><a href="#autogen-studio">AutoGen Studio</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="langgraph-1">LangGraph [1]</span><a href="#langgraph-1" class="header-anchor">#</a></h1><h3><span id="agent-supervisor">Agent Supervisor</span><a href="#agent-supervisor" class="header-anchor">#</a></h3><p><a href="https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/agent_supervisor.ipynb">Agent Supervisor Repo</a> git</p>
<h3><span id="multi-agent-collaboration">Multi Agent Collaboration</span><a href="#multi-agent-collaboration" class="header-anchor">#</a></h3><p><a href="https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/multi-agent-collaboration.ipynb">Basic Multi-agent Collaboration</a> git</p>
<h3><span id="hierarchical-agent-teams">Hierarchical Agent Teams</span><a href="#hierarchical-agent-teams" class="header-anchor">#</a></h3><p><a href="https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb">Hierarchical Agent Teams</a> git</p>
<h1><span id="autogen10111213">AutoGen[10,11,12,13]</span><a href="#autogen10111213" class="header-anchor">#</a></h1><h3><span id="autogen-studio20">AutoGen Studio[20]</span><a href="#autogen-studio20" class="header-anchor">#</a></h3><h1><span id="framework">Framework</span><a href="#framework" class="header-anchor">#</a></h1><ul>
<li>LangGraph</li>
<li>AutoGPT</li>
<li>AutoGen</li>
<li>MetaGPT</li>
<li>CrewAI - OpenAI</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="langgraph">LangGraph</span><a href="#langgraph" class="header-anchor">#</a></h3><ol>
<li><a href="https://blog.langchain.dev/langgraph-multi-agent-workflows/">LangGraph: Multi-Agent Workflows</a></li>
<li><a href="https://www.bilibili.com/video/BV1F541117kW/">LangGraphï¼šMulti-Agent å®æˆ˜</a> V</li>
</ol>
<h3><span id="autogen">AutoGen</span><a href="#autogen" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://zhuanlan.zhihu.com/p/671782824">AutoGenå®æˆ˜åº”ç”¨(ä¸€)ï¼šä»£ç ç”Ÿæˆã€æ‰§è¡Œå’Œè°ƒè¯•</a></li>
<li><a href="https://github.com/www6v/AIGC/tree/master/agent/autogen">Repo</a> git</li>
<li><a href="https://zhuanlan.zhihu.com/p/664937747">Autogen æ–°æ‰‹æŒ‡å—ï¼šåŸºç¡€æ¦‚å¿µå’Œåº”ç”¨</a><br>Autogençš„é«˜çº§åº”ç”¨ å®˜æ–¹ä¾‹å­</li>
<li><a href="https://developer.aliyun.com/article/1394332">AutoGenå¤šä»£ç†å¯¹è¯é¡¹ç›®ç¤ºä¾‹å’Œå·¥ä½œæµç¨‹åˆ†æ</a><br>   è‡ªå®šä¹‰æ–¹æ³•fetch_prices,  å¤šagent<br>1xx. <a href="https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat/">Multi-agent Conversation Framework</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/670586507">Autogençš„åŸºæœ¬æ¡†æ¶,äººå·¥æ™ºèƒ½çš„ç®¡ç†ç³»ç»Ÿâ€”â€”Autogenç³»åˆ—02</a><br>   æºç è§£æ<br>1xx. <a href="https://zhuanlan.zhihu.com/p/660027092">AutoGenï¼šé€šè¿‡å¤šagentå¯¹è¯æ”¯æŒä¸‹ä¸€ä»£ LLM åº”ç”¨ç¨‹åº</a> paper ä¸­æ–‡</li>
</ol>
<h3><span id="autogen-studio">AutoGen Studio</span><a href="#autogen-studio" class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://zhuanlan.zhihu.com/p/680797754">LLMä¹‹Agentï¼ˆåï¼‰| æœ¬åœ°å®‰è£…Microsoft AutoGen Studio 2.0æ•™ç¨‹</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Agents</category>
      </categories>
      <tags>
        <tag>Agents</tag>
      </tags>
  </entry>
  <entry>
    <title>(ç»¼è¿°)å¤šæ¨¡æ€</title>
    <url>/www6vHomeAIGC/2023/01/18/gptMultimodal/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E5%88%86%E7%B1%BB-1">åŸºç¡€æ¨¡å‹åˆ†ç±» [1]</a><ul>
<li><a href="#textually-prompted-models">textually prompted models</a></li>
<li><a href="#visually-prompted-models">visually prompted models</a></li>
<li><a href="#heterogeneous-models">heterogeneous models</a></li>
</ul>
</li>
<li><a href="#%E6%9E%B6%E6%9E%84-1">æ¶æ„ [1]</a></li>
<li><a href="#model-architecture2">Model Architecture[2]</a></li>
<li><a href="#%E5%85%B6%E4%BB%96">å…¶ä»–</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#survey">survey</a></li>
<li><a href="#chat">chat</a></li>
<li><a href="#other">other</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="åŸºç¡€æ¨¡å‹åˆ†ç±»-1">åŸºç¡€æ¨¡å‹åˆ†ç±» [1]</span><a href="#åŸºç¡€æ¨¡å‹åˆ†ç±»-1" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/18/gptMultimodal/pattern.webp" class>

<img src="/www6vHomeAIGC/2023/01/18/gptMultimodal/pattern1.webp" class>

<h3><span id="textually-prompted-models">textually prompted models</span><a href="#textually-prompted-models" class="header-anchor">#</a></h3><ul>
<li>contrastive<br>CLIP  åŒå¡”</li>
<li>generative<br>Flamingo </li>
<li>hybrid<br>BLIP</li>
<li>conversational<br>GPT-4ï¼Œ miniGPT4, LLaVa</li>
</ul>
<p>ä¼ ç»Ÿä¸Šï¼Œè§†è§‰è¯­è¨€æ¨¡å‹ä¸»è¦ç”¨äºéœ€è¦åŒæ—¶ç†è§£è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€çš„ä»»åŠ¡ã€‚ç„¶è€Œï¼Œéšç€CLIPå±•ç¤ºå‡ºçš„å“è¶Šæ€§èƒ½ï¼ŒåŸºäº<strong>è¯­è¨€ç›‘ç£çš„æ¨¡å‹</strong>åœ¨æ˜¾è‘—ä¸Šå‡ï¼Œå¹¶æˆä¸ºä¸»æµæ–¹æ³•ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºæ¢ç´¢ä¾èµ–<strong>è¯­è¨€ä½œä¸ºä¸»è¦ç›‘ç£æ¥æº</strong>çš„æ–¹æ³•ã€‚è¿™äº›ä»¥æ–‡æœ¬ä¸ºæç¤ºçš„æ¨¡å‹å¯ä»¥å¹¿æ³›åˆ†ä¸ºä¸‰ç§ä¸»è¦ç±»å‹ï¼šå¯¹æ¯”ã€ç”Ÿæˆå’Œæ··åˆæ–¹æ³•ã€‚</p>
<h3><span id="visually-prompted-models">visually prompted models</span><a href="#visually-prompted-models" class="header-anchor">#</a></h3><ul>
<li>Foundational<br>SAM</li>
</ul>
<h3><span id="heterogeneous-models">heterogeneous  models</span><a href="#heterogeneous-models" class="header-anchor">#</a></h3><h1><span id="æ¶æ„-1">æ¶æ„ [1]</span><a href="#æ¶æ„-1" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/18/gptMultimodal/arch.webp" class>


<h1><span id="model-architecture2">Model Architecture[2]</span><a href="#model-architecture2" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/18/gptMultimodal/multimodalArach1.jpg" class>

<ul>
<li><p>Modality Encoderæ¨¡æ€ç¼–ç å™¨<br>  å¯¹äºå›¾åƒï¼Œé€šå¸¸æœ‰å››ç§å¯é€‰ç¼–ç å™¨:NFNet-F6 (Brockç­‰äººï¼Œ2021)ã€ViT (Dosovitskiyç­‰äººï¼Œ2020)ã€CLIP ViT (Radfordç­‰äººï¼Œ2021)å’ŒEva-CLIP ViT (Fangç­‰äººï¼Œ2023)ã€‚</p>
<ul>
<li><strong>NFNet-F6</strong>æ˜¯ä¸€ç§æ— å½’ä¸€åŒ–å™¨çš„ResNet (He et al.ï¼Œ 2016)ï¼Œå±•ç¤ºäº†ä¸€ç§è‡ªé€‚åº”æ¢¯åº¦è£å‰ªæŠ€æœ¯ï¼Œå…è®¸åœ¨å¹¿æ³›å¢å¼ºçš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶å®ç°SOTAçº§åˆ«çš„å›¾åƒè¯†åˆ«ã€‚</li>
<li><strong>ViT</strong>å°†Transformer (Vaswani et al.ï¼Œ 2017)åº”ç”¨äºå›¾åƒï¼Œé¦–å…ˆå°†å›¾åƒåˆ’åˆ†ä¸ºå°patchã€‚ç„¶åè¿›è¡Œçº¿æ€§æŠ•å½±ä½¿patchå±•å¹³ï¼Œç„¶åé€šè¿‡å¤šä¸ªTransformerå—è¿›è¡Œç¼–ç ã€‚</li>
<li><strong>CLIP ViT</strong>åœ¨æ–‡æœ¬å’Œå›¾åƒä¹‹é—´å»ºç«‹è¿æ¥ï¼ŒåŒ…æ‹¬ä¸€ä¸ªViTå’Œä¸€ä¸ªæ–‡æœ¬ç¼–ç å™¨ã€‚å®ƒåˆ©ç”¨å¤§é‡çš„æ–‡æœ¬-å›¾åƒå¯¹ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æ¥ä¼˜åŒ–ViTï¼Œå°†é…å¯¹çš„æ–‡æœ¬å’Œå›¾åƒè§†ä¸ºæ­£æ ·æœ¬ï¼Œå…¶ä»–ä¸ºè´Ÿæ ·æœ¬ã€‚</li>
<li>å®ƒçš„<strong>Evaç‰ˆæœ¬</strong>ç¨³å®šäº†å¤§è§„æ¨¡CLIPçš„è®­ç»ƒå’Œä¼˜åŒ–è¿‡ç¨‹ï¼Œä¸ºæ‰©å±•å’ŒåŠ é€Ÿæ˜‚è´µçš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹è®­ç»ƒæä¾›äº†æ–°çš„æ–¹å‘ã€‚å¯¹äºè§†é¢‘ï¼Œå¯ä»¥å‡åŒ€é‡‡æ ·åˆ°5å¸§ï¼Œå¹¶ç»è¿‡ä¸å›¾åƒç›¸åŒçš„é¢„å¤„ç†ã€‚</li>
</ul>
</li>
<li><p>Input Projectorè¾“å…¥æŠ•å½±å™¨<br>  <strong>è¾“å…¥æŠ•å½±å™¨</strong>å¯ä»¥ç›´æ¥é€šè¿‡çº¿æ€§æŠ•å½±å™¨æˆ–å¤šå±‚æ„ŸçŸ¥å™¨(MLP)æ¥å®ç°ï¼Œå³äº¤æ›¿ä½¿ç”¨å‡ ä¸ªçº¿æ€§æŠ•å½±å™¨å’Œéçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚<br>  è¿˜æœ‰æ›´å¤æ‚çš„å®ç°ï¼Œå¦‚äº¤å‰æ³¨æ„Cross-attentionã€Q-Former (Li et al.ï¼Œ 2023c)æˆ–P-Former (Jian et al.ï¼Œ 2023)ã€‚</p>
<ul>
<li><strong>Cross-attention</strong>ä½¿ç”¨ä¸€ç»„å¯è®­ç»ƒå‘é‡ä½œä¸ºæŸ¥è¯¢ï¼Œå¹¶ä½¿ç”¨ç¼–ç ç‰¹å¾FXä½œä¸ºé”®å°†ç‰¹å¾åºåˆ—å‹ç¼©åˆ°å›ºå®šé•¿åº¦ã€‚ç„¶åå°†å‹ç¼©åçš„è¡¨ç¤ºç›´æ¥è¾“å…¥LLM (Baiç­‰äººï¼Œ2023b)æˆ–è¿›ä¸€æ­¥ç”¨äºX-textäº¤å‰æ³¨æ„èåˆ(Alayracç­‰äººï¼Œ2022)ã€‚ </li>
<li><strong>Q-Former</strong>ä»FXä¸­æå–ç›¸å…³ç‰¹å¾ï¼Œç„¶åå°†é€‰ä¸­çš„ç‰¹å¾ä½œä¸ºæç¤ºPXã€‚</li>
<li>åŒæ—¶ï¼ŒP-Formerç”Ÿæˆâ€œå‚è€ƒæç¤ºâ€ï¼Œå¯¹Q-Formerç”Ÿæˆçš„æç¤ºæ–½åŠ å¯¹é½çº¦æŸã€‚ç„¶è€Œï¼ŒQ-å’ŒP-Formeréƒ½éœ€è¦å•ç‹¬çš„PTè¿›ç¨‹è¿›è¡Œåˆå§‹åŒ–ã€‚</li>
</ul>
<table>
<thead>
<tr>
<th>Input Projectorè¾“å…¥æŠ•å½±å™¨</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>Cross-attention</td>
<td>Flamingo, Owl, Qwen-VL</td>
</tr>
<tr>
<td>Q-Former</td>
<td>BLIP2, InstructBLIP, MiniGPT-4, MiniGPT-5</td>
</tr>
<tr>
<td>MLP</td>
<td>CogVLM , LLaVa1.5</td>
</tr>
<tr>
<td>Linear Project</td>
<td>LLaVa, PaLI-x,  MiniGPT-v2</td>
</tr>
</tbody></table>
</li>
</ul>
<img src="/www6vHomeAIGC/2023/01/18/gptMultimodal/multimodalArch.jpg" class>


<h1><span id="å…¶ä»–">å…¶ä»–</span><a href="#å…¶ä»–" class="header-anchor">#</a></h1><ul>
<li><p>å¯¹æ¯”</p>
<ul>
<li>[CNN  æ›´æ·±çš„ç½‘ç»œ]</li>
<li>[transformer æ²¡æœ‰å±€é™]</li>
</ul>
</li>
<li><p>CVä»»åŠ¡</p>
<ul>
<li>åˆ†ç±»ï¼ˆClassificationï¼‰</li>
<li>æ£€æµ‹ï¼ˆDetectionï¼‰</li>
<li>åˆ†å‰²ï¼ˆSegmentationï¼‰</li>
<li>è·Ÿè¸ªï¼ˆTrackingï¼‰</li>
<li>è¡Œä¸ºè¯†åˆ«ï¼ˆAction Recognitionï¼‰</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="survey">survey</span><a href="#survey" class="header-anchor">#</a></h3><ol>
<li><p>ã€ŠFoundational Models Defining a New Era in Vision: A Survey and Outlookã€‹å¤§å­¦<br> <a href="https://blog.csdn.net/qq_45368632/article/details/132180645">è§†è§‰å¤§æ¨¡å‹çš„å…¨é¢è§£æ</a><br> <a href="https://zhuanlan.zhihu.com/p/655135848">åŸºç¡€æ¨¡å‹å®šä¹‰è§†è§‰çš„æ–°æ—¶ä»£ï¼šç»¼è¿°å’Œå±•æœ›</a><br> <a href="https://zhuanlan.zhihu.com/p/648578542">ä¸‡å­—é•¿æ–‡å¸¦ä½ å…¨é¢è§£è¯»è§†è§‰å¤§æ¨¡å‹</a></p>
</li>
<li><p><a href="https://blog.csdn.net/qq_41185868/article/details/135877268">AIä¹‹MLMï¼šã€ŠMM-LLMs: Recent Advances in MultiModal Large Language Modelså¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æœ€æ–°è¿›å±•ã€‹ç¿»è¯‘ä¸è§£è¯»</a> ç¿»è¯‘<br><a href="https://zhuanlan.zhihu.com/p/680487634">è…¾è®¯å‘å¸ƒçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMM-LLMï¼‰çš„æœ€æ–°ç»¼è¿°ã€ä»26ä¸ªæœ€æ–°çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­å½’çº³æœ€ä½³å®è·µ</a><br><a href="https://zhuanlan.zhihu.com/p/680955430">å¤šæ¨¡æ€å¤§æ¨¡å‹æœ€æ–°å®Œæ•´ç»¼è¿° MM-LLMs</a><br><a href="https://mm-llms.github.io/archives/">mm-llms</a> è…¾è®¯</p>
</li>
</ol>
<p>1xx. <a href="https://cloud.tencent.com/developer/article/2322835">MLLMé¦–ç¯‡ç»¼è¿° | ä¸€æ–‡å…¨è§ˆå¤šæ¨¡æ€å¤§æ¨¡å‹çš„å‰ä¸–ã€ä»Šç”Ÿå’Œæœªæ¥</a><br>   <a href="https://arxiv.org/abs/2306.13549">A Survey on Multimodal Large Language Models</a></p>
<h3><span id="chat">chat</span><a href="#chat" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/670821058">[è®ºæ–‡é˜…è¯»] åŒå­åº§ï¼šä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹ç³»åˆ—ï¼ŒGemini: A Family of Highly Capable Multimodal Models</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/663655741">166é¡µè¶…é•¿è®ºæ–‡é˜…è¯»ï¼Œå¤§å¤šæ¨¡æ€æ¨¡å‹çš„é»æ˜ï¼šGPT-4Vçš„åˆæ­¥æ¢ç´¢ï¼ŒThe Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) [ä¸Š]</a></p>
<h3><span id="other">other</span><a href="#other" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/511517344">DeepMindå‡ºæ‰‹ï¼å¤šæ¨¡æ€å°æ ·æœ¬æ‰“è´¥ç²¾è°ƒ</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/669757416">å¤§æ¨¡å‹ç³»åˆ—04 -æ–‡æœ¬å›¾åƒç”Ÿæˆ</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>(å›¾ç”Ÿæ–‡)BLIP-2, Flamingo</title>
    <url>/www6vHomeAIGC/2023/03/15/gptMultimodalBlip/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="blip-2">BLIP-2</span><a href="#blip-2" class="header-anchor">#</a></h1><h3><span id="overview-1">Overview [1]</span><a href="#overview-1" class="header-anchor">#</a></h3><p>ç”¨ä¸€ä¸ªQformeræ¥æå–å›¾åƒç‰¹å¾ï¼ˆç­‰åŒä¸Flamingoçš„perceiver resamplerï¼‰ï¼Œç„¶åç”¨cross- attentionè¿›è¡Œå¤šæ¨¡æ€äº¤äº’ï¼Œæ­¤æ—¶è§†è§‰ç¼–ç å™¨å’ŒLLMéƒ½ä¼šè¢«å†»ç»“ï¼Œ<strong>åªè®­ç»ƒQformer</strong>ï¼Œè€Œåœ¨ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæ—¶ï¼Œå¯ä»¥å†è§£é”è§†è§‰ç¼–ç å™¨ï¼Œè®©å®ƒè·ŸQformerä¸€èµ·è®­ç»ƒ</p>
<h3><span id="ä¸¤é˜¶æ®µçš„è®­ç»ƒç­–ç•¥-1">ä¸¤é˜¶æ®µçš„è®­ç»ƒç­–ç•¥ [1]</span><a href="#ä¸¤é˜¶æ®µçš„è®­ç»ƒç­–ç•¥-1" class="header-anchor">#</a></h3><p>BLIP-2è®¾è®¡äº†ä¸¤é˜¶æ®µçš„è®­ç»ƒç­–ç•¥ï¼Œä»¥ä½¿è§†è§‰ç¼–ç å™¨èƒ½å­¦ä¼šæå–æ›´å…³é”®çš„ä¿¡æ¯ã€‚</p>
<ul>
<li>ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨å¤šç§é¢„è®­ç»ƒä»»åŠ¡ï¼Œå¦‚Image-Text Contrastive Learning(<strong>ITC</strong>)ï¼ŒImage-grounded Text Generation(<strong>ITG</strong>)ï¼ŒImage-Text Matching(<strong>ITM</strong>)è®©Qformerå­¦ä¼šå¦‚ä½•ä»<strong>è§†è§‰ç¼–ç å™¨ä¸­æŠ½å–æ–‡æœ¬ç›¸å…³çš„ç‰¹å¾</strong>ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µï¼Œå°†Qformeræ’å…¥åˆ°LLMsä¸­ï¼Œç”¨language modelingè¿›è¡Œè®­ç»ƒã€‚</li>
</ul>
<h3><span id="æ¶æ„3">æ¶æ„[3]</span><a href="#æ¶æ„3" class="header-anchor">#</a></h3><ul>
<li><strong>ä¸¤ä¸ªé˜¶æ®µè®­ç»ƒ</strong><ul>
<li>é˜¶æ®µä¸€<br>è·å¾—é«˜è´¨é‡çš„ <strong>å›¾æ–‡å¯¹é½å‘é‡è¡¨å¾</strong><br>é€šè¿‡<strong>ITC ITM  ITG ä¸‰ä¸ªæŸå¤±å‡½æ•°</strong>è·å¾—äº†å¾ˆå¥½çš„å›¾ç‰‡æ–‡æœ¬ <strong>å¯¹é½å‘é‡è¡¨å¾èƒ½åŠ›</strong>ï¼Œä»…è®­ç»ƒ<strong>Qformer</strong>ä¸­å¾ˆå°‘çš„å‚æ•°<br>ã€ITM:  image-text æ˜¯å¦æ˜¯åŒ¹é…çš„ |    image å’Œtext éƒ½èƒ½ç›¸äº’çœ‹åˆ°ã€‘<br>ã€ITG: imageç”Ÿæˆtext |    image èƒ½å…¨çœ‹åˆ°, textåªèƒ½é€ä¸ªçš„çœ‹ã€‘<br>ã€ITC: imageå’Œtextçš„å¯¹æ¯”å­¦ä¹ , å¯¹æ¯”å­¦ä¹ åˆ†ç±»åˆ†é”™äº†çš„  é€å…¥ITM è´Ÿæ ·æœ¬ |  imageå’Œ text  ä¹‹é—´æ˜¯ä¸èƒ½çœ‹åˆ°çš„ã€‘</li>
<li>é˜¶æ®µäºŒ<br>é€šè¿‡å‘é‡è¡¨å¾è¿›è¡Œ<strong>æ–‡å­—ç”Ÿæˆ</strong></li>
</ul>
</li>
</ul>
<h3><span id="code-2">code [2]</span><a href="#code-2" class="header-anchor">#</a></h3><h1><span id="flamingo1">Flamingo[1]</span><a href="#flamingo1" class="header-anchor">#</a></h1><h3><span id="æ¶æ„">æ¶æ„</span><a href="#æ¶æ„" class="header-anchor">#</a></h3><p>å®ƒåœ¨Frozenæ¨¡å‹çš„åŸºç¡€ä¸Šåšè¿›ä¸€æ­¥çš„æ”¹è¿›ï¼Œä¸åŒç‚¹ä¸»è¦æœ‰ä¸¤ä¸ªï¼šä¸€æ˜¯ä½¿ç”¨äº†æ›´å¤§çš„LLMsï¼ŒäºŒæ˜¯<strong>å†»ç»“è§†è§‰ç¼–ç å™¨</strong>ï¼Œå¼•å…¥<strong>perceiver resampler</strong>å’Œ<strong>XAttn-Dense</strong>ä¸¤ä¸ªé€‚é…å•å…ƒä½œä¸ºå¯è®­ç»ƒçš„æ¨¡å—ã€‚</p>
<ul>
<li>perceiver resamplerï¼š<br>  ç±»ä¼¼DETRï¼Œé€šè¿‡è®¾è®¡å¤šä¸ªPerceiver Resampleræ¥ç”Ÿæˆ<strong>64ä¸ªå›ºå®šé•¿åº¦çš„tokens</strong>ï¼Œä¸»è¦ä½œç”¨åœ¨äºå¯ä»¥<strong>ä»å›¾åƒä¸­æå–å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡</strong>ï¼Œèƒ½å¤Ÿè§£å†³å›¾åƒç”šè‡³å¤šå¸§è§†é¢‘çš„<strong>feature mapä¸ä¸€è‡´çš„é—®é¢˜</strong>ã€‚ã€å›¾åƒå’Œæ–‡æœ¬å¯¹é½ã€‘</li>
<li>XAttn-Denseï¼šåœ¨æ¯ä¸€å±‚LLMä¸Šéƒ½ä¼šå¢åŠ <strong>corss- attention</strong>ä»¥å…¥åˆ°<strong>LLMä¸­ä¸è§†è§‰å‘é‡è¿›è¡Œäº¤äº’</strong>ï¼Œ<strong>èåˆå¤šæ¨¡æ€ä¿¡æ¯</strong>ã€‚ã€èåˆã€‘</li>
</ul>
<h1><span id="å…¶ä»–">å…¶ä»–</span><a href="#å…¶ä»–" class="header-anchor">#</a></h1><h3><span id="mplug-docowl15-20">mPLUG-DocOwl1.5  [20]</span><a href="#mplug-docowl15-20" class="header-anchor">#</a></h3><p>DocOwl1.5ç”±mPLUG-Owl2åˆå§‹åŒ–ï¼Œä½¿ç”¨<strong>ViT&#x2F;L-14ä½œä¸ºè§†è§‰ç¼–ç å™¨</strong>ï¼Œå¹¶ä½¿ç”¨å¸¦æœ‰æ¨¡æ€è‡ªé€‚åº”æ¨¡å—çš„7Bå¤§æ¨¡å‹ä½œä¸º<strong>è§£ç å™¨</strong>ã€‚<br>æ¯ä¸ªå­å›¾åƒç”±ViT&#x2F;L-14ç¼–ç ä¸º1,024ä¸ªç‰¹å¾ï¼Œç„¶åç”±<strong>H-Reducerç¼©å‡ä¸º256ä¸ªç‰¹å¾</strong>ã€‚</p>
<h3><span id="textmonkey-20">TextMonkey [20]</span><a href="#textmonkey-20" class="header-anchor">#</a></h3><p>ä¸ºäº†å‡å°‘å›¾åƒç‰¹å¾çš„å†—ä½™ï¼Œç»§æ‰¿äº†<strong>Qwen-VL</strong>ä¸­çš„å›¾åƒ<strong>é‡é‡‡æ ·å™¨</strong>ï¼Œåœ¨æ¯ä¸ªçª—å£ä¸­éƒ½ä¼šä½¿ç”¨ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="blip2">blip2</span><a href="#blip2" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://nakaizura.blog.csdn.net/article/details/130757157?spm=1001.2014.3001.5502">åŸºäºLLMsçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆFlamingo, BLIP-2ï¼ŒKOSMOS-1ï¼ŒScienceQAï¼‰</a></p>
</li>
<li><p><a href="https://github.com/www6v/LAVIS/tree/main/projects/blip2">blip2</a> git<br><a href="https://colab.research.google.com/github/salesforce/LAVIS/blob/main/examples/blip2_instructed_generation.ipynb">blip2_instructed_generation</a> git è¿è¡Œè¿‡</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1Ek4y1G74J">å¼ºæ¨ï¼ç§‘å¤§è®¯é£å’Œä¸­ç§‘é™¢ç»ˆäºæŠŠå¤šæ¨¡æ€å¤§æ¨¡å‹è®²æ˜ç™½äº†ï¼ŒCLIPã€blipã€blip2ä¸‰ç§æ¨¡å‹åŸç†ä¸€å£æ°”å­¦å®Œ</a> V ***</p>
</li>
</ol>
<p>1xx.  <a href="https://www.bilibili.com/video/BV18u4y137ZV/">AIè®ºæ–‡ç²¾è¯»ä¹‹å¤šæ¨¡æ€å¤§æ¨¡å‹BLIP-2</a> V</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400402&idx=1&sn=efd84698e6a207b2035995ec2e255417">MiniGPT-4å®ç°åŸç†åŠå…¶æ ¸å¿ƒBLIP2æ¨¡å‹å®è·µï¼šä»ä»£è¡¨æ€§å›¾æ–‡å¯¹æ•°æ®é›†ã€BLIP2æ¨¡å‹ç»“æ„åˆ°è°ƒç”¨å®è·µ</a> *</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/606364639">BLIP2ï¼šä¸‹ä¸€ä»£å¤šæ¨¡æ€æ¨¡å‹çš„é›å½¢</a></p>
<h3><span id="flamingo">Flamingo</span><a href="#flamingo" class="header-anchor">#</a></h3><p>1xx. <a href="https://www.bilibili.com/video/BV1pu411G7ce">[è®ºæ–‡é€Ÿè§ˆ]Flamingo: a Visual Language Model for Few-Shot Learning[2204.14198]</a> V<br>1xx. <a href="https://github.com/Luodian/Otter">Otter  on OpenFlamingo</a> git<br>1xx. <a href="https://github.com/mlfoundations/open_flamingo">open_flamingo</a> git</p>
<h3><span id="å…¶ä»–">å…¶ä»–</span><a href="#å…¶ä»–" class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://mp.weixin.qq.com/s/1MSOZfbKcPW1BTT4f9XvQg">ä¹Ÿçœ‹è·¨æ¨¡æ€å¤§æ¨¡å‹é‡è§æ–‡æ¡£ç†è§£ï¼šmPLUG-DocOwl1.5åŠTextMonkeyæ–¹æ¡ˆä¸­çš„æ•°æ®å·¥ç¨‹ </a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>(å¯¹æ¯”å­¦ä¹ )CLIP</title>
    <url>/www6vHomeAIGC/2023/03/01/gptMultimodalCLIP/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#clip-%E5%9C%A8%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%81%9A%E4%BA%86%E5%93%AA%E4%BA%9B%E4%BA%8B%E6%83%85elmo1">CLIP åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åšäº†å“ªäº›äº‹æƒ…ï¼Ÿ[Elmo][1]</a></li>
<li><a href="#clip-zero-shot%E6%8E%A8%E7%90%861">CLIP Zero-shotæ¨ç†[1]</a><ul>
<li><a href="#%E6%AD%A5%E9%AA%A4">æ­¥éª¤</a></li>
<li><a href="#%E5%B1%80%E9%99%90">å±€é™</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E5%AE%9E%E6%88%98">å®æˆ˜</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="clip-åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åšäº†å“ªäº›äº‹æƒ…elmo1">CLIP åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åšäº†å“ªäº›äº‹æƒ…ï¼Ÿ[Elmo][1]</span><a href="#clip-åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åšäº†å“ªäº›äº‹æƒ…elmo1" class="header-anchor">#</a></h1><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒCLIPï¼ˆContrastive Language-Image Pre-trainingï¼‰æ¨¡å‹ä¸»è¦è¿›è¡Œäº†ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š</p>
<ol>
<li><strong>æ•°æ®é¢„å¤„ç†</strong> : CLIP ä½¿ç”¨äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„æ•°æ®é›†ï¼ŒåŒ…å« 4 äº¿ä¸ª â€œå›¾åƒ - æ–‡æœ¬â€ å¯¹ï¼Œè¿™äº›æ•°æ®éœ€è¦è¿›è¡Œæ¸…æ´—å’Œé¢„å¤„ç†ï¼Œä»¥ä¾¿äºæ¨¡å‹å­¦ä¹ ã€‚</li>
<li><strong>ç‰¹å¾æå–</strong> : é€šè¿‡ Text Encoder å’Œ Image Encoder åˆ†åˆ«å¯¹æ–‡æœ¬å’Œå›¾åƒè¿›è¡Œç‰¹å¾æå–ã€‚Text Encoder é€šå¸¸æ˜¯åŸºäº Transformer çš„æ¨¡å‹ï¼Œè€Œ Image Encoder å¯ä»¥æ˜¯åŸºäº CNNï¼ˆå·ç§¯ç¥ç»ç½‘ç»œï¼‰æˆ–è€… VITï¼ˆVision Transformerï¼‰çš„æ¨¡å‹ã€‚</li>
<li><strong>å¯¹æ¯”å­¦ä¹ </strong> : CLIP é‡‡ç”¨å¯¹æ¯”å­¦ä¹ çš„ç­–ç•¥ï¼Œé€šè¿‡å¯¹æ¯”æ­£ç¡®çš„å›¾åƒ - æ–‡æœ¬å¯¹ä¸é”™è¯¯çš„å›¾åƒ - æ–‡æœ¬å¯¹ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ­£ç¡®å¯¹çš„ç‰¹å¾è¡¨ç¤ºä¸å…¶ä»–å¯¹çš„åŒºåˆ†ã€‚å…·ä½“æ¥è¯´ï¼ŒCLIP é€šè¿‡ InfoNCE æŸå¤±å‡½æ•°æ¥æœ€å¤§åŒ–æ­£ç¡®å¯¹çš„ç›¸ä¼¼åº¦ï¼ŒåŒæ—¶æœ€å°åŒ–é”™è¯¯å¯¹çš„ç›¸ä¼¼åº¦ã€‚</li>
<li><strong>ç‰¹å¾ç©ºé—´å¯¹é½</strong> : é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼ŒCLIP å°†å›¾åƒå’Œæ–‡æœ¬çš„ç‰¹å¾æ˜ å°„åˆ°ä¸€ä¸ªå…±äº«çš„å¤šæ¨¡æ€ç‰¹å¾ç©ºé—´ä¸­ï¼Œä½¿å¾—å›¾åƒç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾å¯ä»¥ç›´æ¥è¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒã€‚</li>
<li><strong>å‚æ•°ä¼˜åŒ–</strong> : é€šè¿‡åå‘ä¼ æ’­å’Œæ¢¯åº¦ä¸‹é™ç­‰æ–¹æ³•ï¼Œä¸æ–­è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œä»è€Œä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚</li>
<li><strong>Zero-shot æ¨ç†èƒ½åŠ›çš„åŸ¹å…»</strong> : åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒCLIP å­¦ä¹ äº†å¦‚ä½•é€šè¿‡æ–‡æœ¬æç¤ºï¼ˆpromptsï¼‰æ¥è¿›è¡Œ zero-shot çš„å›¾åƒåˆ†ç±»ï¼Œå³åœ¨æ²¡æœ‰ç›´æ¥è§‚æµ‹åˆ°çš„ç±»åˆ«æ ‡ç­¾ä¸‹ï¼Œé€šè¿‡æ–‡æœ¬æè¿°æ¥è¯†åˆ«å›¾åƒå†…å®¹ã€‚</li>
<li><strong>æ¨¡å‹è¯„ä¼°ä¸è°ƒæ•´</strong> : é€šè¿‡åœ¨éªŒè¯é›†ä¸Šçš„è¯„ä¼°ï¼Œè°ƒæ•´æ¨¡å‹ç»“æ„å’Œè¶…å‚æ•°ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ€§èƒ½ã€‚</li>
</ol>
<p>é€šè¿‡è¿™äº›è®­ç»ƒæ­¥éª¤ï¼ŒCLIP èƒ½å¤Ÿå­¦ä¹ åˆ°ä¸€ä¸ªå¼ºå¤§çš„å¤šæ¨¡æ€ç‰¹å¾è¡¨ç¤ºï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤šç§è§†è§‰ä»»åŠ¡ä¸Šè¿›è¡Œ zero-shot æˆ– few-shot çš„æ¨ç†ã€‚</p>
<h1><span id="clip-zero-shotæ¨ç†1">CLIP Zero-shotæ¨ç†[1]</span><a href="#clip-zero-shotæ¨ç†1" class="header-anchor">#</a></h1><h3><span id="æ­¥éª¤">æ­¥éª¤</span><a href="#æ­¥éª¤" class="header-anchor">#</a></h3><ul>
<li>é¦–å…ˆï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª<strong>æ ‡ç­¾å…¨é›†</strong>ï¼Œå¦‚å›¾ä¸­ï¼ˆ2ï¼‰æ‰€ç¤ºï¼Œå¹¶å¾—åˆ°æ¯ä¸€ä¸ª<strong>æ ‡ç­¾çš„ç‰¹å¾å‘é‡</strong></li>
<li>ç„¶åï¼Œæˆ‘ä»¬å–ä¸€å¼ å›¾ç‰‡ï¼Œå¦‚å›¾ä¸­ï¼ˆ3ï¼‰æ‰€ç¤ºï¼Œè¿‡Image Encoderåå¾—åˆ°è¯¥<strong>å›¾ç‰‡çš„ç‰¹å¾å‘é‡</strong></li>
<li>æœ€åï¼Œè®¡ç®—å›¾ç‰‡å‘é‡å’Œæ–‡å­—å‘é‡é—´çš„<strong>ç›¸ä¼¼åº¦</strong>ï¼Œå–ç›¸ä¼¼åº¦æœ€é«˜çš„é‚£æ¡labelå³å¯ã€‚</li>
</ul>
<h3><span id="å±€é™">å±€é™</span><a href="#å±€é™" class="header-anchor">#</a></h3><p>  å½“ä½ å–‚ç»™CLIPä¸€å¼ å›¾æ—¶ï¼Œä¸ç®¡è¿™å¼ å›¾ç‰‡å®ƒæ˜¯å¦æœ‰è§è¿‡ï¼ŒCLIPéƒ½ä¸ä¼šç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„æ ‡ç­¾ï¼Œè€Œæ˜¯å»å…¨é›†æ ‡ç­¾ä¸­æ‰¾ä¸€ä¸ªæœ€ç›¸ä¼¼çš„ç»™ä½ ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/660476765">å…³äºå¤šæ¨¡æ€ç»å…¸ä¹‹ä½œCLIPï¼Œè¿˜æœ‰å“ªäº›ç»†èŠ‚æ˜¯ä½ ä¸çŸ¥é“çš„</a> ä»£ç </li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/493489688">ç¥å™¨CLIPï¼šè¿æ¥æ–‡æœ¬å’Œå›¾åƒï¼Œæ‰“é€ å¯è¿ç§»çš„è§†è§‰æ¨¡å‹</a> ***<br>1xx. <a href="https://zhuanlan.zhihu.com/p/486857682">ã€CLIPç³»åˆ—Paperè§£è¯»ã€‘CLIP: Learning Transferable Visual Models From Natural Language Supervision</a> ***<br>1xx. <a href="https://zhuanlan.zhihu.com/p/646790176">CLIP æ¨¡å‹è§£è¯»</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/521151393">è¯¦è§£CLIP (ä¸€) | æ‰“é€šæ–‡æœ¬-å›¾åƒé¢„è®­ç»ƒå®ç°ImageNetçš„zero-shotåˆ†ç±»ï¼Œæ¯”è‚©å…¨ç›‘ç£è®­ç»ƒçš„ResNet50&#x2F;101</a><br>1xx. <a href="https://blog.csdn.net/lsb2002/article/details/132275132">openaiå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼šclipè¯¦è§£åŠå®æˆ˜</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/555314976">CLIPï¼šå¤šæ¨¡æ€é¢†åŸŸé©å‘½è€…</a></p>
<h3><span id="å®æˆ˜">å®æˆ˜</span><a href="#å®æˆ˜" class="header-anchor">#</a></h3><p>1xx. <a href="https://github.com/mlfoundations/open_clip">open_clip Repo</a> git<br>1xx. <a href="https://github.com/www6v/Chinese-CLIP">Chinese-CLIP Repo</a> git<br>1xx. langchain ä¸­æœ‰CLIPçš„å®ç°</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>(ç»¼è¿°)å¤šæ¨¡æ€InstructTuning</title>
    <url>/www6vHomeAIGC/2023/03/15/gptMultimodalInstructTuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#datasets-for-visual-instruction-tuning1">Datasets for Visual Instruction Tuning[1]</a><ul>
<li><a href="#single-turn">Single-turn</a></li>
<li><a href="#multi-turn">Multi-turn</a></li>
</ul>
</li>
<li><a href="#vlit-data-construction-strategy2">VLIT Data Construction Strategy[2]</a><ul>
<li><a href="#annotation-adaption">Annotation Adaption</a></li>
<li><a href="#self-instruct">Self-Instruct</a></li>
</ul>
</li>
<li><a href="#high-quality-vlit-data2">High-Quality VLIT Data[2]</a><ul>
<li><a href="#correctness">Correctness</a></li>
<li><a href="#diversity">Diversity</a></li>
<li><a href="#complexity">Complexity</a></li>
</ul>
</li>
<li><a href="#method-12">Method [1][2]</a><ul>
<li><a href="#annotation-adaption-si">Annotation Adaption-&gt; SI</a></li>
<li><a href="#self-instruct-aa">Self-Instruct -&gt; AA</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="datasets-for-visual-instruction-tuning1">Datasets for Visual Instruction Tuning[1]</span><a href="#datasets-for-visual-instruction-tuning1" class="header-anchor">#</a></h1><h3><span id="single-turn">Single-turn</span><a href="#single-turn" class="header-anchor">#</a></h3><ul>
<li><p>MiniGPT-4<br><strong>MiniGPT-4</strong> [37] curates an image description dataset that contains 3439 image-text pairs for instruction fine-tuning. MiniGPT-4 <strong>randomly selects 5000 images from the Conceptual Caption dataset</strong> [38], [39] and prompts its <strong>pre-trained VLM model</strong> to generate detailed descriptions for each image. The generated descriptions are then** refined and filtered** both manually and by using ChatGPT, resulting in 3439 highquality image-text pairs.</p>
</li>
<li><p>MultiInstruct<br>MultiInstruct [43] build a comprehensive instruction dataset that covers 62 diverse multimodal tasks from 10 broad categories, such VQA, Image-text matching, grounded generation, and so on. These tasks include 34 existing tasks derived from 21 public dataset and 28 new tasks extended from them. Each task is equipped with 5 instruction templates to prompt the model to perform the specific task.</p>
</li>
</ul>
<h3><span id="multi-turn">Multi-turn</span><a href="#multi-turn" class="header-anchor">#</a></h3><ul>
<li>LLaVA<br><strong>LLaVA-Instruct-158k</strong> [9] contains 158 image-text instruction data, including <strong>58k conversation data</strong> asking about the visual content of the image,<strong>23k description data</strong>, and <strong>77k complex reasoning data</strong> where the question may involve multi-step reasoning process.</li>
</ul>
<h1><span id="vlit-data-construction-strategy2">VLIT Data Construction Strategy[2]</span><a href="#vlit-data-construction-strategy2" class="header-anchor">#</a></h1><h3><span id="annotation-adaption">Annotation Adaption</span><a href="#annotation-adaption" class="header-anchor">#</a></h3><ul>
<li>MiniGPT-4</li>
</ul>
<h3><span id="self-instruct">Self-Instruct</span><a href="#self-instruct" class="header-anchor">#</a></h3><ul>
<li>LLaVA</li>
</ul>
<h1><span id="high-quality-vlit-data2">High-Quality VLIT Data[2]</span><a href="#high-quality-vlit-data2" class="header-anchor">#</a></h1><h3><span id="correctness">Correctness</span><a href="#correctness" class="header-anchor">#</a></h3><h3><span id="diversity">Diversity</span><a href="#diversity" class="header-anchor">#</a></h3><h3><span id="complexity">Complexity</span><a href="#complexity" class="header-anchor">#</a></h3><h1><span id="method-12">Method [1][2]</span><a href="#method-12" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>Method</th>
<th>Training Paradigm[2]</th>
<th>Vision Encoder</th>
<th>Language Encoder</th>
<th>Inst[2]</th>
<th>Tuning Data</th>
</tr>
</thead>
<tbody><tr>
<td>MiniGPT-4</td>
<td>FA â†’ VLIT</td>
<td>EvaCLIP ViT</td>
<td>Vicuna</td>
<td>AA</td>
<td>CC3M, CC12M, SBU, LAION 400M, MiniGPT-3.5K</td>
</tr>
<tr>
<td>MiniGPT-v2</td>
<td></td>
<td>EVA</td>
<td>LLaMA2-chat</td>
<td>AA+SI</td>
<td>LAION, CC3M, SBU, GRIT-20M, COCO caption, Text Captions, RefCOCO, RefCOCO+, RefCOCOg, GQA, VQA-v2, OCR-VQA, OKVQA, AOK-VQA, Flickr30k Dataset, Unnatural Instruction Dataset</td>
</tr>
<tr>
<td>LLaVa</td>
<td>FA â†’ VLIT</td>
<td>CLIP ViT</td>
<td>Vicuna</td>
<td>SI</td>
<td>CC3M Concept-balanced 595K, LLaVA-Instruct-158K</td>
</tr>
<tr>
<td>LLaVA-1.5</td>
<td>FA â†’ VLIT</td>
<td>CLIP ViT</td>
<td>Vicuna</td>
<td></td>
<td>LLaVA, ShareGPT, VQAv2, GQA, OKVQA, OCRVQA, A-OKVQA, TextCaps, RefCOCO, VG</td>
</tr>
<tr>
<td>MultiInstruct</td>
<td>VLIT</td>
<td>OFA</td>
<td>OFA</td>
<td>AA</td>
<td>VQAv2, Visual7w, GQA, OK-VQA, Visual Genome, MSCOCO, RefCOCO, COCO-Text, TDIUC, IQA, VAW, MOCHEG, WikiHow</td>
</tr>
<tr>
<td>Otter</td>
<td></td>
<td>CLIP ViT</td>
<td>MPT</td>
<td>SI</td>
<td>MIMIC-IT</td>
</tr>
<tr>
<td>LAMM</td>
<td>VLIT</td>
<td>CLIP ViT-L&#x2F;14</td>
<td>Vicuna</td>
<td>SI</td>
<td>Language-Assisted Multi-Modal Instruction-Tuning Dataset</td>
</tr>
<tr>
<td>Qwen-VL</td>
<td>FA â†’ VLIT(Multi-Task Tuning)</td>
<td>ViT</td>
<td>Qwen-7B</td>
<td></td>
<td>LAION-en&amp;zh, DataComp, Coyo, CC12M&amp;3M, SBU, COCO, In-house Data, GQA, VGQA, VQAv2, DVQA, OCR-VQA, DocVQA, TextVQA, ChartQA, AI2D, GRIT, Visual Genome, RefCOCO, RefCOCO+, RefCOCOg, SynthDoG-en&amp;zh, Common Crawl pdf&amp;HTML</td>
</tr>
<tr>
<td>CogVLM</td>
<td>FA â†’ VLIT</td>
<td>EVA2-CLIP-E</td>
<td>Vicuna-7Bv-1.5</td>
<td></td>
<td>VQAv2, TextVQA</td>
</tr>
<tr>
<td>StableLLaVA</td>
<td>FA â†’ VLIT</td>
<td>CLIP-ViT-L&#x2F;14</td>
<td>LLaMA</td>
<td>AA</td>
<td>Synthesized Image-Dialogue Dataset</td>
</tr>
</tbody></table>
<h3><span id="annotation-adaption-gt-si">Annotation Adaption-&gt; SI</span><a href="#annotation-adaption-gt-si" class="header-anchor">#</a></h3><h3><span id="self-instruct-gt-aa">Self-Instruct -&gt; AA</span><a href="#self-instruct-gt-aa" class="header-anchor">#</a></h3><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p>ã€ŠVisual Instruction Tuning towards General-Purpose Multimodal Model: A Surveyã€‹ ***  ç¬¬4 5ç«   å—æ´‹å¤§å­¦ </p>
</li>
<li><p>ã€ŠVision-Language Instruction Tuning: A Review and Analysisã€‹ ***  ç¬¬2 3 4 5ç«    è…¾è®¯</p>
</li>
<li><p>ã€ŠInstruction Tuning for Large Language Models: A Surveyã€‹ ç¬¬5ç« </p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†|å®æˆ˜)å¤šæ¨¡æ€  LLaVa</title>
    <url>/www6vHomeAIGC/2023/03/14/gptMultimodalLlava/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h3><span id="gpt-assisted-visual-instruction-data-generation-1">GPT-assisted Visual Instruction Data Generation [1]</span><a href="#gpt-assisted-visual-instruction-data-generation-1" class="header-anchor">#</a></h3><ul>
<li><p>detail<br>ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨<strong>çº¯è¯­è¨€ GPT-4 æˆ– ChatGPT ä½œä¸ºå¼ºå¤§çš„æ•™å¸ˆï¼ˆä¸¤è€…éƒ½åªæ¥å—æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼‰ï¼Œæ¥åˆ›å»ºæ¶‰åŠè§†è§‰å†…å®¹çš„æŒ‡ä»¤éµå¾ªæ•°æ®</strong>ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†å°†å›¾åƒç¼–ç ä¸ºè§†è§‰ç‰¹å¾ä»¥æç¤ºçº¯æ–‡æœ¬ GPTï¼Œæˆ‘ä»¬ä½¿ç”¨äº†<strong>ä¸¤ç±»ç¬¦å·</strong>è¡¨ç¤ºï¼š</p>
<p>  iï¼‰<strong>å›¾åƒæè¿°ï¼ˆCaptionsï¼‰</strong>é€šå¸¸ä»ä¸åŒè§’åº¦æè¿°è§†è§‰åœºæ™¯ï¼›<br>  iiï¼‰<strong>è¾¹æ¡†ï¼ˆBounding Boxesï¼‰</strong>é€šå¸¸å®šä½åœºæ™¯ä¸­çš„ç‰©ä½“ï¼Œæ¯ä¸ªæ¡†ç¼–ç ç‰©ä½“æ¦‚å¿µåŠå…¶ç©ºé—´ä½ç½®ã€‚è¡¨ 14 é¡¶éƒ¨å›¾å—å°±æ˜¯ä¸€ä¸ªä¾‹å­ã€‚</p>
</li>
<li><p>158K   è¯­è¨€å›¾åƒæŒ‡ä»¤éµå¾ªæ ·æœ¬</p>
<ul>
<li>58K  å¯¹è¯æ ·æœ¬</li>
<li>23K  è¯¦ç»†æè¿°æ ·æœ¬ </li>
<li>77K  å¤æ‚æ¨ç†æ ·æœ¬</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://datac.blog.csdn.net/article/details/135329498">ã€LMM 001ã€‘LLaVAï¼šå¤§å‹è¯­è¨€å’Œè§†è§‰åŠ©æ‰‹</a></li>
</ol>
<p>1xx. <a href="https://apposcmf8kb5033.pc.xiaoe-tech.com/live_pc/l_64a7d4fde4b0d1e42e7fc7e6">åŸºäºè§†è§‰æŒ‡ä»¤è°ƒæ•´çš„å¤šæ¨¡æ€èŠå¤©æœºå™¨äºº LLaVAï½œAIæ–°é’å¹´è®²åº§Â·å¤§å‹è¯­è¨€æ¨¡å‹ä¸“åœº</a> V</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/683137074">[LLaVAç³»åˆ—]ğŸ“’CLIP&#x2F;LLaVA&#x2F;LLaVA1.5&#x2F;VILAç¬”è®°</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/625723805">miniGPT-4çš„åŒæœŸå·¥ä½œ: å¾®è½¯LLaVaæ¨¡å‹è®ºæ–‡ç¬”è®°</a></p>
<h3><span id="plus">plus</span><a href="#plus" class="header-anchor">#</a></h3><p>1xx. <a href="https://datac.blog.csdn.net/article/details/135329602">ã€LMM 002ã€‘LLaVA-1.5ï¼šå¤§å‹è¯­è¨€å’Œè§†è§‰åŠ©æ‰‹</a></p>
<p>1xx. <a href="https://datac.blog.csdn.net/article/details/135329898">ã€LMM 006ã€‘LLaVA-Plusï¼šå¯ä»¥å­¦ä¹ å¦‚ä½•ä½¿ç”¨å·¥å…·çš„å¤šæ¨¡æ€Agent</a></p>
<h3><span id="å¾®è°ƒllava-å®æˆ˜">å¾®è°ƒllava å®æˆ˜</span><a href="#å¾®è°ƒllava-å®æˆ˜" class="header-anchor">#</a></h3><p><a href="https://github.com/InternLM/Tutorial/blob/camp2/xtuner/readme.md">XTuner å¾®è°ƒ LLMï¼š1.8Bã€å¤šæ¨¡æ€ã€Agent (æ›´æ–°æ’°å†™ä¸­)</a><br><a href="https://github.com/InternLM/Tutorial/blob/camp2/xtuner/llava/xtuner_llava.md">XTunerå¤šæ¨¡æ€è®­ç»ƒä¸æµ‹è¯•</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†|å®æˆ˜)MiniGPT4</title>
    <url>/www6vHomeAIGC/2023/03/15/gptMultimodalMinigpt4/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#introduction1">INTRODUCTION[1]</a></li>
<li><a href="#method1">METHOD[1]</a><ul>
<li><a href="#first-pretraining-stage">FIRST <strong>PRETRAINING</strong> STAGE</a></li>
<li><a href="#curating-a-high-quality-alignment-dataset-for-vision-language-domain">CURATING A <strong>HIGH-QUALITY ALIGNMENT DATASET</strong> FOR VISION-LANGUAGE DOMAIN.</a></li>
<li><a href="#second-stage-finetuning">SECOND-STAGE <strong>FINETUNING</strong></a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E5%8E%9F%E7%90%86">åŸç†</a></li>
<li><a href="#%E5%AE%9E%E6%88%98">å®æˆ˜</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="introduction1">INTRODUCTION[1]</span><a href="#introduction1" class="header-anchor">#</a></h1><p>MiniGPT-4 å¢åŠ äº†ä¸€ä¸ª<strong>æŠ•å½±å±‚</strong>ï¼Œå°†<strong>ç¼–ç çš„è§†è§‰ç‰¹å¾ä¸ Vicuna è¯­è¨€æ¨¡å‹å¯¹é½</strong>ï¼Œå¹¶<strong>å†»ç»“äº†æ‰€æœ‰å…¶ä»–è§†è§‰å’Œè¯­è¨€ç»„ä»¶</strong></p>
<h1><span id="method1">METHOD[1]</span><a href="#method1" class="header-anchor">#</a></h1><ul>
<li><p>å›¾ 1</p>
</li>
<li><p>MiniGPT-4 çš„ç›®æ ‡æ˜¯å°†æ¥è‡ªé¢„è®­ç»ƒè§†è§‰ç¼–ç å™¨çš„è§†è§‰ä¿¡æ¯ä¸å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹é½ï¼ˆAlignmentï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œ</p>
<ul>
<li>ä½¿ç”¨ <strong>Vicunaä½œä¸ºè¯­è¨€è§£ç å™¨</strong>ï¼Œè¯¥è§£ç å™¨åŸºäº LLaMAæ„å»ºï¼Œå¯ä»¥æ‰§è¡Œå„ç§å¤æ‚çš„è¯­è¨€ä»»åŠ¡ã€‚</li>
<li>è§†è§‰æ„ŸçŸ¥æ–¹ï¼šé‡‡ç”¨ä¸ <strong>BLIP-2</strong> ç›¸åŒçš„<strong>è§†è§‰ç¼–ç å™¨</strong>ï¼Œ<strong>ViT Backbone</strong>åŠå…¶é¢„å…ˆè®­ç»ƒå¥½çš„ <strong>Q-Former</strong>ã€‚<br>è¯­è¨€å’Œè§†è§‰æ¨¡å‹éƒ½æ˜¯å¼€æºçš„ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ©ç”¨çº¿æ€§æŠ•å½±å±‚å¼¥åˆè§†è§‰ç¼–ç å™¨ä¸ LLM ä¹‹é—´çš„å·®è·ï¼Œå›¾ 1 æ˜¾ç¤ºäº†æ¨¡å‹æ¦‚è§ˆã€‚</li>
</ul>
</li>
</ul>
<h3><span id="first-pretraining-stage">FIRST <strong>PRETRAINING</strong> STAGE</span><a href="#first-pretraining-stage" class="header-anchor">#</a></h3><ul>
<li><p>ç¬¬ä¸€é˜¶æ®µï¼šåœ¨å¤§é‡å¯¹é½çš„å›¾åƒ-æ–‡æœ¬å¯¹ä¸Šå¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥è·å–è§†è§‰è¯­è¨€çŸ¥è¯†ã€‚</p>
</li>
<li><p>Traditional alignment method [2]</p>
<ul>
<li>Input: Image</li>
<li>Output: Caption</li>
<li>Training Objective: Maximize the likelihood of GT captions</li>
<li>Training Dataset ç»„åˆæ•°æ®é›† [postprocessed by BLIP] <ul>
<li>Conceptual Caption</li>
<li>SBU </li>
<li>LAION</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="curating-a-high-quality-alignment-dataset-for-vision-language-domain">CURATING A <strong>HIGH-QUALITY ALIGNMENT DATASET</strong> FOR VISION-LANGUAGE DOMAIN.</span><a href="#curating-a-high-quality-alignment-dataset-for-vision-language-domain" class="header-anchor">#</a></h3><ul>
<li>Create a dataset with detailed, human-perfered descriptions[2][1]<ul>
<li>model  generates descriptions<br>åœ¨åˆå§‹é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨ä»ç¬¬ä¸€ä¸ªé¢„è®­ç»ƒé˜¶æ®µå¾—åˆ°çš„æ¨¡å‹æ¥<strong>ç”Ÿæˆè¾“å…¥å›¾åƒçš„æè¿°</strong>ã€‚      </li>
<li>polishing and filtering by chatgpt<br>ä¸Šè¿°è‡ªåŠ¨ç”Ÿæˆçš„å›¾ç‰‡è¯´æ˜åŒ…å«<strong>å™ªéŸ³æˆ–ä¸è¿è´¯çš„æè¿°</strong>ï¼Œä¾‹å¦‚å•è¯æˆ–å¥å­é‡å¤ï¼Œå¥å­æ”¯ç¦»ç ´ç¢æˆ–å†…å®¹ä¸ç›¸å…³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†<strong>ChatGPT</strong>ï¼Œé€šè¿‡ä»¥ä¸‹æç¤ºå¯¹æè¿°è¿›è¡Œ<strong>ä¿®è¡¥</strong></li>
<li>further polishing and filtering by rules &amp; human<br>å®Œæˆåå¤„ç†é˜¶æ®µåï¼Œæˆ‘ä»¬ä¼šæ‰‹åŠ¨éªŒè¯æ¯å¼ å›¾ç‰‡è¯´æ˜çš„æ­£ç¡®æ€§ï¼Œä»¥ä¿è¯å…¶é«˜è´¨é‡ã€‚</li>
</ul>
</li>
</ul>
<h3><span id="second-stage-finetuning">SECOND-STAGE <strong>FINETUNING</strong></span><a href="#second-stage-finetuning" class="header-anchor">#</a></h3><ul>
<li>ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨ä¸€ä¸ªè¾ƒå°ä½†é«˜è´¨é‡çš„å›¾åƒ-æ–‡æœ¬æ•°æ®é›†å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶è®¾è®¡äº†å¯¹è¯æ¨¡æ¿ï¼Œä»¥æé«˜ç”Ÿæˆçš„å¯é æ€§å’Œå¯ç”¨æ€§ã€‚</li>
</ul>
<p>ã€blip2èƒ½è¯†åˆ«å›¾åƒï¼Œä½†æ˜¯å¯¹è¯èƒ½åŠ›æ¯”è¾ƒå¼±ï¼Œä¸èƒ½è¯´å‡ºå›¾åƒä¸­çš„ç»†èŠ‚ã€‚åœ¨pre-trainé˜¶æ®µè·å–è§†è§‰è¯­è¨€çŸ¥è¯†ï¼Œ åœ¨fine-tuning é˜¶æ®µè·å–å¯¹è¯èƒ½åŠ›ã€‘  [2]</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="åŸç†">åŸç†</span><a href="#åŸç†" class="header-anchor">#</a></h3><ol>
<li><a href="https://datac.blog.csdn.net/article/details/135399033">ã€LMM 009ã€‘MiniGPT-4ï¼šä½¿ç”¨ Vicuna å¢å¼ºè§†è§‰è¯­è¨€ç†è§£èƒ½åŠ›çš„å¤šæ¨¡æ€å¤§æ¨¡å‹</a> *** </li>
<li><a href="https://www.bilibili.com/video/BV1n24y1F7kv/">MiniGPT-4ã€è¡¨æ ¼æ¨ç†ã€ä»£ç ç”Ÿæˆã€ç”Ÿæˆå¼æ¨ç†-æ¥è‡ªæ–¯å¦ç¦ã€åŒ—å¤§ã€é˜¿åœæœæ‹‰ã€è¾¾æ‘©é™¢çš„å››ä½è®ºæ–‡ä¸€ä½œæ€è¾¨å¤§æ¨¡å‹</a> V<br>1xx. <a href="https://www.bilibili.com/video/BV12Q4y1b7nY/">miniGPT4ï¼šå¤šæ¨¡æ€å›¾æ–‡ç†è§£è®­ç»ƒ</a> V<br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400402&idx=1&sn=efd84698e6a207b2035995ec2e255417">MiniGPT-4å®ç°åŸç†åŠå…¶æ ¸å¿ƒBLIP2æ¨¡å‹å®è·µï¼šä»ä»£è¡¨æ€§å›¾æ–‡å¯¹æ•°æ®é›†ã€BLIP2æ¨¡å‹ç»“æ„åˆ°è°ƒç”¨å®è·µ </a><br>1xx. <a href="https://apposcmf8kb5033.pc.xiaoe-tech.com/live_pc/l_64a7d282e4b007b201a34052">ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸ºMiniGPT-4æ„å»ºè§†è§‰è¯­è¨€ç†è§£èƒ½åŠ›</a> V</li>
</ol>
<h3><span id="å®æˆ˜">å®æˆ˜</span><a href="#å®æˆ˜" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/627671257">å¤§æ€å™¨ï¼Œå¤šæ¨¡æ€å¤§æ¨¡å‹MiniGPT-4å…¥å‘æŒ‡å—</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)å¤šæ¨¡æ€é¢„è®­ç»ƒ æ¦‚è¿°</title>
    <url>/www6vHomeAIGC/2023/03/04/gptMultimodalPretrain/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%84%E8%AE%AD%E7%BB%83">å¤šæ¨¡æ€é¢„è®­ç»ƒ</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86">æ•°æ®é›†</a></li>
<li><a href="#%E6%9E%B6%E6%9E%84transformer">æ¶æ„Transformer</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B-%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">æ¨¡å‹ - è‡ªç›‘ç£å­¦ä¹ </a></li>
</ul>
</li>
<li><a href="#%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1">ä¸‹æ¸¸ä»»åŠ¡</a><ul>
<li><a href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83">å¤šæ¨¡æ€ä¸‹æ¸¸ä»»åŠ¡-æ¨¡å‹å¾®è°ƒ</a></li>
</ul>
</li>
<li><a href="#%E6%9B%B4%E5%A4%A7%E6%9B%B4%E5%BC%BA%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">æ›´å¤§æ›´å¼ºçš„å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/03/04/gptMultimodalPretrain/overview.png" class>


<h1><span id="å¤šæ¨¡æ€é¢„è®­ç»ƒ">å¤šæ¨¡æ€é¢„è®­ç»ƒ</span><a href="#å¤šæ¨¡æ€é¢„è®­ç»ƒ" class="header-anchor">#</a></h1><h2><span id="æ•°æ®é›†">æ•°æ®é›†</span><a href="#æ•°æ®é›†" class="header-anchor">#</a></h2><ul>
<li>å¤§è§„æ¨¡æ— æ ‡æ³¨</li>
<li>å†…å®¹æ‚  å™ªéŸ³å¤š</li>
</ul>
<h2><span id="æ¶æ„transformer">æ¶æ„Transformer</span><a href="#æ¶æ„transformer" class="header-anchor">#</a></h2><ul>
<li><p>åŸºäºtransformer encoder-ç†è§£ä»»åŠ¡<br>å•æµ - vl-bert  UNITER<br>åŒæµ - ViLBERTï¼Œ CLIPï¼ˆåŒæµç»“æ„ï¼Œå¯¹æ¯”å­¦ä¹ ï¼‰</p>
</li>
<li><p>åŸºäºtransformer decoder-ç”Ÿæˆä»»åŠ¡<br>DALL-E  ï¼ˆVQVAE+GPT,  Text-to-Image Generationï¼‰<br>ç°åœ¨éƒ½ç”¨ â†’ SD æ‰©æ•£æ¨¡å‹</p>
</li>
<li><p>åŸºäºencoder+decoder-ç†è§£+ç”Ÿæˆ<br>æ–‡æœ¬çš„decoder</p>
</li>
</ul>
<ol>
<li>encoder + decoder ä¸²è¡Œ,  äº¤å‰æ³¨æ„åŠ›</li>
<li>encoder + decoder å¹¶è¡Œ</li>
</ol>
<h2><span id="æ¨¡å‹-è‡ªç›‘ç£å­¦ä¹ ">æ¨¡å‹ - è‡ªç›‘ç£å­¦ä¹ </span><a href="#æ¨¡å‹-è‡ªç›‘ç£å­¦ä¹ " class="header-anchor">#</a></h2><ul>
<li><p>æ¨¡æ€å†…æ©ç å­¦ä¹ <br>æ–‡æœ¬ è¯­éŸ³ è§†è§‰è‡ªèº«tokençº§åˆ«mask</p>
</li>
<li><p>æ¨¡æ€é—´æ©ç å­¦ä¹ <br>ä¸åŒæ¨¡æ€ä¿¡æ¯çš„ç›¸äº’é¢„æµ‹<br>maskè§†è§‰ï¼Œ è¾“å‡ºå¯¹åº”æ–‡æœ¬</p>
</li>
<li><p>æ¨¡æ€é—´åŒ¹é…å­¦ä¹ <br>åŒ¹é…ä¸å¦çš„åˆ†ç±»é—®é¢˜ - æ­£è´Ÿæ ·æœ¬(äºŒåˆ†ç±»)<br>å¯¹æ¯”å­¦ä¹  - æ¨¡æ€é—´çš„å›¾æ–‡åŒ¹é…å¯¹</p>
</li>
</ul>
<h1><span id="ä¸‹æ¸¸ä»»åŠ¡">ä¸‹æ¸¸ä»»åŠ¡</span><a href="#ä¸‹æ¸¸ä»»åŠ¡" class="header-anchor">#</a></h1><h2><span id="å¤šæ¨¡æ€ä¸‹æ¸¸ä»»åŠ¡-æ¨¡å‹å¾®è°ƒ">å¤šæ¨¡æ€ä¸‹æ¸¸ä»»åŠ¡-æ¨¡å‹å¾®è°ƒ</span><a href="#å¤šæ¨¡æ€ä¸‹æ¸¸ä»»åŠ¡-æ¨¡å‹å¾®è°ƒ" class="header-anchor">#</a></h2><ul>
<li><p>æ¨¡å‹å¾®è°ƒ</p>
<ul>
<li>p+ finetuneï¼ˆå…¨å‚æ•°ï¼‰</li>
<li>p+ prompt-tuning</li>
<li>p+ adaptor-tuning</li>
<li>p+ lora</li>
</ul>
</li>
<li><p>å¤šæ¨¡æ€ä¸‹æ¸¸ä»»åŠ¡</p>
<ul>
<li>ç†è§£ï¼š text&#x2F;audio&#x2F;visual å†…å®¹ç”Ÿæˆ</li>
<li>ç”Ÿæˆï¼š è·¨æ¨¡æ€ æ£€ç´¢&#x2F;é—®ç­”&#x2F;æ¨ç†</li>
</ul>
</li>
</ul>
<h1><span id="æ›´å¤§æ›´å¼ºçš„å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹">æ›´å¤§æ›´å¼ºçš„å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹</span><a href="#æ›´å¤§æ›´å¼ºçš„å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹" class="header-anchor">#</a></h1><ul>
<li><strong>å¼ºå¤§çš„è¯­è¨€æ¨¡å‹</strong></li>
<li>æ›´å¤§çš„è§†è§‰æ¨¡å‹</li>
<li>æ›´å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ•°æ®</li>
<li>æ›´å¤šæ¨¡æ€å½¢å¼çš„æ•°æ®</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV13P411q7tH/">ä¸­ç§‘é™¢åˆ˜é™ï¼šå¤šæ¨¡æ€é¢„è®­ç»ƒçš„è¿›å±•å›é¡¾ä¸å±•æœ›</a>  V</li>
</ol>
<p>1xx. <a href="https://github.com/Coobiw/MiniGPT4Qwen">MiniGPT4Qwen</a> git<br><a href="https://zhuanlan.zhihu.com/p/664612306">å¤šæ¨¡æ€å¤§æ¨¡å‹å®æˆ˜-MiniGPT4Qwenç³»åˆ—1ï¼š3090+2å°æ—¶+é€šä¹‰åƒé—®&#x3D;ä¸ªäººç‰ˆåŒè¯­å¤šæ¨¡æ€å¤§æ¨¡å‹</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>SAM</title>
    <url>/www6vHomeAIGC/2023/03/01/gptMultimodalSAM/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p><a href="https://blog.csdn.net/weixin_44386956/article/details/130262260">ã€æ¨¡å‹è§£è¯»ã€‘ã€ä»£ç å¤ç°ã€‘Segment Anything Model(SAM)</a><br><a href="https://zhuanlan.zhihu.com/p/620355474">ã€è®ºæ–‡è§£è¯»ã€‘MetaAi SAM(Segment Anything) åˆ†å‰²ä¸€åˆ‡</a><br><a href="https://zhuanlan.zhihu.com/p/630529550">Segment Anything(sam)é¡¹ç›®æ•´ç†æ±‡æ€»</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>å¤šæ¨¡æ€ ç³»åˆ—</title>
    <url>/www6vHomeAIGC/2024/04/04/gptMultimodalSeries/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="æ¨¡å—ç‹¬ç«‹">æ¨¡å—ç‹¬ç«‹</span><a href="#æ¨¡å—ç‹¬ç«‹" class="header-anchor">#</a></h1><h3><span id="clip">CLIP</span><a href="#clip" class="header-anchor">#</a></h3><h3><span id="vilt">ViLT</span><a href="#vilt" class="header-anchor">#</a></h3><h3><span id="albef">ALBEF</span><a href="#albef" class="header-anchor">#</a></h3><h1><span id="æ¨¡å—å…±äº«">æ¨¡å—å…±äº«</span><a href="#æ¨¡å—å…±äº«" class="header-anchor">#</a></h1><h3><span id="vlmo">VLMO</span><a href="#vlmo" class="header-anchor">#</a></h3><h3><span id="blip">BLIP</span><a href="#blip" class="header-anchor">#</a></h3><h3><span id="blip2">BLIP2</span><a href="#blip2" class="header-anchor">#</a></h3><h3><span id="beitv3">BEiTv3</span><a href="#beitv3" class="header-anchor">#</a></h3><h1><span id="æ€»ç»“-10">æ€»ç»“ [10]</span><a href="#æ€»ç»“-10" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2024/04/04/gptMultimodalSeries/multimodal.webp" class>

<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h3><ol start="10">
<li><a href="https://zhuanlan.zhihu.com/p/653902791">å¤šæ¨¡æ€å¤§æ¨¡å‹ CLIP, BLIP, BLIP2, LLaVA, miniGPT4, InstructBLIP ç³»åˆ—è§£è¯»</a> ***</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/643969218">[Transformer 101ç³»åˆ—] å¤šæ¨¡æ€çš„å¤§ä¸€ç»Ÿä¹‹è·¯</a>  *** </p>
<p>1xx. <a href="https://blog.csdn.net/qq_52038588/article/details/133893013">å¤šæ¨¡æ€è®ºæ–‡ä¸²è®²</a> ***</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648409338&idx=1&sn=5445ff1e9bedc561393b6da63fdf71f9">å›¾ç”Ÿæ–‡å¤šæ¨¡æ€å¤§æ¨¡å‹å¼€æºé¡¹ç›®å›é¡¾ï¼šå…¼çœ‹20240307å¤§æ¨¡å‹è¿›å±•æ—©æŠ¥</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/662889725">å›¾æ–‡å¤šæ¨¡æ€å¤§æ¨¡å‹ç»¼è¿°</a></p>
<p>1xx. <a href="https://huyenchip.com/2023/10/10/multimodal.html">Multimodality and Large Multimodal Models (LMMs)</a><br>   <a href="https://baoyu.io/translations/lmm/multimodality-and-large-multimodal-models">å¤šæ¨¡æ€å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹ (LMM)[è¯‘]</a>  CLIP Flamingo</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/667942680">å†™åœ¨å¤šæ¨¡æ€å¾æœä¸€åˆ‡ä¹‹å‰ï¼ˆæœªæ¥æ•°æ®å’Œæ¨¡å‹åº”è¯¥æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿï¼‰</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/660662864">Qwen-VLï¼šçªç ´è§†è§‰ä¸è¯­è¨€èåˆçš„å¤šæ¨¡æ€æ¨¡å‹ï¼ŒGPT4Vçš„å›½äº§åŒ–æ›¿ä»£</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/657385270">Qwen-VL: ä¸€ä¸ªé€šç”¨çš„è§†è§‰è¯­è¨€æ¨¡å‹,ç”¨äºç†è§£ã€å®šä½ã€æ–‡æœ¬é˜…è¯»ç­‰</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>(Survey)å¤šæ¨¡æ€</title>
    <url>/www6vHomeAIGC/2023/03/16/gptMultimodalSurvey/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3-3">è§†è§‰ç†è§£ [3]</a></li>
<li><a href="#%E8%A7%86%E8%A7%89%E7%94%9F%E6%88%90-3">è§†è§‰ç”Ÿæˆ [3]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#survey">survey</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="è§†è§‰ç†è§£-3">è§†è§‰ç†è§£ [3]</span><a href="#è§†è§‰ç†è§£-3" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/03/16/gptMultimodalSurvey/understanding.png" class>

<img src="/www6vHomeAIGC/2023/03/16/gptMultimodalSurvey/understanding-method.png" class>


<h1><span id="è§†è§‰ç”Ÿæˆ-3">è§†è§‰ç”Ÿæˆ [3]</span><a href="#è§†è§‰ç”Ÿæˆ-3" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/03/16/gptMultimodalSurvey/generation.png" class>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="survey">survey</span><a href="#survey" class="header-anchor">#</a></h3><ol start="3">
<li>ã€ŠMultimodal Foundation Models:From Specialists to General-Purpose Assistantsã€‹  microsoft<br><a href="https://blog.csdn.net/qq_41185868/article/details/133594461">AGIä¹‹MFMï¼šã€ŠMultimodal Foundation Models: From Specialists to General-Purpose Assistantså¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ï¼šä»ä¸“å®¶åˆ°é€šç”¨åŠ©</a> ç¿»è¯‘<br><a href="https://blog.csdn.net/qq_41200212/article/details/134663233">Multimodal Foundation Models: From Specialists to General-Purpose Assistants</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>ViT,ViLT</title>
    <url>/www6vHomeAIGC/2023/03/01/gptMultimodalVit/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="vilt">ViLT</span><a href="#vilt" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/369733979">ViLTï¼šæœ€ç®€å•çš„å¤šæ¨¡æ€Transformer</a><br>1xx. <a href="https://github.com/dandelin/vilt">ViLT</a> git<br>1xx. <a href="https://blog.csdn.net/qq_42030496/article/details/134641704">ViLT è®ºæ–‡ç²¾è¯»ã€è®ºæ–‡ç²¾è¯»ã€‘</a><br>   <a href="https://www.bilibili.com/video/BV14r4y1j74y/">ViLT è®ºæ–‡ç²¾è¯»ã€è®ºæ–‡ç²¾è¯»ã€‘</a> V<br>1xx. <a href="https://blog.csdn.net/m0_56722835/article/details/125071550">å¤šæ¨¡æ€ViLTæ¨¡å‹ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒåŸç†åŠä»£ç </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>ViT</category>
      </categories>
      <tags>
        <tag>ViT</tag>
      </tags>
  </entry>
  <entry>
    <title>NL2SQL</title>
    <url>/www6vHomeAIGC/2023/01/03/gptNL2SQL/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://github.com/www6v/NL2SQL">https://github.com/www6v/NL2SQL</a><br>1xx. <a href="https://github.com/www6v/nl2sql-">https://github.com/www6v/nl2sql-</a><br>1xx. <a href="https://blog.langchain.dev/llms-and-sql/">LLMs and SQL</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/640580808">å¤§æ¨¡å‹ä¸æ•°æ®ç§‘å­¦ï¼šä»Text-to-SQL å¼€å§‹ï¼ˆä¸€ï¼‰</a> å¤šæ¬¾äº§å“</p>
<p>ç™¾åº¦åƒå¸†-ppt<br>QCon-ppt</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzUxNzk5MTU3OQ==&mid=2247487028&idx=1&sn=7b6767878b7f6b891fc69e408f248ef1">è¯­ä¹‰è§£æ (Text-to-SQL) æŠ€æœ¯ç ”ç©¶åŠåº”ç”¨ ä¸Šç¯‡ </a><br>1xx. <a href="https://mp.weixin.qq.com/s/5lTLW5OOuRMo2zjbzMxr_Q">è¯­ä¹‰è§£æ (Text-to-SQL) æŠ€æœ¯ç ”ç©¶åŠåº”ç”¨ ä¸‹ç¯‡ </a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/670509396">LLMåœ¨ä¸­æ–‡Text2SQLçš„å®è·µ</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/673474672">LLMåœ¨ä¸­æ–‡Text2SQLä»»åŠ¡ä¸Šçš„ä¼˜åŒ–V2.0</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/670913902">LLMåœ¨ä¸­æ–‡Text2SQLä»»åŠ¡ä¸Šçš„ä¼˜åŒ–V1.0</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402400&idx=1&sn=fe122657b35f27090aaca9c144d1d23b">ä¹Ÿçœ‹å¤§æ¨¡å‹ä¸æ•°æ®åº“æŸ¥è¯¢åˆ†æçš„è½åœ°ç»“åˆï¼šC3 Text2SQLæ–¹æ¡ˆåŠData-Copilotæ•°æ®è‡ªåŠ¨åŒ–ç¼–æ’æœºåˆ¶çš„å®ç°æ€æƒ³é˜…è¯» </a> </p>
<hr>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/668557045">C3: Zero-shot Text-to-SQL with ChatGPTç¬”è®°</a><br>1xx. <a href="https://github.com/bigbigwatermalon/C3SQL">C3SQL  </a> git</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648402424&idx=1&sn=e2d26821b6e9a5a2871e0ddbca565c30">å¤§æ¨¡å‹å†æ€»ç»“åŠChatSQLå®è·µæ¡ˆä¾‹åˆ†äº«ï¼šå¤§æ¨¡å‹è®­ç»ƒæ•°æ®åŠå·¥å…·çš„5å¼ è„‘å›¾æ€»ç»“åŠChatSQLå¼€æºé¡¹ç›®å®ç°è§£æ </a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>NL2SQL</category>
      </categories>
      <tags>
        <tag>NL2SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP ä»»åŠ¡</title>
    <url>/www6vHomeAIGC/2023/02/05/gptNLPTask/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="nlpä»»åŠ¡">NLPä»»åŠ¡</span><a href="#nlpä»»åŠ¡" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/02/05/gptNLPTask/NLP_tasks.jpg" class>


<ul>
<li><strong>æ–‡æœ¬æ‘˜è¦</strong> text summarization</li>
<li>ä¿¡æ¯æå– information extraction</li>
<li><strong>é—®ç­”</strong> question answering</li>
<li><strong>æ–‡æœ¬åˆ†ç±»</strong> text classification</li>
<li>å¯¹è¯ conversation</li>
<li>ä»£ç ç”Ÿæˆ code generation</li>
<li><strong>æ¨ç†</strong> reasoning</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399456&idx=1&sn=af2ee30aee9e7f6ed441b8335de033b1">å…³äºChatGPTè§£é”NLPä»»åŠ¡çš„ä¸€æ¬¡æ€»ç»“æ±‡æŠ¥ï¼šä»åº”ç”¨å˜åŒ–ã€14ç±»NLPä»»åŠ¡ä½¿ç”¨æ¡ˆä¾‹çœ‹é€‰å‹æ€è€ƒ</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)PEFT Lora</title>
    <url>/www6vHomeAIGC/2023/01/05/gptPEFTLora/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%9F%BA%E4%BA%8Ellama%E7%9A%84sft">åŸºäºLLaMAçš„SFT</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8Ebloom%E7%9A%84%E5%BE%AE%E8%B0%83">åŸºäºbloomçš„å¾®è°ƒ</a></li>
<li><a href="#lora-%E5%8F%82%E6%95%B0">Lora å‚æ•°</a></li>
<li><a href="#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5">æœ€ä½³å®è·µ</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#bloom">bloom</a></li>
<li><a href="#llama">LLaMA</a></li>
<li><a href="#chatglm">ChatGLM</a></li>
<li><a href="#others">others</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="åŸºäºllamaçš„sft">åŸºäºLLaMAçš„SFT</span><a href="#åŸºäºllamaçš„sft" class="header-anchor">#</a></h1><ul>
<li><p>ç‰ˆæœ¬</p>
<ul>
<li>deepspeedçš„ç‰ˆæœ¬  [3.1]</li>
<li>AutoGPTQçš„ç‰ˆæœ¬  0.6.0 -&gt; gitä¸‹è½½åˆ°æœ¬åœ°å®‰è£…</li>
</ul>
</li>
<li><p>ä»£ç é”™è¯¯</p>
<ul>
<li>use_flash_attention_2 ç›¸å…³çš„é”™è¯¯ [3.2]</li>
</ul>
</li>
<li><p>è„šæœ¬ [3.3]</p>
<ul>
<li>modescope ä¸‹è½½ shakechen&#x2F;Llama-2-7b-chat-hf</li>
<li>å•å¡è®­ç»ƒ<br>1ä¸ªepoch å·®ä¸å¤š7å°æ—¶</li>
</ul>
</li>
<li><p>checkpoint ç”Ÿæˆæ–‡ä»¶</p>
</li>
</ul>
<img src="/www6vHomeAIGC/2023/01/05/gptPEFTLora/llama-lora.png" class>

<img src="/www6vHomeAIGC/2023/01/05/gptPEFTLora/llama-lora1.png" class>

<ul>
<li>æ¨¡å‹ç”Ÿæˆæ–‡ä»¶</li>
</ul>
<img src="/www6vHomeAIGC/2023/01/05/gptPEFTLora/model1.png" class>

<img src="/www6vHomeAIGC/2023/01/05/gptPEFTLora/model2.png" class>



<h1><span id="åŸºäºbloomçš„å¾®è°ƒ">åŸºäºbloomçš„å¾®è°ƒ</span><a href="#åŸºäºbloomçš„å¾®è°ƒ" class="header-anchor">#</a></h1><ul>
<li><p>ç®€å•åŸºç¡€  [2]</p>
<ul>
<li>åŸºåº§æ¨¡å‹<br>Langboat&#x2F;bloom-1b4-zh </li>
<li>æ•°æ®é›†<br>shibing624&#x2F;alpaca-zh</li>
</ul>
</li>
<li><p>ç¨å¤æ‚[1]</p>
<ul>
<li>åŸºåº§æ¨¡å‹<br>bloomz-560m </li>
<li>æ•°æ®é›†<br>ought&#x2F;raft</li>
</ul>
</li>
</ul>
<h1><span id="lora-å‚æ•°">Lora å‚æ•°</span><a href="#lora-å‚æ•°" class="header-anchor">#</a></h1><ul>
<li><p>LoraConfig [2]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">LoraConfig( </span><br><span class="line">base_model_name_or_path=<span class="string">&#x27;Langboat/bloom-1b4-zh&#x27;</span>, </span><br><span class="line">task_type=&lt;TaskType.CAUSAL_LM: <span class="string">&#x27;CAUSAL_LM&#x27;</span>&gt;, </span><br><span class="line">inference_mode=<span class="literal">False</span>, </span><br><span class="line">r=<span class="number">8</span>, </span><br><span class="line">target_modules=&#123;<span class="string">&#x27;query_key_value&#x27;</span>&#125;, </span><br><span class="line">lora_alpha=<span class="number">32</span>, </span><br><span class="line">lora_dropout=<span class="number">0.1</span>, </span><br><span class="line">modules_to_save=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>å‚æ•°è¯´æ˜ [1]</p>
<ul>
<li>task_typeï¼šæŒ‡å®šä»»åŠ¡ç±»å‹ã€‚å¦‚ï¼šæ¡ä»¶ç”Ÿæˆä»»åŠ¡ï¼ˆSEQ_2_SEQ_LMï¼‰ï¼Œå› æœè¯­è¨€å»ºæ¨¡ï¼ˆCAUSAL_LMï¼‰ç­‰ã€‚</li>
<li>inference_modeï¼šæ˜¯å¦åœ¨æ¨ç†æ¨¡å¼ä¸‹ä½¿ç”¨Peftæ¨¡å‹ã€‚</li>
<li>rï¼š LoRAä½ç§©çŸ©é˜µçš„ç»´æ•°ã€‚å…³äºç§©çš„é€‰æ‹©ï¼Œé€šå¸¸ï¼Œä½¿ç”¨4ï¼Œ8ï¼Œ16å³å¯ã€‚</li>
<li>lora_alphaï¼š LoRAä½ç§©çŸ©é˜µçš„ç¼©æ”¾ç³»æ•°ï¼Œä¸ºä¸€ä¸ªå¸¸æ•°è¶…å‚ï¼Œè°ƒæ•´alphaä¸è°ƒæ•´å­¦ä¹ ç‡ç±»ä¼¼ã€‚</li>
<li>lora_dropoutï¼šLoRA å±‚çš„ä¸¢å¼ƒï¼ˆdropoutï¼‰ç‡ï¼Œå–å€¼èŒƒå›´ä¸º[0, 1)ã€‚</li>
<li>target_modulesï¼šè¦æ›¿æ¢ä¸º LoRA çš„æ¨¡å—åç§°åˆ—è¡¨æˆ–æ¨¡å—åç§°çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚é’ˆå¯¹ä¸åŒç±»å‹çš„æ¨¡å‹ï¼Œæ¨¡å—åç§°ä¸ä¸€æ ·.</li>
</ul>
</li>
<li><p>target_modules [1]<br>åœ¨ PEFT ä¸­æ”¯æŒçš„æ¨¡å‹é»˜è®¤çš„æ¨¡å—åå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING = &#123;</span><br><span class="line">    <span class="string">&quot;t5&quot;</span>: [<span class="string">&quot;q&quot;</span>, <span class="string">&quot;v&quot;</span>],</span><br><span class="line">    <span class="string">&quot;mt5&quot;</span>: [<span class="string">&quot;q&quot;</span>, <span class="string">&quot;v&quot;</span>],</span><br><span class="line">    <span class="string">&quot;bart&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;gpt2&quot;</span>: [<span class="string">&quot;c_attn&quot;</span>], <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;bloom&quot;</span>: [<span class="string">&quot;query_key_value&quot;</span>], <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;blip-2&quot;</span>: [<span class="string">&quot;q&quot;</span>, <span class="string">&quot;v&quot;</span>, <span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;opt&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;gptj&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;gpt_neox&quot;</span>: [<span class="string">&quot;query_key_value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;gpt_neo&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;bert&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>], <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;roberta&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;xlm-roberta&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;electra&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;deberta-v2&quot;</span>: [<span class="string">&quot;query_proj&quot;</span>, <span class="string">&quot;value_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;deberta&quot;</span>: [<span class="string">&quot;in_proj&quot;</span>],</span><br><span class="line">    <span class="string">&quot;layoutlm&quot;</span>: [<span class="string">&quot;query&quot;</span>, <span class="string">&quot;value&quot;</span>],</span><br><span class="line">    <span class="string">&quot;llama&quot;</span>: [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],  <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;chatglm&quot;</span>: [<span class="string">&quot;query_key_value&quot;</span>],  <span class="comment">#</span></span><br><span class="line">    <span class="string">&quot;gpt_bigcode&quot;</span>: [<span class="string">&quot;c_attn&quot;</span>],</span><br><span class="line">    <span class="string">&quot;mpt&quot;</span>: [<span class="string">&quot;Wqkv&quot;</span>],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1><span id="æœ€ä½³å®è·µ">æœ€ä½³å®è·µ</span><a href="#æœ€ä½³å®è·µ" class="header-anchor">#</a></h1><ul>
<li>ç§©rçš„å¤§å°[å¢è€å¸ˆ]<ul>
<li>æ¨¡å‹å¦‚æœæ˜¯å‚ç›´ç±»çš„å¤§æ¨¡å‹<br>eg. ç§æœ‰æ•°æ®<br><strong>rè®¾ç½®å¤§ç‚¹</strong></li>
<li>æ¨¡å‹å¦‚æœæ˜¯é€šç”¨ç±»çš„å¤§æ¨¡å‹<br>eg. è¿ç»´å¤§æ¨¡å‹<br><strong>rè®¾ç½®å°ç‚¹</strong></li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="bloom">bloom</span><a href="#bloom" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/649315197">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆäº”ï¼‰-LoRA</a><br><a href="https://github.com/www6v/llm-action/blob/main/train/peft/clm/peft_lora_clm.ipynb">bloom Lora</a> git</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV13w411y7fq/">ã€æ‰‹æŠŠæ‰‹å¸¦ä½ å®æˆ˜HuggingFace Transformers-é«˜æ•ˆå¾®è°ƒç¯‡ã€‘LoRA åŸç†ä¸å®æˆ˜</a> V<br> <a href="https://github.com/www6v/transformers-code/blob/master/03-PEFT/21-lora/chatbot_lora.ipynb">bloom Lora-origin</a>  <a href="https://colab.research.google.com/github/www6v/transformers-code/blob/master/03-PEFT/21-lora/chatbot_lora.ipynb">bloom Lora-origin</a> git   originè¿è¡Œæœ‰é—®é¢˜<br> <a href="https://github.com/www6v/transformers-code/blob/master/03-PEFT/21-lora/chatbot_lora%5Bworkable%5D.ipynb">bloom Lora-modify</a>  <a href="https://colab.research.google.com/drive/1SNy35_CJOobe4AxAecMZJo4LX1TjXvTm">bloom Lora-modify</a> ä¿®æ”¹è¿‡å¯ä»¥åœ¨colabè¿è¡Œçš„ä»£ç </p>
</li>
</ol>
<h3><span id="llama">LLaMA</span><a href="#llama" class="header-anchor">#</a></h3><ol start="3">
<li><a href="https://github.com/www6v/Llama2-Chinese/tree/ww-workable">Llama2-Chinese</a> æ¨¡å‹å¾®è°ƒ-&gt; lora SFT<br>3.1 <a href="https://github.com/www6v/Llama2-Chinese/blob/ww-workable/requirements.txt">requirements.txt</a><br>3.2 <a href="https://github.com/www6v/Llama2-Chinese/blob/ww-workable/train/sft/finetune_clm_lora.py#L460C18-L460C19">finetune_clm_lora.py</a>  æ³¨é‡Šæ‰ç¬¬360è¡Œ<br>3.3 <a href="https://github.com/www6v/Llama2-Chinese/blob/ww-workable/train/sft/finetune_lora.sh">train&#x2F;sft&#x2F;finetune_lora.sh</a></li>
</ol>
<p>1xx. <a href="https://blog.langchain.dev/using-langsmith-to-support-fine-tuning-of-open-source-llms/">Using LangSmith to Support Fine-tuning</a><br>    <a href="https://colab.research.google.com/drive/1tpywvzwOS74YndNXhI8NUaEfPeqOc7ub?usp=sharing&ref=blog.langchain.dev#scrollTo=v1tOYeVGtQKJ">LangSmith + LLaMA Fine-tuning Guide</a></p>
<h3><span id="chatglm">ChatGLM</span><a href="#chatglm" class="header-anchor">#</a></h3><p>1xx. ã€Š13-åŸºäº ChatGLM2çš„ Fine-tuning å®æˆ˜ã€‹ AI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆåŸ¹å…»è®¡åˆ’  2æœŸ<br>    <a href="https://github.com/www6v/fine-tuning-lab/blob/agiclass-v1/chatglm/train_lora.sh">train_lora.sh</a>  åŸºäºæ³•å¾‹æ–‡æœ¬çš„chatglmçš„lora<br>    <a href="https://github.com/www6v/fine-tuning-lab/blob/agiclass-v1/chatglm2/train_lora.sh">train_lora.sh</a>  åŸºäºæ³•å¾‹æ–‡æœ¬çš„chatglm-2çš„lora<br>    <a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/peft/index.ipynb">è¯¾ä»¶</a><br>    biliæœ‰ç›¸å…³çš„æ€»ç»“çš„è§†é¢‘</p>
<p>1xx. <a href="https://github.com/mymusise/ChatGLM-Tuning">ChatGLM-Tuning</a> å¢è€å¸ˆæ¨è</p>
<h3><span id="others">others</span><a href="#others" class="header-anchor">#</a></h3><p>1xx. <a href="https://lightning.ai/pages/community/lora-insights/">Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments</a> ***<br>     <a href="https://www.bilibili.com/video/BV16u4y1a7MH/">å‡ ç™¾æ¬¡å¤§æ¨¡å‹LoRAå’ŒQLoRA å¾®è°ƒå®è·µçš„ç»éªŒåˆ†äº«</a> V</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>P-Tuning</title>
    <url>/www6vHomeAIGC/2023/03/24/gptPEFTPtuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="p-tuning2">P-Tuning[2]</span><a href="#p-tuning2" class="header-anchor">#</a></h1><ul>
<li>P-Tuning çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå°†æç¤ºï¼ˆPromptï¼‰è½¬åŒ–ä¸º<strong>å¯å­¦ä¹ çš„åµŒå…¥å±‚ï¼ˆEmbedding Layerï¼‰</strong></li>
</ul>
<h3><span id="æ¶æ„">æ¶æ„</span><a href="#æ¶æ„" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/03/24/gptPEFTPtuning/ptuning.png" class>

<ul>
<li><p>ä¸€ä¸ªå…³äºâ€œThe capital of Britain is [MASK]â€ ç¤ºä¾‹ï¼š</p>
<ul>
<li>è“è‰²æ˜¯ä¸Šä¸‹æ–‡ â€œBritainâ€ </li>
<li>çº¢è‰²æ˜¯ç›®æ ‡å•è¯ â€œ[MASK]â€ï¼Œ </li>
<li>æ©™è‰²åŒºåŸŸæ˜¯æç¤ºè¯ã€‚</li>
</ul>
</li>
<li><p>ä¼ ç»Ÿæ–¹å¼ ä¸ P-Tuning å¯¹æ¯”ï¼š </p>
<ul>
<li>åœ¨ï¼ˆaï¼‰ä¸­ï¼Œæç¤ºç”Ÿæˆå™¨åªæ¥æ”¶ç¦»æ•£å¥–åŠ±ï¼› </li>
<li>åœ¨ï¼ˆbï¼‰ä¸­ï¼Œè¿ç»­çš„<strong>æç¤ºåµŒå…¥ï¼ˆPrompt Embeddingï¼‰</strong> å’Œ<strong>æç¤ºç¼–ç å™¨ï¼ˆPrompt Encoderï¼‰</strong>ä»¥å¯å¾®çš„æ–¹å¼è¿›è¡Œ ä¼˜åŒ–ã€‚</li>
</ul>
</li>
</ul>
<h1><span id="p-tuning-v22">P-Tuning v2[2]</span><a href="#p-tuning-v22" class="header-anchor">#</a></h1><h3><span id="èƒŒæ™¯">èƒŒæ™¯</span><a href="#èƒŒæ™¯" class="header-anchor">#</a></h3><p>ä¹‹å‰çš„æ–¹æ³•åœ¨ä»¥ä¸‹ä¸¤æ–¹é¢æœ‰æ‰€<strong>é™åˆ¶</strong>ï¼š<br>â€¢ æ¨¡å‹è§„æ¨¡å·®å¼‚ï¼šåœ¨å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼ŒPrompt Tuning å’Œ<br>P-Tuning èƒ½å–å¾—ä¸å…¨é¢å¾®è°ƒç›¸ä¼¼çš„æ•ˆæœï¼Œä½†åœ¨å‚æ•°è¾ƒå°‘<br>çš„æ¨¡å‹ä¸Šåˆ™è¡¨ç°ä¸ä½³ã€‚<br>â€¢ ä»»åŠ¡ç±»å‹å·®å¼‚ï¼šæ— è®ºæ˜¯ Prompt Tuning è¿˜æ˜¯ P-Tuningï¼Œ<br>åœ¨åºåˆ—æ ‡æ³¨ä»»åŠ¡ä¸Šçš„è¡¨ç°éƒ½è¾ƒå·®ã€‚</p>
<h3><span id="ç›®çš„">ç›®çš„</span><a href="#ç›®çš„" class="header-anchor">#</a></h3><p>P-Tuning v2 æ—¨åœ¨ä½¿æç¤ºè°ƒæ•´ï¼ˆPrompt Tuningï¼‰åœ¨ä¸åŒè§„æ¨¡çš„é¢„è®­ç»ƒæ¨¡å‹ä¸Šï¼Œé’ˆå¯¹å„ç§ä¸‹æ¸¸ä»»åŠ¡éƒ½èƒ½è¾¾åˆ°ç±»ä¼¼å…¨é¢å¾®è°ƒï¼ˆFine-tuningï¼‰çš„æ•ˆæœã€‚</p>
<h3><span id="æ¶æ„-1">æ¶æ„ [1]</span><a href="#æ¶æ„-1" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/03/24/gptPEFTPtuning/ptuning-v2.png" class>
<p>åœ¨æ¯ä¸€å±‚éƒ½åŠ å…¥äº†Prompts tokens ä½œä¸ºè¾“å…¥,  è€Œä¸æ˜¯ä»…ä»…åŠ åœ¨è¾“å…¥å±‚</p>
<h1><span id="æ€»ç»“">æ€»ç»“</span><a href="#æ€»ç»“" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/03/24/gptPEFTPtuning/compare.png" class>
<ul>
<li>P-tuning  å’Œ Prompt Tuning ä»…ä»…æ›´æ–°<strong>ç¬¬ä¸€ä¸ªTransformerå±‚</strong></li>
<li>Prefix tuning å’Œ P-Tuning v2 é’ˆå¯¹<strong>æ¯ä¸€ä¸ªTransformer å±‚</strong>è¿›è¡Œæ›´æ–°</li>
<li>Prefix tuning å’Œ P-Tuning éœ€è¦<strong>é‡æ–°å‚æ•°åŒ–(PromptEncoder)</strong>, è€ŒPrompt Tuning å’Œ P-Tuning v2åˆ™<strong>ä¸éœ€è¦</strong></li>
<li>ç®€å•å°†<strong>P-Tuning</strong>è®¤ä¸ºæ˜¯é’ˆå¯¹ <strong>Prompt Tuning</strong>çš„<strong>æ”¹è¿›</strong>,    <strong>P-Tuning v2</strong> è®¤ä¸ºæ˜¯é’ˆå¯¹ <strong>Prefix tuning</strong> çš„<strong>æ”¹è¿›</strong>.</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://aicarrier.feishu.cn/file/H1YvbRyacopEs6xzgZ8c9DDcnIh">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†åŠå®è·µ</a> pdf<br><a href="https://www.bilibili.com/video/BV1qw411c7Hd/">å¦‚ä½•é«˜æ•ˆå¾®è°ƒå¤§æ¨¡å‹ï¼ŸæŠ€æœ¯åŸç†ä¸æœ€ä½³å®è·µæ­ç§˜ï¼</a> V *** </p>
</li>
<li><p>ã€Š3-å¤§æ¨¡å‹å¾®è°ƒæŠ€æœ¯æ­ç§˜-PEFTã€‹ Aiå¤§æ¨¡å‹å¾®è°ƒ</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)PEFT P-Tuning</title>
    <url>/www6vHomeAIGC/2024/01/28/gptPEFTPtuningPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h3><span id="æœ€ä½³å®è·µ1">æœ€ä½³å®è·µ[1]</span><a href="#æœ€ä½³å®è·µ1" class="header-anchor">#</a></h3><ul>
<li>è¦çœ‹losss, ä¹Ÿè¦çœ‹<strong>ä¸šåŠ¡çš„loss</strong></li>
<li>ç”Ÿæˆæ¨¡å‹å¸¸ç”¨çš„è¯„ä»·æ–¹æ³•<ul>
<li><strong>BLEU èƒ½è¯„ä¼°</strong>æµç•…åº¦**</li>
<li>ç»“æœéƒ½æ˜¯æµç•…çš„å‰æä¸‹ï¼ŒROUGE ååº”å‚ç…§å¥ä¸­å¤šå°‘å†…å®¹è¢«ç”Ÿæˆçš„å¥å­åŒ…å«ï¼ˆå¬å›ï¼‰</li>
</ul>
</li>
<li>å‚ç›´æ¨¡å‹<ul>
<li><strong>stfä¹‹åå¤±å»é€šç”¨èƒ½åŠ›</strong></li>
<li>è¦æœ‰<strong>é€šç”¨èƒ½åŠ›</strong>, éœ€è¦<strong>pre-trainå’ŒSTFä¸­éƒ½èå…¥é€šç”¨çš„è¯­æ–™</strong></li>
</ul>
</li>
<li><strong>æ¯ä¸ªæ¨¡å‹çš„å­¦ä¹ ç‡lrä¸ä¸€æ ·</strong><ul>
<li>chatglmçš„å­¦ä¹ ç‡<br>LR&#x3D;2e-2</li>
</ul>
</li>
</ul>
<h3><span id="å­¦ä¹ ç‡">å­¦ä¹ ç‡</span><a href="#å­¦ä¹ ç‡" class="header-anchor">#</a></h3><ul>
<li>æ”¹çš„<strong>ç‰¹åˆ«å¤§</strong><br>æ¨¡å‹è®­ç»ƒçš„æ—¶å€™ä¼š<strong>éœ‡è¡</strong></li>
<li>æ”¹çš„<strong>ç‰¹åˆ«å°</strong><br> æ¨¡å‹è®­ç»ƒçš„æ—¶å€™ä¼š<strong>æ”¶æ•›éå¸¸æ…¢</strong></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li>ã€Š13-åŸºäº ChatGLM2çš„ Fine-tuning å®æˆ˜ã€‹ AI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆåŸ¹å…»è®¡åˆ’  2æœŸ<br><a href="https://github.com/www6v/fine-tuning-lab/blob/agiclass-v1/chatglm/train_pt2.sh">train_pt2.sh</a> git   åŸºäºæ³•å¾‹æ–‡æœ¬çš„chatglmçš„p-tuning<br><a href="https://github.com/www6v/fine-tuning-lab/blob/agiclass-v1/chatglm2/train_pt2.sh">train_pt2.sh</a> git   åŸºäºæ³•å¾‹æ–‡æœ¬çš„chatglm-2çš„P-tuning v2<br><a href="https://github.com/www6v/fullStackLLM/blob/master/08-fine-tuning/peft/index.ipynb">è¯¾ä»¶</a><br>biliæœ‰ç›¸å…³çš„æ€»ç»“çš„è§†é¢‘</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)PEFT QLoRA</title>
    <url>/www6vHomeAIGC/2024/01/12/gptPEFTQLora/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86-1">æŠ€æœ¯åŸç† [1]</a></li>
<li><a href="#%E5%AE%9E%E6%88%981-2">å®æˆ˜1 [2]</a></li>
<li><a href="#%E5%8F%82%E6%95%B0">å‚æ•°</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="æŠ€æœ¯åŸç†-1">æŠ€æœ¯åŸç† [1]</span><a href="#æŠ€æœ¯åŸç†-1" class="header-anchor">#</a></h1><p>ä½¿ç”¨ä¸€ç§æ–°é¢–çš„é«˜ç²¾åº¦æŠ€æœ¯å°†é¢„è®­ç»ƒæ¨¡å‹é‡åŒ–ä¸º 4 bitï¼Œç„¶åæ·»åŠ ä¸€å°ç»„å¯å­¦ä¹ çš„ä½ç§©é€‚é…å™¨æƒé‡ï¼Œè¿™äº›æƒé‡é€šè¿‡é‡åŒ–æƒé‡çš„åå‘ä¼ æ’­æ¢¯åº¦è¿›è¡Œå¾®è°ƒã€‚<br>QLoRAæå‡ºäº†ä¸¤ç§æŠ€æœ¯å®ç°é«˜ä¿çœŸ 4 bitå¾®è°ƒâ€”â€”4 bit NormalFloat(NF4) é‡åŒ–å’ŒåŒé‡åŒ–ã€‚</p>
<ul>
<li><p>4bit NormalFloatï¼ˆNF4ï¼‰ï¼šå¯¹äºæ­£æ€åˆ†å¸ƒæƒé‡è€Œè¨€ï¼Œä¸€ç§ä¿¡æ¯ç†è®ºä¸Šæœ€ä¼˜çš„æ–°æ•°æ®ç±»å‹ï¼Œè¯¥æ•°æ®ç±»å‹å¯¹æ­£æ€åˆ†å¸ƒæ•°æ®äº§ç”Ÿæ¯” 4 bitæ•´æ•°å’Œ 4bit æµ®ç‚¹æ•°æ›´å¥½çš„å®è¯ç»“æœã€‚</p>
</li>
<li><p>åŒé‡åŒ–ï¼šå¯¹ç¬¬ä¸€æ¬¡é‡åŒ–åçš„é‚£äº›å¸¸é‡å†è¿›è¡Œä¸€æ¬¡é‡åŒ–ï¼Œå‡å°‘å­˜å‚¨ç©ºé—´ã€‚</p>
</li>
<li><p>åˆ†é¡µä¼˜åŒ–å™¨:  ä½¿ç”¨æ­¤åŠŸèƒ½ä¸ºä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆOptimizerï¼‰åˆ†é…åˆ†é¡µå†…å­˜ï¼Œç„¶ååœ¨ GPU å†…å­˜ä¸è¶³æ—¶å°†å…¶è‡ªåŠ¨å¸è½½åˆ° CPU å†…å­˜ï¼Œå¹¶åœ¨ä¼˜åŒ–å™¨æ›´æ–°æ­¥éª¤éœ€è¦æ—¶å°†å…¶åŠ è½½å› GPU å†…å­˜ã€‚</p>
</li>
</ul>
<img src="/www6vHomeAIGC/2024/01/12/gptPEFTQLora/qlora.png" class>

<p>å®éªŒè¯æ˜ï¼Œæ— è®ºæ˜¯ä½¿ç”¨16bitã€8bitè¿˜æ˜¯4bitçš„é€‚é…å™¨æ–¹æ³•ï¼Œéƒ½èƒ½å¤Ÿå¤åˆ¶16bitå…¨å‚æ•°å¾®è°ƒçš„åŸºå‡†æ€§èƒ½ã€‚è¿™è¯´æ˜ï¼Œå°½ç®¡é‡åŒ–è¿‡ç¨‹ä¸­ä¼šå­˜åœ¨æ€§èƒ½æŸå¤±ï¼Œä½†é€šè¿‡é€‚é…å™¨å¾®è°ƒï¼Œå®Œå…¨å¯ä»¥æ¢å¤è¿™äº›æ€§èƒ½ã€‚</p>
<h1><span id="å®æˆ˜1-2">å®æˆ˜1 [2]</span><a href="#å®æˆ˜1-2" class="header-anchor">#</a></h1><h1><span id="å‚æ•°">å‚æ•°</span><a href="#å‚æ•°" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/636215898">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆäº”ï¼‰-LoRAã€AdaLoRAã€QLoRA</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/636644164">é«˜æ•ˆå¾®è°ƒæŠ€æœ¯QLoRAå®æˆ˜ï¼ŒåŸºäºLLaMA-65Bå¾®è°ƒä»…éœ€48Gæ˜¾å­˜ï¼ŒçœŸé¦™</a>  å…ˆæ˜¯è®­ç»ƒllama-7b, å†æ˜¯è®­ç»ƒllama-65b<br><a href="https://github.com/www6v/llm-action/tree/main/train/qlora">qlora</a> git</p>
</li>
<li><p><a href="https://github.com/zyds/transformers-code/tree/master/04-Kbit%20Training/27-4bits_training">4bits_training</a><br><a href="https://www.bilibili.com/video/BV1DQ4y1t7e8/">ã€æ‰‹æŠŠæ‰‹å¸¦ä½ å®æˆ˜HuggingFace Transformers-ä½ç²¾åº¦è®­ç»ƒç¯‡ã€‘4bité‡åŒ–ä¸QLoRAæ¨¡å‹è®­ç»ƒ</a> V</p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/671089942">[å¤§æ¨¡å‹å¾®è°ƒæŠ€æœ¯] LoRAã€QLoRAã€QA-LoRA åŸç†ç¬”è®°</a><br>1xx. <a href="https://cloud.tencent.com/developer/article/2375230">å¤§æ¨¡å‹å®æ“ | LoRAã€QLoRAå¾®è°ƒå¤§æ¨¡å‹å®æˆ˜æŠ€å·§åˆ†äº«ï¼Œå«å¸¸è§QAè§£ç­”ï¼</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>ç§‘ç ”-å·¥å…·</title>
    <url>/www6vHomeAIGC/2024/02/11/gptPaperTools/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="è®ºæ–‡ç®¡ç†1">è®ºæ–‡ç®¡ç†[1]</span><a href="#è®ºæ–‡ç®¡ç†1" class="header-anchor">#</a></h1><ul>
<li><p>Readpaper<br><a href="https://readpaper.com/new">https://readpaper.com/new</a><br>è®ºæ–‡åœ¨çº¿é˜…è¯»ï¼Œè®ºæ–‡æœç´¢ï¼Œç®¡ç†</p>
</li>
<li><p>Connected Papers å¼•ç”¨å…³ç³»<br><a href="https://www.connectedpapers.com/">https://www.connectedpapers.com/</a></p>
</li>
<li><p>AI é¡¶ä¼šå€’è®¡æ—¶<br><a href="https://aideadlin.es/?sub=ML,CV,NLP">https://aideadlin.es/?sub=ML,CV,NLP</a></p>
</li>
<li><p>Aminer<br><a href="https://www.aminer.cn/">https://www.aminer.cn/</a><br>æœ€æ–°çš„è¿›å±•å¦‚ä½•<br>è¿˜æœ‰ä¸ªå¿…è¯»è®ºæ–‡ç³»åˆ—</p>
</li>
</ul>
<h1><span id="å†™ä½œ1">å†™ä½œ[1]</span><a href="#å†™ä½œ1" class="header-anchor">#</a></h1><ul>
<li><p>DeepLç¿»è¯‘<br>deepl.com&#x2F;translator</p>
</li>
<li><p>overleaf<br>overleaf.com&#x2F;project</p>
</li>
</ul>
<h1><span id="è®ºæ–‡å…ƒç´ -1">è®ºæ–‡å…ƒç´  [1]</span><a href="#è®ºæ–‡å…ƒç´ -1" class="header-anchor">#</a></h1><ul>
<li><p>quillbot.com&#x2F;<br>æ”¹å†™, æ£€æŸ¥è¯­æ³•, æ‘˜è¦ç”Ÿæˆ</p>
</li>
<li><p>Table generator<br><a href="https://www.tablesgenerator.com/latex_tables">https://www.tablesgenerator.com/latex_tables</a><br>latexè¡¨æ ¼ç”Ÿæˆ</p>
</li>
<li><p>echarts<br><a href="https://echarts.apache.org/examples/en/index.html#chart-type-bar">https://echarts.apache.org/examples/en/index.html#chart-type-bar</a><br>ç”»å›¾</p>
</li>
<li><p>detexify Latexç¬¦å·<br><a href="http://detexify.kirelabs.org/classify.html">http://detexify.kirelabs.org/classify.html</a><br>æ‰‹ç»˜ç¬¦å·è½¬æ¢æˆlatexä»£ç </p>
</li>
<li><p>DBLP<br>dblp.uni-trier.de&#x2F;<br>latexå¼•ç”¨</p>
</li>
<li><p>esoda è¯ç»„ç”¨æ³•ç¤ºä¾‹<br>esoda.org&#x2F;</p>
</li>
<li><p>wikidiff è¿‘ä¹‰è¯ç†è§£<br><a href="https://wikidiff.com/neglect/omit">https://wikidiff.com/neglect/omit</a></p>
</li>
<li><p>åœ¨çº¿latexå…¬å¼ç¼–è¾‘å™¨<br><a href="https://www.latexlive.com/##">https://www.latexlive.com/##</a></p>
</li>
<li><p>mathpix å…¬å¼å›¾ç‰‡è½¬æ¢æˆlatex<br><a href="https://mathpix.com/">https://mathpix.com/</a><br>å…¬å¼å›¾ç‰‡è¯†åˆ«æˆlatexå…¬å¼</p>
</li>
</ul>
<h1><span id="aigc-æ–‡æ¡£åˆ†æampç§‘ç ”">AIGC æ–‡æ¡£åˆ†æ&amp;ç§‘ç ”</span><a href="#aigc-æ–‡æ¡£åˆ†æampç§‘ç ”" class="header-anchor">#</a></h1><ul>
<li><p>åœ¨çº¿æ–‡æ¡£åˆ†æ<br>Microsoft Edge Dev + new Bing  ***</p>
</li>
<li><p>æ–‡çŒ®æŸ¥æ‰¾ + æ¶¦è‰²<br>Skype + new Bing  ***</p>
</li>
<li><p>æœ¬åœ°æ–‡æ¡£åˆ†æ</p>
<ul>
<li><p>VPN</p>
<ul>
<li>chatpdf  æ”¶è´¹  ***<br><a href="https://www.chatpdf.com/">Chat with any PDF</a> æ€»ç»“æ–‡çŒ®</li>
<li><a href="https://chatdoc.com/">Chat with documents</a></li>
</ul>
</li>
<li><p>éVPN</p>
<ul>
<li><a href="https://chatpaper.org/">ChatPaper</a>  Paper ä¸­æ–‡<br><a href="https://github.com/kaixindelele/ChatPaper">ChatPaper</a> git</li>
<li><a href="https://chat2doc.cn/">é˜…è¯»æ–‡æ¡£çš„å¥½å¸®æ‰‹</a>  æ”¶è´¹</li>
<li><a href="https://lightpdf.com/chatdoc">LightPDF AI Tools</a> *** </li>
<li><a href="https://docalysis.com/files/hwylw4">docalysis</a> ***</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="newbing-chat-2">NewBing chat [2]</span><a href="#newbing-chat-2" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2024/02/11/gptPaperTools/newBing.jpg" class>

<h3><span id="å­¦æœ¯prompt">å­¦æœ¯Prompt</span><a href="#å­¦æœ¯prompt" class="header-anchor">#</a></h3><ul>
<li>åœ¨çº¿æ–‡çŒ®å…¨æ–‡åˆ†æ [new Bing] <ul>
<li>å¸®æˆ‘æ€»ç»“ä¸€ä¸‹è¿™ç¯‡æ–‡ç« çš„<strong>è¦ç‚¹</strong></li>
<li>å¸®æˆ‘æ­£å¯¹æœ¬ç ”ç©¶è®ºæ–‡å†™ä¸€ç¯‡<strong>æ€»ç»“æŠ¥å‘Š</strong>ï¼Œ 600å­—</li>
<li>å¸®æˆ‘æ€»ç»“æœ¬ç ”ç©¶çš„è®¨è®ºéƒ¨åˆ† é‡‡ç”¨äº†å“ªç§<strong>å†™ä½œæ¡†æ¶</strong>ï¼Œ æ˜¯å¦è¿›è¡Œäº†ä¸å…¶å®ƒç ”ç©¶çš„å¯¹æ¯”ï¼Œæœ‰æ— è¡¨æ˜æœ¬ç ”ç©¶çš„<strong>å±€é™æ€§</strong>å’Œ<strong>æœªæ¥ç ”ç©¶å¯èƒ½æ€§</strong>?</li>
<li>å¸®æˆ‘æ€»ç»“æœ¬ç ”ç©¶çš„æ–¹æ³•éƒ¨åˆ†ç”¨äº†å“ªäº›<strong>ç ”ç©¶æ–¹æ³•</strong>ï¼Ÿ</li>
<li>æœ¬ç ”ç©¶æ–¹æ³•éƒ¨åˆ†çš„Western Blotæ˜¯å¦‚ä½•å®æ–½çš„ï¼Ÿ</li>
<li>æ€»ç»“ä¸‹æœ¬è®ºæ–‡Introductionéƒ¨åˆ†åœ¨å†™ä½œæ–¹é¢ï¼Œæœ‰å“ªäº›<strong>è¯æ±‡å’Œå¥å¼</strong>å€¼å¾—åœ¨SCIè®ºæ–‡å†™ä½œä¸­ç§¯ç´¯å€Ÿé‰´</li>
</ul>
</li>
</ul>
<h1><span id="tools">Tools</span><a href="#tools" class="header-anchor">#</a></h1><ul>
<li><a href="https://app.seaml.es/">Seamless for science</a> bibi1<br>abstract</li>
<li><a href="https://typeset.io/">scispace</a>  bibi1<br>æ¶¦è‰² åˆ¤é‡</li>
<li><a href="https://www.txyz.ai/">txyz</a></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://zhuanlan.zhihu.com/p/661767969">å·¥æ¬²å–„ç§‘ç ”ï¼Œå¿…å…ˆåˆ©å…¶å™¨</a></li>
<li><a href="https://www.bilibili.com/video/BV18M4y1C7HY/">æ•´åˆchatGPTçš„æ–°å¿…åº”ï¼ˆNewBing chatï¼‰ç®€ç›´å°±æ˜¯ç§‘ç ”ç¥å™¨ï¼</a></li>
</ol>
]]></content>
      <categories>
        <category>ç§‘ç ”</category>
      </categories>
      <tags>
        <tag>ç§‘ç ”</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†|å®æˆ˜)æ··åˆç²¾åº¦</title>
    <url>/www6vHomeAIGC/2024/02/01/gptPrecision/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%9B%AE%E7%9A%843">ç›®çš„[3]</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8%E7%9A%84%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E5%8E%9F%E5%9B%A0">ä½¿ç”¨çš„æ··åˆç²¾åº¦åŸå› </a></li>
<li><a href="#%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">æ··åˆç²¾åº¦è§£å†³æ–¹æ¡ˆ</a><ul>
<li><a href="#fp32-%E6%9D%83%E9%87%8D%E5%A4%87%E4%BB%BD-12">FP32 æƒé‡å¤‡ä»½ [1][2]</a></li>
<li><a href="#loss-scale12">Loss Scale[1][2]</a></li>
</ul>
</li>
<li><a href="#%E5%AE%9E%E6%88%98">å®æˆ˜</a><ul>
<li><a href="#llama%E5%8D%8A%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%8320">llamaåŠç²¾åº¦è®­ç»ƒ[20]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E5%8E%9F%E7%90%86">åŸç†</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81">ä»£ç </a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="ç›®çš„3">ç›®çš„[3]</span><a href="#ç›®çš„3" class="header-anchor">#</a></h1><p>ä¸ºäº†<strong>åŠ å¿«è®­ç»ƒæ—¶é—´</strong>ã€<strong>å‡å°‘ç½‘ç»œè®­ç»ƒæ—¶å€™æ‰€å ç”¨çš„å†…å­˜</strong>ï¼Œå¹¶ä¸”ä¿å­˜è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ç²¾åº¦æŒå¹³çš„æ¡ä»¶ä¸‹ï¼Œä¸šç•Œæå‡ºè¶Šæ¥è¶Šå¤šçš„æ··åˆç²¾åº¦è®­ç»ƒçš„æ–¹æ³•</p>
<h1><span id="ä½¿ç”¨çš„æ··åˆç²¾åº¦åŸå› ">ä½¿ç”¨çš„æ··åˆç²¾åº¦åŸå› </span><a href="#ä½¿ç”¨çš„æ··åˆç²¾åº¦åŸå› " class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2024/02/01/gptPrecision/solution.png" class>

<h1><span id="æ··åˆç²¾åº¦è§£å†³æ–¹æ¡ˆ">æ··åˆç²¾åº¦è§£å†³æ–¹æ¡ˆ</span><a href="#æ··åˆç²¾åº¦è§£å†³æ–¹æ¡ˆ" class="header-anchor">#</a></h1><h3><span id="fp32-æƒé‡å¤‡ä»½-12">FP32 æƒé‡å¤‡ä»½ [1][2]</span><a href="#fp32-æƒé‡å¤‡ä»½-12" class="header-anchor">#</a></h3><p>è¿™ç§æ–¹æ³•ä¸»è¦æ˜¯ç”¨äº<strong>è§£å†³èˆå…¥è¯¯å·®</strong>çš„é—®é¢˜ã€‚</p>
<img src="/www6vHomeAIGC/2024/02/01/gptPrecision/weight-backup.jpg" class> 

<h3><span id="loss-scale12">Loss Scale[1][2]</span><a href="#loss-scale12" class="header-anchor">#</a></h3><p>Loss Scale ä¸»è¦æ˜¯ä¸ºäº†<strong>è§£å†³ fp16 underflow</strong>çš„é—®é¢˜ã€‚</p>
<img src="/www6vHomeAIGC/2024/02/01/gptPrecision/loss-scale.jpg" class> 


<h1><span id="å®æˆ˜">å®æˆ˜</span><a href="#å®æˆ˜" class="header-anchor">#</a></h1><h3><span id="llamaåŠç²¾åº¦è®­ç»ƒ20">llamaåŠç²¾åº¦è®­ç»ƒ[20]</span><a href="#llamaåŠç²¾åº¦è®­ç»ƒ20" class="header-anchor">#</a></h3><ul>
<li>ç°è±¡<br>losså…ˆå˜å¤§ï¼Œå†ä¸º0<br>lossçˆ†ç‚¸ï¼Œlossæ¶ˆå¤±</li>
<li>è§£å†³æ–¹æ¡ˆ<br>padding&#x3D;left<br>æ”¹ä¸ºpadding&#x3D;right</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;D:/Pretrained_models/modelscope/Llama-2-7b-ms&quot;</span>, low_cpu_mem_usage=<span class="literal">True</span>, torch_dtype=torch.half, device_map=<span class="string">&quot;auto&quot;</span>)</span><br></pre></td></tr></table></figure>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="åŸç†">åŸç†</span><a href="#åŸç†" class="header-anchor">#</a></h3><ol>
<li><a href="https://www.bilibili.com/video/BV1R94y1g78L?p=6">æ··åˆç²¾åº¦</a>  *** V</li>
<li><a href="https://zhuanlan.zhihu.com/p/103685761">æµ…è°ˆæ··åˆç²¾åº¦è®­ç»ƒ</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/441591808">å…¨ç½‘æœ€å…¨-æ··åˆç²¾åº¦è®­ç»ƒåŸç†</a>  ***<br>1xx. <a href="https://zhuanlan.zhihu.com/p/608634079">ã€æ·±åº¦å­¦ä¹ ã€‘æ··åˆç²¾åº¦è®­ç»ƒä¸æ˜¾å­˜åˆ†æ</a></li>
</ol>
<h3><span id="ä»£ç ">ä»£ç </span><a href="#ä»£ç " class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://www.bilibili.com/video/BV1CB4y1R78v/">åŠç²¾åº¦è®­ç»ƒä¸LLaMA2è®­ç»ƒå®æˆ˜</a> æœ‰ä»£ç <br><a href="https://github.com/www6v/transformers-code/blob/master/04-Kbit%20Training/25-16bits_training/llama2_lora_16bit.ipynb">llama2_lora_16bit.ipynb</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/165152789">PyTorchçš„è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰</a><br>1xx. <a href="https://tensorflow.google.cn/guide/mixed_precision?hl=zh-cn">æ··åˆç²¾åº¦</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Precision</category>
      </categories>
      <tags>
        <tag>Precision</tag>
      </tags>
  </entry>
  <entry>
    <title>Prompt-How to use</title>
    <url>/www6vHomeAIGC/2021/05/26/gptPrompt/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E4%B9%94%E5%93%88%E9%87%8C%E6%B2%9F%E9%80%9A%E8%A7%86%E7%AA%97-4-%E8%B1%A1%E9%99%90">ä¹”å“ˆé‡Œæ²Ÿé€šè§†çª—-4 è±¡é™</a><ul>
<li><a href="#%E4%BD%A0%E4%B8%8D%E7%9F%A5%E9%81%93gpt%E7%9F%A5%E9%81%93">ä½ ä¸çŸ¥é“ï¼ŒGPTçŸ¥é“</a></li>
<li><a href="#%E4%BD%A0%E7%9F%A5%E9%81%93gpt%E4%B9%9F%E7%9F%A5%E9%81%93">ä½ çŸ¥é“ï¼ŒGPTä¹ŸçŸ¥é“</a></li>
<li><a href="#%E4%BD%A0%E7%9F%A5%E9%81%93gpt%E4%B8%8D%E7%9F%A5%E9%81%93">ä½ çŸ¥é“ï¼ŒGPTä¸çŸ¥é“</a></li>
<li><a href="#%E4%BD%A0%E5%92%8Cgpt%E9%83%BD%E4%B8%8D%E7%9F%A5%E9%81%93">ä½ å’ŒGPTéƒ½ä¸çŸ¥é“</a></li>
</ul>
</li>
<li><a href="#%E8%BE%BE%E5%85%8B%E6%95%88%E5%BA%94">è¾¾å…‹æ•ˆåº”</a><ul>
<li><a href="#%E6%A3%80%E9%AA%8C%E8%87%AA%E5%B7%B1%E8%AE%A4%E7%9F%A5%E8%83%BD%E5%8A%9B%E6%B0%B4%E5%B9%B3%E6%8F%90%E9%97%AE%E5%8F%A5%E5%BC%8F">æ£€éªŒè‡ªå·±è®¤çŸ¥&#x2F;èƒ½åŠ›æ°´å¹³æé—®å¥å¼</a></li>
</ul>
</li>
<li><a href="#%E7%9F%A5%E9%81%93%E5%81%9A%E5%88%B0">çŸ¥é“åšåˆ°</a></li>
<li><a href="#%E8%A7%92%E8%89%B2%E5%85%B3%E7%B3%BB">è§’è‰²å…³ç³»</a></li>
<li><a href="#%E9%80%9A%E7%94%A8">é€šç”¨</a><ul>
<li><a href="#%E6%B2%9F%E9%80%9A%E6%A8%A1%E5%BC%8F">æ²Ÿé€šæ¨¡å¼</a></li>
<li><a href="#%E5%BD%92%E7%BA%B3">å½’çº³</a></li>
<li><a href="#%E6%80%9D%E7%BB%B4%E9%93%BE">æ€ç»´é“¾</a></li>
<li><a href="#%E6%B2%A1%E5%95%A5%E7%94%A8">æ²¡å•¥ç”¨</a></li>
</ul>
</li>
<li><a href="#prompt-how-to-use">Prompt - How to use</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="ä¹”å“ˆé‡Œæ²Ÿé€šè§†çª—-4-è±¡é™">ä¹”å“ˆé‡Œæ²Ÿé€šè§†çª—-4 è±¡é™</span><a href="#ä¹”å“ˆé‡Œæ²Ÿé€šè§†çª—-4-è±¡é™" class="header-anchor">#</a></h1><h3><span id="ä½ ä¸çŸ¥é“gptçŸ¥é“">ä½ ä¸çŸ¥é“ï¼ŒGPTçŸ¥é“</span><a href="#ä½ ä¸çŸ¥é“gptçŸ¥é“" class="header-anchor">#</a></h3><p>1ã€å…ƒé—®é¢˜ï¼šæˆ‘æƒ³äº†è§£xxxxï¼Œæˆ‘åº”è¯¥å‘ä½ é—®å“ªäº›é—®é¢˜ï¼Ÿ<br>2ã€è¯·ç»™æˆ‘åˆ—å‡ºxxxé¢†åŸŸ&#x2F;è¡Œä¸šç›¸å…³çš„ï¼Œæœ€å¸¸ç”¨çš„50ä¸ªæ¦‚å¿µï¼Œå¹¶åšç®€å•è§£é‡Šã€‚å¦‚æœæœ‰è‹±æ–‡ç¼©å†™ï¼Œè¯·ç»™å‡ºå®Œæ•´çš„è‹±æ–‡è§£é‡Šã€‚<br>3ã€è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹elon muskçš„ä¸»è¦ç”Ÿå¹³äº‹è¿¹ã€‚è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹teslaè¿™å®¶ä¼ä¸šçš„å‘å±•å†ç¨‹ã€‚</p>
<h3><span id="ä½ çŸ¥é“gptä¹ŸçŸ¥é“">ä½ çŸ¥é“ï¼ŒGPTä¹ŸçŸ¥é“</span><a href="#ä½ çŸ¥é“gptä¹ŸçŸ¥é“" class="header-anchor">#</a></h3><p>æ£€éªŒè®¤çŸ¥ï¼š<br>1ã€å¯¹äºxxxä¸»é¢˜&#x2F;æŠ€èƒ½ï¼Œä½ è®¤ä¸ºå“ªäº›æ˜¯æˆ‘å¿…é¡»ç†è§£å’ŒæŒæ¡çš„æ ¸å¿ƒè¦ç‚¹ï¼Ÿ<br>2ã€æˆ‘ç†è§£çš„xxxæ˜¯è¿™æ ·çš„ï¼Œä½ è§‰å¾—æˆ‘çš„ç†è§£å¯¹å—ï¼Ÿ<br>3ã€æˆ‘å¯¹xxxæœ‰ä¸€äº›æƒ³æ³•ï¼Œä½ èƒ½å¸®æˆ‘æ‰¹åˆ¤æ€§åœ°åˆ†æä¸€ä¸‹è¿™äº›æƒ³æ³•çš„ä¼˜ç‚¹å’Œç¼ºç‚¹å—ï¼Ÿ<br>4ã€æˆ‘æ­£åœ¨è€ƒè™‘xxxçš„å†³å®šï¼Œä½ èƒ½å¸®æˆ‘åˆ†æä¸€ä¸‹å¯èƒ½çš„ç»“æœå’Œå½±å“å—ï¼Ÿ</p>
<p>æ‰©å……è®¤çŸ¥ï¼š<br>1ã€æˆ‘çŸ¥é“xxxçš„æ¦‚å¿µï¼Œæˆ‘æƒ³çŸ¥é“æ›´å¤šå…³äºxxxçš„ä¿¡æ¯ã€‚<br>2ã€æˆ‘åœ¨xxxé—®é¢˜ä¸Šé‡åˆ°å›°éš¾ï¼Œä½ èƒ½æä¾›ä¸€äº›å¯èƒ½çš„è§£å†³æ–¹æ¡ˆæˆ–å»ºè®®å—ï¼Ÿ<br>3ã€æˆ‘æƒ³è¦æ·±å…¥å­¦ä¹ xxxï¼Œä½ èƒ½æ¨èä¸€äº›è¿›é˜¶çš„å­¦ä¹ èµ„æºæˆ–å­¦ä¹ è·¯å¾„å—ï¼Ÿ<br>4ã€æˆ‘æƒ³è¦åœ¨xxxé¢†åŸŸæœ‰æ‰€åˆ›æ–°ï¼Œä½ èƒ½æä¾›ä¸€äº›å¯å‘æˆ–æƒ³æ³•å—ï¼Ÿ<br>5ã€æˆ‘æƒ³åœ¨xxxé¢†åŸŸæå‡è‡ªå·±ï¼Œä½ èƒ½æ ¹æ®æœ€æ–°çš„ç ”ç©¶å’Œè¶‹åŠ¿ç»™æˆ‘ä¸€äº›å»ºè®®å—ï¼Ÿ<br>6ã€æˆ‘æ­£åœ¨è€ƒè™‘å­¦ä¹ xxxï¼Œä½ èƒ½ç»™æˆ‘ä¸€äº›å…³äºè¿™ä¸ªé¢†åŸŸæœªæ¥å‘å±•çš„è§‚ç‚¹å—ï¼Ÿ<br>7ã€ï¼ˆèƒŒæ™¯ä¿¡æ¯xxxï¼‰ï¼Œæˆ‘è¦åšå…³äºxxxçš„ç ”ç©¶ï¼Œæˆ‘è®¤ä¸ºåŸå› æ˜¯ï¼Œè¿˜æœ‰å…¶ä»–å¯èƒ½çš„åŸå› å—ï¼Ÿç»™å‡ºä¸€äº›å¯èƒ½çš„ç ”ç©¶å‡è®¾ã€‚<br>8ã€æˆ‘æ˜¯ä¸€ä¸ªxxæ–°æ‰‹ï¼Œé©¬ä¸Šè¦é‡‡è®¿è¿™ä¸ªè¡Œä¸šçš„èµ„æ·±å¤§ä½¬ï¼Œæˆ‘åº”è¯¥å‘ä»–è¯·æ•™å“ªäº›æœ‰ä»·å€¼çš„é—®é¢˜ï¼Ÿ</p>
<h3><span id="ä½ çŸ¥é“gptä¸çŸ¥é“">ä½ çŸ¥é“ï¼ŒGPTä¸çŸ¥é“</span><a href="#ä½ çŸ¥é“gptä¸çŸ¥é“" class="header-anchor">#</a></h3><p>ä»‹ç»èƒŒæ™¯ç°è±¡ä¹‹åå¯ä»¥å‘gptå‘é—®ï¼Œä½ æ€ä¹ˆçœ‹å¾…è¿™ç§ç°è±¡ï¼Ÿå¯èƒ½çš„åŸå› æœ‰å“ªäº›ï¼Ÿè¿™ä¼šå¯¹xxxäº§ç”Ÿä»€ä¹ˆæ ·çš„å½±å“ï¼Ÿä½ è§‰å¾—xxxåº”è¯¥æ€ä¹ˆåšï¼Ÿ</p>
<h3><span id="ä½ å’Œgptéƒ½ä¸çŸ¥é“">ä½ å’ŒGPTéƒ½ä¸çŸ¥é“</span><a href="#ä½ å’Œgptéƒ½ä¸çŸ¥é“" class="header-anchor">#</a></h3><p>å¦‚æœxxxï¼Œè¿™å¯¹ç¤¾ä¼šä¼šäº§ç”Ÿä»€ä¹ˆå½±å“ï¼Ÿ</p>
<h1><span id="è¾¾å…‹æ•ˆåº”">è¾¾å…‹æ•ˆåº”</span><a href="#è¾¾å…‹æ•ˆåº”" class="header-anchor">#</a></h1><h3><span id="æ£€éªŒè‡ªå·±è®¤çŸ¥x2fèƒ½åŠ›æ°´å¹³æé—®å¥å¼">æ£€éªŒè‡ªå·±è®¤çŸ¥&#x2F;èƒ½åŠ›æ°´å¹³æé—®å¥å¼</span><a href="#æ£€éªŒè‡ªå·±è®¤çŸ¥x2fèƒ½åŠ›æ°´å¹³æé—®å¥å¼" class="header-anchor">#</a></h3><p>1ã€ä¸ºäº†æµ‹è¯•æˆ‘å¯¹xxxçš„ç†è§£ç¨‹åº¦ï¼Œä½ ä¼šé—®æˆ‘ä»€ä¹ˆé—®é¢˜æ¥æ£€éªŒæˆ‘çš„æ°´å¹³ï¼Œæœ€å°‘10ä¸ªã€‚<br>2ã€æˆ‘æ˜¯xxé¢†åŸŸçš„ä¸“å®¶ï¼Œä½ ä¼šé—®æˆ‘å“ªäº›é—®é¢˜æ¥æ£€éªŒæˆ‘çš„ä¸“ä¸šæ°´å¹³ï¼Ÿ<br>3ã€è¿½é—®ä¸€å¥ï¼Œè¿™äº›æˆ‘éƒ½æ‡‚ï¼Œè¿˜æœ‰æ›´ä¸“ä¸šæ›´ç»†æ›´æ·±çš„é—®é¢˜å—ï¼Ÿ<br>4ã€ä½ é—®æˆ‘ç­”çš„æ¸¸æˆ</p>
<p>æ‰©å±•è‡ªå·±èƒ½åŠ›è¾¹ç•Œçš„æé—®å¥å¼æˆ‘å·²ç»å¾ˆç²¾é€šxxxäº†ï¼Œæˆ‘æƒ³çŸ¥é“æˆ‘æ˜¯å¦è¿˜æœ‰éœ€è¦å­¦ä¹ çš„åœ°æ–¹ï¼Ÿç„¶åä¸åœçš„é—®ï¼Œè¿˜æœ‰å‘¢è¿˜æœ‰å‘¢ï¼Ÿ</p>
<h1><span id="çŸ¥é“åšåˆ°">çŸ¥é“åšåˆ°</span><a href="#çŸ¥é“åšåˆ°" class="header-anchor">#</a></h1><p>è®©GPTå®Œæˆå…·ä½“ä»»åŠ¡<br>1ã€æˆ‘æƒ³åšxxxï¼Œä½ èƒ½ç»™æˆ‘æä¾›ä»€ä¹ˆå¸®åŠ©ï¼Ÿ<br>2ã€æˆ‘æƒ³è¦ä½ åšxxxï¼Œæˆ‘åº”è¯¥ç»™ä½ è¾“å…¥ä»€ä¹ˆä¿¡æ¯ï¼Ÿ<br>3ã€ç›´æ¥ä¸‹æŒ‡ä»¤</p>
<h1><span id="è§’è‰²å…³ç³»">è§’è‰²å…³ç³»</span><a href="#è§’è‰²å…³ç³»" class="header-anchor">#</a></h1><ul>
<li>æ¨¡æ‹Ÿè™šæ‹Ÿäººç‰©</li>
<li>æ¨¡æ‹Ÿåäºº</li>
<li>æ¨¡æ‹Ÿä¸€æ®µå…³ç³»</li>
<li>æ¨¡æ‹Ÿå¤šä¸ªå…·ä½“çš„äºº</li>
<li>æ¨¡æ‹Ÿå¤šç±»äºº</li>
</ul>
<h1><span id="é€šç”¨">é€šç”¨</span><a href="#é€šç”¨" class="header-anchor">#</a></h1><h3><span id="æ²Ÿé€šæ¨¡å¼">æ²Ÿé€šæ¨¡å¼</span><a href="#æ²Ÿé€šæ¨¡å¼" class="header-anchor">#</a></h3><p>prompt &#x3D;  å®šä¹‰è§’è‰²+èƒŒæ™¯ä¿¡æ¯+ä»»åŠ¡ç›®æ ‡+è¾“å‡ºè¦æ±‚</p>
<h3><span id="å½’çº³">å½’çº³</span><a href="#å½’çº³" class="header-anchor">#</a></h3><ul>
<li>ä½¿ç”¨markdownæ ¼å¼å†™å¯Œçˆ¸çˆ¸ç©·çˆ¸çˆ¸çš„æ€ç»´å¯¼å›¾ï¼Œä»¥ä»£ç æ ¼å¼è¾“å‡º</li>
<li>ä»¥è„‘å›¾çš„æ–¹å¼å½’çº³ä¸Šæ–‡</li>
<li>è¯·ç”¨æçº²çš„æ–¹å¼æ¥å½’çº³ä¸Šæ–‡</li>
<li>è¯·ç”¨ç®€ç»ƒçš„åˆ—æçº²çš„æ–¹å¼æ¥å½’çº³ä¸Šæ–‡</li>
</ul>
<h3><span id="æ€ç»´é“¾">æ€ç»´é“¾</span><a href="#æ€ç»´é“¾" class="header-anchor">#</a></h3><h3><span id="æ²¡å•¥ç”¨">æ²¡å•¥ç”¨</span><a href="#æ²¡å•¥ç”¨" class="header-anchor">#</a></h3><p>è¯·ç”¨ç®€å•çš„è¯­å¥æ¥å½’çº³ä¸Šæ–‡ï¼Œå½’çº³çš„è¯­å¥å¯ä»¥ç”Ÿæˆè„‘å›¾<br>è¯·ç”¨é‡‘å­—å¡”æ€ç»´çš„æ–¹å¼æ¥ç®€å•çš„å½’çº³ä¸Šæ–‡</p>
<h1><span id="prompt-how-to-use">Prompt - How to use</span><a href="#prompt-how-to-use" class="header-anchor">#</a></h1><ul>
<li><p><a href="https://learnprompting.org/zh-Hans/docs/intro">Learn Prompting</a> *** **</p>
</li>
<li><p><a href="https://www.aishort.top/">Chatgpt ShortCut</a><br><a href="https://github.com/rockbenben/ChatGPT-Shortcut">ChatGPT Shortcut </a></p>
</li>
<li><p><a href="https://prompts.chat/"> Awesome ChatGPT Prompts</a>  </p>
</li>
<li><p><a href="https://snackprompt.com/">snackprompt.com</a> ***</p>
</li>
<li><p><a href="https://flowgpt.com/">flowgpt</a> ***</p>
</li>
<li><p><a href="https://prompthero.com/">prompthero</a></p>
</li>
<li><p><a href="https://publicprompts.art/">publicprompts</a></p>
</li>
<li><p><a href="https://learningprompt.wiki/">https://learningprompt.wiki/</a> prompt å­¦ä¹ æ•™ç¨‹</p>
</li>
<li><p><a href="https://gpt.candobear.com/prompt">Prompt å¤§å…¨</a></p>
</li>
<li><p><a href="https://gp477l8icq.feishu.cn/wiki/ZYkUwbXgzi5eqYkHl0MceNrSnhb">æç¤ºæŒ‡ä»¤åº“</a>  æ±‡æ€»</p>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p><a href="https://www.bilibili.com/video/BV1Lg4y1c7fk/">å­¦å®Œè¿™ä¸ªè§†é¢‘ï¼Œç®€å†åŠ ä¸€æ¡ï¼šç†Ÿç»ƒæŒæ¡ChatGPTè§£å†³å¤æ‚é—®é¢˜ï½œChatGPTä½¿ç”¨æ•™ç¨‹</a>  ***</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>prompt</category>
      </categories>
      <tags>
        <tag>prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>Prompt-Code</title>
    <url>/www6vHomeAIGC/2021/05/28/gptPromptCode/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%B7%A5%E5%85%B7">å·¥å…·</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3-%E7%AE%80%E5%8D%95%E4%BB%BB%E5%8A%A1-1">ä»£ç ç›¸å…³-ç®€å•ä»»åŠ¡ [1]</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3-%E7%B9%81%E7%90%90%E5%B7%A5%E4%BD%9C-1">ä»£ç ç›¸å…³- ç¹çå·¥ä½œ [1]</a></li>
<li><a href="#%E8%BF%90%E7%BB%B4-ops-4">è¿ç»´ Ops [4]</a><ul>
<li><a href="#%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-vs-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80">ç¼–ç¨‹è¯­è¨€ vs è‡ªç„¶è¯­è¨€</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="å·¥å…·">å·¥å…·</span><a href="#å·¥å…·" class="header-anchor">#</a></h1><ul>
<li>Copilot *** - æ”¶è´¹</li>
<li>AWS CodeWhispter</li>
<li>Cursor ***</li>
<li>tabnine å…è´¹</li>
<li>Code Llama  - å¼€æº</li>
</ul>
<h1><span id="ä»£ç ç›¸å…³-ç®€å•ä»»åŠ¡-1">ä»£ç ç›¸å…³-ç®€å•ä»»åŠ¡ [1]</span><a href="#ä»£ç ç›¸å…³-ç®€å•ä»»åŠ¡-1" class="header-anchor">#</a></h1><ul>
<li><p><strong>æ³¨é‡Š</strong><br> ä½ ä½œä¸ºä¸€åç¨‹åºå‘˜ï¼Œè¯·è§£é‡Šä¸€ä¸‹ä¸‹é¢è¿™æ®µä»£ç </p>
</li>
<li><p><strong>é˜²å¾¡æ€§ç¼–ç¨‹</strong><br> è¯·ä¸ºè¿™æ®µä»£ç å¢åŠ é˜²å¾¡æ€§ç¼–ç¨‹çš„åŠŸèƒ½</p>
</li>
<li><p>å†™å•å…ƒæµ‹è¯• </p>
</li>
<li><p><strong>æ—¶é—´å¤æ‚åº¦  time complexity</strong><br> è¿™æ®µä»£ç çš„æ—¶é—´å¤æ‚åº¦æ˜¯å¤šå°‘</p>
</li>
<li><p>æµç¨‹å›¾<br> ç”»å‡ºredis masterå’Œslaveä¹‹é—´åŒæ­¥çš„æµç¨‹å›¾</p>
</li>
<li><p>Writing shell script</p>
</li>
<li><p>Writing git commands<br>ä¸€ä¸ªåˆ†æ”¯ä¸­çš„ä»£ç åˆå¹¶åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ä¸­</p>
</li>
<li><p><strong>Improve code</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">  How do i improve this code?</span><br><span class="line">  fruits = [<span class="string">&quot;apple&quot;</span>, <span class="string">&quot;banana&quot;</span>, <span class="string">&quot;cherry&quot;</span>]</span><br><span class="line">  newlist = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> fruits:</span><br><span class="line">  <span class="keyword">if</span> <span class="string">&quot;a&quot;</span> <span class="keyword">in</span> x:</span><br><span class="line">    newlist.append(x)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(newlist)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Translating Code</strong> ä»£ç è½¬æ¢</p>
<ul>
<li>Convert this Python code to Javascript    </li>
<li>è¯·æŠŠä¸‹é¢è¿™æ®µpythonä»£ç è½¬æ¢æˆJavaä»£ç </li>
</ul>
</li>
</ul>
<h1><span id="ä»£ç ç›¸å…³-ç¹çå·¥ä½œ-1">ä»£ç ç›¸å…³- ç¹çå·¥ä½œ [1]</span><a href="#ä»£ç ç›¸å…³-ç¹çå·¥ä½œ-1" class="header-anchor">#</a></h1><ul>
<li><p>Building API</p>
<ul>
<li>I need an API built with express.js to return the list of products. Each product should have attributes like ID, title, description, price and imageUrl</li>
<li>modify the code and  retrieve the products from a MongoDB database</li>
<li>use TypeScript in this code</li>
<li>Generate this API using Python and FastAPI</li>
</ul>
</li>
<li><p><strong>Generating Dummy Data</strong></p>
<ul>
<li>Generate dummy data for a table called customers. Each customer should have an ID, first name, last name and city.</li>
<li>I donâ€™t need a Javascript. Just give the data.</li>
<li>Create a Python class for storing these objects.</li>
</ul>
</li>
<li><p><strong>SQL</strong></p>
<ul>
<li>write a SQL query to generate a table called products with these columnsï¼š<br>IDï¼ˆintï¼‰<br>titleï¼ˆstringï¼‰<br>category(int)</li>
<li>write a query to retrieve the top 5 customers in Shanghai</li>
<li>Revise this query and join the customers table with the orders table to find out how much each cumster has spent. Then pick the top 5 who have spent the most.</li>
</ul>
</li>
<li><p>æ­£åˆ™  [2]</p>
</li>
<li><p>CronJob [2]</p>
</li>
<li><p>K8s</p>
</li>
</ul>
<h1><span id="è¿ç»´-ops-4">è¿ç»´ Ops [4]</span><a href="#è¿ç»´-ops-4" class="header-anchor">#</a></h1><h2><span id="ç¼–ç¨‹è¯­è¨€-vs-è‡ªç„¶è¯­è¨€">ç¼–ç¨‹è¯­è¨€ vs è‡ªç„¶è¯­è¨€</span><a href="#ç¼–ç¨‹è¯­è¨€-vs-è‡ªç„¶è¯­è¨€" class="header-anchor">#</a></h2><table>
<thead>
<tr>
<th>è¯­è¨€ç±»å‹</th>
<th>æ‰§è¡ŒåŸç†</th>
</tr>
</thead>
<tbody><tr>
<td>C++è¯­è¨€</td>
<td>C++è¯­è¨€ â€“&gt; ç¼–è¯‘å™¨&#x2F;é“¾æ¥å™¨ â€“&gt; æ—¢å®šä»»åŠ¡</td>
</tr>
<tr>
<td>Javaè¯­è¨€</td>
<td>Javaè¯­è¨€ â€“&gt; ç¼–è¯‘å™¨&#x2F;è™šæ‹Ÿæœº â€“&gt; æ—¢å®šä»»åŠ¡</td>
</tr>
<tr>
<td>Pythonè¯­è¨€</td>
<td>Pythonè¯­è¨€ â€“&gt; è§£é‡Šå™¨ â€“&gt; æ—¢å®šä»»åŠ¡</td>
</tr>
<tr>
<td>äººç±»è‡ªç„¶è¯­è¨€</td>
<td>äººç±»è‡ªç„¶è¯­è¨€ â€“&gt; LLMs â€“&gt; å„ç§åç«¯ç»„ä»¶ â€“&gt; æ—¢å®šä»»åŠ¡</td>
</tr>
</tbody></table>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV1Z84y1G7nY/">ã€ChatGPTã€‘é¢å‘ç¨‹åºå‘˜çš„ChatGPTä½¿ç”¨æ•™ç¨‹38ç§æ–¹å¼æ¥æå‡ç”Ÿäº§åŠ›</a> V</li>
<li><a href="https://time.geekbang.org/opencourse/videointro/100540901">GitHub Copilot å®è·µè¯¾</a><br>03, 04, 06<br><a href="https://github.com/www6v/AICoder">AICoder</a> git</li>
<li><a href="https://cloud.tencent.com/developer/article/2207540">ChatGPT å¸®æˆ‘è·‘äº†ä¸€ä¸ªå®Œæ•´çš„ DevOps æµæ°´çº¿ï¼Œç¦»äº†ä¸ªå¤§è°±â€¦</a><br><a href="https://github.com/www6v/AICoder/tree/master/Cursor/">Gin on K8s</a> git</li>
<li><a href="https://www.promptops.com/">PromptOps</a>    </li>
<li><a href="https://www.geeksforgeeks.org/chatgpt-prompts-for-software-developers/">Top 20 ChatGPT Prompts For Software Developers</a> æœª</li>
</ol>
<pre><code>

</code></pre>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>prompt</category>
      </categories>
      <tags>
        <tag>prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Prompt Engineering</title>
    <url>/www6vHomeAIGC/2022/11/10/gptPromptEngineering/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#basic-prompting-2">Basic Prompting [2]</a><ul>
<li><a href="#zero-shot-prompting-3">Zero-Shot Prompting [3]</a></li>
<li><a href="#few-shot-prompting-3">Few-Shot Prompting [3]</a></li>
</ul>
</li>
<li><a href="#cot-2">CoT [2]</a><ul>
<li><a href="#chain-of-thought-promptingcot-3">Chain-of-Thought Prompting(CoT) [3]</a></li>
<li><a href="#self-consistencycot-sc-3">Self-Consistency(CoT-SC) [3]</a></li>
<li><a href="#tree-of-thoughts-tot">Tree of Thoughts (ToT)</a></li>
<li><a href="#cot-vs-cot-sc-vs-tot-3">CoT vs. CoT-SC vs. ToT  [3]</a></li>
<li><a href="#tips-and-extensions-2">Tips and Extensions   [2]</a></li>
</ul>
</li>
<li><a href="#automatic-prompt-design-2">Automatic Prompt Design [2]</a></li>
<li><a href="#six-strategies-for-getting-better-results1">Six strategies for getting better results[1]</a><ul>
<li><a href="#write-clear-instructions">Write clear instructions</a></li>
<li><a href="#provide-reference-text">Provide reference text</a></li>
<li><a href="#split-complex-tasks-into-simpler-subtasks">Split complex tasks into simpler subtasks</a></li>
<li><a href="#give-the-model-time-to-think">Give the model time to â€œthinkâ€</a></li>
<li><a href="#use-external-tools">Use external tools</a></li>
<li><a href="#test-changes-systematically">Test changes systematically</a></li>
</ul>
</li>
<li><a href="#%E4%BC%98%E7%82%B9vs-%E7%BC%BA%E7%82%B9">ä¼˜ç‚¹vs ç¼ºç‚¹</a><ul>
<li><a href="#%E4%BC%98%E7%82%B9">ä¼˜ç‚¹</a></li>
<li><a href="#%E7%BC%BA%E7%82%B9">ç¼ºç‚¹</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E6%A1%88%E4%BE%8B">æ¡ˆä¾‹</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="basic-prompting-2">Basic Prompting [2]</span><a href="#basic-prompting-2" class="header-anchor">#</a></h1><h3><span id="zero-shot-prompting-3">Zero-Shot Prompting [3]</span><a href="#zero-shot-prompting-3" class="header-anchor">#</a></h3><h3><span id="few-shot-prompting-3">Few-Shot Prompting [3]</span><a href="#few-shot-prompting-3" class="header-anchor">#</a></h3><h1><span id="cot-2">CoT [2]</span><a href="#cot-2" class="header-anchor">#</a></h1><h3><span id="chain-of-thought-promptingcot-3">Chain-of-Thought Prompting(CoT) [3]</span><a href="#chain-of-thought-promptingcot-3" class="header-anchor">#</a></h3><ul>
<li>Few-shot CoT</li>
<li>Zero-shot COT<br><strong>â€œLetâ€™s think step by stepâ€</strong></li>
</ul>
<h3><span id="self-consistencycot-sc-3">Self-Consistency(CoT-SC) [3]</span><a href="#self-consistencycot-sc-3" class="header-anchor">#</a></h3><p>The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to <strong>select</strong> the most consistent answer.  </p>
<h3><span id="tree-of-thoughts-tot">Tree of Thoughts (ToT)</span><a href="#tree-of-thoughts-tot" class="header-anchor">#</a></h3><h3><span id="cot-vs-cot-sc-vs-tot-3">CoT vs. CoT-SC vs. ToT  [3]</span><a href="#cot-vs-cot-sc-vs-tot-3" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/11/10/gptPromptEngineering/TOT.jpg" class>

<h3><span id="tips-and-extensions-2">Tips and Extensions   [2]</span><a href="#tips-and-extensions-2" class="header-anchor">#</a></h3><p>Self-Ask </p>
<h1><span id="automatic-prompt-design-2">Automatic Prompt Design [2]</span><a href="#automatic-prompt-design-2" class="header-anchor">#</a></h1><ul>
<li>Automatic Chain-of-Thought (Auto-CoT) [3]</li>
</ul>
<h1><span id="six-strategies-for-getting-better-results1">Six strategies for getting better results[1]</span><a href="#six-strategies-for-getting-better-results1" class="header-anchor">#</a></h1><h3><span id="write-clear-instructions">Write clear instructions</span><a href="#write-clear-instructions" class="header-anchor">#</a></h3><p>   æ¸…æ™°çš„æŒ‡ä»¤</p>
<h3><span id="provide-reference-text">Provide reference text</span><a href="#provide-reference-text" class="header-anchor">#</a></h3><h3><span id="split-complex-tasks-into-simpler-subtasks">Split complex tasks into simpler subtasks</span><a href="#split-complex-tasks-into-simpler-subtasks" class="header-anchor">#</a></h3><pre><code>å¤æ‚ä»»åŠ¡ç®€å•åŒ–
</code></pre>
<h3><span id="give-the-model-time-to-think">Give the model time to â€œthinkâ€</span><a href="#give-the-model-time-to-think" class="header-anchor">#</a></h3><p>   ç»™æ¨¡å‹æ—¶é—´å»æ€è€ƒ</p>
<h3><span id="use-external-tools">Use external tools</span><a href="#use-external-tools" class="header-anchor">#</a></h3><p>   ä½¿ç”¨å¤–éƒ¨å·¥å…·</p>
<h3><span id="test-changes-systematically">Test changes systematically</span><a href="#test-changes-systematically" class="header-anchor">#</a></h3><h1><span id="ä¼˜ç‚¹vs-ç¼ºç‚¹">ä¼˜ç‚¹vs ç¼ºç‚¹</span><a href="#ä¼˜ç‚¹vs-ç¼ºç‚¹" class="header-anchor">#</a></h1><h3><span id="ä¼˜ç‚¹">ä¼˜ç‚¹</span><a href="#ä¼˜ç‚¹" class="header-anchor">#</a></h3><p>ç®€å•  å®¹æ˜“ä¸Šæ‰‹</p>
<h3><span id="ç¼ºç‚¹">ç¼ºç‚¹</span><a href="#ç¼ºç‚¹" class="header-anchor">#</a></h3><ul>
<li>ä¸Šé™æœ‰é™  </li>
<li>æ¨¡å‹é€‚é…<br>promptè¦é€‚é…æ¯ä¸ªæ¨¡å‹</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://platform.openai.com/docs/guides/prompt-engineering">Prompt engineering</a>  openai</li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">Prompt Engineering </a> paper</li>
<li><a href="https://www.promptingguide.ai/techniques">Prompt Engineering Guide</a> guide<br><a href="https://github.com/www6v/Prompt-Engineering-Guide">Prompt-Engineering-Guide </a> *** git</li>
</ol>
<p>1xx.   ã€ç¤¾åŒºç¬¬åä¸‰è®²ã€‘ è€åˆ˜è¯´NLPçº¿ä¸Šäº¤æµ  *** å¾ˆå…¨ </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/682352630">[è®ºæ–‡é˜…è¯»] Prompt Engineeringç»¼è¿°</a></p>
<p>1xx. <a href="https://blog.langchain.dev/the-prompt-landscape/">The Prompt Landscape</a>  langchain</p>
<p>1xx. <a href="https://colab.research.google.com/github/comet-ml/comet-llm/blob/main/examples/CometLLM_Prompts.ipynb">CometLLM - suite of LLMOps tools - track and visualize LLM prompts and chains</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/671915693">å¤§æ¨¡å‹ PUA æŒ‡å—ï¼šæ¥è‡ª Google Meta Microsoft ç­‰å¤§å‚</a> </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/632369186">NLPï¼ˆåä¸‰ï¼‰ï¼šPrompt Engineering é¢é¢è§‚</a></p>
<p>1xx. <a href="https://github.com/brexhq/prompt-engineering?tab=readme-ov-file"> prompt-engineering</a> git</p>
<p>1xx. <a href="https://finisky.github.io/chain-of-thought-prompting-summary/">Chain-of-Thought Prompting ç®€è¯» </a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399405&idx=1&sn=75cc058ff83467aa6bf107cf69335e71">ChatGPTåº”ç”¨ç«¯çš„Promptè§£æï¼šä»æ¦‚å¿µã€åŸºæœ¬æ„æˆã€å¸¸è§ä»»åŠ¡ã€æ„é€ ç­–ç•¥åˆ°å¼€æºå·¥å…·ä¸æ•°æ®é›† </a></p>
<p>1xx. <a href="https://github.com/Eladlev/AutoPrompt">AutoPrompt Repo</a> git</p>
<h3><span id="æ¡ˆä¾‹">æ¡ˆä¾‹</span><a href="#æ¡ˆä¾‹" class="header-anchor">#</a></h3><ol start="200">
<li><a href="https://mp.weixin.qq.com/s/nXoZJ4xfgihA2mnBQ8EdIQ">è¿ç»´å¤§æ¨¡å‹æ¢ç´¢ä¹‹ Text2PromQL é—®ç­”æœºå™¨äºº </a>     æ¶æ„å›¾ï¼Œ æœ€åä¸¤ä¸ªé‡ç‚¹æ€»ç»“   æœª</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>prompt</category>
      </categories>
      <tags>
        <tag>Prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Prompt Tuning</title>
    <url>/www6vHomeAIGC/2023/01/06/gptPromptTuning/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="nplèŒƒå¼-1">NPLèŒƒå¼ [1]</span><a href="#nplèŒƒå¼-1" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/06/gptPromptTuning/npl4Paragiam.jpg" class title="4ç§èŒƒå¼">


<h1><span id="prompt-tuning-2">Prompt Tuning [2]</span><a href="#prompt-tuning-2" class="header-anchor">#</a></h1><ul>
<li>ğŸ”” Prompt Tuning<ul>
<li>ğŸ”— æ–‡ç« ï¼šThe Power of Scale for Parameter-Efficient Prompt Tuning (EMNLP 2021) <a href="https://aclanthology.org/2021.emnlp-main.243/">https://aclanthology.org/2021.emnlp-main.243/</a></li>
<li>ğŸ”‘å…³é”®è¯å’Œæ‘˜è¦<ul>
<li>Keywords: Large-scale PLMs, Parameter-efficient Tuning, Prompt Tuning</li>
<li>æ‘˜è¦<ul>
<li>Promptå˜æˆå¯å­¦ä¹ çš„å‘é‡ï¼Œå›ºå®šPLMï¼Œå¾®è°ƒPromptæ¥é€‚é…ä¸‹æ¸¸ä»»åŠ¡</li>
<li>PLMå‚æ•°è§„æ¨¡è¶Šå¤§ï¼ŒPrompt Tuningçš„æ€§èƒ½å’Œå…¨å‚æ•°å¾®è°ƒè¶Šæ¥è¿‘</li>
<li>è¿™ç§åŸºäº<strong>Soft Prompt</strong>çš„Prompt Tuningæ–¹æ³•å¯ä»¥çœ‹ä½œæ˜¯<strong>Prefix Tuningçš„ç®€åŒ–ç‰ˆæœ¬</strong>ï¼ˆåªåŠ åœ¨è¾“å…¥ä¸Šï¼‰</li>
</ul>
</li>
</ul>
</li>
<li>âš™ï¸ç ”ç©¶è®¾è®¡å’Œç»“è®º<ul>
<li>æ–¹æ³•   <ul>
<li>æ¨¡å‹ç¤ºæ„å›¾ï¼šxxx</li>
<li>æ¨¡å‹åŸºæœ¬æ€è·¯ï¼š<ul>
<li>ç»å…¸åˆ†ç±»ï¼šP(Y | X; Î¸)<ul>
<li>Hard Prompt: P(Y | [P;X] ; Î¸)<ul>
<li>Soft Prompt: P(Y | [P;X] ; Î¸; Î”)</li>
</ul>
</li>
</ul>
</li>
<li>Pre-Training<ul>
<li>Fine-Tuning<ul>
<li>Prompt Tuning</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>å®ç°ç»†èŠ‚ï¼š<ul>
<li>æ¨¡å‹å‚æ•°é‡<ul>
<li>å‚æ•°é‡ï¼šT5 ~ T5-XXL(10B)</li>
<li>é¢„è®­ç»ƒï¼šLM Adaptation</li>
</ul>
</li>
<li>Prompté•¿åº¦ï¼šxxx<ul>
<li>1ã€5ã€20ã€100ã€150</li>
</ul>
</li>
<li>åˆå§‹åŒ–æ–¹æ³•ï¼šxxx<ul>
<li>éšæœºåˆå§‹åŒ–</li>
<li>ä½¿ç”¨é¢„è®¾æ–‡æœ¬çš„è¯å‘é‡åˆå§‹åŒ–ï¼Œç±»ä¼¼äºè®¾è®¡hard promptï¼Œç„¶åå°†hard promptè½¬åŒ–ä¸ºsoft prompt</li>
<li>ä½¿ç”¨ç±»åˆ«è¯å‘é‡åˆå§‹åŒ–ï¼Œç±»ä¼¼äºæä¾›é€‰é¡¹</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>å®éªŒ<ul>
<li>æ•°æ®é›†ï¼šSuperGLUE</li>
<li>xxx<ul>
<li>Promptçš„è§„æ¨¡è¶Šå¤§ï¼Œæ€§èƒ½ç›¸å¯¹è€Œè¨€ä¼šè¶Šå¥½</li>
</ul>
</li>
<li>xxx<ul>
<li>åŸºäºè¯­ä¹‰ä¿¡æ¯çš„åˆå§‹åŒ–æ¯”éšæœºåˆå§‹åŒ–è¦å¥½</li>
</ul>
</li>
<li>xxx<ul>
<li>LM Adaptation å¯¹æ€§èƒ½æå‡æ˜¾è‘—</li>
<li>Prompt Tuningè¿˜æ˜¯éœ€è¦å¤§æ¨¡å‹æœ‰è¾ƒå¥½çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›</li>
</ul>
</li>
<li>xxx<ul>
<li>æ¨¡å‹å‚æ•°è§„æ¨¡è¶Šå¤§ï¼ŒPrompt Tuningæ•ˆæœè¶Šå¥½</li>
<li>10Bå‚æ•°æ—¶ä¸å…¨å‚æ•°å¾®è°ƒæ€§èƒ½æ¥è¿‘</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>ğŸ“šè®ºæ–‡è´¡çŒ®<ul>
<li>ä¼˜ç‚¹ï¼ˆè®¡ç®—å‹å¥½ï¼‰<ul>
<li>å¤§æ¨¡å‹çš„<strong>å¾®è°ƒæ–°èŒƒå¼</strong></li>
<li><strong>ä¸€ä¸ªä¸­å¿ƒæ¨¡å‹æœåŠ¡å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡</strong>ï¼Œ<strong>èŠ‚çœå‚æ•°å­˜å‚¨é‡</strong></li>
<li><strong>æ— éœ€ä¼˜åŒ–æ¨¡å‹å‚æ•°</strong>ï¼ŒèŠ‚çœä¼˜åŒ–å™¨çš„è®¡ç®—é‡å’Œå­˜å‚¨é‡</li>
<li><strong>åªåœ¨è¾“å…¥å±‚è¿›è¡Œæ“ä½œ</strong>ï¼Œé€‚åˆå¤šä»»åŠ¡åœºæ™¯ä¸‹çš„è®¡ç®—åˆå¹¶</li>
</ul>
</li>
<li>ç¼ºç‚¹ï¼ˆæ€§èƒ½å’Œæ”¶æ•›æ€§å­˜åœ¨é—®é¢˜ï¼‰<ul>
<li>Prompt Tuningçš„<strong>æ”¶æ•›é€Ÿåº¦å¾ˆæ…¢</strong></li>
<li>Prompt Tuningçš„æ¨¡å‹<strong>æ€§èƒ½ä¸ç¨³å®š</strong></li>
<li>Few-shotåœºæ™¯ä¸Šè¡¨ç°ä¸ä½³</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="prompt-tuning3">Prompt Tuning[3]</span><a href="#prompt-tuning3" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/06/gptPromptTuning/promptTuning.JPG" class>

<ul>
<li>Allow an <strong>additional k tunable tokens</strong> per downstream task to <strong>be prepended to the input text</strong></li>
<li>No intermediate-layer prefixes or task-specific output layers</li>
<li><strong>Freeze the entire pre-trained model</strong> and <strong>only optimize the embedding layer</strong></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/396098543">[ç»¼è¿°]é¹é£å¤§ç¥çš„Pre-train, Prompt, and Predict [1]</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV18P411E7VK/">æ¸…ååšåå¸¦ä½ è½»æ¾åƒé€Prompt Tuningé¡¶ä¼šå¤§æ¨¡å‹è®ºæ–‡</a> V</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1Wg4y1K77R/">ç¬¬ä¸ƒè¯¾ï¼šPrompt Tuning</a> ***  V  æœ‰ppt</p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/395115779">è¿‘ä»£è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å‘å±•çš„â€œç¬¬å››èŒƒå¼â€</a>  Prompt Learning</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/396971490">PromptèŒƒå¼çš„ç¼˜èµ·ï½œPattern-Exploiting Training</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/400790006">PromptèŒƒå¼ç¬¬äºŒé˜¶æ®µï½œPrefix-tuningã€P-tuningã€Prompt-tuning</a></p>
<h3><span id="p-tuning-v2">P-tuning v2</span><a href="#p-tuning-v2" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/423306405">æ¸…åP-tuning v2ã€è°·æ­ŒSPoTï½œPromptå¯ä»¥è¶…è¿‡ç²¾è°ƒäº†å—ï¼Ÿ</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Prompt-Tuning</category>
      </categories>
      <tags>
        <tag>Prompt-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)PromptTuning</title>
    <url>/www6vHomeAIGC/2023/01/25/gptPromptTuningPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p><a href="https://zhuanlan.zhihu.com/p/646748939">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆäºŒï¼‰-Prompt Tuning</a><br><a href="https://zhuanlan.zhihu.com/p/635686756">å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆäºŒï¼‰-BitFitã€Prefix Tuningã€Prompt Tuning</a><br><a href="https://github.com/www6v/llm-action/blob/main/train/peft/clm/peft_prompt_tuning_clm.ipynb">peft_prompt_tuning_clm.ipynb</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Prompt-Tuning</category>
      </categories>
      <tags>
        <tag>Prompt-Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)Pytorch</title>
    <url>/www6vHomeAIGC/2023/03/28/gptPytorch/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h1><span id="code">Code</span><a href="#code" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p><a href="https://github.com/www6v/AIGC/tree/master/framework/pytorch">Pytorch</a>  å¢è€å¸ˆ</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)æ¨¡å‹å‹ç¼©-é‡åŒ–æ¦‚è¿°</title>
    <url>/www6vHomeAIGC/2023/02/19/gptQuantization/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E9%87%8F%E5%8C%96">é‡åŒ–</a><ul>
<li><a href="#%E9%87%8F%E5%8C%96%E7%9A%84%E5%AE%9A%E4%B9%89-3">é‡åŒ–çš„å®šä¹‰ [3]</a></li>
<li><a href="#%E9%87%8F%E5%8C%96%E7%9A%84%E4%B8%A4%E4%B8%AA%E9%98%B6%E6%AE%B5-3">é‡åŒ–çš„ä¸¤ä¸ªé˜¶æ®µ [3]</a></li>
<li><a href="#%E9%87%8F%E5%8C%96%E5%88%86%E7%B1%BB">é‡åŒ–åˆ†ç±»</a></li>
<li><a href="#quantization">Quantization</a></li>
</ul>
</li>
<li><a href="#ptq-%E5%88%86%E7%B1%BB">PTQ åˆ†ç±»</a><ul>
<li><a href="#weight-quantization-106">Weight Quantization  [10][6]</a></li>
<li><a href="#weight-and-activation-quantization-10">Weight and Activation Quantization [10]</a></li>
<li><a href="#%E6%AF%94%E8%BE%831">æ¯”è¾ƒ[1]</a></li>
</ul>
</li>
<li><a href="#%E4%BD%8E%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95chat">ä½ç²¾åº¦è®­ç»ƒæ–¹æ³•[chat]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="é‡åŒ–">é‡åŒ–</span><a href="#é‡åŒ–" class="header-anchor">#</a></h1><h3><span id="é‡åŒ–çš„å®šä¹‰-3">é‡åŒ–çš„å®šä¹‰  [3]</span><a href="#é‡åŒ–çš„å®šä¹‰-3" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/02/19/gptQuantization/quantization.jpeg" class>

<h3><span id="é‡åŒ–çš„ä¸¤ä¸ªé˜¶æ®µ-3">é‡åŒ–çš„ä¸¤ä¸ªé˜¶æ®µ  [3]</span><a href="#é‡åŒ–çš„ä¸¤ä¸ªé˜¶æ®µ-3" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/02/19/gptQuantization/twoProcedures.jpeg" class>


<h3><span id="é‡åŒ–åˆ†ç±»">é‡åŒ–åˆ†ç±»</span><a href="#é‡åŒ–åˆ†ç±»" class="header-anchor">#</a></h3><ul>
<li><p>é‡åŒ–åˆ†ç±» [3][5]</p>
<ul>
<li>Quantization-Aware Training (QAT)<br><strong>Need more data and time, More accurate</strong></li>
<li>Quantization-Aware Fine-tuning(QAF)   [9]</li>
<li>Post-Training Quantization (PTQ)<br><strong>Need fewer data and time, Less accurate</strong></li>
</ul>
</li>
<li><p>PyTorch æ”¯æŒçš„ä¸‰ç§é‡åŒ–ç±»å‹ [4]</p>
<ul>
<li>dynamic quantization (weights quantized with activations read&#x2F;stored in floating point and quantized for compute)</li>
<li>static quantization (weights quantized, activations quantized, calibration required post training)    <strong>-&gt;PTQ</strong></li>
<li>static quantization aware training (weights quantized, activations quantized, quantization numerics modeled during training)   <strong>-&gt;QAT</strong></li>
</ul>
</li>
</ul>
<h3><span id="quantization">Quantization</span><a href="#quantization" class="header-anchor">#</a></h3><ul>
<li>QAT -&gt; Expensive</li>
<li>PTQ -&gt; More feasible than QAT</li>
</ul>
<h1><span id="ptq-åˆ†ç±»">PTQ åˆ†ç±»</span><a href="#ptq-åˆ†ç±»" class="header-anchor">#</a></h1><h3><span id="weight-quantization-106">Weight Quantization  [10][6]</span><a href="#weight-quantization-106" class="header-anchor">#</a></h3><ul>
<li>LLM.int8() </li>
<li>GPTQ </li>
<li>AWQ</li>
</ul>
<h3><span id="weight-and-activation-quantization-10">Weight and Activation Quantization [10]</span><a href="#weight-and-activation-quantization-10" class="header-anchor">#</a></h3><ul>
<li>SmoothQuant[8]</li>
</ul>
<h3><span id="æ¯”è¾ƒ1">æ¯”è¾ƒ[1]</span><a href="#æ¯”è¾ƒ1" class="header-anchor">#</a></h3><table>
<thead>
<tr>
<th></th>
<th>Weight only quant</th>
<th>smoothquant(PTQ )</th>
<th>fp8(PTQ )</th>
</tr>
</thead>
<tbody><tr>
<td>Latency Reduction</td>
<td>â˜…â˜…</td>
<td>â˜…â˜…â˜…(best)</td>
<td>â˜…â˜…â˜…(best)</td>
</tr>
<tr>
<td>Modal Acc</td>
<td>â˜…â˜…</td>
<td>â˜…</td>
<td>â˜…â˜…â˜…(best)</td>
</tr>
<tr>
<td>Memory Saving</td>
<td>â˜…â˜…</td>
<td>â˜…â˜…â˜…(best)</td>
<td>â˜…â˜…â˜…(best)</td>
</tr>
<tr>
<td>Ease of use</td>
<td>â˜…â˜…â˜…(best)</td>
<td>â˜…â˜…</td>
<td>â˜…</td>
</tr>
</tbody></table>
<h1><span id="ä½ç²¾åº¦è®­ç»ƒæ–¹æ³•chat">ä½ç²¾åº¦è®­ç»ƒæ–¹æ³•[chat]</span><a href="#ä½ç²¾åº¦è®­ç»ƒæ–¹æ³•chat" class="header-anchor">#</a></h1><ul>
<li>åŠç²¾åº¦æµ®ç‚¹æ•°ï¼ˆFP16ï¼‰è®­ç»ƒ</li>
<li>æ··åˆç²¾åº¦è®­ç»ƒï¼ˆMixed Precision Trainingï¼‰</li>
<li>é‡åŒ–è®­ç»ƒï¼ˆQuantization Trainingï¼‰</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV1h44y1c72B">å¤§è¯­è¨€æ¨¡å‹æ¨ç†ï¼šä½ç²¾åº¦æœ€ä½³å®è·µ</a> V</li>
<li><a href="https://zhuanlan.zhihu.com/p/649460612">å¤§æ¨¡å‹è®­ç»ƒï½œæ¦‚å¿µç¯‡</a></li>
<li>&lt;&lt; An Introduction to Quantization of Large Language Model &gt;&gt; </li>
<li>4.1<a href="https://pytorch.org/docs/stable/quantization.html">pytorch Quantization</a><br>4.2 <a href="https://pytorch.org/blog/introduction-to-quantization-on-pytorch/">Introduction to Quantization on PyTorch</a> </li>
<li><a href="https://zhuanlan.zhihu.com/p/662881352">å¤§æ¨¡å‹é‡åŒ–æ¦‚è¿°</a>  ***</li>
<li><a href="/www6vHomeAIGC/2023/03/26/gptQuantizationWeight/" title="(åŸç†)Weight Only(LLM.int8(), GPTQ, AWQ)">(åŸç†)Weight Only(LLM.int8(), GPTQ, AWQ)</a> self</li>
<li>xxx</li>
<li><a href="https://juejin.cn/post/7330079146515611687">å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†-SmoothQuant </a></li>
<li><a href="/www6vHomeAIGC/2024/01/12/gptPEFTQLora/" title="(å®æˆ˜)PEFT QLoRA">(å®æˆ˜)PEFT QLoRA</a>   self</li>
<li>ã€ŠA Survey on Model Compression for Large Language Modelsã€‹</li>
</ol>
<p>1xx. <a href="https://www.zhihu.com/question/510246227">ç¥ç»ç½‘ç»œä½æ¯”ç‰¹é‡åŒ–ä¸­è®­ç»ƒå’Œæ¨ç†æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>é‡åŒ–</category>
      </categories>
      <tags>
        <tag>é‡åŒ–</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)æ¨¡å‹å‹ç¼©-é‡åŒ–</title>
    <url>/www6vHomeAIGC/2024/03/22/gptQuantizationPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%AE%9E%E6%88%98-ptq1">å®æˆ˜-PTQ[1]</a><ul>
<li><a href="#%E9%87%8F%E5%8C%96%E4%B8%8E8bit%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">é‡åŒ–ä¸8bitæ¨¡å‹è®­ç»ƒ</a></li>
</ul>
</li>
<li><a href="#%E5%AE%9E%E6%88%982-%E9%87%8F%E5%8C%96%E6%8E%A8%E7%90%86-%E9%87%8F%E5%8C%96%E6%8E%A8%E7%90%86-8">å®æˆ˜2-é‡åŒ–æ¨ç† é‡åŒ–æ¨ç† [8]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="å®æˆ˜-ptq1">å®æˆ˜-PTQ[1]</span><a href="#å®æˆ˜-ptq1" class="header-anchor">#</a></h1><h3><span id="é‡åŒ–ä¸8bitæ¨¡å‹è®­ç»ƒ">é‡åŒ–ä¸8bitæ¨¡å‹è®­ç»ƒ</span><a href="#é‡åŒ–ä¸8bitæ¨¡å‹è®­ç»ƒ" class="header-anchor">#</a></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;D:/Pretrained_models/modelscope/Llama-2-7b-ms&quot;</span>, low_cpu_mem_usage=<span class="literal">True</span>, </span><br><span class="line">                                             torch_dtype=torch.half, device_map=<span class="string">&quot;auto&quot;</span>, load_in_8bit=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h1><span id="å®æˆ˜2-é‡åŒ–æ¨ç†-é‡åŒ–æ¨ç†-8">å®æˆ˜2-é‡åŒ–æ¨ç† é‡åŒ–æ¨ç† [8]</span><a href="#å®æˆ˜2-é‡åŒ–æ¨ç†-é‡åŒ–æ¨ç†-8" class="header-anchor">#</a></h1><ul>
<li><p>Trainingçš„æ¨¡å‹</p>
<img src="/www6vHomeAIGC/2024/03/22/gptQuantizationPractice/dirs.png" class>
</li>
<li><p>åˆå¹¶åçš„æ¨¡å‹</p>
<img src="/www6vHomeAIGC/2024/03/22/gptQuantizationPractice/dir.png" class>
</li>
<li><p>4bité‡åŒ–æ¨ç†</p>
<img src="/www6vHomeAIGC/2024/03/22/gptQuantizationPractice/xtuner-chat.png" class></li>
</ul>
<blockquote>
<p>Trainingçš„æ—¶å€™è¦ç”¨tmux</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tmux new -s finetune</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tmux attach -t finetune</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ctcl +b , D</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>16bité‡åŒ–æ¨ç†æ…¢,  è¦ç”¨4bité‡åŒ–æ¨ç†</p>
</blockquote>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://www.bilibili.com/video/BV1EN411g7Yn/"> é‡åŒ–ä¸8bitæ¨¡å‹è®­ç»ƒ</a> V<br><a href="https://www.bilibili.com/video/BV1EN411g7Yn/">ã€æ‰‹æŠŠæ‰‹å¸¦ä½ å®æˆ˜HuggingFace Transformers-ä½ç²¾åº¦è®­ç»ƒç¯‡ã€‘é‡åŒ–ä¸8bitæ¨¡å‹è®­ç»ƒ</a><br>   <a href="https://github.com/www6v/transformers-code/blob/master/04-Kbit%20Training/26-8bits_training/llama2_lora_8bit.ipynb">llama2_lora_8bit.ipynb</a></p>
</li>
<li><p><a href="https://github.com/www6v/tutorial/tree/main/xtuner">internLM fine-tuning on xtuner</a><br><a href="https://www.bilibili.com/video/BV1yK4y1B75J/">(4)XTuner å¤§æ¨¡å‹å•å¡ä½æˆæœ¬å¾®è°ƒå®æˆ˜</a> V</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>é‡åŒ–</category>
      </categories>
      <tags>
        <tag>é‡åŒ–</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Weight Only(LLM.int8(), GPTQ, AWQ)</title>
    <url>/www6vHomeAIGC/2023/03/26/gptQuantizationWeight/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="llmint8-2">LLM.int8() [2]</span><a href="#llmint8-2" class="header-anchor">#</a></h1><h3><span id="åŸç†">åŸç†</span><a href="#åŸç†" class="header-anchor">#</a></h3><p>LLM.int8()æ˜¯ä¸€ç§é‡‡ç”¨<strong>æ··åˆç²¾åº¦åˆ†è§£</strong>çš„é‡åŒ–æ–¹æ³•ã€‚è¯¥æ–¹æ¡ˆå…ˆåšäº†ä¸€ä¸ªçŸ©é˜µåˆ†è§£ï¼Œå¯¹ç»å¤§éƒ¨åˆ†æƒé‡å’Œæ¿€æ´»ç”¨8bité‡åŒ–ï¼ˆvector-wiseï¼‰ã€‚å¯¹<strong>ç¦»ç¾¤ç‰¹å¾</strong>çš„å‡ ä¸ªç»´åº¦ä¿ç•™16bitï¼Œå¯¹å…¶åšé«˜ç²¾åº¦çš„çŸ©é˜µä¹˜æ³•ã€‚</p>
<h3><span id="ç®—æ³•">ç®—æ³•</span><a href="#ç®—æ³•" class="header-anchor">#</a></h3><p>LLM.int8() é€šè¿‡ä¸‰ä¸ªæ­¥éª¤å®ŒæˆçŸ©é˜µä¹˜æ³•è®¡ç®—:</p>
<ul>
<li>ä»è¾“å…¥çš„éšå«çŠ¶æ€ä¸­ï¼ŒæŒ‰åˆ—æå–<strong>å¼‚å¸¸å€¼ (ç¦»ç¾¤ç‰¹å¾ï¼Œå³å¤§äºæŸä¸ªé˜ˆå€¼çš„å€¼)ã€‚</strong></li>
<li>å¯¹ç¦»ç¾¤ç‰¹å¾è¿›è¡Œ FP16 çŸ©é˜µè¿ç®—ï¼Œå¯¹éç¦»ç¾¤ç‰¹å¾è¿›è¡Œé‡åŒ–ï¼Œåš INT8 çŸ©é˜µè¿ç®—ï¼›</li>
<li>åé‡åŒ–éç¦»ç¾¤å€¼çš„çŸ©é˜µä¹˜ç»“æœï¼Œå¹¶ä¸ç¦»ç¾¤å€¼çŸ©é˜µä¹˜ç»“æœç›¸åŠ ï¼Œè·å¾—æœ€ç»ˆçš„ FP16 ç»“æœã€‚</li>
</ul>
<h1><span id="gptq2">GPTQ[2]</span><a href="#gptq2" class="header-anchor">#</a></h1><h3><span id="åŸç†">åŸç†</span><a href="#åŸç†" class="header-anchor">#</a></h3><p>GPTQ é‡‡ç”¨<strong>int4&#x2F;fp16 (W4A16) çš„æ··åˆé‡åŒ–</strong>æ–¹æ¡ˆï¼Œå…¶ä¸­<strong>æ¨¡å‹æƒé‡</strong>è¢«é‡åŒ–ä¸º <strong>int4</strong> æ•°å€¼ç±»å‹ï¼Œè€Œ<strong>æ¿€æ´»å€¼</strong>åˆ™ä¿ç•™åœ¨ <strong>float16</strong>ï¼Œæ˜¯ä¸€ç§<strong>ä»…æƒé‡é‡åŒ–</strong>æ–¹æ³•ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæ¨¡å‹æƒé‡è¢«åŠ¨æ€åœ°åé‡åŒ–å› float16 å¹¶åœ¨è¯¥æ•°å€¼ç±»å‹ä¸‹è¿›è¡Œå®é™…çš„è¿ç®—ï¼›åŒ OBQ  ä¸€æ ·ï¼ŒGPTQè¿˜æ˜¯ä»<strong>å•å±‚é‡åŒ–</strong>çš„è§’åº¦è€ƒè™‘ï¼Œ<strong>å¸Œæœ›æ‰¾åˆ°ä¸€ä¸ªé‡åŒ–è¿‡çš„æƒé‡ï¼Œä½¿çš„æ–°çš„æƒé‡å’Œè€çš„æƒé‡ä¹‹é—´è¾“å‡ºçš„ç»“æœå·®åˆ«æœ€å°</strong>ã€‚</p>
<p>GPTQ å°†æƒé‡åˆ†ç»„ï¼ˆå¦‚ï¼š128åˆ—ä¸ºä¸€ç»„ï¼‰ä¸ºå¤šä¸ªå­çŸ©é˜µï¼ˆblockï¼‰ã€‚å¯¹æŸä¸ª block å†…çš„æ‰€æœ‰å‚æ•°é€ä¸ªé‡åŒ–ï¼Œæ¯ä¸ªå‚æ•°é‡åŒ–åï¼Œéœ€è¦é€‚å½“è°ƒæ•´è¿™ä¸ª block å†…å…¶ä»–æœªé‡åŒ–çš„å‚æ•°ï¼Œä»¥å¼¥è¡¥é‡åŒ–é€ æˆçš„ç²¾åº¦æŸå¤±ã€‚å› æ­¤ï¼ŒGPTQ é‡åŒ–éœ€è¦å‡†å¤‡æ ¡å‡†æ•°æ®é›†ã€‚</p>
<h3><span id="å®ç°">å®ç°</span><a href="#å®ç°" class="header-anchor">#</a></h3><p>AutoGPTQ ä»£ç åº“é›†æˆåˆ°äº† Transformers ä¸­ï¼Œè®©ç”¨æˆ·ä½¿ç”¨ GPTQ ç®—æ³•åœ¨ <strong>8 bitã€4 bitã€3 bit</strong>ï¼Œç”šè‡³æ˜¯ <strong>2 bit</strong> ç²¾åº¦ä¸‹é‡åŒ–å’Œè¿è¡Œæ¨¡å‹æˆä¸ºå¯èƒ½ã€‚å½“ä½¿ç”¨ <strong>int4 é‡åŒ–</strong>æ—¶ï¼Œç²¾åº¦çš„ä¸‹é™å¯ä»¥å¿½ç•¥ä¸è®¡ï¼ŒåŒæ—¶åœ¨å°æ‰¹é‡æ¨ç†ä¸Šä¿æŒç€ä¸ fp16 åŸºçº¿ç›¸å½“çš„é€Ÿåº¦ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒGPTQ æ–¹æ³•ä¸ bitsandbytes æå‡ºçš„è®­ç»ƒåé‡åŒ–æ–¹æ³•æœ‰æ‰€ä¸åŒï¼ŒGPTQ éœ€è¦<strong>åœ¨é‡åŒ–é˜¶æ®µ</strong>æä¾›ä¸€ä¸ª<strong>æ ¡å‡†æ•°æ®é›†</strong>ã€‚</p>
<h1><span id="awq-3">AWQ [3]</span><a href="#awq-3" class="header-anchor">#</a></h1><h3><span id="æŠ€æœ¯åŸç†">æŠ€æœ¯åŸç†</span><a href="#æŠ€æœ¯åŸç†" class="header-anchor">#</a></h3><p>AWQæ˜¯ä¸€ç§å¯¹å¤§æ¨¡å‹<strong>ä»…æƒé‡é‡åŒ–</strong>æ–¹æ³•ã€‚é€šè¿‡<strong>ä¿æŠ¤æ›´â€œé‡è¦â€çš„æƒé‡ä¸è¿›è¡Œé‡åŒ–</strong>ï¼Œä»è€Œåœ¨ä¸è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹æé«˜å‡†ç¡®ç‡ã€‚</p>
<h3><span id="å®ç°">å®ç°</span><a href="#å®ç°" class="header-anchor">#</a></h3><p>ç›®å‰ï¼Œé™¤äº†å®˜æ–¹æä¾›äº†å¯¹äºAWQçš„æ”¯æŒï¼ˆllm-awqï¼‰ä¹‹å¤–ï¼Œç¤¾åŒºæœ‰ç›¸å½“å¤šçš„å·¥å…·ï¼ˆå¦‚ï¼š<strong>AutoAWQ</strong>ã€<strong>vLLM</strong>ã€ HuggingFace TGIã€LMDeployã€ <strong>TensorRT-LLM</strong>ã€FastChat ç­‰ï¼‰æä¾›äº†å¯¹AWQçš„æ”¯æŒã€‚</p>
<h1><span id="æ€»ç»“">æ€»ç»“</span><a href="#æ€»ç»“" class="header-anchor">#</a></h1><ul>
<li><p>LLM.int8()<br> å±äº round-to-nearest (RTN) é‡åŒ–ï¼šèˆå…¥åˆ°æœ€è¿‘çš„å®šç‚¹æ•°ã€‚<br>ã€keyword: æ··åˆç²¾åº¦åˆ†è§£    ç¦»ç¾¤å€¼ã€‘</p>
</li>
<li><p>GPT-Q<br> æŠŠé‡åŒ–é—®é¢˜è§†ä½œ<strong>ä¼˜åŒ–é—®é¢˜</strong>ï¼Œé€å±‚å¯»æ‰¾æœ€ä¼˜çš„é‡åŒ–æƒé‡ã€‚<br>ã€keyword: æ··åˆé‡åŒ–  ä¼˜åŒ–é—®é¢˜ã€‘</p>
</li>
</ul>
<h3><span id="awq-vs-gptq-1">AWQ vs GPTQ [1]</span><a href="#awq-vs-gptq-1" class="header-anchor">#</a></h3><table>
<thead>
<tr>
<th><strong>ç‰¹å¾&#x2F;ç®—æ³•</strong></th>
<th><strong>AWQ</strong></th>
<th><strong>GPTQ</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>è®¾è®¡ç›®çš„</strong></td>
<td>é‡åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œ<strong>ç‰¹åˆ«å¼ºè°ƒä¿æŠ¤æ˜¾è‘—æƒé‡</strong>ï¼Œä»¥å‡å°‘é‡åŒ–è¯¯å·®ã€‚</td>
<td><strong>ä¸“ä¸ºGPTæ¨¡å‹è®¾è®¡</strong>ï¼Œé«˜æ•ˆåœ°å®Œæˆæƒé‡é‡åŒ–ï¼Œä»¥å‡å°‘è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ã€‚</td>
</tr>
<tr>
<td><strong>é‡åŒ–æ–¹æ³•</strong></td>
<td>åŸºäº<strong>æ¿€æ´»åˆ†å¸ƒ</strong>è€Œä¸æ˜¯æƒé‡æ¥é€‰æ‹©ä¿æŠ¤çš„æƒé‡ã€‚</td>
<td><strong>ä¸€æ¬¡æ€§æƒé‡é‡åŒ–</strong>ï¼ŒåŸºäºè¿‘ä¼¼äºŒé˜¶ä¿¡æ¯ã€‚</td>
</tr>
<tr>
<td><strong>ç²¾åº¦å’Œæ•ˆç‡</strong></td>
<td>åœ¨ä¸åŒæ¨¡å‹å’Œä½ç²¾åº¦ä¸Š<strong>éƒ½è¡¨ç°ä¼˜å¼‚</strong>ï¼Œèƒ½å¤Ÿæé«˜è§†è§‰è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚</td>
<td>åœ¨<strong>æä½ä½æ•°é‡åŒ–ï¼ˆå¦‚2ä½ï¼‰</strong>ä¸‹ä»ä¿æŒåˆç†å‡†ç¡®åº¦ï¼Œèƒ½åœ¨<strong>çŸ­æ—¶é—´</strong>å†…é‡åŒ–å¤§è§„æ¨¡æ¨¡å‹ã€‚</td>
</tr>
<tr>
<td><strong>ç¡¬ä»¶é€‚åº”æ€§</strong></td>
<td>æ”¯æŒé«˜æ•ˆæ¨ç†æ¡†æ¶ï¼Œé€‚ç”¨äºæ¡Œé¢å’Œç§»åŠ¨GPUã€‚</td>
<td>ä½¿å¾—åœ¨å•ä¸ªGPUä¸Šæ‰§è¡Œå¤§è§„æ¨¡æ¨¡å‹æˆä¸ºå¯èƒ½ï¼Œæé«˜äº†æ¨ç†é€Ÿåº¦ã€‚</td>
</tr>
<tr>
<td><strong>åº”ç”¨èŒƒå›´</strong></td>
<td>é€‚ç”¨äº<strong>å¤šç§æ¨¡å‹å’Œä»»åŠ¡</strong>ï¼ŒåŒ…æ‹¬<strong>å¤šæ¨¡æ€</strong>è¯­è¨€æ¨¡å‹ã€‚</td>
<td><strong>ä¸“é—¨é’ˆå¯¹GPTæ¨¡å‹</strong>ï¼Œé€‚ç”¨äºé«˜è®¡ç®—éœ€æ±‚çš„æ¨¡å‹ã€‚</td>
</tr>
<tr>
<td><strong>æ¨ç†æ€§èƒ½æå‡</strong></td>
<td>æä¾›æ˜¾è‘—çš„é€Ÿåº¦æå‡ï¼Œå°¤å…¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¡¨ç°çªå‡ºã€‚</td>
<td>åœ¨é«˜ç«¯å’Œæˆæœ¬æ•ˆç›Šé«˜çš„GPUä¸Šå‡å®ç°æ˜¾è‘—çš„æ¨ç†é€Ÿåº¦æå‡ã€‚</td>
</tr>
</tbody></table>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p>ã€Š8-å®æˆ˜Transformersæ¨¡å‹é‡åŒ–ã€‹ Aiå¤§æ¨¡å‹å¾®è°ƒ</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/680212402">å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†-LLM.int8()ã€GPTQ</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/681578090">å¤§æ¨¡å‹é‡åŒ–æŠ€æœ¯åŸç†-AWQã€AutoAWQ</a></p>
</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399136&idx=1&sn=bd0a7237940c2ac800e06ae6d247349e">NLPå¤§æ¨¡å‹å‹ç¼©å…³é”®æŠ€æœ¯è§£è¯»ï¼šç”¨äºå¤§å‹Transformerçš„8-bitçŸ©é˜µä¹˜æ³•åŸç†åŠå…¶ç®€å•å®ç°</a><br>   <a href="https://huggingface.co/blog/zh/hf-bitsandbytes-integration">å¤§è§„æ¨¡ Transformer æ¨¡å‹ 8 æ¯”ç‰¹çŸ©é˜µä¹˜ç®€ä»‹ - åŸºäº Hugging Face Transformersã€Accelerate ä»¥åŠ bitsandbytes </a>  LLM.int8()</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>é‡åŒ–</category>
      </categories>
      <tags>
        <tag>é‡åŒ–</tag>
      </tags>
  </entry>
  <entry>
    <title>(ç»¼è¿°)RAG</title>
    <url>/www6vHomeAIGC/2022/11/02/gptRAG/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#rag-overview2">RAG Overview[2]</a></li>
<li><a href="#rag-vs-ft-2">RAG vs FT [2]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E7%BB%BC%E8%BF%B0">ç»¼è¿°</a></li>
<li><a href="#%E8%AF%84%E4%BC%B0">è¯„ä¼°</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="rag-overview2">RAG Overview[2]</span><a href="#rag-overview2" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/11/02/gptRAG/rag-overview.jpg" class>


<h1><span id="rag-vs-ft-2">RAG vs FT [2]</span><a href="#rag-vs-ft-2" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/11/02/gptRAG/rag-vs-ft.jpg" class>




<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="ç»¼è¿°">ç»¼è¿°</span><a href="#ç»¼è¿°" class="header-anchor">#</a></h3><ol start="2">
<li><p>ã€ŠRetrieval-Augmented Generation for Large Language Models: A Surveyã€‹<br><a href="https://baoyu.io/translations/ai-paper/2312.10997-retrieval-augmented-generation-for-large-language-models-a-survey">é¢å‘å¤§è¯­è¨€æ¨¡å‹çš„æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼šç»¼è¿° [è¯‘]</a>  ç¿»è¯‘<br><a href="https://zhuanlan.zhihu.com/p/673910600">LLMä¹‹RAGç†è®ºï¼ˆäºŒï¼‰| RAGç»¼è¿°è®ºæ–‡è¯¦è§£</a><br><a href="https://cloud.tencent.com/developer/article/2373340">åŒæµå¤§å­¦å‘å¸ƒæœ€æ–°æ£€ç´¢å¢å¼º(RAG)çš„LLMç”ŸæˆæŠ€æœ¯ç»¼è¿°</a><br><a href="https://mp.weixin.qq.com/s/JjcN6OoxNK7tddmIOpvr2g">é¢å‘å¤§æ¨¡å‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç»¼è¿° </a><br><a href="https://www.promptingguide.ai/zh/research/rag">å¤§è¯­è¨€æ¨¡å‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æ–¹æ³•</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/661465330?utm_id=0">NLPï¼ˆå»¿ä¸€ï¼‰ï¼šä» RAG åˆ° Self-RAG â€”â€” LLM çš„çŸ¥è¯†å¢å¼º</a> ***</p>
</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s/FKv9glaGZD0qbLmB2zg6bg">åŒ—å¤§æœ€æ–°ç»¼è¿°ç²¾è¯»ï¼šRAGåœ¨AIGCä¸­çš„å‰ä¸–ä»Šç”Ÿï¼Œè¦†ç›–300ç¯‡è®ºæ–‡ï¼</a><br>   <a href="https://mp.weixin.qq.com/s?__biz=MzkzODMxNTkzNg==&mid=2247484337&idx=1&sn=484db46f6a974cb26b7659096b31cdd8">æœ€æ–°RAGç»¼è¿°æ¥äº†ï¼åŒ—äº¬å¤§å­¦å‘å¸ƒAIGCçš„æ£€ç´¢å¢å¼ºæŠ€æœ¯ç»¼è¿°</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s/jgyIOOzRWAgilcW4HfufNQ">è¡Œä¸šå¤§æ¨¡å‹è½åœ°çš„ä¸€äº›æœ‰è¶£è°ƒç ”æ€»ç»“ï¼šå…¼çœ‹å¤§æ¨¡å‹RAGé—®ç­”å››å¤§æŠ€æœ¯ç»¼è¿°</a> å››å¤§ç»¼è¿°</p>
<h3><span id="è¯„ä¼°">è¯„ä¼°</span><a href="#è¯„ä¼°" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404511&idx=2&sn=fefb78c1d920cb5b437f2e3da9935637">å†çœ‹å¤§æ¨¡å‹RAGæ£€ç´¢å¢å¼ºå¦‚ä½•è¯„ä¼°ï¼šRAGASå¼€æºè‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404476&idx=2&sn=d07b27dc9162ab0aaec3108004e4cfbe">å¤§æ¨¡å‹RAGæ£€ç´¢å¢å¼ºé—®ç­”å¦‚ä½•è¯„ä¼°ï¼šå™ªå£°ã€æ‹’ç­”ã€åäº‹å®ã€ä¿¡æ¯æ•´åˆå››å¤§èƒ½åŠ›è¯„æµ‹ä»»åŠ¡æ¢ç´¢ </a></p>
<p>XXX<br>1xx. <a href="https://baoyu.io/translations/ai-paper/2005.11401-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks">çŸ¥è¯†å¯†é›†å‹è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ç ”ç©¶ [è¯‘]</a><br>1xx. <a href="https://baoyu.io/translations/rag/mastering-rag-how-to-architect-an-enterprise-rag-system">æ„å»ºä¼ä¸šçº§ RAG ç³»ç»Ÿçš„é«˜çº§æŒ‡å— [è¯‘]</a><br>1xx. <a href="https://baoyu.io/translations/ai-paper/2401.05856v1-seven-failure-points-when-engineering-a-retrieval-augmented-generation-system">åœ¨æ„å»ºæ£€ç´¢å¢å¼ºå‹ç”Ÿæˆç³»ç»Ÿæ—¶çš„ä¸ƒå¤§æŒ‘æˆ˜ [è¯‘]</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)RAG Baichuanæ¡ˆä¾‹</title>
    <url>/www6vHomeAIGC/2023/04/18/gptRAGBaichuan/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="baichuan-rag1">Baichuan RAG[1]</span><a href="#baichuan-rag1" class="header-anchor">#</a></h1><ul>
<li>å€Ÿé‰´äº†Metaçš„CoVeæŠ€æœ¯</li>
<li>è‡ªç ”çš„TSFï¼ˆThink-Step Further)æŠ€æœ¯<br>çŒœæµ‹å…¶æœ¬è´¨åº”è¯¥æ˜¯å¯¹Step-back promptingæ–¹æ³•çš„æ”¹è‰¯</li>
<li>è‡ªç ”äº†Baichuan-Text-Embeddingå‘é‡æ¨¡å‹ </li>
<li>æ··åˆæ£€ç´¢<br>å‘é‡æ£€ç´¢ä¸ç¨€ç–æ£€ç´¢å¹¶è¡Œçš„</li>
<li>self-Critique</li>
</ul>
<h1><span id="æ€»ç»“2">æ€»ç»“[2]</span><a href="#æ€»ç»“2" class="header-anchor">#</a></h1><ol>
<li><strong>å¤šè½®é—®ç­”ç­‰åœºæ™¯çš„å¬å›å’Œä¼ ç»Ÿæœç´¢å¼•æ“çš„å¬å›åˆ†å¸ƒè¿˜ä¸å¤ªä¸€æ ·ã€‚</strong>ç™¾å·å€ŸåŠ©å­é—®é¢˜æ£€ç´¢æ•ˆæœæ›´é«˜çš„ç‰¹ç‚¹ï¼Œå¯¹åŸå§‹å¤æ‚é—®é¢˜è¿›è¡Œæ‹†è§£ã€æ‹“å±•æ¥è§£å†³å¤æ‚é—®é¢˜æ£€ç´¢è´¨é‡åå·®çš„é—®é¢˜ã€‚</li>
<li><strong>å¯¹äºæ²¡è§è¿‡çš„è¯­æ–™ç›´æ¥ç”¨å‘é‡æ£€ç´¢çš„ç»“æœå¯èƒ½ä¸å¤ªç†æƒ³ã€‚</strong>ç™¾å·åœ¨å¤§é‡è¯­æ–™ä¸Šåˆ©ç”¨æ— ç›‘ç£æ–¹æ³•è®­ç»ƒembeddingæ¨¡å‹æ¥ä¼˜åŒ–æ•ˆæœã€‚è€Œè¡Œä¸šå¤§æ¨¡å‹æ›´å€¾å‘äºç§æœ‰çš„æ•°æ®ï¼Œè¦æå‡ç§æœ‰æ•°æ®çš„è®­ç»ƒæ•ˆæœè¿˜å¾—ç»§ç»­åœ¨ç§æœ‰åŒ–æ•°æ®ä¸Šè®­ç»ƒæ•ˆæœä¼šæ›´ä½³ã€‚</li>
<li><strong>Queryæ‹“å±• + å¤šè·¯å¬å› + Rerank + self-Critiqueå¯èƒ½æ˜¯ç°é˜¶æ®µæ¯”è¾ƒå¥½çš„ä¸€ç§RAGæ–¹å¼ï¼Œä½†æ˜¯å…¶ä¹Ÿä¼šå¸¦æ¥æ›´å¤šæˆæœ¬ã€‚</strong>æ€»ä½“æ€è·¯æœ‰ç‚¹åƒReAct[3]ç³»åˆ—çš„è¿›é˜¶ç‰ˆæœ¬ï¼Œå…¶åœ¨æœç´¢ä¾§å’Œç­”æ¡ˆä¿®æ­£ä¾§éƒ½åšäº†æ›´å¤šçš„ä¸€äº›å·¥ä½œæ¥ä¼˜åŒ–å®é™…æ•ˆæœã€‚å…¶ç¼ºç‚¹æ˜¯éœ€è¦å¤šæ¬¡è°ƒç”¨å¤§æ¨¡å‹ï¼Œä¼šå¸¦æ¥é¢å¤–çš„æˆæœ¬ï¼ŒçœŸå®çº¿ä¸Šæ˜¯å¦é‡‡ç”¨è¿™ç§ç­–ç•¥è¿˜æœ‰å¾…éªŒè¯ã€‚</li>
</ol>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648407638&idx=1&sn=5c167b4a11bc483f5790ef1e0340d670">å¤§æ¨¡å‹RAGé—®ç­”è¡Œä¸šæœ€ä½³æ¡ˆä¾‹åŠå¾®è°ƒã€æ¨ç†åŒé˜¶æ®µå®ç°æ¨¡å¼ï¼šåŸºäºæ¨¡å—åŒ–(Modular)RAGè‡ªå®šä¹‰RAG Flow</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/675770700">ç™¾å·æ™ºèƒ½RAGæ–¹æ¡ˆæ€»ç»“ï¼šæœç´¢å‡ºç”Ÿçš„ç™¾å·æ™ºèƒ½å¤§æ¨¡å‹RAGçˆ¬å‘ä¹‹è·¯</a></p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/658469464">LLM&#x2F;ç™¾å·Baichuan2-53Bæœç´¢å¢å¼º-å¼€æ”¾API</a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650901201&idx=1&sn=3a9bd61403fb4b024ec5d8c128990495">å¤§æ¨¡å‹+æœç´¢æ„å»ºå®Œæ•´æŠ€æœ¯æ ˆï¼Œç™¾å·æ™ºèƒ½ç”¨æœç´¢å¢å¼ºç»™ä¼ä¸šå®šåˆ¶åŒ–ä¸‹äº†ä¸€å‰‚ã€ŒçŒ›è¯ã€</a></p>
<p>1xx. <a href="https://blog.csdn.net/qq_27590277/article/details/135421245">ç™¾å·æ™ºèƒ½RAGæ–¹æ¡ˆæ€»ç»“ï¼šæœç´¢å‡ºç”Ÿçš„ç™¾å·æ™ºèƒ½å¤§æ¨¡å‹RAGçˆ¬å‘ä¹‹è·¯</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG Framework</title>
    <url>/www6vHomeAIGC/2023/05/09/gptRAGFramework/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%A1%86%E6%9E%B6-0">æ¡†æ¶ [0]</a></li>
<li><a href="#ragflow12elmo">RAGflow[1,2][ELmo]</a></li>
<li><a href="#qanything3">QAnything<a href="https://github.com/chatchat-space/Langchain-Chatchat/releases/tag/v0.2.8">3</a></a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="æ¡†æ¶-0">æ¡†æ¶ [0]</span><a href="#æ¡†æ¶-0" class="header-anchor">#</a></h1><ul>
<li><p><a href="https://github.com/infiniflow/ragflow/tree/main"><strong>ragflow</strong></a> </p>
</li>
<li><p><a href="https://github.com/netease-youdao/QAnything/tree/master"><strong>QAnything</strong></a> </p>
</li>
<li><p><a href="https://github.com/chatchat-space/Langchain-Chatchat/releases/tag/v0.2.8"><strong>langchainchat</strong></a></p>
</li>
<li><p><a href="https://github.com/labring/FastGPT"><strong>FastGPT</strong></a>  </p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/"><strong>LangChain</strong></a> </p>
</li>
<li><p><a href="https://github.com/run-llama/llama_index/"><strong>LlamaIndex</strong></a></p>
</li>
<li><p><a href="https://github.com/langchain4j/langchain4j">langchain4j</a> </p>
</li>
<li><p><a href="https://github.com/Azure/GPT-RAG">GPT-RAG</a> </p>
</li>
<li><p><a href="https://github.com/Unstructured-IO/unstructured"><strong>Unstructured</strong></a></p>
</li>
<li><p><a href="https://github.com/StanGirard/quivr">Quivr</a> </p>
</li>
<li><p><a href="https://github.com/langgenius/dify"><strong>Dify</strong></a> </p>
</li>
<li><p><a href="https://github.com/weaviate/Verba">Verba</a> </p>
</li>
<li><p><a href="https://github.com/danswer-ai/danswer">danswer</a></p>
</li>
</ul>
<h1><span id="ragflow12elmo">RAGflow[1,2][ELmo]</span><a href="#ragflow12elmo" class="header-anchor">#</a></h1><p>RAGFlow æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„ RAG å¼•æ“ï¼Œå®ƒè§£å†³æ•°æ®çš„é—®é¢˜ï¼Œå› ä¸ºå¦‚æœä¸å¯¹ç”¨æˆ·æ•°æ®åŠ ä»¥åŒºåˆ†å’Œæ¸…æ™°ï¼Œè¯†åˆ«å…¶ä¸­çš„è¯­ä¹‰ï¼Œå°±å®¹æ˜“å¯¼è‡´ Garbage In Garbage Outã€‚RAGFlow åŒ…å«äº†å¦‚ä¸‹çš„å®Œæ•´ RAG æµç¨‹ï¼Œç¡®ä¿æ•°æ®ä» Garbage In Garbage Out å˜ä¸º Quality In Quality Outã€‚</p>
<p>RAGFlow çš„æœ€å¤§ç‰¹è‰²ï¼Œå°±æ˜¯å¤šæ ·åŒ–çš„æ–‡æ¡£æ™ºèƒ½å¤„ç†ï¼Œå› æ­¤å®ƒæ²¡æœ‰é‡‡ç”¨ç°æˆçš„ RAG ä¸­é—´ä»¶ï¼Œè€Œæ˜¯å®Œå…¨é‡æ–°ç ”å‘äº†ä¸€å¥—æ™ºèƒ½æ–‡æ¡£ç†è§£ç³»ç»Ÿï¼Œå¹¶ä»¥æ­¤ä¸ºä¾æ‰˜æ„å»º RAG ä»»åŠ¡ç¼–æ’ä½“ç³»ã€‚</p>
<p>è¿™ä¸ªç³»ç»Ÿçš„ç‰¹ç‚¹åŒ…å«ï¼š</p>
<ol>
<li>å®ƒæ˜¯ä¸€å¥—åŸºäº AI æ¨¡å‹çš„<strong>æ™ºèƒ½æ–‡æ¡£å¤„ç†ç³»ç»Ÿ</strong>ï¼›</li>
<li>å®ƒæ˜¯ä¸€å¥—åŒ…å«<strong>å„ç§ä¸åŒæ¨¡æ¿</strong>çš„æ™ºèƒ½æ–‡æ¡£å¤„ç†ç³»ç»Ÿï¼›</li>
<li>æ™ºèƒ½æ–‡æ¡£å¤„ç†çš„<strong>å¯è§†åŒ–å’Œå¯è§£é‡Šæ€§</strong>ï¼›</li>
<li>RAGFlow æ˜¯ä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»Ÿï¼Œè€Œç›®å‰å¼€æºçš„ RAGï¼Œå¤§éƒ½å¿½è§†äº† RAG æœ¬èº«çš„æœ€å¤§ä¼˜åŠ¿ä¹‹ä¸€ï¼šå¯ä»¥è®© LLM ä»¥å¯æ§çš„æ–¹å¼å›ç­”é—®é¢˜ï¼Œæˆ–è€…æ¢ç§è¯´æ³•ï¼šæœ‰ç†æœ‰æ®ã€æ¶ˆé™¤å¹»è§‰ã€‚</li>
</ol>
<h1><span id="qanything3">QAnything</span><a href="#qanything3" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="0">
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648407281&idx=2&sn=f39b46cad1787123b485d76dff33bc93">å¤§æ¨¡å‹RAGé—®ç­”ç ”å‘çœŸå®å›¾é‰´ï¼šä¸€å‘¨å‡ºDemoï¼ŒåŠå¹´ç”¨ä¸å¥½ï¼Œç¼è¡¥ä¹‹è·¯æ¼«æ¼« </a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV12T42117VT/">RAGFlowï¼šé‡‡ç”¨OCRå’Œæ·±åº¦æ–‡æ¡£ç†è§£ç»“åˆçš„æ–°ä¸€ä»£ RAG å¼•æ“</a> V</p>
</li>
<li><p><a href="https://www.infoq.cn/article/hjJM3kV620iDoYYOBtPs">æ£€ç´¢å¢å¼ºç”Ÿæˆå¼•æ“ RAGFlow æ­£å¼å¼€æºï¼</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1HF4m1w7rY/">æœ‰é“QAnythingèƒŒåçš„æ•…äº‹ï¼šå…³äºRAGçš„ä¸€ç‚¹ç»éªŒåˆ†äº«</a> V</p>
</li>
</ol>
<p>1xx. <a href="https://llamahub.ai/">LlamaHub</a><br>      Mix and match our Data Loaders and Agent Tools to build custom RAG apps or use our LlamaPacks as a starting point for your retrieval use cases.</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Modular RAG</title>
    <url>/www6vHomeAIGC/2023/04/21/gptRAGModularRAG/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#modular-rag1">Modular RAG[1]</a><ul>
<li><a href="#indexing">indexing</a></li>
<li><a href="#pre-retrival%E9%98%B6%E6%AE%B5">pre-retrivalé˜¶æ®µ</a></li>
<li><a href="#retrieval">Retrieval</a></li>
<li><a href="#post-retrieval-%E5%8C%85%E6%8B%AC%E4%B8%80%E4%BA%9B%E5%90%8E%E5%A4%84%E7%90%86%E7%9A%84%E6%A8%A1%E5%9D%97">post-retrieval åŒ…æ‹¬ä¸€äº›åå¤„ç†çš„æ¨¡å—</a></li>
<li><a href="#generation%E9%98%B6%E6%AE%B5">Generationé˜¶æ®µ</a></li>
<li><a href="#orchestraction%E9%98%B6%E6%AE%B5">orchestractioné˜¶æ®µ</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#modular-rag">Modular RAG</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="modular-rag1">Modular RAG[1]</span><a href="#modular-rag1" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/04/21/gptRAGModularRAG/moduleRAG.webp" class>

<h3><span id="indexing">indexing</span><a href="#indexing" class="header-anchor">#</a></h3><ul>
<li><strong>chunkä¼˜åŒ–</strong><ul>
<li>small-to-big<br>ç”¨å°å—åšç´¢å¼•ï¼Œä½†å¬å›å¤§å—</li>
<li>sliding window<br>æ»‘åŠ¨çª—å£ï¼Œæé«˜è¯­ä¹‰è¿è´¯æ€§</li>
<li>summaryæ‘˜è¦ï¼ˆè§£å†³è·¨æ–‡æ¡£ï¼‰ä»¥åŠç»“æ„åŒ–çš„ç»„ç»‡<br>ä¾‹å¦‚ä½¿ç”¨çŸ¥è¯†å›¾è°±è¿›è¡Œæ–‡æ¡£å†…å®¹çš„ç»„ç»‡ï¼Œæ ¹æ®æ–‡æ¡£ç»“æ„è¿›è¡Œå±‚çº§ç»„ç»‡</li>
</ul>
</li>
</ul>
<h3><span id="pre-retrivalé˜¶æ®µ">pre-retrivalé˜¶æ®µ</span><a href="#pre-retrivalé˜¶æ®µ" class="header-anchor">#</a></h3><ul>
<li><strong>query-routing</strong> [2]<ul>
<li>Metadata Router&#x2F; Filter  é—®é¢˜çš„åˆ†å‘</li>
<li>Semantic Router  æ„å›¾åˆ†ç±»</li>
</ul>
</li>
<li><strong>query-expansion</strong>  <ul>
<li>Multi-Query ä¸€å˜å¤š</li>
<li>Sub-Query æ‹†åˆ†å­query</li>
<li>CoVe[3]</li>
</ul>
</li>
<li><strong>query transformer</strong> <ul>
<li>query rewriteæ”¹å†™</li>
<li>HyDE</li>
<li>Step-back Prompting</li>
</ul>
</li>
<li><strong>query construction</strong>  <ul>
<li>text-cypher  </li>
<li>text2sql </li>
<li>å°†ç»“æ„åŒ–çŸ¥è¯†åˆ©ç”¨èµ·æ¥</li>
</ul>
</li>
</ul>
<h3><span id="retrieval">Retrieval</span><a href="#retrieval" class="header-anchor">#</a></h3><ul>
<li><strong>Retriver Selection</strong> æ£€ç´¢æ–¹å¼çš„é€‰æ‹©<ul>
<li>Sparse Retriever<br>ç¨€ç–æ£€ç´¢ï¼ˆeså­—ç¬¦ä¸²åŒ¹é…ï¼‰</li>
<li>Dense Retriever<br>ç¨ å¯†æ£€ç´¢ï¼ˆå‘é‡åŒ–æ£€ç´¢ï¼‰</li>
</ul>
</li>
<li>Retriever Fine-tuning  æ£€ç´¢çš„å¾®è°ƒ  [4] #<ul>
<li>SFT<br>ã€embedding tuningã€‘</li>
<li>adapter</li>
</ul>
</li>
</ul>
<h3><span id="post-retrieval-åŒ…æ‹¬ä¸€äº›åå¤„ç†çš„æ¨¡å—">post-retrieval åŒ…æ‹¬ä¸€äº›åå¤„ç†çš„æ¨¡å—</span><a href="#post-retrieval-åŒ…æ‹¬ä¸€äº›åå¤„ç†çš„æ¨¡å—" class="header-anchor">#</a></h3><ul>
<li><strong>reranké‡æ’</strong><ul>
<li>Rule-base Rerank  åŸºäºè§„åˆ™çš„</li>
<li>Model-base Rerank åŸºäºæ¨¡å‹çš„<br>åŸºäºå¤§æ¨¡å‹llmæœ¬èº«çš„</li>
</ul>
</li>
<li>compresion&#x2F;selection ä¸Šä¸‹æ–‡å‹ç¼© <ul>
<li>llmlingua </li>
<li>recomp</li>
<li>selective context</li>
<li>æ ¸å¿ƒåœ¨äºåˆ©ç”¨ä¸åŒçš„æ‰‹æ®µï¼Œå°†ä¸Šä¸‹æ–‡ä¸­ä¸é‡è¦çš„ä¿¡æ¯è¿›è¡Œå‰”é™¤</li>
</ul>
</li>
</ul>
<h3><span id="generationé˜¶æ®µ">Generationé˜¶æ®µ</span><a href="#generationé˜¶æ®µ" class="header-anchor">#</a></h3><ul>
<li>Generator Selection<ul>
<li>Cloud API-base Generator</li>
<li>On-Premises</li>
</ul>
</li>
<li>Generator Fine-tuning  [4] #<ul>
<li>SFT </li>
<li>Distillation</li>
<li>Dual FT<br>Fine-tuning both Generator and Retriever to align their preferences<br>RA-DIT</li>
</ul>
</li>
<li>åˆ™åŒ…æ‹¬å¯¹åº•å±‚åŸºç¡€æ¨¡å‹çš„ä¸€äº›äº‹æƒ…ï¼Œæ¯”å¦‚åŸºäºcloud-apiï¼Œè¿˜æ˜¯è¿›è¡ŒSFTå¾®è°ƒã€‚<br>ã€Generator æŒ‡çš„å°±æ˜¯LLMã€‘</li>
</ul>
<h3><span id="orchestractioné˜¶æ®µ">orchestractioné˜¶æ®µ</span><a href="#orchestractioné˜¶æ®µ" class="header-anchor">#</a></h3><ul>
<li>Scheduling</li>
<li>Fusion<ul>
<li>Possibility Ensemble</li>
<li>RRF (Reciprocal Rank Fusion )</li>
</ul>
</li>
<li>åˆ™åŒ…æ‹¬å¯¹å„ä¸ªæ¨¡å—ä¹‹é—´çš„æ‰§è¡Œå’Œé€šä¿¡è¿›è¡Œç®¡ç†</li>
</ul>
<blockquote>
<p> #ç¬¦å·   Modular RAG ç›¸å¯¹ advanced RAG çš„ç‰¹æ®Šé˜¶æ®µ</p>
</blockquote>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="modular-rag">Modular RAG</span><a href="#modular-rag" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://mp.weixin.qq.com/s/j07PkTCoxBzAhkyON1puPg">å€¼å¾—ä¸€çœ‹çš„å¤§æ¨¡å‹RAGé—®ç­”æ€»æ‹¬æ€§æ¢³ç†ï¼šæ¨¡å—åŒ–(Modular)RAGèŒƒå¼çš„å®šä¹‰ã€æ„æˆåŠæœºé‡ </a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648407638&idx=1&sn=5c167b4a11bc483f5790ef1e0340d670">å¤§æ¨¡å‹RAGé—®ç­”è¡Œä¸šæœ€ä½³æ¡ˆä¾‹åŠå¾®è°ƒã€æ¨ç†åŒé˜¶æ®µå®ç°æ¨¡å¼ï¼šåŸºäºæ¨¡å—åŒ–(Modular)RAGè‡ªå®šä¹‰RAG Flow </a></p>
</li>
<li><a href="/www6vHomeAIGC/2023/05/14/gptRAGRouting/" title="Query Routing">Query Routing</a>  self
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/669977863">å¦‚ä½•ä½¿ç”¨LLMsï¼šChain of Verification (CoVe)</a><br> <a href="https://sourajit16-02-93.medium.com/chain-of-verification-cove-understanding-implementation-e7338c7f4cb5">Chain of Verification (CoVe) â€” Understanding &amp; Implementation</a></p>
</li>
<li><a href="/www6vHomeAIGC/2022/12/07/gptRAGPerformance/" title="(åŸç†)Advanced RAG">(åŸç†)Advanced RAG</a>  self</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)å¤šæ¨¡æ€ RAG</title>
    <url>/www6vHomeAIGC/2023/03/14/gptRAGMultimodal/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%A4%9A%E6%A8%A1%E6%80%81rag-12">å¤šæ¨¡æ€RAG [1][2]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E5%8E%9F%E7%90%86">åŸç†</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="å¤šæ¨¡æ€rag-12">å¤šæ¨¡æ€RAG [1][2]</span><a href="#å¤šæ¨¡æ€rag-12" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="åŸç†">åŸç†</span><a href="#åŸç†" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/661465330?utm_id=0">NLPï¼ˆå»¿ä¸€ï¼‰ï¼šä» RAG åˆ° Self-RAG â€”â€” LLM çš„çŸ¥è¯†å¢å¼º</a> *** </p>
</li>
<li><p>ã€ŠRetrieving Multimodal Information for Augmented Generation: A Surveyã€‹<br><a href="https://zhuanlan.zhihu.com/p/665078079">ä¸‡å­—ç»¼è¿°ï¼š2023å¹´å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯(mRAG)æœ€æ–°è¿›å±•ä¸è¶‹åŠ¿-å›¾ç‰‡ã€ä»£ç ã€å›¾è°±ã€è§†é¢‘ã€å£°éŸ³ã€æ–‡æœ¬</a><br><a href="https://zhuanlan.zhihu.com/p/678812531">å¤šæ¨¡æ€RAGç»¼è¿°</a></p>
</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648409004&idx=2&sn=7f36d3ff5e170442486a5d413373c563">æœ´ç´ å¤šæ¨¡æ€RAGå¦‚ä½•å®ç°ï¼Ÿå…¼çœ‹RAGä¸Šä¸‹æ–‡è¿‡æ»¤æ–¹æ¡ˆFILCOåŠ202402å¤§æ¨¡å‹æ—©æŠ¥ </a>    å¤šæ¨¡æ€RAG ä¸¤ç§å®ç°æ–¹å¼</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)å¤šæ¨¡æ€ RAG</title>
    <url>/www6vHomeAIGC/2023/03/14/gptRAGMultimodalPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%A4%9A%E6%A8%A1%E6%80%81rag-%E5%A4%9A%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2%E5%99%A8-1011">å¤šæ¨¡æ€RAG-å¤šå‘é‡æ£€ç´¢å™¨ [10][11]</a><ul>
<li><a href="#semi-structured-tables-text-rag-20">semi-structured (tables + text) RAG [20]</a></li>
<li><a href="#multi-modal-text-tables-images-rag-13">multi-modal (text + tables + images) RAG  [13]</a></li>
<li><a href="#private-multi-modal-text-tables-images-rag-22">private multi-modal (text + tables + images)  RAG [22]</a></li>
<li><a href="#%E7%BB%84%E4%BB%B6">ç»„ä»¶</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E5%AE%9E%E6%88%98">å®æˆ˜</a></li>
<li><a href="#notebook">notebook</a></li>
<li><a href="#template">template</a></li>
<li><a href="#llamaindex">llamaindex</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="å¤šæ¨¡æ€rag-å¤šå‘é‡æ£€ç´¢å™¨-1011">å¤šæ¨¡æ€RAG-å¤šå‘é‡æ£€ç´¢å™¨ [10][11]</span><a href="#å¤šæ¨¡æ€rag-å¤šå‘é‡æ£€ç´¢å™¨-1011" class="header-anchor">#</a></h1><h3><span id="semi-structured-tables-text-rag-20">semi-structured (tables + text) RAG [20]</span><a href="#semi-structured-tables-text-rag-20" class="header-anchor">#</a></h3><p> åˆ†æpdfä¸­è¡¨æ ¼ </p>
<h3><span id="multi-modal-text-tables-images-rag-13">multi-modal (text + tables + images) RAG  [13]</span><a href="#multi-modal-text-tables-images-rag-13" class="header-anchor">#</a></h3><p>åˆ†æPDFä¸­å›¾ç‰‡</p>
<ul>
<li><p><strong>Option 1</strong>  [åŸºäºCLIP] [23][30][32][33]</p>
<ul>
<li>Use multimodal embeddings <strong>(such as <a href="https://openai.com/research/clip">CLIP</a>)</strong> to embed images and text</li>
<li>Retrieve both using similarity search</li>
<li>Pass <strong>raw images and text chunks</strong> to a multimodal LLM for answer synthesis<br> {é€‰é¡¹1ï¼šå¯¹æ–‡æœ¬å’Œè¡¨æ ¼ç”Ÿæˆsummaryï¼Œç„¶ååº”ç”¨å¤šæ¨¡æ€embeddingæ¨¡å‹æŠŠæ–‡æœ¬&#x2F;è¡¨æ ¼summaryã€åŸå§‹å›¾ç‰‡è½¬åŒ–æˆembeddingå­˜å…¥å¤šå‘é‡æ£€ç´¢å™¨ã€‚å¯¹è¯æ—¶ï¼Œæ ¹æ®queryå¬å›åŸå§‹æ–‡æœ¬&#x2F;è¡¨æ ¼&#x2F;å›¾åƒã€‚ç„¶åå°†å…¶å–‚ç»™å¤šæ¨¡æ€LLMç”Ÿæˆåº”ç­”ç»“æœã€‚}[10]</li>
</ul>
</li>
<li><p><strong>Option 2</strong>   [21] </p>
<ul>
<li>Use a multimodal LLM (such as <a href="https://openai.com/research/gpt-4v-system-card">GPT4-V</a>, <a href="https://llava.hliu.cc/">LLaVA</a>, or <a href="https://www.adept.ai/blog/fuyu-8b">FUYU-8b</a>) to produce <strong>text summaries from images</strong></li>
<li>Embed and retrieve text </li>
<li>Pass text chunks to an LLM for answer synthesis<br>ã€å°†å›¾ç‰‡è½¬æˆæ‘˜è¦ï¼Œå’Œå…¶ä»–æ–‡æœ¬ä¿¡æ¯æ•´åˆåœ¨æ–‡æœ¬ç²’åº¦è¿›è¡Œæ£€ç´¢ã€‘[12]<br> {é€‰é¡¹2ï¼šé¦–å…ˆåº”ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆGPT4-Vã€LLaVAã€FUYU-8bï¼‰ç”Ÿæˆå›¾ç‰‡summaryã€‚ç„¶åå¯¹æ–‡æœ¬&#x2F;è¡¨æ ¼&#x2F;å›¾ç‰‡summaryè¿›è¡Œå‘é‡åŒ–å­˜å…¥å¤šå‘é‡æ£€ç´¢å™¨ä¸­ã€‚å½“ç”Ÿæˆåº”ç­”çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ä¸å…·å¤‡æ—¶ï¼Œå¯æ ¹æ®queryå¬å›åŸå§‹æ–‡æœ¬&#x2F;è¡¨æ ¼+å›¾ç‰‡summaryã€‚}[10]</li>
</ul>
</li>
<li><p>Option 3 [24] [31][34]</p>
<ul>
<li>Use a multimodal LLM (such as <a href="https://openai.com/research/gpt-4v-system-card">GPT4-V</a>, <a href="https://llava.hliu.cc/">LLaVA</a>, or <a href="https://www.adept.ai/blog/fuyu-8b">FUYU-8b</a>) to produce text summaries from images</li>
<li>Embed and retrieve image summaries with a reference to the raw image </li>
<li>Pass <strong>raw images and text chunks</strong> to a multimodal LLM for answer synthesis<br> ã€å®é™…æ¨¡å‹è¾“å…¥ä½¿ç”¨çš„æ˜¯å›¾ç‰‡ã€‘<br>   ã€å›¾ç‰‡æ¦‚è¦ä¾ç„¶æ˜¯ç”¨äºæ£€ç´¢ï¼ˆGPT-4Vï¼ŒLLaVAï¼ŒFUYU-8bï¼‰ã€‘[12]<br>  {é€‰é¡¹3ï¼šå‰ç½®é˜¶æ®µåŒé€‰é¡¹2ç›¸åŒã€‚å¯¹è¯æ—¶ï¼Œæ ¹æ®queryå¬å›åŸå§‹æ–‡æœ¬&#x2F;è¡¨æ ¼&#x2F;å›¾ç‰‡ã€‚æ„é€ å®Œæ•´Promptï¼Œè®¿é—®å¤šæ¨¡æ€å¤§æ¨¡å‹ç”Ÿæˆåº”ç­”ç»“æœã€‚}[10]</li>
</ul>
</li>
</ul>
<h3><span id="private-multi-modal-text-tables-images-rag-22">private multi-modal (text + tables + images)  RAG [22]</span><a href="#private-multi-modal-text-tables-images-rag-22" class="header-anchor">#</a></h3><h3><span id="ç»„ä»¶">ç»„ä»¶</span><a href="#ç»„ä»¶" class="header-anchor">#</a></h3><ul>
<li>pdfè§£æ<br>unstructured</li>
<li>store<br>MultiVectorRetriever - å…ƒæ•°æ®+æ•°æ®</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="å®æˆ˜">å®æˆ˜</span><a href="#å®æˆ˜" class="header-anchor">#</a></h3><ol start="10">
<li><p><a href="https://www.zhihu.com/question/628651389/answer/3321989558">æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æœ‰ä»€ä¹ˆå¥½çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Ÿ</a> </p>
</li>
<li><p><a href="https://blog.langchain.dev/semi-structured-multi-modal-rag/">Multi-Vector Retriever for RAG on tables, text, and images</a> ***<br><a href="https://blog.csdn.net/lichunericli/article/details/135724777">åŸºäºå¤šå‘é‡æ£€ç´¢å™¨çš„å¤šæ¨¡æ€RAGå®ç°ï¼šç”¨äºè¡¨æ ¼ã€æ–‡æœ¬å’Œå›¾åƒ</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/665814914">langchainçš„multi model RAG-ä»¥å¤šæ¨¡æ€pdfæ–‡ä»¶ä¸ºä¾‹å­</a></p>
</li>
<li><p><a href="https://blog.langchain.dev/multi-modal-rag-template/">Multi-modal RAG on slide decks</a></p>
</li>
</ol>
<p>1xx. <a href="https://docs.google.com/presentation/d/19x0dvHGhbJOOUWqvPKrECPi1yI3makcoc-8tFLj9Sos/edit?ref=blog.langchain.dev&pli=1#slide=id.g2642e7050fc_0_370">Using Multi-Modal LLMs</a>  page21</p>
<h3><span id="notebook">notebook</span><a href="#notebook" class="header-anchor">#</a></h3><ol start="20">
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb">Semi_Structured_RAG</a>  notebook<br><a href="https://github.com/www6v/AIGC/blob/master/Advanced-RAG/01_semi_structured_data.ipynb">Advanced-RAG semi_structured_data</a>   notebook  {åŠç»“æ„åŒ–-è§£æpdfä¸­çš„è¡¨æ ¼ï¼Œ  è¿è¡Œæ²¡é—®é¢˜ï¼Œèƒ½é—®è¡¨æ ¼ä¸­çš„æ•°æ®}</p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb">Semi_structured_and_multi_modal_RAG</a> notebook </p>
</li>
<li><p><a href="https://github.com/www6v/AIGC/blob/master/langchain-cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb">Private Semi-structured and Multi-modal RAG w&#x2F; LLaMA2 and LLaVA</a>  notebook {å¤šæ¨¡æ€- è§£æpdfä¸­çš„å›¾ç‰‡  è¿è¡Œæœ‰é—®é¢˜}<br><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb">Private Semi-structured and Multi-modal RAG w&#x2F; LLaMA2 and LLaVA</a> notebook</p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/multi_modal_RAG_chroma.ipynb">Chroma multi-modal RAG</a> notebook</p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb">Multi-modal RAG</a> notebook</p>
</li>
</ol>
<h3><span id="template">template</span><a href="#template" class="header-anchor">#</a></h3><ol start="30">
<li><a href="https://github.com/langchain-ai/langchain/tree/master/templates/rag-multi-modal-local">rag-multi-modal-local</a><br>OpenCLIP(image embedding)  + bakllava(answer synthesis)</li>
<li><a href="https://github.com/langchain-ai/langchain/tree/master/templates/rag-multi-modal-mv-local">rag-multi-modal-mv-local</a><br>bakllava(image summaries embedding) +  bakllava (answer synthesis)</li>
<li><a href="https://github.com/langchain-ai/langchain/tree/master/templates/rag-chroma-multi-modal">rag-chroma-multi-modal</a><br>OpenCLIP(image embedding) + GPT-4V (answer synthesis)</li>
<li><a href="https://github.com/langchain-ai/langchain/tree/master/templates/rag-gemini-multi-modal">rag-gemini-multi-modal</a><br>OpenCLIP(image embedding) + Gemini(answer synthesis)</li>
<li><a href="https://github.com/langchain-ai/langchain/tree/master/templates/rag-chroma-multi-modal-multi-vector">rag-chroma-multi-modal-multi-vector</a><br>GPT-4V(image summaries embedding) + GPT-4V (answer synthesis)</li>
</ol>
<h3><span id="llamaindex">llamaindex</span><a href="#llamaindex" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s/93CdvD8FLZjaA7E724bf7g">æœ´ç´ å¤šæ¨¡æ€RAGå¦‚ä½•å®ç°ï¼Ÿå…¼çœ‹RAGä¸Šä¸‹æ–‡è¿‡æ»¤æ–¹æ¡ˆFILCOåŠ202402å¤§æ¨¡å‹æ—©æŠ¥ </a><br>1xx. <a href="https://docs.llamaindex.ai/en/stable/examples/multi_modal/gpt4v_multi_modal_retrieval/">Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index&#x2F;Retriever</a><br>1xx. <a href="https://www.llamaindex.ai/blog/multimodal-rag-pipeline-with-llamaindex-and-neo4j-a2c542eb0206">Multimodal RAG pipeline with LlamaIndex and Neo4j</a><br>1xx. <a href="https://github.com/tomasonjo/blogs/blob/master/llm/neo4j_llama_multimodal.ipynb">neo4j_llama_multimodal.ipynb</a> git</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)RAG OpenAIæ¡ˆä¾‹</title>
    <url>/www6vHomeAIGC/2022/12/27/gptRAGOpenAI/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#openai-rag-%E6%A1%88%E4%BE%8B3">OpenAI RAG æ¡ˆä¾‹[3]</a><ul>
<li><a href="#query-transformations5">Query Transformations[5]</a></li>
<li><a href="#query-construction-4">Query Construction [4]</a></li>
</ul>
</li>
<li><a href="#advanced-rag">Advanced RAG</a><ul>
<li><a href="#%E6%9E%B6%E6%9E%84-1">æ¶æ„ [1]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="openai-rag-æ¡ˆä¾‹3">OpenAI RAG æ¡ˆä¾‹[3]</span><a href="#openai-rag-æ¡ˆä¾‹3" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/12/27/gptRAGOpenAI/openai-rag.jpg" class>

<ol>
<li>retrieval with consine similarity</li>
<li><strong>HyDE retrieval</strong> [5]<br>Fine-tune Embeddings<br><strong>Chunk&#x2F;embedding experiments</strong></li>
<li><strong>Reranking</strong> [6][8]<br>Classification step</li>
<li>Prompt engineering<br><strong>Tool use</strong><br><strong>Query expansion</strong>[5]</li>
</ol>
<h3><span id="query-transformations5">Query Transformations[5]</span><a href="#query-transformations5" class="header-anchor">#</a></h3><ul>
<li><strong>Query expansion</strong><br>Multi-query retriever </li>
<li><strong>HyDE</strong></li>
<li>Step back prompting<br> [æŠ½è±¡prompting]</li>
<li>Rewrite-Retrieve-Read</li>
</ul>
<h3><span id="query-construction-4">Query Construction [4]</span><a href="#query-construction-4" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/12/27/gptRAGOpenAI/structured_data_stacks.jpg" class>

<table>
<thead>
<tr>
<th><strong>Examples</strong></th>
<th><strong>Data source</strong></th>
<th><strong>References</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Text-to-metadata-filter</strong></td>
<td>Vectorstores</td>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/?ref=blog.langchain.dev#constructing-from-scratch-with-lcel"><strong>Docs</strong></a></td>
</tr>
<tr>
<td><strong>Text-to-SQL</strong></td>
<td>SQL DB</td>
<td><a href="https://python.langchain.com/docs/use_cases/qa_structured/sql?ref=blog.langchain.dev"><strong>Docs</strong></a><strong>,</strong> <a href="https://blog.langchain.dev/llms-and-sql/"><strong>blog</strong></a><strong>,</strong> <a href="https://blog.langchain.dev/incorporating-domain-specific-knowledge-in-sql-llm-solutions/"><strong>blog</strong></a></td>
</tr>
</tbody></table>
<ul>
<li>Text-to-metadata-filter [7]</li>
</ul>
<p>A <strong>self-querying</strong> retriever is one that, as the name suggests, has the  ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a <strong>structured query</strong> and then applies that structured query to its underlying  VectorStore. This allows the retriever to not only use the user-input  query for semantic similarity comparison with the contents of stored  documents but to also <strong>extract filters from the user query on the  metadata of stored documents and to execute those filters</strong>.</p>
<h1><span id="advanced-rag">Advanced RAG</span><a href="#advanced-rag" class="header-anchor">#</a></h1><h3><span id="æ¶æ„-1">æ¶æ„ [1]</span><a href="#æ¶æ„-1" class="header-anchor">#</a></h3><ul>
<li>ç¦»çº¿ index</li>
<li>åœ¨çº¿ æŸ¥è¯¢</li>
</ul>
<img src="/www6vHomeAIGC/2022/12/27/gptRAGOpenAI/rag.jpg" class>


<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://blog.langchain.dev/deconstructing-rag/">Deconstructing RAG</a> ***</p>
</li>
<li><p>xxx</p>
</li>
<li><p><a href="https://blog.langchain.dev/applying-openai-rag/">Applying OpenAIâ€™s RAG Strategies</a>   *** </p>
</li>
<li><p><a href="https://blog.langchain.dev/query-construction/">Query Construction</a> ***</p>
</li>
<li><p><a href="https://blog.langchain.dev/query-transformations/">Query Transformations</a></p>
</li>
<li><p><a href="https://txt.cohere.com/rerank/">Say Goodbye to Irrelevant Search Results: Cohere Rerank Is Here</a><br><a href="https://github.com/langchain-ai/langchain/tree/master/templates/rag-pinecone-rerank">Rerank</a><br><a href="https://python.langchain.com/docs/integrations/retrievers/cohere-reranker">Cohere Reranker</a></p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/docs/docs/modules/data_connection/retrievers/self_query.ipynb">self_query</a></p>
</li>
<li><p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb">RAG Fusion</a><br><a href="https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1">Forget RAG, the Future is RAG-Fusion</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Advanced RAG</title>
    <url>/www6vHomeAIGC/2022/12/07/gptRAGPerformance/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#overview">Overview</a><ul>
<li><a href="#advanced-rag-2">Advanced RAG [2]</a></li>
<li><a href="#advanced-rag-1">Advanced RAG [1]</a></li>
</ul>
</li>
<li><a href="#embedding">Embedding</a></li>
<li><a href="#%E7%B4%A2%E5%BC%95">ç´¢å¼•</a><ul>
<li><a href="#%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F">ç´¢å¼•æ–¹å¼</a><ul>
<li><a href="#smaller-chunks-1112">Smaller chunks [11][12]</a></li>
<li><a href="#hypothetical-questions-1112">Hypothetical questions [11][12]</a></li>
<li><a href="#summary-1112">Summary [11][12]</a></li>
<li><a href="#%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E7%B4%A2%E5%BC%951">å‘é‡å­˜å‚¨ç´¢å¼•[1]</a></li>
<li><a href="#%E5%B1%82%E6%AC%A1%E7%B4%A2%E5%BC%951">å±‚æ¬¡ç´¢å¼•[1]</a></li>
<li><a href="#%E5%81%87%E8%AE%BE%E9%97%AE%E9%A2%98%E5%92%8Chyde1">å‡è®¾é—®é¢˜å’ŒHyDE[1]</a></li>
<li><a href="#%E4%B8%8A%E4%B8%8B%E6%96%87%E4%B8%B0%E5%AF%8C1">ä¸Šä¸‹æ–‡ä¸°å¯Œ[1]</a></li>
<li><a href="#%E8%9E%8D%E5%90%88%E6%A3%80%E7%B4%A2%E6%88%96%E6%B7%B7%E5%90%88%E6%90%9C%E7%B4%A21">èåˆæ£€ç´¢æˆ–æ··åˆæœç´¢[1]</a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E5%9D%9713">åˆ†å—[13]</a><ul>
<li><a href="#%E5%88%86%E5%9D%97%E6%96%B9%E6%B3%95">åˆ†å—æ–¹æ³•</a></li>
<li><a href="#%E5%88%86%E5%9D%97%E4%BC%98%E5%8C%96">åˆ†å—ä¼˜åŒ–</a></li>
<li><a href="#%E5%88%86%E5%9D%97%E5%8F%82%E6%95%B0">åˆ†å—å‚æ•°</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#pre-retrival%E9%98%B6%E6%AE%B5">pre-retrivalé˜¶æ®µ</a><ul>
<li><a href="#query-transformer-%E6%9F%A5%E8%AF%A2%E8%BD%AC%E6%8D%A2-301">query transformer æŸ¥è¯¢è½¬æ¢ [30][1]</a></li>
<li><a href="#query-routing-%E6%9F%A5%E8%AF%A2%E8%B7%AF%E7%94%B1-311">query-routing æŸ¥è¯¢è·¯ç”±  [31][1]</a></li>
</ul>
</li>
<li><a href="#retrieval">Retrieval</a><ul>
<li><a href="#%E6%A3%80%E7%B4%A2%E5%99%A8-retriever">æ£€ç´¢å™¨ Retriever</a></li>
</ul>
</li>
<li><a href="#post-retrieval">Post-Retrieval</a><ul>
<li><a href="#reranker20">Reranker[20]</a></li>
<li><a href="#fusion23">Fusion[23]</a></li>
</ul>
</li>
<li><a href="#encoder-and-llm-fine-tuning">Encoder and LLM fine-tuning</a><ul>
<li><a href="#encoder-fine-tuning40">Encoder fine-tuning[40]</a></li>
<li><a href="#ranker-fine-tuning41">Ranker fine-tuning[41]</a></li>
<li><a href="#llm-fine-tuning42">LLM fine-tuning[42]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#overview-1">Overview</a></li>
<li><a href="#index">index</a></li>
<li><a href="#post-retrieval-1">Post-Retrieval</a></li>
</ul>
</li>
<li><a href="#pre-retrival">pre-retrival</a><ul>
<li><a href="#fine-tuning">fine-tuning</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h1><h3><span id="advanced-rag-2">Advanced RAG [2]</span><a href="#advanced-rag-2" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/12/07/gptRAGPerformance/advanced-rag.JPG" class>

<h3><span id="advanced-rag-1">Advanced RAG [1]</span><a href="#advanced-rag-1" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/12/07/gptRAGPerformance/advaced.png" class>


<h1><span id="embedding">Embedding</span><a href="#embedding" class="header-anchor">#</a></h1><ul>
<li>HyDE<br>At a high level, HyDE is an embedding technique that takes queries, <strong>generates a hypothetical answer</strong>, and then embeds that generated document and uses that as the final example.</li>
</ul>
<blockquote>
<p>æœ€ä½³å®è·µ<br><strong>BGE</strong> ä¼˜äº OpenAI ADA02</p>
</blockquote>
<h1><span id="ç´¢å¼•">ç´¢å¼•</span><a href="#ç´¢å¼•" class="header-anchor">#</a></h1><h2><span id="ç´¢å¼•æ–¹å¼">ç´¢å¼•æ–¹å¼</span><a href="#ç´¢å¼•æ–¹å¼" class="header-anchor">#</a></h2><h3><span id="smaller-chunks-1112">Smaller chunks [11][12]</span><a href="#smaller-chunks-1112" class="header-anchor">#</a></h3><p>Indexing by <strong>small data chunks</strong><br>æŒ‰å­éƒ¨åˆ†ç´¢å¼•æ•°æ®å—ï¼šå°†æ–‡æœ¬å—æ‹†åˆ†ä¸ºè¾ƒå°çš„éƒ¨åˆ†ï¼Œå¦‚å¥å­ï¼Œè¿›è¡Œå¤šæ¬¡ç´¢å¼•ã€‚è¿™æœ‰åŠ©äº<br>å¤„ç†å¤æ‚æ–‡æœ¬å—ï¼Œå‡å°‘å™ªéŸ³è¾“å‡ºï¼Œç¡®ä¿æ›´å‡†ç¡®åŒ¹é…ç”¨æˆ·æŸ¥è¯¢ã€‚</p>
<h3><span id="hypothetical-questions-1112">Hypothetical questions [11][12]</span><a href="#hypothetical-questions-1112" class="header-anchor">#</a></h3><p>Indexing by <strong>the questions the document answers</strong><br>æŒ‰æ–‡æœ¬å—å›ç­”çš„é—®é¢˜ç´¢å¼•æ•°æ®å—ï¼šè®©LLMç”Ÿæˆä¸æ‹†åˆ†çš„æ–‡æœ¬å—ç›¸å…³çš„å‡è®¾æ€§é—®é¢˜ï¼Œå¹¶ç”¨<br>äºç´¢å¼•ã€‚è¿™ç§æ–¹æ³•ä¿æŒç”¨æˆ·æŸ¥è¯¢ä¸æ•°æ®æ ¸å¿ƒå†…å®¹ä¸€è‡´ï¼Œé™ä½æ¨¡ç³Šæ€§ã€‚</p>
<h3><span id="summary-1112">Summary [11][12]</span><a href="#summary-1112" class="header-anchor">#</a></h3><p>Indexing by <strong>the summary of the document</strong></p>
<p>æŒ‰æ–‡æœ¬å—æ‘˜è¦ç´¢å¼•æ•°æ®å—ï¼šç±»ä¼¼äºç¬¬äºŒç§æ–¹æ³•ï¼Œä½¿ç”¨å—æ‘˜è¦è€Œä¸æ˜¯å›ç­”çš„å‡è®¾é—®é¢˜æ¥åˆ›<br>å»ºç´¢å¼•ã€‚ç‰¹åˆ«é€‚ç”¨äºæ–‡æœ¬å—ä¸­åŒ…å«å¤šä½™ä¿¡æ¯æˆ–ä¸ç”¨æˆ·æŸ¥è¯¢æ— å…³çš„æƒ…å†µã€‚</p>
<h3><span id="å‘é‡å­˜å‚¨ç´¢å¼•1">å‘é‡å­˜å‚¨ç´¢å¼•[1]</span><a href="#å‘é‡å­˜å‚¨ç´¢å¼•1" class="header-anchor">#</a></h3><ul>
<li>è¿‘ä¼¼æœ€è¿‘é‚»å®ç°ï¼ˆå¦‚èšç±»ã€æ ‘æˆ–HNSWç®—æ³•ï¼‰<br>Faissã€nmslibã€annoy</li>
<li>LlamaIndex</li>
</ul>
<h3><span id="å±‚æ¬¡ç´¢å¼•1">å±‚æ¬¡ç´¢å¼•[1]</span><a href="#å±‚æ¬¡ç´¢å¼•1" class="header-anchor">#</a></h3><ul>
<li>åˆ›å»º<strong>ä¸¤ä¸ªç´¢å¼•</strong>â€”ä¸€ä¸ªç”±æ‘˜è¦ç»„æˆï¼Œå¦ä¸€ä¸ªç”±æ–‡æ¡£å—ç»„æˆï¼Œå¹¶åˆ†ä¸¤æ­¥æ£€ç´¢ï¼Œé¦–å…ˆé€šè¿‡æ‘˜è¦è¿‡æ»¤æ‰ç›¸å…³æ–‡æ¡£ï¼Œç„¶ååªåœ¨è¿™ä¸ªç›¸å…³ç»„å†…æ£€ç´¢ã€‚</li>
</ul>
<h3><span id="å‡è®¾é—®é¢˜å’Œhyde1">å‡è®¾é—®é¢˜å’ŒHyDE[1]</span><a href="#å‡è®¾é—®é¢˜å’Œhyde1" class="header-anchor">#</a></h3><h3><span id="ä¸Šä¸‹æ–‡ä¸°å¯Œ1">ä¸Šä¸‹æ–‡ä¸°å¯Œ[1]</span><a href="#ä¸Šä¸‹æ–‡ä¸°å¯Œ1" class="header-anchor">#</a></h3><ul>
<li>å¥å­çª—å£æ£€ç´¢<br>ä¸ºäº†åœ¨è·å–æœ€ç›¸å…³çš„å•ä¸ªå¥å­åæ›´å¥½åœ°å¯¹æ‰¾åˆ°çš„ä¸Šä¸‹æ–‡è¿›è¡Œæ¨ç†ï¼Œæˆ‘ä»¬<strong>å°†ä¸Šä¸‹æ–‡çª—å£åœ¨æ£€ç´¢åˆ°çš„å¥å­ä¹‹å‰å’Œä¹‹åæ‰©å±•äº†kä¸ªå¥å­ï¼Œç„¶åå°†æ­¤æ‰©å±•çš„ä¸Šä¸‹æ–‡å‘é€ç»™LLM</strong>ã€‚</li>
<li>è‡ªåŠ¨åˆå¹¶æ£€ç´¢å™¨ï¼ˆåˆå<strong>çˆ¶æ–‡æ¡£æ£€ç´¢å™¨</strong>ï¼‰</li>
</ul>
<h3><span id="èåˆæ£€ç´¢æˆ–æ··åˆæœç´¢1">èåˆæ£€ç´¢æˆ–æ··åˆæœç´¢[1]</span><a href="#èåˆæ£€ç´¢æˆ–æ··åˆæœç´¢1" class="header-anchor">#</a></h3><p>åŸºäºå…³é”®å­—çš„è€å¼æœç´¢â€”ç¨€ç–æ£€ç´¢ç®—æ³•ï¼ˆå¦‚tf-idfæˆ–æœç´¢è¡Œä¸šæ ‡å‡†BM25ï¼‰å’Œç°ä»£è¯­ä¹‰æˆ–å‘é‡æœç´¢ï¼Œå¹¶å°†å…¶ç»„åˆåˆ°ä¸€ä¸ªæ£€ç´¢ç»“æœä¸­ã€‚</p>
<ul>
<li>Reciprocal Rank Fusion (RRF)ç®—æ³•<br>å¯¹æ£€ç´¢åˆ°çš„ç»“æœè¿›è¡Œé‡æ–°æ’åºä»¥è·å¾—æœ€ç»ˆè¾“å‡º</li>
<li>å®ç°<br>LangChain  - Ensemble Retrieverç±»</li>
</ul>
<h2><span id="åˆ†å—13">åˆ†å—[13]</span><a href="#åˆ†å—13" class="header-anchor">#</a></h2><h3><span id="åˆ†å—æ–¹æ³•">åˆ†å—æ–¹æ³•</span><a href="#åˆ†å—æ–¹æ³•" class="header-anchor">#</a></h3><ul>
<li>å›ºå®šå¤§å°åˆ†å—</li>
<li>å†…å®¹æ„ŸçŸ¥åˆ†å—<ul>
<li>å¥å­åˆ†å—<ul>
<li>ç›´æ¥åˆ†å‰²<br>æŒ‰å¥ç‚¹ï¼ˆâ€œ.â€ï¼‰å’Œæ¢è¡Œç¬¦åˆ†å‰²å¥å­</li>
<li>NLTK<br><code>from langchain.text_splitter import NLTKTextSplitter</code></li>
<li>spaCy<br><code>from langchain.text_splitter import SpacyTextSplitter</code></li>
</ul>
</li>
<li>é€’å½’åˆ†å—<br>ä½¿ç”¨ä¸€ç»„åˆ†éš”ç¬¦ä»¥åˆ†å±‚å’Œè¿­ä»£çš„æ–¹å¼å°†è¾“å…¥æ–‡æœ¬åˆ’åˆ†ä¸ºæ›´å°çš„å—<br><code>from langchain.text_splitter import RecursiveCharacterTextSplitter</code></li>
<li>ä¸“é—¨åˆ†å—<ul>
<li>Markdown</li>
<li>LaTex</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="åˆ†å—ä¼˜åŒ–">åˆ†å—ä¼˜åŒ–</span><a href="#åˆ†å—ä¼˜åŒ–" class="header-anchor">#</a></h3><ul>
<li>é¢„å¤„ç†æ•°æ®</li>
<li>é€‰æ‹©å—å¤§å°èŒƒå›´</li>
<li>è¯„ä¼°æ¯ä¸ªå—å¤§å°çš„æ€§èƒ½</li>
</ul>
<h3><span id="åˆ†å—å‚æ•°">åˆ†å—å‚æ•°</span><a href="#åˆ†å—å‚æ•°" class="header-anchor">#</a></h3><p>chuck_size, ,chunk overlap<br>top_k</p>
<blockquote>
<p>æœ€ä½³å®è·µ<br>  æŒ‰<strong>é€»è¾‘åˆ†å—</strong>å¯ä»¥æ˜æ˜¾æå‡<strong>æ£€ç´¢å™¨çš„å‡†ç¡®ç‡</strong></p>
</blockquote>
<h1><span id="pre-retrivalé˜¶æ®µ">pre-retrivalé˜¶æ®µ</span><a href="#pre-retrivalé˜¶æ®µ" class="header-anchor">#</a></h1><h3><span id="query-transformer-æŸ¥è¯¢è½¬æ¢-301">query transformer æŸ¥è¯¢è½¬æ¢ [30][1]</span><a href="#query-transformer-æŸ¥è¯¢è½¬æ¢-301" class="header-anchor">#</a></h3><h3><span id="query-routing-æŸ¥è¯¢è·¯ç”±-311">query-routing æŸ¥è¯¢è·¯ç”±  [31][1]</span><a href="#query-routing-æŸ¥è¯¢è·¯ç”±-311" class="header-anchor">#</a></h3><p>LlamaIndexå’ŒLangChainéƒ½æ”¯æŒæŸ¥è¯¢è·¯ç”±å™¨</p>
<h1><span id="retrieval">Retrieval</span><a href="#retrieval" class="header-anchor">#</a></h1><h3><span id="æ£€ç´¢å™¨-retriever">æ£€ç´¢å™¨ Retriever</span><a href="#æ£€ç´¢å™¨-retriever" class="header-anchor">#</a></h3><ul>
<li>Ensemble Retriever<br>æœ€å¸¸è§çš„æ¨¡å¼æ˜¯å°†<strong>ç¨€ç–æ£€ç´¢å™¨ï¼ˆå¦‚BM25ï¼‰</strong>ä¸<strong>å¯†é›†æ£€ç´¢å™¨ï¼ˆå¦‚åµŒå…¥ç›¸ä¼¼åº¦ï¼‰</strong>ç»“åˆèµ·æ¥ï¼Œå› ä¸ºå®ƒä»¬çš„ä¼˜åŠ¿æ˜¯äº’è¡¥çš„ã€‚è¿™ä¹Ÿè¢«ç§°ä¸ºâ€œæ··åˆæœç´¢â€ã€‚<strong>ç¨€ç–æ£€ç´¢å™¨</strong>æ“…é•¿åŸºäº<strong>å…³é”®è¯æŸ¥æ‰¾</strong>ç›¸å…³æ–‡æ¡£ï¼Œè€Œ<strong>å¯†é›†æ£€ç´¢å™¨</strong>æ“…é•¿åŸºäº<strong>è¯­ä¹‰ç›¸ä¼¼æ€§æŸ¥æ‰¾</strong>ç›¸å…³æ–‡æ¡£ã€‚</li>
</ul>
<blockquote>
<p>æœ€ä½³å®è·µ<br><strong>BM25+FAAIS   å¥½äº FAAISç›¸ä¼¼åº¦æœç´¢</strong><br><strong>FAAISç›¸ä¼¼åº¦æœç´¢ å¥½äº HyDEå’Œä¸Šä¸‹æ–‡å‹ç¼©</strong></p>
</blockquote>
<h1><span id="post-retrieval">Post-Retrieval</span><a href="#post-retrieval" class="header-anchor">#</a></h1><h2><span id="reranker20">Reranker[20]</span><a href="#reranker20" class="header-anchor">#</a></h2><h2><span id="fusion23">Fusion[23]</span><a href="#fusion23" class="header-anchor">#</a></h2><p>å…¶æ€æƒ³åœ¨äºé€šè¿‡ç”Ÿæˆå¤šä¸ªç”¨æˆ·æŸ¥è¯¢å’Œé‡æ–°æ’åºç»“æœæ¥è§£å†³RAGå›ºæœ‰çš„çº¦æŸï¼›åˆ©ç”¨å€’æ•°æ’åºèåˆï¼ˆRRFï¼‰å’Œè‡ªå®šä¹‰å‘é‡è¯„åˆ†åŠ æƒï¼Œç”Ÿæˆå…¨é¢å‡†ç¡®çš„ç»“æœã€‚</p>
<h1><span id="encoder-and-llm-fine-tuning">Encoder and LLM fine-tuning</span><a href="#encoder-and-llm-fine-tuning" class="header-anchor">#</a></h1><h3><span id="encoder-fine-tuning40">Encoder fine-tuning[40]</span><a href="#encoder-fine-tuning40" class="header-anchor">#</a></h3><h3><span id="ranker-fine-tuning41">Ranker fine-tuning[41]</span><a href="#ranker-fine-tuning41" class="header-anchor">#</a></h3><p>å®ƒçš„å·¥ä½œæ–¹å¼å¦‚ä¸‹ï¼šå°†æŸ¥è¯¢å’Œæ£€ç´¢åˆ°çš„å‰kä¸ªæ–‡æœ¬å—ä¼ é€’ç»™äº¤å‰ç¼–ç å™¨ï¼Œå¹¶ç”¨SEPä»¤ç‰Œåˆ†éš”ï¼Œå¹¶å°†å…¶å¾®è°ƒä¸ºè¾“å‡º1è¡¨ç¤ºç›¸å…³å—ï¼Œè¾“å‡º0è¡¨ç¤ºä¸ç›¸å…³ã€‚</p>
<h3><span id="llm-fine-tuning42">LLM fine-tuning[42]</span><a href="#llm-fine-tuning42" class="header-anchor">#</a></h3><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="overview">Overview</span><a href="#overview" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6">Advanced RAG Techniques: an Illustrated Overview</a>  ***<br><a href="https://mp.weixin.qq.com/s/CO7hMv4RW7OE6zwUmVfp5A">æœ€å…¨çš„RAGæŠ€æœ¯æ¦‚è§ˆ </a><br><a href="https://zhuanlan.zhihu.com/p/673922981">é«˜çº§æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯(RAG)å…¨é¢æŒ‡å—ï¼šåŸç†ã€åˆ†å—ã€ç¼–ç ã€ç´¢å¼•ã€å¾®è°ƒã€Agentã€å±•æœ›</a> </p>
</li>
<li><p>ã€ŠRetrieval-Augmented Generation for Large Language Models: A Surveyã€‹</p>
</li>
</ol>
<p>1xx. <a href="https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b">A Cheat Sheet and Some Recipes For Building Advanced RAG</a><br>     <a href="https://mp.weixin.qq.com/s/KM8c3PUww1SOK1dbLjn1Tw">LlamaIndexå®˜æ–¹å¹´åº¦å·¨çŒ®ï¼šé«˜æ¸…å¤§å›¾çºµè§ˆé«˜çº§ RAGæŠ€æœ¯ï¼Œå¼ºçƒˆæ¨èæ”¶è— </a> *** çœ‹å›¾<br>     <a href="https://baoyu.io/translations/rag/a-cheat-sheet-and-some-recipes-for-building-advanced-rag">æ„å»ºé«˜çº§ RAG çš„æŒ‡å—å’ŒæŠ€å·§ [è¯‘]</a></p>
<h3><span id="index">index</span><a href="#index" class="header-anchor">#</a></h3><ol start="11">
<li><p><a href="https://www.bilibili.com/video/BV1dH4y1C7Ck/">3ç§é«˜çº§ç´¢å¼•æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡RAGæ€§èƒ½</a> V<br>  <a href="https://thetechbuffet.substack.com/p/rag-indexing-methods">The Tech Buffet #12: Improve RAG Pipelines With These 3 Indexing Methods</a><br>  <a href="https://newsletter.theaiedge.io/p/how-to-optimize-your-rag-pipelines">How To Optimize Your RAG Pipelines</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1Vu4y1H72s/">ã€RAGå®æˆ˜ã€‘ Multi-Vector-Retrievalå®ç°ä¸‰ç§é«˜çº§ç´¢å¼•æ–¹æ³•</a> V<br><a href="https://github.com/www6v/AIGC/blob/master/retriever%2Bindex/MultiVectorRetriever">MultiVectorRetriever</a>  git<br> <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector">MultiVector Retriever</a></p>
</li>
<li><p><a href="https://hustai.gitee.io/zh/posts/rag/Chunking-Strategies.html">å¤§è¯­è¨€æ¨¡å‹åº”ç”¨ä¸­çš„æ–‡æœ¬åˆ†å—ç­–ç•¥</a><br>  <a href="https://yangfei.me/tutorials/chunking-strategies">LLM åº”ç”¨ä¸­çš„åˆ†å—ç­–ç•¥ </a></p>
</li>
</ol>
<p>1xx. <a href="https://baoyu.io/translations/rag/5-levels-of-text-splitting">æ–‡æœ¬åˆ†å‰²çš„äº”ä¸ªå±‚æ¬¡ [è¯‘]</a></p>
<h3><span id="post-retrieval">Post-Retrieval</span><a href="#post-retrieval" class="header-anchor">#</a></h3><ol start="20">
<li><a href="/www6vHomeAIGC/2023/05/14/gptRAGRerank/" title="RAG Rerank">RAG Rerank</a> self</li>
<li><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb">RAG Fusion</a> git<br>  <a href="https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1">Forget RAG, the Future is RAG-Fusion</a><br>  <a href="https://blog.csdn.net/lichunericli/article/details/135451681">å¿˜è®°RAGï¼Œæœªæ¥æ˜¯RAG-Fusion</a><br>  <a href="https://mp.weixin.qq.com/s/NFjn8pUsQaSx85nhBphORA">å†è°ˆå¤§æ¨¡å‹RAGé—®ç­”ä¸­çš„ä¸‰ä¸ªç°å®é—®é¢˜ï¼šå…¼çœ‹RAG-Fusionå¤šqueryèåˆç­–ç•¥ã€å›ç­”å¼•æ–‡ç”Ÿæˆç­–ç•¥åŠç›¸å…³æ•°æ®é›†æ¦‚è¿°</a></li>
</ol>
<h1><span id="pre-retrival">pre-retrival</span><a href="#pre-retrival" class="header-anchor">#</a></h1><ol start="30">
<li><a href="/www6vHomeAIGC/2023/04/20/gptQueryTransformation/" title="Query Transformation">Query Transformation</a>  self</li>
<li><a href="/www6vHomeAIGC/2023/05/14/gptRAGRouting/" title="Query Routing">Query Routing</a>  self</li>
</ol>
<h3><span id="fine-tuning">fine-tuning</span><a href="#fine-tuning" class="header-anchor">#</a></h3><ol start="40">
<li><p><a href="https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding/">Finetune Embeddings</a> notebook</p>
</li>
<li><p><a href="https://docs.llamaindex.ai/en/stable/examples/finetuning/cross_encoder_finetuning/cross_encoder_finetuning/">How to Finetune a cross-encoder using LLamaIndex</a> notebook</p>
</li>
<li><p><a href="https://docs.llamaindex.ai/en/stable/examples/finetuning/openai_fine_tuning/">Fine Tuning GPT-3.5-Turbo</a> notebook</p>
</li>
</ol>
<p>1xx. <a href="https://www.youtube.com/watch?v=ahnGLM-RC1Y">A Survey of Techniques for Maximizing LLM Performance</a>  *** V<br>    <a href="https://zhuanlan.zhihu.com/p/670880685">A Survey of Techniques for Maximizing LLM Performanceæ¢³ç†</a> </p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648406795&idx=1&sn=00ea4aab819eed3d622287fa1d32816f">å¤§æ¨¡å‹RAGé—®ç­”æŠ€æœ¯æ¶æ„åŠæ ¸å¿ƒæ¨¡å—å›é¡¾ï¼šä»Embeddingã€prompt-embeddingåˆ°Reranker </a> ***</p>
<p>1xx. CON<br>   <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648406194&idx=1&sn=aafe667fa5a73bd89a00272c5598c98e">å¼•å…¥COTç¼“è§£å¤§æ¨¡å‹RAGé—®ç­”çš„ä¸Šä¸‹æ–‡åŒºåˆ†é—®é¢˜ï¼šå…¼çœ‹Langchainçš„è¡¨æ ¼æ£€ç´¢æ€è·¯åŠGPTBIASè¯„ä¼°æ¡†æ¶ </a> CON<br>   <a href="https://cobusgreyling.medium.com/chain-of-note-con-retrieval-for-llms-763ead1ae5c5">Chain-Of-Note (CoN) Retrieval For LLMs</a><br>   <a href="https://praveengovindaraj.com/cutting-through-the-noise-chain-of-notes-con-robust-approach-to-super-power-your-rag-pipelines-0df5f1ce7952">Cutting Through the Noise: Chain-of-Noteâ€™s (CoN) Robust Approach to super power your RAG pipelines</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG ä¼˜åŒ–</title>
    <url>/www6vHomeAIGC/2023/05/09/gptRAGOptimize/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E6%9C%B4%E7%B4%A0rag-embedding">æœ´ç´ RAG Embedding</a><ul>
<li><a href="#embedding-%E5%8F%AC%E5%9B%9E%E6%96%B9%E6%A1%88%E5%8F%8A%E5%B1%80%E9%99%90%E6%80%A71">Embedding å¬å›æ–¹æ¡ˆåŠå±€é™æ€§[1]</a></li>
<li><a href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">è§£å†³æ–¹æ¡ˆ</a></li>
</ul>
</li>
<li><a href="#%E8%A1%8C%E4%B8%9A%E9%97%AE%E7%AD%943">è¡Œä¸šé—®ç­”[3]</a><ul>
<li><a href="#%E6%8C%91%E6%88%98">æŒ‘æˆ˜</a></li>
<li><a href="#%E4%BC%98%E5%8C%96">ä¼˜åŒ–</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#xxx">xxx</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="æœ´ç´ rag-embedding">æœ´ç´ RAG Embedding</span><a href="#æœ´ç´ rag-embedding" class="header-anchor">#</a></h1><h3><span id="embedding-å¬å›æ–¹æ¡ˆåŠå±€é™æ€§1">Embedding å¬å›æ–¹æ¡ˆåŠå±€é™æ€§[1]</span><a href="#embedding-å¬å›æ–¹æ¡ˆåŠå±€é™æ€§1" class="header-anchor">#</a></h3><ul>
<li>å¬å›<strong>ç²¾åº¦ä½</strong></li>
<li><strong>ç²’åº¦è¿‡ç²—</strong></li>
<li>ä¸æ”¯æŒæ¡ä»¶æŸ¥è¯¢&#x2F;ç»Ÿè®¡</li>
<li>ä¸èƒ½æ›¿ä»£ä¿¡æ¯æå–</li>
</ul>
<h3><span id="è§£å†³æ–¹æ¡ˆ">è§£å†³æ–¹æ¡ˆ</span><a href="#è§£å†³æ–¹æ¡ˆ" class="header-anchor">#</a></h3><ul>
<li><p>é—®é¢˜ç†è§£â€”â€”å‡†ç¡®è¯†åˆ«<strong>ç”¨æˆ·æ„å›¾</strong>(ä¼ ç»ŸNLP)  [2]</p>
</li>
<li><p>åŸºäº<strong>å…³é”®è¯Embedding</strong>çš„å…¥åº“å’Œæœç´¢ [2]</p>
<ul>
<li><strong>å…³é”®è¯æå–</strong><ul>
<li>å®ç°ä¿¡æ¯æŠ½å–ï¼ˆInformation Extractionï¼ŒIEï¼‰<ul>
<li>å®ä½“å…³ç³»ä¸‰å…ƒç»„æŠ½å–(RE, Relation Extraction )</li>
<li>å‘½åå®ä½“è¯†åˆ«(NER, Name-Entity Recognition)</li>
<li>äº‹ä»¶æŠ½å–(EE, Event Extraction)</li>
</ul>
</li>
</ul>
</li>
<li>åŸºäº LLM æå– [ä¸æ¨è]<ul>
<li>ç»“æœä¸å‡†ç¡®ã€å¼€é”€ä¹Ÿå¤§</li>
</ul>
</li>
<li><strong>ä¼ ç»Ÿ NLP æ–¹æ³•æå–</strong>[æ¨è]<ul>
<li>åè¯çŸ­è¯­æå–ä¸æ•´åˆ</li>
<li>ä¾å­˜åˆ†æ</li>
<li>æˆåˆ†å¥æ³•åˆ†æ</li>
</ul>
</li>
<li>æ€»ç»“<br>ä»<strong>å®Œæ•´è¯­å¥çš„ Embedding</strong>ï¼Œåˆ‡æ¢ä¸º<strong>å…³é”®è¯ Embedding</strong>ï¼š</li>
<li>ä¼˜åŠ¿<ul>
<li>ç›¸æ¯”ä¼ ç»Ÿ Embeddingï¼Œå¤§å¹…æå‡<strong>å¬å›ç²¾å‡†åº¦</strong>ã€‚</li>
<li>ä½¿ç”¨ä¼ ç»Ÿ NLP åœ¨ä¸“é¡¹é—®é¢˜å¤„ç†ä¸Šï¼Œç›¸æ¯” LLM æä¾›æ›´å¥½çš„ç²¾åº¦å’Œæ€§èƒ½ã€‚</li>
</ul>
</li>
</ul>
</li>
<li><p>çŸ¥è¯†åº“å­˜å‚¨é€‰å‹</p>
<ul>
<li>Vector Store<ul>
<li>åˆ†ç‰‡:  åŒºåˆ†<strong>å±‚çº§ç»“æ„</strong></li>
</ul>
</li>
<li>Relational Database</li>
<li>Graph Database   <ul>
<li><strong>å›¾æ•°æ®æ£€ç´¢</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="è¡Œä¸šé—®ç­”3">è¡Œä¸šé—®ç­”[3]</span><a href="#è¡Œä¸šé—®ç­”3" class="header-anchor">#</a></h1><h3><span id="æŒ‘æˆ˜">æŒ‘æˆ˜</span><a href="#æŒ‘æˆ˜" class="header-anchor">#</a></h3><ul>
<li>ç‰ˆé¢å¤æ‚å¤šæ ·</li>
<li>æ–‡æœ¬åˆ†å—<br><strong>å­˜åœ¨çŸ¥è¯†ç‚¹è¢«åˆ†å‰²ã€ä¸å®Œæ•´çš„æƒ…å†µ</strong>ã€‚</li>
<li>å¤šå› ç´ å½±å“å†…å®¹å¬å›æ•ˆæœ<ul>
<li>ä¾‹å¦‚ï¼šæ–‡æ¡£å†…å®¹ç›¸ä¼¼åº¦é«˜(ä¸“ä¸šæ–‡æ¡£ç»†åˆ†é¢†åŸŸã€ç‰ˆæœ¬è¿­ä»£ç­‰)ï¼›</li>
<li>é€šç”¨çš„<strong>å‘é‡ç›¸ä¼¼åº¦ç®—æ³•</strong>æ•ˆæœä¸å¥½(é—®é¢˜ä¸é—®é¢˜åŒ¹é… VSé—®é¢˜ä¸ç­”æ¡ˆåŒ¹é…)ï¼›</li>
<li>å¬å›ç‡å—æ–‡æ¡£åº“å¢å¤§è€Œé™ä½</li>
</ul>
</li>
</ul>
<h3><span id="ä¼˜åŒ–">ä¼˜åŒ–</span><a href="#ä¼˜åŒ–" class="header-anchor">#</a></h3><ul>
<li><p>å‘é‡åŒ–ä¸Šçš„ä¼˜åŒ–</p>
<ul>
<li>è®­ç»ƒç›®æ ‡ä¼˜åŒ–ä¸ºæå‡<strong>Queryä¸æ®µè½çš„ç›¸å…³æ€§</strong>ï¼Œä½¿å¾—<strong>é—®é¢˜å’Œç›¸å…³æ®µè½çš„è¯­ä¹‰å‘é‡è¡¨ç¤ºæ›´æ¥è¿‘</strong>ï¼Œè®­ç»ƒæ¨¡å‹æœ‰<strong>sbert</strong>ï¼Œ<strong>cosent</strong>ç­‰</li>
</ul>
</li>
<li><p>å…³é”®ä¿¡æ¯ä¸Šçš„ä¼˜åŒ–</p>
<ul>
<li>åœ¨æ–‡æ¡£å†…å®¹çš„ä¿¡æ¯å‹ç¼©ä¸Šï¼Œè¿›è¡Œæ–‡æœ¬<strong>å…³é”®è¯å’Œæ‘˜è¦çš„æå–</strong><ul>
<li>ä»å®Œæ•´è¯­å¥çš„Embeddingï¼Œåˆ‡æ¢ä¸º<strong>å…³é”®è¯Embedding</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/664921095">RAGæ¢ç´¢ä¹‹è·¯çš„è¡€æ³ªå²åŠæ›™å…‰</a>  è…¾è®¯<br> Embedding, Retrieval</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/641132245">LLM+Embeddingæ„å»ºé—®ç­”ç³»ç»Ÿçš„å±€é™æ€§åŠä¼˜åŒ–æ–¹æ¡ˆ</a><br>åŸºäºå…³é”®è¯Embeddingçš„å…¥åº“å’Œæœç´¢çš„æµç¨‹å›¾,  ç»“åˆä¼ ç»Ÿnlpä»»åŠ¡<br>1xx. <a href="https://zhuanlan.zhihu.com/p/627655485">åŸºäºå¤§è¯­è¨€æ¨¡å‹æ„å»ºçŸ¥è¯†é—®ç­”ç³»ç»Ÿ</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404338&idx=1&sn=3c8f8c44ac7a1d925216b40833525b25">å†çœ‹ä¸šç•Œå¤§æ¨¡å‹è¡Œä¸šé—®ç­”çš„å›°éš¾åŠè‹¥å¹²ä¸šç•Œå®è·µï¼šå…¼çœ‹æ™ºèƒ½å®¢æœå¸¸ç”¨è·¯çº¿åŠå¤šåœºæ™¯prompt </a><br>é—®é¢˜ ä¼˜åŒ–</p>
</li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648407281&idx=2&sn=f39b46cad1787123b485d76dff33bc93">å¤§æ¨¡å‹RAGé—®ç­”ç ”å‘çœŸå®å›¾é‰´ï¼šä¸€å‘¨å‡ºDemoï¼ŒåŠå¹´ç”¨ä¸å¥½ï¼Œç¼è¡¥ä¹‹è·¯æ¼«æ¼« </a></p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648407056&idx=1&sn=0a0ce93a9199a2eae36493a515e42181">æ¸©æ•…è€ŒçŸ¥æ–°:å¤§æ¨¡å‹RAGé—®ç­”ç ”å‘çš„7ä¸ªå¤±åˆ†ç‚¹åŠMOEä¸“å®¶ç»„åˆæ¨¡å‹çš„è‹¥å¹²æµ…æ </a><br>   ã€ŠSeven Failure Points When Engineering a Retrieval Augmented Generation Systemã€‹</p>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648403693&idx=1&sn=e47f34cd58f103d37998dbbfd01c41ee">å¤§æ¨¡å‹è¡Œä¸šè½åœ°å®è·µçš„ä¸€äº›æ€»ç»“å’Œè§‚ç‚¹ï¼šå¤§æ¨¡å‹è¡Œä¸šé—®ç­”è½åœ°ä¸­çš„ç°å®æŒ‘æˆ˜ä»¥åŠæ½œåœ¨çš„ç¼“è§£ç­–ç•¥</a><br>   ã€ŠDataFunCon2023æ·±åœ³ç«™-20231125-åˆ˜ç„•å‹‡-å¤§æ¨¡å‹è¡Œä¸šé—®ç­”çš„ç°å®æŒ‘æˆ˜åŠæ½œåœ¨çš„ç¼“è§£ç­–ç•¥ã€‹ pdf</p>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648404651&idx=2&sn=335db95e104a5b09e33ac2245bae4fd2">å†çœ‹RAGåœ¨çœŸå®é‡‘èæ–‡æ¡£é—®ç­”åœºæ™¯çš„å®è·µæ–¹æ¡ˆï¼šSMP2023 é‡‘èå¤§æ¨¡å‹æŒ‘æˆ˜èµ›çš„ä¸¤ç§ä»£è¡¨å®ç°æ€è·¯</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)RAG</title>
    <url>/www6vHomeAIGC/2022/12/31/gptRAGPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#naive-rag">Naive RAG</a><ul>
<li><a href="#langchain-chatchat-%E6%9E%B6%E6%9E%84">Langchain-Chatchat æ¶æ„</a></li>
<li><a href="#langchain-chatchat">Langchain-Chatchat</a></li>
</ul>
</li>
<li><a href="#vectorkg-rag1516">Vector+KG RAG[15][16]</a></li>
<li><a href="#data-processing17">Data processing[17]</a></li>
<li><a href="#%E5%8C%BB%E7%96%97%E9%97%AE%E7%AD%94rag20">åŒ»ç–—é—®ç­”RAG[20]</a><ul>
<li><a href="#%E6%9E%B6%E6%9E%84">æ¶æ„</a></li>
<li><a href="#chuck">chuck</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F">æ•°æ®æ ¼å¼</a></li>
<li><a href="#%E6%94%B9%E5%86%99query">æ”¹å†™query</a></li>
<li><a href="#%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B">å¬å›æ¨¡å‹</a></li>
<li><a href="#%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B">æ’åºæ¨¡å‹</a></li>
<li><a href="#%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F">ç´¢å¼•æ–¹å¼</a></li>
<li><a href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B">å¤§æ¨¡å‹</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#naive-rag-1">Naive RAG</a></li>
<li><a href="#%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1">çŸ¥è¯†å›¾è°±</a></li>
<li><a href="#xxx">xxx</a></li>
<li><a href="#%E5%8C%BB%E7%96%97%E9%97%AE%E7%AD%94">åŒ»ç–—é—®ç­”</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="naive-rag">Naive RAG</span><a href="#naive-rag" class="header-anchor">#</a></h1><h3><span id="langchain-chatchat-æ¶æ„">Langchain-Chatchat æ¶æ„</span><a href="#langchain-chatchat-æ¶æ„" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/12/31/gptRAGPractice/langchain+chatglm.jpg" class>

<ul>
<li>ç»„ä»¶<ul>
<li>æœ¬åœ°çŸ¥è¯†åº“</li>
<li>Embedding æ¨¡å‹</li>
<li>å‘é‡æ•°æ®åº“</li>
<li>Prompt Template</li>
</ul>
</li>
</ul>
<h3><span id="langchain-chatchat">Langchain-Chatchat</span><a href="#langchain-chatchat" class="header-anchor">#</a></h3><ul>
<li>éƒ¨ç½² <ul>
<li>windows 10 [5]<br>éƒ¨ç½²æœ¬åœ°ï¼Œ æ²¡æ˜¾å­˜ï¼Œå¡</li>
<li>Linux [2]<br>éƒ¨ç½²   32C125G ï¼Œæ²¡æ˜¾å­˜ï¼Œ æ¨ç†å¾ˆæ…¢ </li>
<li>Docker</li>
</ul>
</li>
</ul>
<h1><span id="vectorkg-rag1516">Vector+KG RAG[15][16]</span><a href="#vectorkg-rag1516" class="header-anchor">#</a></h1><h1><span id="data-processing17">Data processing[17]</span><a href="#data-processing17" class="header-anchor">#</a></h1><p>é•¿æ–‡æœ¬   å˜æˆ   QA pair</p>
<ul>
<li>è§„åˆ™åŒ¹é…</li>
<li>åˆ©ç”¨LLMæŠ½å–</li>
<li>äººå·¥å¤„ç†</li>
</ul>
<h1><span id="åŒ»ç–—é—®ç­”rag20">åŒ»ç–—é—®ç­”RAG[20]</span><a href="#åŒ»ç–—é—®ç­”rag20" class="header-anchor">#</a></h1><h3><span id="æ¶æ„">æ¶æ„</span><a href="#æ¶æ„" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/12/31/gptRAGPractice/arch.JPG" class>

<h3><span id="chuck">chuck</span><a href="#chuck" class="header-anchor">#</a></h3><p><strong>æ®µè½</strong><br>å¥å­<br>token</p>
<h3><span id="æ•°æ®æ ¼å¼">æ•°æ®æ ¼å¼</span><a href="#æ•°æ®æ ¼å¼" class="header-anchor">#</a></h3><p>{â€œidâ€: xxx, â€œç—…æƒ…æè¿°â€: â€œxxxâ€,  â€œæ²»ç–—æ–¹æ¡ˆâ€: â€œxxxâ€ }</p>
<h3><span id="æ”¹å†™query">æ”¹å†™query</span><a href="#æ”¹å†™query" class="header-anchor">#</a></h3><ul>
<li>HyDE</li>
<li>RAG Fusion -&gt; Generate Similar query<br>ç”¨æˆ·çš„æŸ¥è¯¢ä¸ç²¾å‡†ï¼Œè¦æ‰©å……query, ç”¨å¤§æ¨¡å‹æ”¹å†™</li>
</ul>
<h3><span id="å¬å›æ¨¡å‹">å¬å›æ¨¡å‹</span><a href="#å¬å›æ¨¡å‹" class="header-anchor">#</a></h3><ul>
<li><p>bertæ¨¡å‹</p>
<ul>
<li><strong>sbert</strong><ul>
<li><strong>2ä¸ªbertæ¨¡å‹</strong>ï¼Œå…±äº«å‚æ•°ï¼Œs1,s2å‘é‡åŒ–ååš<strong>ç›¸ä¼¼åº¦</strong>è®¡ç®—</li>
<li><strong>é€Ÿåº¦å¿«</strong></li>
<li>ç›¸ä¼¼åº¦<br>æ¬§å¼è·ç¦»</li>
</ul>
</li>
<li>åœ¨ç™¾ä¸‡è¯­æ–™ä¸Šè®­ç»ƒ<ul>
<li><strong>è¯­æ–™æ ¼å¼</strong><br>[s1][s2] 0 - æ— å…³<br>[s1][s2] 1-ç±»ä¼¼</li>
</ul>
</li>
</ul>
</li>
<li><p>æ ¹æ®query, å¬å›idå’Œvalueæ•´æ¡è®°å½•</p>
</li>
</ul>
<h3><span id="æ’åºæ¨¡å‹">æ’åºæ¨¡å‹</span><a href="#æ’åºæ¨¡å‹" class="header-anchor">#</a></h3><ul>
<li>bertæ¨¡å‹<ul>
<li>1ä¸ªberæ¨¡å‹</li>
<li><strong>é€Ÿåº¦æ…¢</strong></li>
<li><strong>æ ¼å¼</strong><ul>
<li>query[sep]s2  -&gt; ç»è¿‡softmaxï¼Œäº§ç”Ÿ2åˆ†ç±»ï¼Œ0-1</li>
</ul>
</li>
<li>ä¹Ÿè¦è®­ç»ƒ<ul>
<li>åŒ<strong>å¬å›æ¨¡å‹è®­ç»ƒæ–¹å¼</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="ç´¢å¼•æ–¹å¼">ç´¢å¼•æ–¹å¼</span><a href="#ç´¢å¼•æ–¹å¼" class="header-anchor">#</a></h3><ul>
<li>æ ‘ç´¢å¼•</li>
<li>çŸ¥è¯†å›¾è°±çš„ç´¢å¼•</li>
</ul>
<h3><span id="å¤§æ¨¡å‹">å¤§æ¨¡å‹</span><a href="#å¤§æ¨¡å‹" class="header-anchor">#</a></h3><ul>
<li>ç»¼åˆå½’çº³çš„ä½œç”¨</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id="naive-rag">Naive RAG</span><a href="#naive-rag" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://github.com/chatchat-space/Langchain-Chatchat">Langchain-Chatchat </a> master<br>Langchain ä¸ ChatGLM ç­‰è¯­è¨€æ¨¡å‹çš„æœ¬åœ°çŸ¥è¯†åº“é—®ç­”<br><a href="https://github.com/chatchat-space/Langchain-Chatchat/tree/v0.2.4">Langchain-Chatchat</a>  v0.2.4<br><a href="https://gitee.com/deepeye/langchain-ChatGLM">langchain-ChatGLM</a>  gitee </p>
</li>
<li><p><a href="https://github.com/www6v/Langchain-Chatchat-Colab">Colab for Langchain-Chatchat</a>   linux å¯ä»¥éƒ¨ç½²  v0.2.6</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/649055955">langChain-ChatGLM å°è¯•ï¼Œè¸©å‘è®°å½•</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/651189680">Langchain-Chatchat + é˜¿é‡Œé€šä¹‰åƒé—®Qwen ä¿å§†çº§æ•™ç¨‹ | æ¬¡ä¸–ä»£çŸ¥è¯†ç®¡ç†è§£å†³æ–¹æ¡ˆ</a>    Langchain-Chatchat + é€šä¹‰åƒé—®</p>
</li>
<li><p><a href="https://blog.csdn.net/weixin_43094965/article/details/133044128">win10 å®‰è£… Langchain-Chatchat é¿å‘æŒ‡å—ï¼ˆ2023å¹´9æœˆ18æ—¥v0.2.4ç‰ˆæœ¬ï¼ŒåŒ…å«å…¨éƒ¨ä¸‹è½½å†…å®¹ï¼ï¼‰</a></p>
</li>
</ol>
<h3><span id="çŸ¥è¯†å›¾è°±">çŸ¥è¯†å›¾è°±</span><a href="#çŸ¥è¯†å›¾è°±" class="header-anchor">#</a></h3><ol start="15">
<li><p><a href="https://neo4j.com/developer-blog/unstructured-knowledge-graph-neo4j-langchain/">Enhanced QA Integrating Unstructured Knowledge Graph Using Neo4j and LangChain</a>  </p>
</li>
<li><p><a href="https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/">Using a Knowledge Graph to implement a DevOps RAG application</a></p>
</li>
</ol>
<h3><span id="xxx">xxx</span><a href="#xxx" class="header-anchor">#</a></h3><ol start="17">
<li>&lt;&lt;å¤§æ¨¡å‹ç»“åˆ RAG æ„å»ºå®¢æœåœºæ™¯è‡ªåŠ¨é—®ç­”ç³»ç»Ÿ&gt;&gt;  NVIDIAå¤§æ¨¡å‹æ—¥ç³»åˆ—æ´»åŠ¨</li>
</ol>
<h3><span id="åŒ»ç–—é—®ç­”">åŒ»ç–—é—®ç­”</span><a href="#åŒ»ç–—é—®ç­”" class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://www.bilibili.com/video/BV1fW421P7u6?p=5">åŸºäºç™¾ä¸‡è¯­æ–™çš„åŒ»ç–—RAGé¡¹ç›®</a> v</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG Rerank</title>
    <url>/www6vHomeAIGC/2023/05/14/gptRAGRerank/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>





 
<h1><span id="reranker-22">Reranker [22]</span><a href="#reranker-22" class="header-anchor">#</a></h1><p>A reranking model â€” also known as a <strong>cross-encoder</strong> â€” is a type of model that,<strong>given a query and document pair, will output a similarity score.</strong> </p>
<p><img src="https://www.pinecone.io/_next/image/?url=https://cdn.sanity.io/images/vr8gru94/production/9f0d2f75571bb58eecf2520a23d300a5fc5b1e2c-2440x1100.png&w=3840&q=65" alt="Rerankers"></p>
<h1><span id="äº§å“">äº§å“</span><a href="#äº§å“" class="header-anchor">#</a></h1><h3><span id="bge-ranker-20">BGE Ranker [20]</span><a href="#bge-ranker-20" class="header-anchor">#</a></h3><p><strong>äº¤å‰ç¼–ç å™¨</strong>å°†å¯¹æŸ¥è¯¢å’Œç­”æ¡ˆå®æ—¶è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼Œè¿™æ¯”**å‘é‡æ¨¡å‹(å³åŒç¼–ç å™¨)**æ›´å‡†ç¡®ï¼Œä½†æ¯”å‘é‡æ¨¡å‹æ›´è€—æ—¶ã€‚ å› æ­¤ï¼Œå®ƒå¯ä»¥ç”¨æ¥å¯¹åµŒå…¥æ¨¡å‹è¿”å›çš„å‰kä¸ªæ–‡æ¡£é‡æ–°æ’åºã€‚ æˆ‘ä»¬åœ¨å¤šè¯­è¨€æ•°æ®ä¸Šè®­ç»ƒäº†äº¤å‰ç¼–ç å™¨ï¼Œæ•°æ®æ ¼å¼ä¸å‘é‡æ¨¡å‹ç›¸åŒï¼Œå› æ­¤æ‚¨å¯ä»¥æ ¹æ®æˆ‘ä»¬çš„ç¤ºä¾‹ è½»æ¾åœ°å¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚ </p>
<h3><span id="bce24">BCE[24]</span><a href="#bce24" class="header-anchor">#</a></h3><p>ä¸­æ–‡æ•ˆæœæ¯”BGEå¥½[è€åˆ˜è¯´nlp]</p>
<h3><span id="ä¼˜ç§€çš„ç»„åˆ-21">ä¼˜ç§€çš„ç»„åˆ [21]</span><a href="#ä¼˜ç§€çš„ç»„åˆ-21" class="header-anchor">#</a></h3><p>OpenAI + CohereRerank<br>Voyage + big-reranker-large</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="20">
<li><p><a href="https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md">BGE Reranker</a><br>  <a href="https://www.bilibili.com/video/BV1sQ4y137Ft/">transformersäºŒæ¬¡å¼€å‘â€”â€”bge-rerankeræ¨¡å‹å¾®è°ƒæµç¨‹</a> V<br><a href="https://mp.weixin.qq.com/s/XnkQFCdbvjox1Y06IbIlYw">RAG å†æ·»æ–°åˆ©å™¨ï¼æ™ºæºå¼€æºæœ€å¼ºæ£€ç´¢æ’åºæ¨¡å‹ BGE Re-Ranker v2.0 </a></p>
</li>
<li><p><a href="https://luxiangdong.com/2023/11/06/rerank-ev/#">æå‡RAGâ€”â€”é€‰æ‹©æœ€ä½³Embeddingå’Œé‡æ–°æ’åæ¨¡å‹ </a><br>  <a href="https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83">Boosting RAG: Picking the Best Embedding &amp; Reranker models</a></p>
</li>
<li><p><a href="https://www.pinecone.io/learn/series/rag/rerankers/">Rerankers and Two-Stage Retrieval</a>     ***          æ–‡ä¸­çš„ç¬¬äºŒé˜¶æ®µå°±æ˜¯æŒ‡Reranker</p>
</li>
<li><p><a href="https://github.com/netease-youdao/BCEmbedding">youdao RerankerModal</a> BCE</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>Query Routing</title>
    <url>/www6vHomeAIGC/2023/05/14/gptRAGRouting/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="ç±»å‹1">ç±»å‹[1]</span><a href="#ç±»å‹1" class="header-anchor">#</a></h1><ul>
<li>LLM Completion Routers</li>
<li>LLM Function Calling Routers</li>
<li>Semantic Routers[2]</li>
<li>Zero Shot Classification Routers</li>
<li>Language Classification Routers</li>
</ul>
<p><img src="https://miro.medium.com/v2/format:webp/1*fJnUoOwsykBTU1MyLgHQFg.png" alt="Routers"></p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://towardsdatascience.com/routing-in-rag-driven-applications-a685460a7220">Routing in RAG-Driven Applications</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1H64y1E75Y/">Sematic router è®©LLMæ›´åŠ å¿«é€Ÿåšå‡ºå†³ç­–</a> V<br><a href="https://github.com/aurelio-labs/semantic-router/">semantic-router Repo</a> git</p>
</li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†|å®æˆ˜)Self-Reflective RAG</title>
    <url>/www6vHomeAIGC/2023/03/02/gptRAGSelfReflective/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#cognitive-architecture-2">Cognitive Architecture [2]</a></li>
<li><a href="#corrective-rag">Corrective RAG</a></li>
<li><a href="#self-rag-3">Self-RAG [3]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#corrective-rag-1">Corrective RAG</a></li>
<li><a href="#self-rag">SELF-RAG</a></li>
<li><a href="#self-rag">Self-RAG</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="cognitive-architecture-2">Cognitive Architecture [2]</span><a href="#cognitive-architecture-2" class="header-anchor">#</a></h1><ul>
<li>Cognitive architectures for RAG [1]</li>
</ul>
<h1><span id="corrective-rag">Corrective RAG</span><a href="#corrective-rag" class="header-anchor">#</a></h1><h1><span id="self-rag-3">Self-RAG [3]</span><a href="#self-rag-3" class="header-anchor">#</a></h1><p>Self-RAG åˆ™æ˜¯æ›´åŠ ä¸»åŠ¨å’Œæ™ºèƒ½çš„å®ç°æ–¹å¼ï¼Œä¸»è¦æ­¥éª¤æ¦‚æ‹¬å¦‚ä¸‹ï¼š</p>
<ol>
<li>åˆ¤æ–­æ˜¯å¦éœ€è¦é¢å¤–æ£€ç´¢äº‹å®æ€§ä¿¡æ¯ï¼ˆretrieve on demandï¼‰ï¼Œä»…å½“æœ‰éœ€è¦æ—¶æ‰å¬å›</li>
<li>å¹³è¡Œå¤„ç†æ¯ä¸ªç‰‡æ®µï¼šç”Ÿäº§prompt+ä¸€ä¸ªç‰‡æ®µçš„ç”Ÿæˆç»“æœ</li>
<li>ä½¿ç”¨**åæ€å­—æ®µ(Reflection tokens)**ï¼Œæ£€æŸ¥è¾“å‡ºæ˜¯å¦ç›¸å…³ï¼Œé€‰æ‹©æœ€ç¬¦åˆéœ€è¦çš„ç‰‡æ®µï¼›</li>
<li>å†é‡å¤æ£€ç´¢</li>
<li>ç”Ÿæˆç»“æœä¼šå¼•ç”¨ç›¸å…³ç‰‡æ®µï¼Œä»¥åŠè¾“å‡ºç»“æœæ˜¯å¦ç¬¦åˆè¯¥ç‰‡æ®µï¼Œä¾¿äºæŸ¥è¯äº‹å®ã€‚</li>
</ol>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://blog.langchain.dev/agentic-rag-with-langgraph/">Self-Reflective RAG with LangGraph</a></p>
</li>
<li><p><a href="https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/">OpenAIâ€™s Bet on a Cognitive Architecture</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/661465330?utm_id=0">NLPï¼ˆå»¿ä¸€ï¼‰ï¼šä» RAG åˆ° Self-RAG â€”â€” LLM çš„çŸ¥è¯†å¢å¼º</a> ***</p>
</li>
</ol>
<p>1xx. <a href="https://blog.csdn.net/2301_78285120/article/details/136103211">å†™çš„å¤ªé€šé€äº†ï¼å¤§æ¨¡å‹è‡ªçœå¼ RAG ä¸ LangGraph çš„å®è·µï¼</a></p>
<h3><span id="corrective-rag">Corrective RAG</span><a href="#corrective-rag" class="header-anchor">#</a></h3><p>1xx. <a href="https://arxiv.org/pdf/2401.15884.pdf">Corrective Retrieval Augmented Generation</a> Figure 2<br>1xx. <a href="https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_crag.ipynb">Corrective RAG (CRAG)</a> git</p>
<p>1xx. ã€ç¤¾åŒºç¬¬åä¸‰è®²ã€‘ è€åˆ˜è¯´NLPçº¿ä¸Šäº¤æµ</p>
<h3><span id="self-rag">SELF-RAG</span><a href="#self-rag" class="header-anchor">#</a></h3><p>1xx. <a href="https://arxiv.org/pdf/2310.11511.pdf">SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND<br>CRITIQUE THROUGH SELF-REFLECTION</a> Figure 1<br>1xx. <a href="https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag.ipynb">Self-RAG</a> git</p>
<h3><span id="self-rag">Self-RAG</span><a href="#self-rag" class="header-anchor">#</a></h3><p>1xx. <a href="https://github.com/www6v/self-rag">original implementation of SELF-RAG</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>Retrievers</title>
    <url>/www6vHomeAIGC/2022/12/31/gptRetrievers/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#langchain-retrievers10">Langchain Retrievers[10]</a><ul>
<li><a href="#multiqueryretriever">MultiQueryRetriever</a></li>
<li><a href="#contextual-compression">Contextual compression</a></li>
<li><a href="#ensemble-retriever">Ensemble Retriever</a></li>
<li><a href="#multivector-retriever">MultiVector Retriever</a></li>
<li><a href="#parent-document-retriever">Parent Document Retriever</a></li>
<li><a href="#self-querying">Self-querying</a></li>
</ul>
</li>
<li><a href="#langchian-retriever10">Langchian Retriever[10]</a></li>
<li><a href="#langchain-vs-llamaindex-1">langchain vs. llamaindex [1]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="langchain-retrievers10">Langchain Retrievers[10]</span><a href="#langchain-retrievers10" class="header-anchor">#</a></h1><h3><span id="multiqueryretriever">MultiQueryRetriever</span><a href="#multiqueryretriever" class="header-anchor">#</a></h3><p>The MultiQueryRetriever automates the process of prompt tuning by using an LLM to <strong>generate multiple queries from different perspectives for a given user input query</strong>. </p>
<h3><span id="contextual-compression">Contextual compression</span><a href="#contextual-compression" class="header-anchor">#</a></h3><h3><span id="ensemble-retriever">Ensemble Retriever</span><a href="#ensemble-retriever" class="header-anchor">#</a></h3><p>The EnsembleRetriever takes a list of retrievers as input and ensemble the results of their get_relevant_documents() methods and <strong>rerank the results based on the Reciprocal Rank Fusion algorithm</strong>.<br>The most common pattern is to <strong>combine a sparse retriever (like BM25) with a dense retriever (like embedding similarity)</strong>, because their strengths are complementary. It is also known as â€œhybrid searchâ€.</p>
<h3><span id="multivector-retriever">MultiVector Retriever</span><a href="#multivector-retriever" class="header-anchor">#</a></h3><p>The methods to create multiple vectors per document include:<br>    - Smaller chunks: split a document into smaller chunks, and embed those (this is ParentDocumentRetriever).<br>    - Summary: create a summary for each document, embed that along with (or instead of) the document.<br>    - Hypothetical questions: create hypothetical questions that each document would be appropriate to answer, embed those along with (or instead of) the document.</p>
<h3><span id="parent-document-retriever">Parent Document Retriever</span><a href="#parent-document-retriever" class="header-anchor">#</a></h3><p>chunks of data</p>
<h3><span id="self-querying">Self-querying</span><a href="#self-querying" class="header-anchor">#</a></h3><p>This allows the retriever to not only use the user-input query for <strong>semantic similarity comparison</strong> with the contents of stored documents but to also extract filters from the user query on <strong>the metadata</strong> of stored documents and to execute those filters.</p>
<h1><span id="langchian-retriever10">Langchian Retriever[10]</span><a href="#langchian-retriever10" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>Name</th>
<th>Index Type</th>
<th>Uses an LLM</th>
<th>When to Use</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore">Vectorstore</a></td>
<td>Vectorstore</td>
<td>No</td>
<td>If you are just getting started and looking for something quick and easy.</td>
<td>This is the <strong>simplest method</strong> and the one that is easiest to get started with. It involves creating embeddings for each piece of text.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever">ParentDocument</a></td>
<td>Vectorstore + Document Store</td>
<td>No</td>
<td>If your pages have lots of smaller pieces of distinct information that are best indexed by themselves, but best retrieved all together.</td>
<td>This involves indexing <strong>multiple chunks</strong> for each document. Then you find the  chunks that are most similar in embedding space, but you retrieve the  <strong>whole parent</strong> document and <strong>return</strong> that (rather than individual chunks).</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector">Multi Vector</a></td>
<td>Vectorstore + Document Store</td>
<td>Sometimes during indexing</td>
<td>If you are able to extract information from documents that you think is more relevant to index than the text itself.</td>
<td>This involves creating multiple vectors for each document. Each vector could be created in a <strong>myriad of ways</strong> - examples include <strong>summaries of the text</strong> and <strong>hypothetical questions</strong>.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/self_query">Self Query</a></td>
<td>Vectorstore</td>
<td>Yes</td>
<td>If users are asking questions that are better answered by fetching  documents based on metadata rather than similarity with the text.</td>
<td>This uses an LLM to transform user input into two things: (1) a string to  look up semantically, (2) a <strong>metadata filer</strong> to go along with it. This is  useful because oftentimes questions are about the METADATA of documents  (not the content itself).</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression">Contextual Compression</a></td>
<td>Any</td>
<td>Sometimes</td>
<td>If you are finding that your retrieved documents contain too much irrelevant information and are distracting the LLM.</td>
<td>This puts a <strong>post-processing step</strong> on top of another retriever and extracts  only the most relevant information from retrieved documents. This can be done with embeddings or an LLM.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/time_weighted_vectorstore">Time-Weighted Vectorstore</a></td>
<td>Vectorstore</td>
<td>No</td>
<td>If you have timestamps associated with your documents, and you want to retrieve the most recent ones</td>
<td>This fetches documents based on a combination of semantic similarity (as in  normal vector retrieval) and recency (looking at timestamps of indexed  documents)</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever">Multi-Query Retriever</a></td>
<td>Any</td>
<td>Yes</td>
<td>If users are asking questions that are complex and require multiple pieces of distinct information to respond</td>
<td>This uses an LLM to <strong>generate multiple queries</strong> from the original one. This is useful when the original query needs pieces of information about  multiple topics to be properly answered. By generating multiple queries, we can then fetch documents for each of them.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble">Ensemble</a></td>
<td>Any</td>
<td>No</td>
<td>If you have multiple retrieval methods and want to try combining them.</td>
<td>This fetches documents from <strong>multiple retrievers</strong> and then <strong>combines</strong> them.</td>
</tr>
<tr>
<td><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/long_context_reorder">Long-Context Reorder</a></td>
<td>Any</td>
<td>No</td>
<td>If you are working with a long-context model and noticing that itâ€™s not  paying attention to information in the middle of retrieved documents.</td>
<td>This fetches documents from an underlying retriever, and then reorders them  so that the most similar are near the beginning and end. This is useful  because itâ€™s been shown that for longer context models they sometimes  donâ€™t pay attention to information in the middle of the context window.</td>
</tr>
</tbody></table>
<h1><span id="langchain-vs-llamaindex-1">langchain vs. llamaindex [1]</span><a href="#langchain-vs-llamaindex-1" class="header-anchor">#</a></h1><table>
<thead>
<tr>
<th>langchain</th>
<th>llamaindex</th>
</tr>
</thead>
<tbody><tr>
<td>Ensemble</td>
<td>Hybrid Fusion</td>
</tr>
<tr>
<td>Rewrite-Retrieve-Read</td>
<td>Query Rewriting</td>
</tr>
<tr>
<td></td>
<td>AutoMerging</td>
</tr>
<tr>
<td>ParentDocumentRetrieval</td>
<td>Small-to-Big Retrieval</td>
</tr>
<tr>
<td></td>
<td>Sentence Window Retrieval</td>
</tr>
</tbody></table>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV1qe411r78b/">ã€é«˜çº§RAG || åŸç†ä»‹ç»ã€‘Llamaindex 5ç§é«˜çº§RAGæ–¹æ³•</a> V </li>
<li><a href="https://python.langchain.com/docs/modules/data_connection/retrievers">retrievers</a></li>
</ol>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Retrievers</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)SELF-INSTRUCT, Self-QA</title>
    <url>/www6vHomeAIGC/2023/02/21/gptSelfInstruct/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#self-instruct">SELF-INSTRUCT</a><ul>
<li><a href="#%E8%87%AA%E5%8A%A8%E6%8C%87%E4%BB%A4%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%901">è‡ªåŠ¨æŒ‡ä»¤æ•°æ®ç”Ÿæˆ[1]</a></li>
</ul>
</li>
<li><a href="#self-qa3">Self-QA[3]</a><ul>
<li><a href="#%E6%80%9D%E6%83%B3">æ€æƒ³</a></li>
<li><a href="#%E6%8C%87%E4%BB%A4%E7%94%9F%E6%88%90%E9%98%B6%E6%AE%B5">æŒ‡ä»¤ç”Ÿæˆé˜¶æ®µ</a></li>
<li><a href="#%E6%8C%87%E4%BB%A4%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%E9%98%B6%E6%AE%B5">æŒ‡ä»¤ç­”æ¡ˆç”Ÿæˆé˜¶æ®µ</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="self-instruct">SELF-INSTRUCT</span><a href="#self-instruct" class="header-anchor">#</a></h1><h3><span id="è‡ªåŠ¨æŒ‡ä»¤æ•°æ®ç”Ÿæˆ1">è‡ªåŠ¨æŒ‡ä»¤æ•°æ®ç”Ÿæˆ[1]</span><a href="#è‡ªåŠ¨æŒ‡ä»¤æ•°æ®ç”Ÿæˆ1" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/02/21/gptSelfInstruct/selfInstruct.jpg" class>
<p>1ï¼‰æŒ‡ä»¤ç”Ÿæˆ<br>2ï¼‰è¯†åˆ«æŒ‡ä»¤æ˜¯å¦ä»£è¡¨åˆ†ç±»ä»»åŠ¡<br>3ï¼‰ç”¨è¾“å…¥ä¼˜å…ˆæˆ–è¾“å‡ºä¼˜å…ˆçš„æ–¹æ³•ç”Ÿæˆå®ä¾‹<br>4ï¼‰è¿‡æ»¤ä½è´¨é‡æ•°æ®</p>
<ul>
<li>å®ç°æ­¥éª¤[3]<ul>
<li>äººå·¥è®¾è®¡175ä¸ªè¡¨ç¤ºä¸åŒä»»åŠ¡çš„æŒ‡ä»¤ï¼Œå¹¶ä¸”ç»™æ¯æ¡æ•°æ®éƒ½ç¼–å†™äº†ï¼ˆæŒ‡ä»¤, è¾“å…¥, è¾“å‡ºï¼‰&#x2F;ï¼ˆæŒ‡ä»¤, è¾“å‡ºï¼‰ï¼Œå°†è¿™175æ¡æ•°æ®ä½œä¸ºç§å­æ± ã€‚</li>
<li>ä½¿ç”¨æ¨¡å‹ç”Ÿæˆæ–°çš„æŒ‡ä»¤ï¼›</li>
<li>å¯¹è¯¥æ¨¡å‹ç”Ÿæˆçš„æŒ‡ä»¤åˆ¤æ–­æ˜¯å¦åˆ†ç±»ä»»åŠ¡ï¼›</li>
<li>ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå®ä¾‹ï¼›</li>
<li>å¯¹ä¸Šè¿°æ¨¡å‹ç”Ÿæˆçš„æ•°æ®è¿›è¡Œè¿‡æ»¤å’Œåå¤„ç†ï¼›</li>
<li>å°†ç»è¿‡è¿‡æ»¤å’Œåå¤„ç†çš„æ•°æ®æ·»åŠ åˆ°ç§å­æ± ä¸­ï¼›</li>
<li>ä¸€ç›´é‡å¤ä¸Šè¿°2åˆ°6æ­¥ç›´åˆ°ç§å­æ± æœ‰è¶³å¤Ÿå¤šçš„æ•°æ®ï¼›</li>
</ul>
</li>
</ul>
<h1><span id="self-qa3">Self-QA[3]</span><a href="#self-qa3" class="header-anchor">#</a></h1><h3><span id="æ€æƒ³">æ€æƒ³</span><a href="#æ€æƒ³" class="header-anchor">#</a></h3><p>çŸ¥è¯†å¼•å¯¼çš„æŒ‡ä»¤ç”ŸæˆKnowledge-Guided Instruction Generation</p>
<h3><span id="æŒ‡ä»¤ç”Ÿæˆé˜¶æ®µ">æŒ‡ä»¤ç”Ÿæˆé˜¶æ®µ</span><a href="#æŒ‡ä»¤ç”Ÿæˆé˜¶æ®µ" class="header-anchor">#</a></h3><ul>
<li>é‡‡ç”¨è¯­è¨€æ¨¡å‹æœ¬èº«æ¥æ ¹æ®æ— ç›‘ç£çš„æ–‡æœ¬ç”ŸæˆæŒ‡ä»¤ã€‚è¿™ç§æ–¹æ³•ä½¿ç”Ÿæˆçš„æŒ‡ä»¤å…·æœ‰é¢†åŸŸé’ˆå¯¹æ€§ï¼Œå¹¶ä¸æ‰€æä¾›çš„æ— ç›‘ç£æ–‡æœ¬çš„å†…å®¹ç›¸å…³ã€‚<ul>
<li>éç»“æ„åŒ–çš„çŸ¥è¯†ï¼Œå¦‚ç½‘é¡µå’Œä¹¦ç±æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨ã€‚</li>
<li><strong>ç»“æ„åŒ–æ•°æ®</strong>ï¼Œå¦‚è¡¨æ ¼å’ŒçŸ¥è¯†å›¾è°±ï¼Œåœ¨è¢«åˆ©ç”¨ä¹‹å‰éœ€è¦<strong>è½¬æ¢ä¸ºéç»“æ„åŒ–æ–‡æœ¬æ•°æ®</strong>ã€‚å¦‚é€šè¿‡ä½¿ç”¨æ¨¡æ¿å¡«å……æ§½æˆ–å°†æ¯ä¸ªæ•°æ®æ¡ç›®ä¸ç›¸åº”çš„å±æ€§åç§°è¿æ¥èµ·æ¥æ¥å®ç°ã€‚</li>
</ul>
</li>
</ul>
<h3><span id="æŒ‡ä»¤ç­”æ¡ˆç”Ÿæˆé˜¶æ®µ">æŒ‡ä»¤ç­”æ¡ˆç”Ÿæˆé˜¶æ®µ</span><a href="#æŒ‡ä»¤ç­”æ¡ˆç”Ÿæˆé˜¶æ®µ" class="header-anchor">#</a></h3><ul>
<li>å°†<strong>ç”Ÿæˆçš„æŒ‡ä»¤é—®é¢˜</strong>è®©å¤§æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œ<strong>ç”Ÿæˆç­”æ¡ˆ</strong></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399792&idx=1&sn=c70e1d13b68399b0c19cfbf658f35d77">é¢å‘å¤§æ¨¡å‹å¾®è°ƒçš„instructionæŒ‡ä»¤è‡ªåŠ¨åŒ–ç”ŸæˆæŠ€æœ¯ï¼šSELF-INSTRUCTæŒ‡ä»¤è‡ªåŠ¨åŒ–ç”Ÿæˆæ¡†æ¶å·¥ä½œä»‹ç»</a></p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1nQ4y1A7Po">Stanford Alpaca</a> V<br><a href="https://github.com/www6v/stanford_alpaca/blob/main/generate_instruction.py">stanford_alpaca generate_instruction</a> git</p>
</li>
<li><p>ã€Šç¬¬äºŒç«  å¤§æ¨¡å‹è®­ç»ƒä¸å¾®è°ƒç ”å‘èƒŒåçš„æ•°æ®è‰ºæœ¯ã€‹ LLMå¤§è¯­è¨€æ¨¡å‹ç®—æ³•ç‰¹è®­  é‚£ä½ç§‘æŠ€ ***<br> <strong>SELF-INSTRUCT</strong>ï¼Œ Baizeï¼Œ <strong>Evol-instruct</strong>ï¼Œ <strong>Self-QA</strong>ï¼Œ Ultra-chat</p>
</li>
</ol>
<p>1xx. <a href="https://blog.csdn.net/qq_16949707/article/details/131266543">ACL2023 | å¤§æ¨¡å‹å¦‚ä½•å¿«é€Ÿæ„å»ºæŒ‡ä»¤éµå¾ªæ•°æ®é›†ï¼Ÿself-instructï¼šç”¨175æ¡ç§å­æ•°æ®è¿½ä¸ŠInstructGPT001æ•ˆæœ</a></p>
<p>1xx. <a href="https://github.com/yizhongw/self-instruct/">self-instruct</a> git</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/650596719">å¤§æ¨¡å‹SFTå¾®è°ƒæŒ‡ä»¤æ•°æ®çš„ç”Ÿæˆ</a><br>   SELF-INSTRUCTï¼Œ Wizardï¼Œ Backtranslation</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/618334308">è®©ChatGPTç”Ÿæˆè®­ç»ƒChatGPTçš„è®­ç»ƒæ•°æ®</a><br>   BELLE</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>STF</category>
      </categories>
      <tags>
        <tag>STF</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT  å­¦ä¹ èµ„æº</title>
    <url>/www6vHomeAIGC/2022/08/01/gptStudy/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%B7%A5%E7%A8%8B">å·¥ç¨‹</a></li>
<li><a href="#%E8%AF%BE%E7%A8%8B">è¯¾ç¨‹</a><ul>
<li><a href="#%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4">æå®¢æ—¶é—´</a></li>
<li><a href="#%E7%9F%A5%E4%B9%8E">çŸ¥ä¹</a></li>
<li><a href="#%E6%B8%85%E5%8D%8E">æ¸…å</a></li>
<li><a href="#%E7%99%BE%E5%BA%A6">ç™¾åº¦</a></li>
<li><a href="#%E4%B9%9D%E5%A4%A9">ä¹å¤©</a></li>
</ul>
</li>
<li><a href="#%E5%B7%A5%E4%B8%9A%E7%95%8C">å·¥ä¸šç•Œ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="å·¥ç¨‹">å·¥ç¨‹</span><a href="#å·¥ç¨‹" class="header-anchor">#</a></h1><ul>
<li><a href="https://github.com/www6v/openai-cookbook">openai-cookbook</a><br><a href="https://cookbook.openai.com/">cookbook.openai</a></li>
</ul>
<h1><span id="è¯¾ç¨‹">è¯¾ç¨‹</span><a href="#è¯¾ç¨‹" class="header-anchor">#</a></h1><h3><span id="æå®¢æ—¶é—´">æå®¢æ—¶é—´</span><a href="#æå®¢æ—¶é—´" class="header-anchor">#</a></h3><ul>
<li><a href="https://shimo.im/docs/47kgM6NewnSO613V">å°šç¡…è°·Ã—æå®¢æ—¶é—´ã€ŠAI å¤§æ¨¡å‹å®æˆ˜è®­ç»ƒè¥ã€‹å¤§çº²</a> </li>
<li><a href="https://shimo.im/docs/XKq42v7061SxZ2AN/read">AI å¤§æ¨¡å‹åº”ç”¨å¼€å‘å®æˆ˜è¥1æœŸå¤§çº²</a> </li>
<li><a href="https://w.1yb.co/KqBR58E">ã€ŠAI å¤§æ¨¡å‹å¾®è°ƒè®­ç»ƒè¥ã€‹å¤§çº²</a>  </li>
<li><a href="https://time.geekbang.org/opencourse/videointro/100540901">GitHub Copilot å®è·µè¯¾</a>  </li>
<li><a href="https://time.geekbang.org/opencourse/videointro/100541101">ChatGPT ä» 0 åˆ° 1</a>  åŸºç¡€</li>
<li><a href="https://time.geekbang.org/opencourse/videointro/100541201">ChatGPT å’Œé¢„è®­ç»ƒæ¨¡å‹å®æˆ˜è¯¾</a></li>
</ul>
<h3><span id="çŸ¥ä¹">çŸ¥ä¹</span><a href="#çŸ¥ä¹" class="header-anchor">#</a></h3><ul>
<li><a href="https://agiclass.feishu.cn/docx/DDzxdQZBooXw9Jx4DdWcLZjLnHd">ã€ŠAI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆã€‹è¯¾ç¨‹è¡¨ï¼ˆç¬¬ 02 æœŸï¼‰ </a>  </li>
<li><a href="https://www.zhihu.com/people/dou-hong-jian-44/posts">AI Boxä¸“æ </a>  ä¸­å›½äººå¤§  AI ***<br>å¤§æ¨¡å‹survey</li>
</ul>
<h3><span id="æ¸…å">æ¸…å</span><a href="#æ¸…å" class="header-anchor">#</a></h3><ul>
<li><a href="https://www.zhihu.com/education/video-course/1545850719483392000">ã€æ¸…å NLP X OpenBMBã€‘å¤§æ¨¡å‹å…¬å¼€è¯¾ï½œå¸¦ä½ ä»å…¥é—¨åˆ°å®æˆ˜</a>  V ***</li>
</ul>
<h3><span id="ç™¾åº¦">ç™¾åº¦</span><a href="#ç™¾åº¦" class="header-anchor">#</a></h3><p><a href="https://cloud.baidu.com/qianfandev/topic/267956">ã€Šå¤§æ¨¡å‹åº”ç”¨å®è·µã€‹å®è®­è¥</a></p>
<h3><span id="ä¹å¤©">ä¹å¤©</span><a href="#ä¹å¤©" class="header-anchor">#</a></h3><p><a href="https://appze9inzwc2314.pc.xiaoe-tech.com/p/t_pc/goods_pc_detail/goods_detail/p_64467371e4b0cf39e6c0c026?fromH5=true&entry_type=2002&share_type=5&type=3&entry=2">å¤§æ¨¡å‹æŠ€æœ¯å®æˆ˜è¯¾ </a></p>
<h1><span id="å·¥ä¸šç•Œ">å·¥ä¸šç•Œ</span><a href="#å·¥ä¸šç•Œ" class="header-anchor">#</a></h1><p><a href="https://rocketmq-learning.com/">rocketmq-learning ç¤¾åŒº</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>gpt</category>
        <category>study</category>
      </categories>
      <tags>
        <tag>gpt</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT è®ºæ–‡</title>
    <url>/www6vHomeAIGC/2023/01/20/gptStudyPaper/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#paper">Paper</a></li>
<li><a href="#gpt%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%911">GPTç ”ç©¶æ–¹å‘[1]</a></li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="paper">Paper</span><a href="#paper" class="header-anchor">#</a></h1><ul>
<li><p><a href="https://github.com/www6v/paper-reading">paper-reading</a> æç‰§å¤§ç¥</p>
<ul>
<li>Transformer  *** <ul>
<li>GPT-4</li>
<li>Instruct GPT *** </li>
<li>GPT, GPT-2, GPT-3 ç²¾è¯»  ***</li>
</ul>
</li>
<li>å¤šæ¨¡æ€<ul>
<li>CLIP</li>
<li>ViLT</li>
</ul>
</li>
<li>Chain of Thought  ***</li>
</ul>
</li>
<li><p><a href="https://shimo.im/docs/XKq42v7061SxZ2AN/read">AI å¤§æ¨¡å‹åº”ç”¨å¼€å‘å®æˆ˜è¥1æœŸå¤§çº²</a><br>åŸºç¡€ç¯‡ - è®ºæ–‡ *** </p>
</li>
<li><p><a href="https://blog.csdn.net/v_JULY_v/article/details/129508065">LLM&#x2F;ChatGPTä¸å¤šæ¨¡æ€å¿…è¯»è®ºæ–‡150ç¯‡(å·²æ›´è‡³ç¬¬101ç¯‡)</a> </p>
</li>
<li><p><a href="https://github.com/zjunlp/LLMAgentPapers">LLMAgentPapers</a> æµ™æ±Ÿå¤§å­¦</p>
</li>
<li><p><a href="https://github.com/zjunlp/Prompt4ReasoningPapers">Prompt4ReasoningPapers</a> æµ™æ±Ÿå¤§å­¦</p>
</li>
</ul>
<h1><span id="gptç ”ç©¶æ–¹å‘1">GPTç ”ç©¶æ–¹å‘[1]</span><a href="#gptç ”ç©¶æ–¹å‘1" class="header-anchor">#</a></h1><ul>
<li>Efficient (PEFT)</li>
<li>Existing stuff(pretrained model)  -åº”ç”¨<br>New directions</li>
<li>Plug-and-play<br> é€šç”¨æ¨¡å—ç»„ä»¶ï¼Œèƒ½ç”¨åœ¨å„ä¸ªé¢†åŸŸï¼Œ baseline</li>
<li>Dataset,  evaluation and survey</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><a href="https://www.bilibili.com/video/BV1oX4y1d7X6">å¤§æ¨¡å‹æ—¶ä»£ä¸‹åšç§‘ç ”çš„å››ä¸ªæ€è·¯ã€è®ºæ–‡ç²¾è¯»Â·52ã€‘</a></li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/673788545">AI Agent &amp; å¤§æ¨¡å‹ç»å…¸è®ºæ–‡æ¨è</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>gpt</category>
        <category>study</category>
      </categories>
      <tags>
        <tag>gpt</tag>
      </tags>
  </entry>
  <entry>
    <title>AIGC æ±‡æ€»</title>
    <url>/www6vHomeAIGC/2022/11/16/gptSummary/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="basic">Basic</span><a href="#basic" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeAIGC/2021/08/11/ai/" title="AI åº”ç”¨åœºæ™¯">AI åº”ç”¨åœºæ™¯</a> </li>
<li><a href="/www6vHomeAIGC/2022/01/22/aiOverview/" title="äººå·¥æ™ºèƒ½ çŸ¥è¯†ç‚¹">äººå·¥æ™ºèƒ½ çŸ¥è¯†ç‚¹</a></li>
<li><a href="/www6vHomeAIGC/2022/06/07/aiMachineLearning/" title="Machine Learning">Machine Learning</a></li>
</ul>
<h2><span id="deeplearning">DeepLearning</span><a href="#deeplearning" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeAIGC/2022/06/11/aiDeepLearning/" title="Deep Learning">Deep Learning</a></li>
<li><a href="/www6vHomeAIGC/2023/03/28/gptPytorch/" title="(å®æˆ˜)Pytorch">(å®æˆ˜)Pytorch</a></li>
</ul>
<h2><span id="nlp">NLP</span><a href="#nlp" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeAIGC/2023/02/05/gptNLPTask/" title="NLP ä»»åŠ¡">NLP ä»»åŠ¡</a>  </li>
<li><a href="/www6vHomeAIGC/2023/02/18/gptDocSimilarity/" title="çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦">çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦</a></li>
</ul>
<h2><span id="model">Model</span><a href="#model" class="header-anchor">#</a></h2><ul>
<li>åŸºç¡€<ul>
<li><a href="/www6vHomeAIGC/2022/10/30/gptLargeModelSurvey/" title="(ç»¼è¿°)å¤§æ¨¡å‹">(ç»¼è¿°)å¤§æ¨¡å‹</a></li>
<li><a href="/www6vHomeAIGC/2023/02/17/gptLargeModel/" title="å¤§æ¨¡å‹">å¤§æ¨¡å‹</a> </li>
<li><a href="/www6vHomeAIGC/2022/11/30/gptTransformer/" title="(åŸç†)Transformer">(åŸç†)Transformer</a> </li>
<li><a href="/www6vHomeAIGC/2023/02/16/gptTransformerCode/" title="(å®æˆ˜)Transformer">(å®æˆ˜)Transformer</a>  </li>
<li><a href="/www6vHomeAIGC/2023/04/18/gptEmbedding/" title="(åŸç†)Embedding">(åŸç†)Embedding</a>   </li>
<li><a href="/www6vHomeAIGC/2023/03/30/gptTemperature/" title="Temperature &amp; Top-p">Temperature &amp; Top-p</a></li>
</ul>
</li>
<li>åŸºåº§æ¨¡å‹<ul>
<li><a href="/www6vHomeAIGC/2022/12/11/gptFamily/" title="GPT ç³»åˆ—">GPT ç³»åˆ—</a>  </li>
<li><a href="/www6vHomeAIGC/2023/01/01/gptLlama/" title="LLaMA">LLaMA</a>   </li>
<li><a href="/www6vHomeAIGC/2023/02/24/gptLlamaFamily/" title="LLaMA å®¶æ—">LLaMA å®¶æ—</a>   </li>
<li><a href="/www6vHomeAIGC/2023/01/06/gptChatGLM/" title="ChatGLM">ChatGLM</a>   </li>
<li><a href="/www6vHomeAIGC/2023/01/04/gptLeaderBoard/" title="æ’è¡Œæ¦œ">æ’è¡Œæ¦œ</a></li>
</ul>
</li>
<li><a href="/www6vHomeAIGC/2023/01/25/gptImpossibleTriangle/" title="(åŸç†)ä¸å¯èƒ½ä¸‰è§’">(åŸç†)ä¸å¯èƒ½ä¸‰è§’</a> </li>
<li><a href="/www6vHomeAIGC/2023/02/03/gptEmergent/" title="(åŸç†)æ¶Œç°ç°è±¡">(åŸç†)æ¶Œç°ç°è±¡</a>   </li>
<li><a href="/www6vHomeAIGC/2023/02/06/gptHallucination/" title="(åŸç†)å¹»è§‰é—®é¢˜">(åŸç†)å¹»è§‰é—®é¢˜</a>    </li>
<li><a href="/www6vHomeAIGC/2023/02/07/gptEval/" title="æµ‹è¯„">æµ‹è¯„</a></li>
</ul>
<h2><span id="training-amp-inference">Training &amp; Inference</span><a href="#training-amp-inference" class="header-anchor">#</a></h2><ul>
<li>è®­ç»ƒ<ul>
<li><a href="/www6vHomeAIGC/2022/11/19/gptLargeModelTraining/" title="(åŸç†)Training">(åŸç†)Training</a></li>
<li><a href="/www6vHomeAIGC/2023/01/15/gptLargeModelTrainingPractice/" title="(å®æˆ˜)Training">(å®æˆ˜)Training</a> </li>
<li><a href="/www6vHomeAIGC/2023/02/03/gptContinualPretraining/" title="(åŸç†|å®æˆ˜)ç»§ç»­Pre-Training">(åŸç†|å®æˆ˜)ç»§ç»­Pre-Training</a>  </li>
<li><a href="/www6vHomeAIGC/2023/02/21/gptChineseLlama/" title="(å®æˆ˜)Chinese-LLaMA PT+SFT">(å®æˆ˜)Chinese-LLaMA PT+SFT</a>   </li>
<li><a href="/www6vHomeAIGC/2023/01/06/gptTrainParallelism/" title="(åŸç†)åˆ†å¸ƒå¼å¹¶è¡ŒTraining">(åŸç†)åˆ†å¸ƒå¼å¹¶è¡ŒTraining</a>    </li>
<li><a href="/www6vHomeAIGC/2023/03/23/gptTrainZeroDeepspeed/" title="(åŸç†)Zero Deepspeed">(åŸç†)Zero Deepspeed</a>    </li>
<li><a href="/www6vHomeAIGC/2023/03/25/gptTrainDeepspeedPractice/" title="(å®æˆ˜)Deepspeed">(å®æˆ˜)Deepspeed</a>     </li>
<li><a href="/www6vHomeAIGC/2024/02/01/gptPrecision/" title="(åŸç†|å®æˆ˜)æ··åˆç²¾åº¦">(åŸç†|å®æˆ˜)æ··åˆç²¾åº¦</a></li>
</ul>
</li>
<li>æ¨ç† <ul>
<li><a href="/www6vHomeAIGC/2023/03/21/gptInferFramework/" title="(åŸç†)æ¨ç†-æ¡†æ¶">(åŸç†)æ¨ç†-æ¡†æ¶</a> </li>
<li><a href="/www6vHomeAIGC/2023/02/02/gptInferFrameworkPractice/" title="(å®æˆ˜)æ¨ç†-æ¡†æ¶">(å®æˆ˜)æ¨ç†-æ¡†æ¶</a> </li>
<li><a href="/www6vHomeAIGC/2023/01/01/gptInference/" title="(ç»¼è¿°)æ¨ç†ä¼˜åŒ–">(ç»¼è¿°)æ¨ç†ä¼˜åŒ–</a></li>
</ul>
</li>
<li>æ¨¡å‹å‹ç¼©<ul>
<li><a href="/www6vHomeAIGC/2023/02/19/gptQuantization/" title="(åŸç†)æ¨¡å‹å‹ç¼©-é‡åŒ–æ¦‚è¿°">(åŸç†)æ¨¡å‹å‹ç¼©-é‡åŒ–æ¦‚è¿°</a> </li>
<li><a href="/www6vHomeAIGC/2023/03/26/gptQuantizationWeight/" title="(åŸç†)Weight Only(LLM.int8(), GPTQ, AWQ)">(åŸç†)Weight Only(LLM.int8(), GPTQ, AWQ)</a> </li>
<li><a href="/www6vHomeAIGC/2024/03/22/gptQuantizationPractice/" title="(å®æˆ˜)æ¨¡å‹å‹ç¼©-é‡åŒ–">(å®æˆ˜)æ¨¡å‹å‹ç¼©-é‡åŒ–</a></li>
</ul>
</li>
</ul>
<h2><span id="data">Data *</span><a href="#data" class="header-anchor">#</a></h2><ul>
<li>List<ul>
<li><a href="/www6vHomeAIGC/2023/01/08/gptDataSet/" title="(list)æ•°æ®é›†">(list)æ•°æ®é›†</a> </li>
<li><a href="/www6vHomeAIGC/2023/04/24/gptDataSetPretrainList/" title="(List) Pretrain æ•°æ®é›†">(List) Pretrain æ•°æ®é›†</a> </li>
<li><a href="/www6vHomeAIGC/2023/04/24/gptDatasetSFTList/" title="(List)SFTæ•°æ®é›†">(List)SFTæ•°æ®é›†</a>  </li>
<li><a href="/www6vHomeAIGC/2023/04/01/gptDatasetMulitmodal/" title="(list)å¤šæ¨¡æ€  æ•°æ®é›†">(list)å¤šæ¨¡æ€  æ•°æ®é›†</a></li>
</ul>
</li>
<li>DataProcess<ul>
<li><a href="/www6vHomeAIGC/2023/04/01/gptDatasetSurvey/" title="(Survey)Dataset">(Survey)Dataset</a> </li>
<li><a href="/www6vHomeAIGC/2023/02/05/gptDataProcess/" title="(Survey)æ•°æ®å¤„ç†">(Survey)æ•°æ®å¤„ç†</a>  </li>
<li><a href="/www6vHomeAIGC/2023/03/19/gptDataProcessPractice/" title="(å®æˆ˜)æ•°æ®å¤„ç†">(å®æˆ˜)æ•°æ®å¤„ç†</a>  </li>
<li><a href="/www6vHomeAIGC/2023/04/24/gptDataProcessAnnotation/" title="(åŸç†|å®æˆ˜)Data  Annotation">(åŸç†|å®æˆ˜)Data  Annotation</a></li>
</ul>
</li>
<li>Data Management<ul>
<li><a href="/www6vHomeAIGC/2023/04/27/gptDataManagement/" title="(Survey)Data Management">(Survey)Data Management</a>  </li>
<li>Pretrain  <ul>
<li><a href="/www6vHomeAIGC/2024/02/27/gptDataRefinedWeb/" title="(è´¨é‡è¿‡æ»¤)RefinedWeb, Textbooks">(è´¨é‡è¿‡æ»¤)RefinedWeb, Textbooks</a>  </li>
<li><a href="/www6vHomeAIGC/2023/02/26/gptTrainTokenizer/" title="Tokenizer">Tokenizer</a></li>
</ul>
</li>
<li>SFT <ul>
<li>Data Quality<ul>
<li>Instruction Quality<ul>
<li><a href="/www6vHomeAIGC/2023/04/27/gptDataSFTQuality/" title="(åŸç†)LIMA, LESS">(åŸç†)LIMA, LESS</a></li>
</ul>
</li>
<li>Instruction Diversity<ul>
<li><a href="/www6vHomeAIGC/2023/02/21/gptSelfInstruct/" title="(åŸç†)SELF-INSTRUCT, Self-QA">(åŸç†)SELF-INSTRUCT, Self-QA</a></li>
</ul>
</li>
<li>Instruction Complexity  <ul>
<li><a href="/www6vHomeAIGC/2023/03/18/gptDataWizard/" title="(åŸç†)Wizard">(åŸç†)Wizard</a></li>
</ul>
</li>
</ul>
</li>
<li>Task composition<ul>
<li><a href="/www6vHomeAIGC/2023/02/06/gptDatasetSFT/" title="(åŸç†)SFT æ•°æ®ç»„åˆ">(åŸç†)SFT æ•°æ®ç»„åˆ</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="/www6vHomeAIGC/2023/04/26/gptDataSFTScaling/" title="(åŸç†)SFT Scaling">(åŸç†)SFT Scaling</a>  </li>
<li><a href="/www6vHomeAIGC/2023/05/05/gptDataSelection/" title="(åŸç†)Data Selection">(åŸç†)Data Selection</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><span id="finetuning">FineTuning</span><a href="#finetuning" class="header-anchor">#</a></h2><ul>
<li>PEFT<ul>
<li><a href="/www6vHomeAIGC/2022/11/18/gptFineTuning/" title="(åŸç†)PEFT">(åŸç†)PEFT</a> </li>
<li><a href="/www6vHomeAIGC/2022/12/28/gptFineTuningWhen/" title="(åŸç†)Fine-Tuning æ—¶æœº">(åŸç†)Fine-Tuning æ—¶æœº</a>  </li>
<li><a href="/www6vHomeAIGC/2022/12/20/gptFineTuningPEFT/" title="(å®æˆ˜)PEFT æ¦‚è¿°">(å®æˆ˜)PEFT æ¦‚è¿°</a></li>
</ul>
</li>
<li>Soft Prompt<ul>
<li><a href="/www6vHomeAIGC/2023/01/06/gptPromptTuning/" title="(åŸç†)Prompt Tuning">(åŸç†)Prompt Tuning</a> </li>
<li><a href="/www6vHomeAIGC/2023/03/24/gptPEFTPtuning/" title="P-Tuning">P-Tuning</a>  </li>
<li><a href="/www6vHomeAIGC/2024/01/28/gptPEFTPtuningPractice/" title="(å®æˆ˜)PEFT P-Tuning">(å®æˆ˜)PEFT P-Tuning</a>  </li>
<li><a href="/www6vHomeAIGC/2023/01/25/gptPromptTuningPractice/" title="(å®æˆ˜)PromptTuning">(å®æˆ˜)PromptTuning</a></li>
</ul>
</li>
<li>Lora<ul>
<li><a href="/www6vHomeAIGC/2023/01/05/gptPEFTLora/" title="(å®æˆ˜)PEFT Lora">(å®æˆ˜)PEFT Lora</a> </li>
<li><a href="/www6vHomeAIGC/2024/01/12/gptPEFTQLora/" title="(å®æˆ˜)PEFT QLoRA">(å®æˆ˜)PEFT QLoRA</a></li>
</ul>
</li>
<li>Instruct Tuning *<ul>
<li><a href="/www6vHomeAIGC/2023/01/06/gptInstructTuning/" title="(åŸç†)Instruct Tuning">(åŸç†)Instruct Tuning</a>  </li>
<li><a href="/www6vHomeAIGC/2023/03/12/gptInstructTuningSurvey/" title="(Survey)Instruct Tuning">(Survey)Instruct Tuning</a></li>
</ul>
</li>
<li>BERT<ul>
<li><a href="/www6vHomeAIGC/2024/01/26/gptFineTuningBert/" title="Fine Tuning-Bert">Fine Tuning-Bert</a></li>
</ul>
</li>
</ul>
<h2><span id="multimodal">Multimodal *</span><a href="#multimodal" class="header-anchor">#</a></h2><ul>
<li>Survey<ul>
<li><a href="/www6vHomeAIGC/2023/01/18/gptMultimodal/" title="(ç»¼è¿°)å¤šæ¨¡æ€">(ç»¼è¿°)å¤šæ¨¡æ€</a> </li>
<li><a href="/www6vHomeAIGC/2023/03/16/gptMultimodalSurvey/" title="(Survey)å¤šæ¨¡æ€">(Survey)å¤šæ¨¡æ€</a></li>
</ul>
</li>
<li>Train  *<ul>
<li><a href="/www6vHomeAIGC/2023/03/04/gptMultimodalPretrain/" title="(åŸç†)å¤šæ¨¡æ€é¢„è®­ç»ƒ æ¦‚è¿°">(åŸç†)å¤šæ¨¡æ€é¢„è®­ç»ƒ æ¦‚è¿°</a>  </li>
<li><a href="/www6vHomeAIGC/2023/03/15/gptMultimodalInstructTuning/" title="(ç»¼è¿°)å¤šæ¨¡æ€InstructTuning">(ç»¼è¿°)å¤šæ¨¡æ€InstructTuning</a></li>
</ul>
</li>
<li>ç³»åˆ—<ul>
<li><a href="/www6vHomeAIGC/2024/04/04/gptMultimodalSeries/" title="å¤šæ¨¡æ€ ç³»åˆ—">å¤šæ¨¡æ€ ç³»åˆ—</a>   </li>
<li>backbone <ul>
<li><a href="/www6vHomeAIGC/2023/03/01/gptMultimodalCLIP/" title="(å¯¹æ¯”å­¦ä¹ )CLIP">(å¯¹æ¯”å­¦ä¹ )CLIP</a>  </li>
<li><a href="/www6vHomeAIGC/2023/03/01/gptMultimodalSAM/" title="SAM">SAM</a>   </li>
<li><a href="/www6vHomeAIGC/2023/03/01/gptMultimodalVit/" title="ViT,ViLT">ViT,ViLT</a>   </li>
<li><a href="/www6vHomeAIGC/2023/03/15/gptMultimodalBlip/" title="(å›¾ç”Ÿæ–‡)BLIP-2, Flamingo">(å›¾ç”Ÿæ–‡)BLIP-2, Flamingo</a></li>
</ul>
</li>
<li>chat<ul>
<li><a href="/www6vHomeAIGC/2023/03/14/gptMultimodalLlava/" title="(åŸç†|å®æˆ˜)å¤šæ¨¡æ€  LLaVa">(åŸç†|å®æˆ˜)å¤šæ¨¡æ€  LLaVa</a>  </li>
<li><a href="/www6vHomeAIGC/2023/03/15/gptMultimodalMinigpt4/" title="(åŸç†|å®æˆ˜)MiniGPT4">(åŸç†|å®æˆ˜)MiniGPT4</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><span id="rag">RAG *</span><a href="#rag" class="header-anchor">#</a></h2><ul>
<li>RAG<ul>
<li><a href="/www6vHomeAIGC/2022/11/02/gptRAG/" title="(ç»¼è¿°)RAG">(ç»¼è¿°)RAG</a></li>
<li><a href="/www6vHomeAIGC/2022/12/31/gptRAGPractice/" title="(å®æˆ˜)RAG">(å®æˆ˜)RAG</a></li>
<li><a href="/www6vHomeAIGC/2023/05/09/gptRAGFramework/" title="RAG Framework">RAG Framework</a> </li>
<li><a href="/www6vHomeAIGC/2023/05/09/gptRAGOptimize/" title="RAG ä¼˜åŒ–">RAG ä¼˜åŒ–</a></li>
</ul>
</li>
<li>æ¡ˆä¾‹ <ul>
<li><a href="/www6vHomeAIGC/2022/12/27/gptRAGOpenAI/" title="(åŸç†)RAG OpenAIæ¡ˆä¾‹">(åŸç†)RAG OpenAIæ¡ˆä¾‹</a> </li>
<li><a href="/www6vHomeAIGC/2023/04/18/gptRAGBaichuan/" title="(åŸç†)RAG Baichuanæ¡ˆä¾‹">(åŸç†)RAG Baichuanæ¡ˆä¾‹</a></li>
</ul>
</li>
<li>pattern *<ul>
<li><a href="/www6vHomeAIGC/2023/04/21/gptRAGModularRAG/" title="(åŸç†)Modular RAG">(åŸç†)Modular RAG</a> </li>
<li><a href="/www6vHomeAIGC/2022/12/07/gptRAGPerformance/" title="(åŸç†)Advanced RAG">(åŸç†)Advanced RAG</a></li>
<li><a href="/www6vHomeAIGC/2023/03/02/gptRAGSelfReflective/" title="(åŸç†|å®æˆ˜)Self-Reflective RAG">(åŸç†|å®æˆ˜)Self-Reflective RAG</a></li>
</ul>
</li>
<li>module <ul>
<li><a href="/www6vHomeAIGC/2023/04/20/gptQueryTransformation/" title="Query Transformation">Query Transformation</a>  </li>
<li><a href="/www6vHomeAIGC/2023/05/14/gptRAGRouting/" title="Query Routing">Query Routing</a>   </li>
<li><a href="/www6vHomeAIGC/2023/05/14/gptRAGRerank/" title="RAG Rerank">RAG Rerank</a></li>
</ul>
</li>
<li>Multimodal RAG  *<ul>
<li><a href="/www6vHomeAIGC/2023/03/14/gptRAGMultimodal/" title="(åŸç†)å¤šæ¨¡æ€ RAG">(åŸç†)å¤šæ¨¡æ€ RAG</a>  </li>
<li><a href="/www6vHomeAIGC/2023/03/14/gptRAGMultimodalPractice/" title="(å®æˆ˜)å¤šæ¨¡æ€ RAG">(å®æˆ˜)å¤šæ¨¡æ€ RAG</a>   </li>
<li><a href="/www6vHomeAIGC/2023/04/19/gptDocumentAI/" title="æ–‡æ¡£æ™ºèƒ½">æ–‡æ¡£æ™ºèƒ½</a></li>
</ul>
</li>
</ul>
<h2><span id="agent">Agent *</span><a href="#agent" class="header-anchor">#</a></h2><ul>
<li>Overview<ul>
<li><a href="/www6vHomeAIGC/2022/11/02/gptAgent/" title="(åŸç†)Agent">(åŸç†)Agent</a></li>
<li><a href="/www6vHomeAIGC/2023/04/06/gptAgentCategory/" title="Agent åˆ†ç±»[æœ‰è¶£|æœ‰ç”¨]">Agent åˆ†ç±»[æœ‰è¶£|æœ‰ç”¨]</a></li>
<li><a href="/www6vHomeAIGC/2023/03/05/gptAgentList/" title="(Survey)Agent List">(Survey)Agent List</a>  </li>
<li><a href="/www6vHomeAIGC/2023/01/01/gptAgentPractice/" title="(å®æˆ˜)Agent">(å®æˆ˜)Agent</a> </li>
<li><a href="/www6vHomeAIGC/2023/05/13/gptAgentChallenge/" title="(åŸç†)Agent Challenge">(åŸç†)Agent Challenge</a></li>
</ul>
</li>
<li>Reflection<ul>
<li><a href="/www6vHomeAIGC/2023/04/07/gptAgentReflection/" title="Reflection Agent">Reflection Agent</a></li>
</ul>
</li>
<li>Planning<ul>
<li><a href="/www6vHomeAIGC/2023/05/13/gptAgentPlanning/" title="Agent Planning">Agent Planning</a>     </li>
<li><a href="/www6vHomeAIGC/2023/03/02/gptAgentPlanAndExecute/" title="(åŸç†|å®æˆ˜)Plan-And-Execute Agent">(åŸç†|å®æˆ˜)Plan-And-Execute Agent</a></li>
</ul>
</li>
<li>Multi-agent collaboration<ul>
<li><a href="/www6vHomeAIGC/2023/01/21/gptMultiAgents/" title="(åŸç†)Multi-Agents">(åŸç†)Multi-Agents</a>  </li>
<li><a href="/www6vHomeAIGC/2023/05/07/gptMultiAgentsPractice/" title="(å®æˆ˜)LangGraph,AutoGen">(å®æˆ˜)LangGraph,AutoGen</a></li>
</ul>
</li>
<li>Tool use  *<ul>
<li><a href="/www6vHomeAIGC/2022/11/16/gptFunctionCall/" title="(åŸç†|å®æˆ˜) OpenAI Function Call">(åŸç†|å®æˆ˜) OpenAI Function Call</a> </li>
<li><a href="/www6vHomeAIGC/2023/01/27/gptAgentTool/" title="(åŸç†)Agent-Tools">(åŸç†)Agent-Tools</a>  </li>
<li><a href="/www6vHomeAIGC/2023/04/08/gptAgentToolGorilla/" title="(åŸç†)Gorilla">(åŸç†)Gorilla</a>   </li>
<li><a href="/www6vHomeAIGC/2023/04/07/gptAgentTuning/" title="Agent Tuning">Agent Tuning</a>   </li>
<li><a href="/www6vHomeAIGC/2023/02/03/gptAgentToolformer/" title="(åŸç†)Toolformer">(åŸç†)Toolformer</a></li>
</ul>
</li>
<li>Multimodal Agent  *<ul>
<li><a href="/www6vHomeAIGC/2023/02/21/gptAgentMultimodal/" title="Agent å¤šæ¨¡æ€">Agent å¤šæ¨¡æ€</a>  </li>
<li><a href="/www6vHomeAIGC/2023/03/05/gptAgentWeb/" title="(åŸç†)Web Agent">(åŸç†)Web Agent</a></li>
</ul>
</li>
</ul>
<h2><span id="application">Application</span><a href="#application" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeAIGC/2022/05/09/gpt/" title="GPT-å·¥å…·å’Œåº”ç”¨">GPT-å·¥å…·å’Œåº”ç”¨</a></li>
<li><a href="/www6vHomeAIGC/2022/12/28/gptLLMOps/" title="LLMOps">LLMOps</a> </li>
<li><a href="/www6vHomeAIGC/2022/11/27/gptVectorStore/" title="å‘é‡æ•°æ®åº“">å‘é‡æ•°æ®åº“</a></li>
<li><a href="/www6vHomeAIGC/2023/01/03/gptNL2SQL/" title="NL2SQL">NL2SQL</a> </li>
<li>å‚ç±»æ¨¡å‹<ul>
<li><a href="/www6vHomeAIGC/2023/01/04/gptDomain/" title="å‚ç±»å¤§æ¨¡å‹">å‚ç±»å¤§æ¨¡å‹</a> </li>
<li><a href="/www6vHomeAIGC/2022/11/24/gptDomainFinance/" title="é‡‘èå¤§æ¨¡å‹">é‡‘èå¤§æ¨¡å‹</a>   </li>
<li><a href="/www6vHomeAIGC/2023/02/07/gptDomainMed/" title="åŒ»ç–—å¤§æ¨¡å‹">åŒ»ç–—å¤§æ¨¡å‹</a>   </li>
<li><a href="/www6vHomeAIGC/2024/02/07/gptDomainLaw/" title="æ³•å¾‹å¤§æ¨¡å‹">æ³•å¾‹å¤§æ¨¡å‹</a></li>
</ul>
</li>
</ul>
<h2><span id="prompt">Prompt</span><a href="#prompt" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeAIGC/2022/11/10/gptPromptEngineering/" title="(åŸç†)Prompt Engineering">(åŸç†)Prompt Engineering</a></li>
<li><a href="/www6vHomeAIGC/2023/02/08/gptCOT/" title="COT">COT</a> </li>
<li><a href="/www6vHomeAIGC/2021/05/28/gptPromptCode/" title="Prompt-Code">Prompt-Code</a></li>
<li><a href="/www6vHomeAIGC/2021/05/26/gptPrompt/" title="Prompt-How to use">Prompt-How to use</a></li>
</ul>
<h2><span id="langchain">Langchain</span><a href="#langchain" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeAIGC/2022/11/02/gptLangchain/" title="Langchain">Langchain</a></li>
<li><a href="/www6vHomeAIGC/2022/12/31/gptRetrievers/" title="Retrievers">Retrievers</a> </li>
<li><a href="/www6vHomeAIGC/2023/01/11/gptLangchainAgent/" title="Langchain  Agent">Langchain  Agent</a></li>
</ul>
<h2><span id="study">Study</span><a href="#study" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeAIGC/2022/08/01/gptStudy/" title="GPT  å­¦ä¹ èµ„æº">GPT  å­¦ä¹ èµ„æº</a></li>
<li><a href="/www6vHomeAIGC/2022/01/22/aiStudyResouce/" title="äººå·¥æ™ºèƒ½-å­¦ä¹ èµ„æº">äººå·¥æ™ºèƒ½-å­¦ä¹ èµ„æº</a></li>
</ul>
<h2><span id="research">Research</span><a href="#research" class="header-anchor">#</a></h2><ul>
<li><a href="/www6vHomeAIGC/2024/02/11/gptPaperTools/" title="ç§‘ç ”-å·¥å…·">ç§‘ç ”-å·¥å…·</a> </li>
<li><a href="/www6vHomeAIGC/2023/01/20/gptStudyPaper/" title="GPT è®ºæ–‡">GPT è®ºæ–‡</a></li>
<li><a href="/www6vHomeAIGC/2023/02/25/gptSurveyList/" title="Survey List">Survey List</a> </li>
<li><a href="/www6vHomeAIGC/2023/03/04/gptAgentPaper/" title="Paper-Agent">Paper-Agent</a></li>
</ul>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>æ±‡æ€»</category>
      </categories>
      <tags>
        <tag>AIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>Survey List</title>
    <url>/www6vHomeAIGC/2023/02/25/gptSurveyList/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="awesome-llm-survey">Awesome-LLM-Survey</span><a href="#awesome-llm-survey" class="header-anchor">#</a></h1><ul>
<li><a href="#awesome-llm-survey">Awesome-LLM-Survey</a><ul>
<li><p><a href="#general-survey">General Survey</a> *** </p>
</li>
<li><p><a href="#training-of-llm">Training of LLM</a></p>
<ul>
<li><a href="#instruction-tuning">Instruction Tuning</a> *** </li>
<li><a href="#human-alignment-for-llm">Human Alignment for LLM</a> *</li>
</ul>
</li>
<li><p><a href="#prompt-of-llm">Prompt of LLM</a></p>
<ul>
<li><a href="#chain-of-thought-for-llm">Chain of Thought for LLM</a> *** </li>
<li><a href="#prompt-engineering-for-llm">Prompt Engineering for LLM</a> * </li>
<li><a href="#retrieval-augmented-llm">Retrieval-Augmented LLM</a> ***</li>
</ul>
</li>
<li><p><a href="#challenge-of-llm">Challenge of LLM</a></p>
<ul>
<li><p><a href="#hallucination-in-llm">Hallucination in LLM</a> ***</p>
</li>
<li><p><a href="#compression-for-llm">Compression for LLM</a> ***</p>
</li>
<li><p><a href="#evaluation-of-llm">Evaluation of LLM</a></p>
</li>
<li><p><a href="#reasoning-with-llm">Reasoning with LLM</a></p>
</li>
<li><p><a href="#long-context-for-llm">Long-Context for LLM</a></p>
</li>
<li><p><a href="#factuality-in-llm">Factuality in LLM</a></p>
</li>
<li><p><a href="#knowledge-for-llm">Knowledge for LLM</a></p>
</li>
<li><p><a href="#self-correction-for-llm">Self-Correction for LLM</a></p>
</li>
<li><p><a href="#tool-using-of-llm">Tool Using of LLM</a> ***</p>
</li>
<li><p><a href="#agent-of-llm">Agent of LLM</a> ***</p>
</li>
<li><p><a href="#efficiency-of-llm">Efficiency of LLM</a> *** </p>
</li>
<li><p><a href="#data-of-llm">Data of LLM</a> ***</p>
</li>
<li><p><a href="#continual-learning-of-llm">Continual Learning of LLM</a></p>
</li>
</ul>
</li>
<li><p><a href="#mulitmodal-of-llm">Mulitmodal of LLM</a></p>
<ul>
<li><a href="#visual-llm">Visual LLM</a></li>
</ul>
</li>
<li><p><a href="#llm-for-domain-application">LLM for Domain Application</a></p>
<ul>
<li><a href="#llm-for-health">LLM for Health</a></li>
<li><a href="#llm-for-finance">LLM for Finance</a> ***</li>
<li><a href="#llm-for-education">LLM for Education</a></li>
<li><a href="#llm-for-law">LLM for Law</a></li>
<li><a href="#llm-for-mental-health">LLM for Mental Health</a></li>
</ul>
</li>
<li><p><a href="#llm-for-downstream-tasks">LLM for Downstream Tasks</a></p>
<ul>
<li><p><a href="#llm-for-recommendation">LLM for Recommendation</a></p>
</li>
<li><p><a href="#llm-for-information-retrieval">LLM for Information Retrieval</a></p>
</li>
<li><p><a href="#llm-for-software-engineering">LLM for Software Engineering</a></p>
</li>
<li><p><a href="#llm-for-time-series">LLM for Time Series</a></p>
</li>
<li><p><a href="#detection-of-llms-generated-content">Detection of LLMs-Generated Content</a></p>
</li>
<li><p><a href="#llm-for-information-extraction">LLM for Information Extraction</a></p>
</li>
</ul>
</li>
<li><p><a href="#star-history">Star History</a></p>
</li>
</ul>
</li>
</ul>
<hr>
<h2><span id="general-survey">General Survey</span><a href="#general-survey" class="header-anchor">#</a></h2><ul>
<li><p>Challenges and Applications of Large Language Models, 2023.07 <a href="https://arxiv.org/abs/2307.10169">[paper]</a> *** </p>
</li>
<li><p>A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT, 2023.02 <a href="https://arxiv.org/abs/2302.09419">[paper]</a> ***</p>
</li>
<li><p>A Survey of Large Language Models, 2023.11 <a href="https://arxiv.org/abs/2303.18223">[paper]</a><a href="https://github.com/RUCAIBox/LLMSurvey">[project]</a>  ***</p>
</li>
<li><p>A Comprehensive Overview of Large Language Models *</p>
</li>
<li><p>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</p>
</li>
<li><p>Pre-Trained Models: Past, Present and Future</p>
</li>
<li><p>A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4, 2023.10 <a href="https://arxiv.org/pdf/2310.12321.pdf">[paper]</a></p>
</li>
<li><p>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond, 2023.04  <a href="https://arxiv.org/abs/2304.13712">[paper]</a><a href="https://github.com/Mooler0410/LLMsPracticalGuide">[project]</a></p>
</li>
<li><p>Large language models: a comprehensive survey of its applications, challenges, limitations, and future prospects, 2023.12 <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.23589741.v4">[paper]</a> <a href="https://github.com/anas-zafar/LLM-Survey">[project]</a></p>
</li>
<li><p>The future of gpt: A taxonomy of existing chatgpt research, current challenges, and possible future directions, 2023.04 <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4413921">[paper]</a></p>
</li>
<li><p>A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges, 2023.10 <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.24171183.v1">[paper]</a></p>
</li>
<li><p>Understanding LLMs: A Comprehensive Overview from Training to Inference, 2024.01 <a href="https://arxiv.org/pdf/2401.02038.pdf">[paper]</a></p>
</li>
</ul>
<hr>
<h2><span id="training-of-llm">Training of LLM</span><a href="#training-of-llm" class="header-anchor">#</a></h2><h3><span id="instruction-tuning">Instruction Tuning</span><a href="#instruction-tuning" class="header-anchor">#</a></h3><ul>
<li>Are Prompts All the Story? No. A Comprehensive and Broader View of Instruction Learning, 2023.03 <a href="https://arxiv.org/pdf/2303.10475.pdf">[paper]</a> <a href="https://github.com/RenzeLou/awesome-instruction-learning">[project]</a></li>
<li>Vision-Language Instruction Tuning: A Review and Analysis, 2023,11 <a href="https://arxiv.org/abs/2311.08172">[paper]</a><a href="https://github.com/palchenli/VL-Instruction-Tuning">[project]</a></li>
<li>Instruction Tuning for Large Language Models: A Survey, 2023.08 <a href="https://arxiv.org/abs/2308.10792">[paper]</a>  ***</li>
</ul>
<h3><span id="human-alignment-for-llm">Human Alignment for LLM</span><a href="#human-alignment-for-llm" class="header-anchor">#</a></h3><ul>
<li><p>AI Alignment: A Comprehensive Survey, 2023.10 <a href="https://arxiv.org/pdf/2310.19852">[paper]</a><a href="https://www.alignmentsurvey.com/">[project]</a></p>
</li>
<li><p>Large Language Model Alignment: A Survey, 2023.09 <a href="https://arxiv.org/abs/2309.15025">[paper]</a></p>
</li>
<li><p>From Instructions to Intrinsic Human Values â€“ A Survey of Alignment Goals for Big Model, 2023.08 <a href="https://arxiv.org/abs/2308.12014">[paper]</a><a href="https://github.com/ValueCompass/Alignment-Goal-Survey">[project]</a></p>
</li>
<li><p>Aligning Large Language Models with Human: A Survey, 2023.07 <a href="https://arxiv.org/abs/2307.12966">[paper]</a><a href="https://github.com/GaryYufei/AlignLLMHumanSurvey">[project]</a> ***</p>
</li>
</ul>
<hr>
<h2><span id="prompt-of-llm">Prompt of LLM</span><a href="#prompt-of-llm" class="header-anchor">#</a></h2><h3><span id="chain-of-thought-for-llm">Chain of Thought for LLM</span><a href="#chain-of-thought-for-llm" class="header-anchor">#</a></h3><ul>
<li><p>Towards Better Chain-of-Thought Prompting Strategies: A Survey, 2023.10 <a href="https://arxiv.org/pdf/2310.04959.pdf">[paper]</a></p>
</li>
<li><p>A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future, 2023.09 <a href="https://arxiv.org/abs/2309.06256">[paper]</a><a href="https://github.com/zchuz/CoT-Reasoning-Survey">[project]</a></p>
</li>
<li><p>Igniting Language Intelligence: The Hitchhikerâ€™s Guide From Chain-of-Thought Reasoning to Language Agents, 2023.11 <a href="https://arxiv.org/pdf/2311.11797.pdf">[paper]</a> <a href="https://github.com/Zoeyyao27/CoT-Igniting-Agent">[project]</a></p>
</li>
</ul>
<h3><span id="prompt-engineering-for-llm">Prompt Engineering for LLM</span><a href="#prompt-engineering-for-llm" class="header-anchor">#</a></h3><ul>
<li><p>Prompting Frameworks for Large Language Models: A Survey, 2023.11 <a href="https://arxiv.org/pdf/2311.12785.pdf">[paper]</a><a href="https://github.com/lxx0628/Prompting-Framework-Survey">[project]</a></p>
</li>
<li><p>Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review, 2023.10 <a href="https://arxiv.org/pdf/2310.14735.pdf">[paper]</a></p>
</li>
<li><p>Towards Better Chain-of-Thought Prompting Strategies: A Survey, 2023.10 <a href="https://arxiv.org/pdf/2310.04959.pdf">[paper]</a></p>
</li>
</ul>
<h3><span id="retrieval-augmented-llm">Retrieval-Augmented LLM</span><a href="#retrieval-augmented-llm" class="header-anchor">#</a></h3><ul>
<li><p>Retrieving Multimodal Information for Augmented Generation: A Survey  *** </p>
</li>
<li><p>Retrieval-Augmented Generation for AI-Generated Content: A Survey *** </p>
</li>
<li><p>A Survey on Retrieval-Augmented Text Generation, 2022.02 <a href="https://arxiv.org/abs/2202.01110">[paper]</a></p>
</li>
<li><p>Retrieval-Augmented Generation for Large Language Models: A Survey, 2023.12 <a href="https://arxiv.org/pdf/2312.10997.pdf">[paper]</a> <a href="https://github.com/Tongji-KGLLM/RAG-Survey">[project]</a> ***</p>
</li>
</ul>
<hr>
<h2><span id="challenge-of-llm">Challenge of LLM</span><a href="#challenge-of-llm" class="header-anchor">#</a></h2><h3><span id="hallucination-in-llm">Hallucination in LLM</span><a href="#hallucination-in-llm" class="header-anchor">#</a></h3><ul>
<li><p>Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey, 2023.11 <a href="https://arxiv.org/pdf/2311.07914">[paper]</a></p>
</li>
<li><p>A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions, 2023.11 <a href="https://arxiv.org/pdf/2311.05232">[paper]</a><a href="https://github.com/LuckyyySTA/Awesome-LLM-hallucination">[project]</a> ***</p>
</li>
<li><p>A Survey of Hallucination in â€œLargeâ€ Foundation Models, 2023.09  <a href="https://arxiv.org/paper/2309.05922">[paper]</a><a href="https://github.com/vr25/hallucination-foundation-model-survey">[project]</a></p>
</li>
<li><p>Sirenâ€™s Song in the AI Ocean: A Survey on Hallucination in Large Language Models, 2023.09 <a href="https://arxiv.org/abs/2309.01219">[paper]</a><a href="https://arxiv.org/abs/2309.01219">[project]</a></p>
</li>
<li><p>Cognitive Mirage: A Review of Hallucinations in Large Language Models, 2023.09 <a href="https://arxiv.org/paper/2309.06794.paper">[paper]</a><a href="https://github.com/hongbinye/Cognitive-Mirage-Hallucinations-in-LLMs">[project]</a></p>
</li>
<li><p>Augmenting LLMs with Knowledge: A survey on hallucination prevention, 2023.09 <a href="https://arxiv.org/pdf/2309.16459.pdf">[paper]</a></p>
</li>
<li><p>A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models, 2024.01 <a href="https://arxiv.org/pdf/2401.01313.pdf">[paper]</a></p>
</li>
<li><p>Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Modelsâ€™ Alignment, 2023.08 <a href="https://arxiv.org/abs/2308.05374">[paper]</a></p>
</li>
</ul>
<h3><span id="compression-for-llm">Compression for LLM</span><a href="#compression-for-llm" class="header-anchor">#</a></h3><ul>
<li>A Survey on Model Compression for Large Language Models, 2023.08 <a href="https://arxiv.org/abs/2308.07633">[paper]</a>  ***</li>
<li>A Comprehensive Survey of Compression Algorithms for Language Models, 2024.01 [<a href="https://arxiv.org/pdf/2401.15347.pdf">paper</a>]</li>
</ul>
<h3><span id="evaluation-of-llm">Evaluation of LLM</span><a href="#evaluation-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Evaluating Large Language Models: A Comprehensive Survey, 2023.10 <a href="https://arxiv.org/pdf/2310.19736.pdf">[paper]</a><a href="https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers">[project]</a> ***</p>
</li>
<li><p>A Survey on Evaluation of Large Language Models, 2023.07 <a href="https://arxiv.org/abs/2307.03109">[paper]</a><a href="https://llm-eval.github.io/">[project]</a> ***</p>
</li>
</ul>
<h3><span id="reasoning-with-llm">Reasoning with LLM</span><a href="#reasoning-with-llm" class="header-anchor">#</a></h3><ul>
<li><p>Reasoning with Language Model Prompting: A Survey, 2022.12 <a href="https://arxiv.org/abs/2212.09597">[paper]</a><a href="https://github.com/zjunlp/Prompt4ReasoningPapers">[project]</a></p>
</li>
<li><p>A Survey of Reasoning with Foundation Models, 2023.12 [[papaer]] (<a href="https://arxiv.org/pdf/2312.11562.pdf)[[project]](https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models)">https://arxiv.org/pdf/2312.11562.pdf)[[project]](https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models)</a> ***</p>
</li>
</ul>
<h3><span id="long-context-for-llm">Long-Context for LLM</span><a href="#long-context-for-llm" class="header-anchor">#</a></h3><ul>
<li>Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey, 2023.11 <a href="https://arxiv.org/pdf/2311.12351">[paper]</a></li>
<li>Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding, 2023.12 <a href="https://arxiv.org/abs/2312.17044">[paper]</a></li>
</ul>
<h3><span id="factuality-in-llm">Factuality in LLM</span><a href="#factuality-in-llm" class="header-anchor">#</a></h3><ul>
<li><p>A Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity, 2023.10 <a href="https://arxiv.org/abs/2310.07521">[paper]</a><a href="https://github.com/wangcunxiang/LLM-Factuality-Survey">[project]</a></p>
</li>
<li><p>Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models, 2023.10 <a href="https://arxiv.org/pdf/2310.16570.pdf">[paper]</a></p>
</li>
</ul>
<h3><span id="knowledge-for-llm">Knowledge for LLM</span><a href="#knowledge-for-llm" class="header-anchor">#</a></h3><ul>
<li><p>Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges, 2023.11 <a href="https://arxiv.org/pdf/2311.15766">[paper]</a></p>
</li>
<li><p>Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications, 2023.11 <a href="https://arxiv.org/pdf/2311.05876.pdf">[paper]</a></p>
</li>
<li><p>Knowledge Editing for Large Language Models: A Survey, 2023.10 <a href="https://arxiv.org/pdf/2310.16218.pdf">[paper]</a></p>
</li>
<li><p>Editing Large Language Models: Problems, Methods, and Opportunities, 2023.05 <a href="https://arxiv.org/abs/2305.13172">[paper]</a><a href="https://github.com/zjunlp/EasyEdit">[project]</a></p>
</li>
<li><p>Building trust in conversational ai: A comprehensive review and solution architecture for explainable, privacy-aware systems using llms and knowledge graph, 2023.08 <a href="https://arxiv.org/pdf/2308.13534.pdf">[paper]</a></p>
</li>
</ul>
<h3><span id="self-correction-for-llm">Self-Correction for LLM</span><a href="#self-correction-for-llm" class="header-anchor">#</a></h3><ul>
<li>Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies, 2023.08 <a href="https://arxiv.org/abs/2308.03188">[paper]</a><a href="https://github.com/teacherpeterpan/self-correction-llm-papers">[project]</a></li>
</ul>
<h3><span id="tool-using-of-llm">Tool Using of LLM</span><a href="#tool-using-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Foundation Models for Decision Making: Problems, Methods, and Opportunities, 2023.03 <a href="https://arxiv.org/abs/2303.04129">[paper]</a></p>
</li>
<li><p>Augmented Language Models: a Survey, 2023.02 <a href="https://arxiv.org/abs/2302.07842">[paper]</a> ***</p>
</li>
<li><p>Tool Learning with Foundation Models</p>
</li>
</ul>
<h3><span id="agent-of-llm">Agent of LLM</span><a href="#agent-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Understanding the planning of LLM agents: A survey, 2024 </p>
</li>
<li><p>A Survey on Large Language Model based Autonomous Agents, 2023.08 <a href="https://arxiv.org/abs/2308.11432">[paper]</a><a href="https://github.com/Paitesanshi/LLM-Agent-Survey">[project]</a> ***</p>
</li>
<li><p>The Rise and Potential of Large Language Model Based Agents: A Survey, 2023.09 <a href="https://arxiv.org/abs/2309.07864">[paper]</a><a href="https://github.com/WooooDyy/LLM-Agent-Paper-List">[project]</a> ***</p>
</li>
<li><p>Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives, 2023.12 <a href="https://arxiv.org/pdf/2312.11970.pdf">[paper]</a></p>
</li>
</ul>
<h3><span id="efficiency-of-llm">Efficiency of LLM</span><a href="#efficiency-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning ***</p>
</li>
<li><p>The Power of Scale for Parameter-Efficient Prompt Tuning</p>
</li>
<li><p>Efficient Large Language Models: A Survey, 2023.12 <a href="https://arxiv.org/pdf/2312.03863">[paper]</a><a href="https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey">[project]</a> ***</p>
</li>
<li><p>The Efficiency Spectrum of Large Language Models: An Algorithmic Survey, 2023.12 <a href="https://arxiv.org/pdf/2310.10844.pdf">[paper]</a><a href="https://github.com/tding1/Efficient-LLM-Survey">[project]</a></p>
</li>
<li><p>Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment, 2023.12 <a href="https://arxiv.org/pdf/2312.12148.pdf">[paper]</a></p>
</li>
<li><p>A Survey on Hardware Accelerators for Large Language Models, 2024.01 [<a href="https://arxiv.org/pdf/2401.09890.pdf">paper</a>]</p>
</li>
</ul>
<h3><span id="data-of-llm">Data of LLM</span><a href="#data-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Data Management For Large Language Models: A Survey, 2023.12 <a href="https://arxiv.org/pdf/2312.01700">[paper]</a><a href="https://github.com/ZigeW/data_management_LLM">[project]</a></p>
</li>
<li><p>Data-centric Artificial Intelligence: A Survey</p>
</li>
</ul>
<h3><span id="continual-learning-of-llm">Continual Learning of LLM</span><a href="#continual-learning-of-llm" class="header-anchor">#</a></h3><ul>
<li>Continual Learning with Pre-Trained Models: A Survey, 2024.01 <a href="https://arxiv.org/pdf/2401.16386">[paper]</a> <a href="https://github.com/sun-hailong/LAMDA-PILOT">[project]</a></li>
</ul>
<hr>
<h2><span id="mulitmodal-of-llm">Mulitmodal of LLM</span><a href="#mulitmodal-of-llm" class="header-anchor">#</a></h2><h3><span id="visual-llm">Visual LLM</span><a href="#visual-llm" class="header-anchor">#</a></h3><ul>
<li><p>An Empirical Study of Training End-to-End Vision-and-Language Transformers, 2022.03 *** microsoft +</p>
</li>
<li><p>Multimodal Foundation Models: From Specialists to General-Purpose Assistants, 2023.09 *** microsoft +</p>
</li>
<li><p>Foundational Models Defining a New Era in Vision: A Survey and Outlook, 2023.07 ***  å¤§å­¦ +</p>
</li>
<li><p>MM-LLMs: Recent Advances in MultiModal Large Language Models, 2024.02 *** è…¾è®¯  +</p>
</li>
<li><p>Vision-Language Instruction Tuning: A Review and Analysis, 2023,11 <a href="https://arxiv.org/abs/2311.08172">[paper]</a><a href="https://github.com/palchenli/VL-Instruction-Tuning">[project]</a> *** + </p>
</li>
<li><p>How to Bridge the Gap between Modalities: A Comprehensive Survey on Multimodal Large Language Model, 2023.11 <a href="https://arxiv.org/pdf/2311.07594.pdf">[paper]</a> *</p>
</li>
<li><p>A Survey on Multimodal Large Language Models, 2023.06  <a href="https://arxiv.org/abs/2306.13549">[paper]</a> <a href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models">[project]</a> ***</p>
</li>
<li><p>Multimodal Large Language Models: A Survey, 2023.11 <a href="https://arxiv.org/pdf/2311.13165.pdf">[paper]</a> **</p>
</li>
<li><p>Large Language Models Meet Computer Vision: A Brief Survey, 2023.11 <a href="https://arxiv.org/pdf/2311.16673.pdf">[paper]</a> *</p>
</li>
<li><p>Foundational Models Defining a New Era in Vision: A Survey and Outlook, 2023.07 <a href="https://arxiv.org/pdf/2307.13721.pdf">[paper]</a><a href="https://github.com/awaisrauf/Awesome-CV-Foundational-Models">[project]</a> ***  + </p>
</li>
<li><p>Video Understanding with Large Language Models: A Survey, 2023.12 <a href="https://arxiv.org/pdf/2312.17432.pdf">[paper]</a> <a href="https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding">[project]</a></p>
</li>
</ul>
<hr>
<h2><span id="llm-for-domain-application">LLM for Domain Application</span><a href="#llm-for-domain-application" class="header-anchor">#</a></h2><h3><span id="domain">domain</span><a href="#domain" class="header-anchor">#</a></h3><ul>
<li>Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey</li>
</ul>
<h3><span id="llm-for-health">LLM for Health</span><a href="#llm-for-health" class="header-anchor">#</a></h3><ul>
<li><p>A Survey of Large Language Models in Medicine: Progress, Application, and Challenge, 2023.11 <a href="https://arxiv.org/pdf/2311.05112">[paper]</a><a href="https://github.com/AI-in-Health/MedLLMsPracticalGuide">[project]</a></p>
</li>
<li><p>Large Language Models Illuminate a Progressive Pathway to Artificial  Healthcare Assistant: A Review, 2023.10 <a href="https://arxiv.org/pdf/2311.01918">[paper]</a><a href="https://github.com/mingze-yuan/Awesome-LLM-Healthcare">[project]</a></p>
</li>
<li><p>Large AI Models in Health Informatics: Applications, Challenges, and the Future, 2023.03 <a href="https://arxiv.org/abs/2303.11568">[paper]</a><a href="https://github.com/Jianing-Qiu/Awesome-Healthcare-Foundation-Models">[project]</a></p>
</li>
<li><p>A SWOT (Strengths, Weaknesses, Opportunities, and Threats) Analysis of ChatGPT in the Medical Literature: Concise Review, 2023.11 <a href="https://www.jmir.org/2023/1/e49368/PDF">[paper]</a></p>
</li>
<li><p>ChatGPT in Healthcare: A Taxonomy and Systematic Review, 2023.03 <a href="https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1">[paper]</a></p>
</li>
</ul>
<h3><span id="llm-for-finance">LLM for Finance</span><a href="#llm-for-finance" class="header-anchor">#</a></h3><ul>
<li><p>Large Language Models in Finance: A Survey, 2023.09 <a href="https://arxiv.org/abs/2311.10723">[paper]</a></p>
</li>
<li><p>A Survey of Large Language Models in Finance (FinLLMs) ***</p>
</li>
</ul>
<h3><span id="llm-for-education">LLM for Education</span><a href="#llm-for-education" class="header-anchor">#</a></h3><ul>
<li>ChatGPT and Beyond: The Generative AI Revolution in Education, 2023.11 <a href="https://arxiv.org/pdf/2311.15198">[paper]</a></li>
</ul>
<h3><span id="llm-for-law">LLM for Law</span><a href="#llm-for-law" class="header-anchor">#</a></h3><ul>
<li>Large Language Models in Law: A Survey, 2023.12 <a href="https://arxiv.org/pdf/2312.03718">[paper]</a></li>
</ul>
<h3><span id="llm-for-mental-health">LLM for Mental Health</span><a href="#llm-for-mental-health" class="header-anchor">#</a></h3><ul>
<li>A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement, 2023.10 <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10601652/">[paper]</a></li>
<li>Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects, 2023.12 <a href="https://arxiv.org/pdf/2312.04578.pdf">[paper]</a></li>
<li>Large Language Models in Mental Health Care: a Scoping Review, 2024.01 <a href="https://arxiv.org/pdf/2401.02984.pdf">[paper]</a></li>
</ul>
<hr>
<h2><span id="llm-for-downstream-tasks">LLM for Downstream Tasks</span><a href="#llm-for-downstream-tasks" class="header-anchor">#</a></h2><h3><span id="llm-for-recommendation">LLM for Recommendation</span><a href="#llm-for-recommendation" class="header-anchor">#</a></h3><ul>
<li>User Modeling in the Era of Large Language Models: Current Research and Future Directions, 2023.12 <a href="https://doi.org/10.48550/arXiv.2312.11518">[paper]</a><a href="https://github.com/TamSiuhin/LLM-UM-Reading">[project]</a></li>
<li>A Survey on Large Language Models for Personalized and Explainable  Recommendations, 2023.11 <a href="https://arxiv.org/pdf/2311.12338">[paper]</a></li>
<li>Large Language Models for Generative Recommendation: A Survey and Visionary Discussions, 2023.09 <a href="https://arxiv.org/abs/2309.01157">[paper]</a></li>
<li>A Survey on Large Language Models for Recommendation, 2023.08 <a href="https://arxiv.org/abs/2305.19860">[paper]</a><a href="https://github.com/WLiK/LLM4Rec-Awesome-Papers">[project]</a></li>
<li>How Can Recommender Systems Benefit from Large Language Models: A Survey, 2023.06 <a href="https://arxiv.org/abs/2306.05817">[paper]</a><a href="https://github.com/CHIANGEL/Awesome-LLM-for-RecSys">[project]</a></li>
</ul>
<h3><span id="llm-for-information-retrieval">LLM for Information Retrieval</span><a href="#llm-for-information-retrieval" class="header-anchor">#</a></h3><ul>
<li>Large Language Models for Information Retrieval: A Survey, 2023.08 <a href="https://arxiv.org/abs/2308.07107">[paper]</a><a href="https://github.com/RUC-NLPIR/LLM4IR-Survey">[project]</a></li>
</ul>
<h3><span id="llm-for-software-engineering">LLM for Software Engineering</span><a href="#llm-for-software-engineering" class="header-anchor">#</a></h3><ul>
<li>Large Language Models for Software Engineering: Survey and Open Problems, 2023.10 <a href="https://arxiv.org/abs/2310.03533">[paper]</a></li>
<li>Large Language Models for Software Engineering: A Systematic Literature Review, 2023.08 <a href="https://arxiv.org/abs/2308.10620">[paper]</a></li>
</ul>
<h3><span id="llm-for-time-series">LLM for Time Series</span><a href="#llm-for-time-series" class="header-anchor">#</a></h3><ul>
<li>Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook, 2023.10 <a href="https://arxiv.org/abs/2310.10196">[paper]</a><a href="https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM">[project]</a></li>
</ul>
<h3><span id="detection-of-llms-generated-content">Detection of LLMs-Generated Content</span><a href="#detection-of-llms-generated-content" class="header-anchor">#</a></h3><ul>
<li>A Survey on Detection of LLMs-Generated Content, 2023.10 <a href="https://arxiv.org/abs/2310.15654">[paper]</a><a href="https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection">[project]</a></li>
<li>A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions, 2023.10 <a href="https://arxiv.org/pdf/2310.14724.pdf">[paper]</a><br><a href="https://github.com/NLP2CT/LLM-generated-Text-Detection">[project]</a></li>
<li>Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text, 2023.09 <a href="https://arxiv.org/pdf/2309.07689.pdf">[paper]</a></li>
<li></li>
</ul>
<h3><span id="llm-for-information-extraction">LLM for Information Extraction</span><a href="#llm-for-information-extraction" class="header-anchor">#</a></h3><ul>
<li>Large Language Models for Generative Information Extraction: A Survey, 2023.12 <a href="https://arxiv.org/pdf/2312.17617.pdf">[paper]</a> <a href="https://github.com/quqxui/Awesome-LLM4IE-Papers">[project]</a></li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p><a href="https://github.com/www6v/Awesome-LLM-Survey">Awesome-LLM-Survey</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>paper</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>Temperature &amp; Top-p</title>
    <url>/www6vHomeAIGC/2023/03/30/gptTemperature/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="temperature">Temperature</span><a href="#temperature" class="header-anchor">#</a></h1><h1><span id="top-p">Top-p</span><a href="#top-p" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://www.bilibili.com/video/BV1rm411R7d9/">LLMè§£ç å‚æ•°Temperature Top K &amp; Top Pæœ‰å•¥ä½œç”¨ï¼Ÿ#å°å·¥èš</a> V<br>   <a href="https://docs.cohere.com/docs/predictable-outputs">Predictable Outputs</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/666315413">åˆ›é€ æ€§vsç¡®å®šæ€§ï¼šå¤§è¯­è¨€æ¨¡å‹(LLM)ä¸­çš„æ¸©åº¦(Temperature)å’ŒTop_Pæ€ä¹ˆè°ƒï¼Ÿ</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Temperature</category>
      </categories>
      <tags>
        <tag>Temperature</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)Deepspeed</title>
    <url>/www6vHomeAIGC/2023/03/25/gptTrainDeepspeedPractice/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>





<h1><span id="deepspeed-é…ç½®0">DeepSpeed é…ç½®[0]</span><a href="#deepspeed-é…ç½®0" class="header-anchor">#</a></h1><h3><span id="zero-2-é…ç½®-12">ZeRO-2 é…ç½® [1][2]</span><a href="#zero-2-é…ç½®-12" class="header-anchor">#</a></h3><h3><span id="zero-3-é…ç½®34">ZeRO-3 é…ç½®[3][4]</span><a href="#zero-3-é…ç½®34" class="header-anchor">#</a></h3><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol start="0">
<li>ã€Šå¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ Microsoft DeepSpeedã€‹ Aiå¤§æ¨¡å‹å¾®è°ƒ</li>
<li><a href="https://github.com/www6v/LLM-quickstart/blob/main/deepspeed/config/ds_config_zero2.json">ds_config_zero2.json</a></li>
<li><a href="https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/pretrain/ds_config_zero2.json">ds_config_zero2.json</a></li>
<li><a href="https://github.com/www6v/LLM-quickstart/blob/main/deepspeed/config/ds_config_zero3.json">ds_config_zero3.json</a></li>
<li><a href="https://github.com/LlamaFamily/Llama-Chinese/blob/main/train/pretrain/ds_config_zero3.json">ds_config_zero3.json</a></li>
</ol>
<p>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648399768&idx=1&sn=3be1a2e9d8753c06b65f474c289b710f">NLPå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å¾®è°ƒå®è·µï¼šDeepSpeed+Transformerså®ç°ç®€å•å¿«æ·ä¸Šæ‰‹ç™¾äº¿å‚æ•°æ¨¡å‹å¾®è°ƒ </a> FLAN-T5  + DeepSpeed</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Deepspeed</category>
      </categories>
      <tags>
        <tag>Deepspeed</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)åˆ†å¸ƒå¼å¹¶è¡ŒTraining</title>
    <url>/www6vHomeAIGC/2023/01/06/gptTrainParallelism/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C-1">åˆ†å¸ƒå¼å¹¶è¡Œ [1]</a><ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C-4">æ•°æ®å¹¶è¡Œ [4]</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C">æ¨¡å‹å¹¶è¡Œ</a><ul>
<li><a href="#%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C-3">å¼ é‡å¹¶è¡Œ [3]</a></li>
<li><a href="#%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C-3">æµæ°´çº¿å¹¶è¡Œ [3]</a></li>
</ul>
</li>
<li><a href="#%E5%A4%9A%E7%BB%B4%E6%B7%B7%E5%90%88%E5%B9%B6%E8%A1%8C5">å¤šç»´æ··åˆå¹¶è¡Œ[5]</a><ul>
<li><a href="#dp-pp">DP + PP</a></li>
<li><a href="#3d-%E5%B9%B6%E8%A1%8Cdp-pp-tp">3D å¹¶è¡Œï¼ˆDP + PP + TPï¼‰</a></li>
<li><a href="#zero-dp-pp-tp">ZeRO-DP + PP + TP</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E6%A1%86%E6%9E%B6">æ¡†æ¶</a></li>
<li><a href="#%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8Cpipeline-parallelism-pp4kimi">æµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelism, PPï¼‰[4][kimi]</a><ul>
<li><a href="#%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98">å¯èƒ½å­˜åœ¨çš„é—®é¢˜</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96">å¦‚ä½•ä¼˜åŒ–</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#%E5%AE%9E%E6%88%98">å®æˆ˜</a></li>
<li><a href="#%E5%85%B6%E4%BB%96">å…¶ä»–</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>


<h1><span id="åˆ†å¸ƒå¼å¹¶è¡Œ-1">åˆ†å¸ƒå¼å¹¶è¡Œ [1]</span><a href="#åˆ†å¸ƒå¼å¹¶è¡Œ-1" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2023/01/06/gptTrainParallelism/pararllelTraining.jpg" class>

<h3><span id="æ•°æ®å¹¶è¡Œ-4">æ•°æ®å¹¶è¡Œ [4]</span><a href="#æ•°æ®å¹¶è¡Œ-4" class="header-anchor">#</a></h3><p>æ•°æ®å¹¶è¡Œå¯ä»¥åˆ†ä¸º<strong>ä¸­å¿ƒåŒ–æ–¹å¼</strong>çš„å’Œ<strong>æ— ä¸­å¿ƒåŒ–æ–¹å¼</strong>çš„ï¼Œå¯¹åº”äºpytorché‡Œé¢çš„<strong>DataParallel</strong>å’Œ<strong>DistributedDataParallel(DDP)</strong></p>
<h3><span id="æ¨¡å‹å¹¶è¡Œ">æ¨¡å‹å¹¶è¡Œ</span><a href="#æ¨¡å‹å¹¶è¡Œ" class="header-anchor">#</a></h3><p><strong>å¼ é‡å¹¶è¡Œ</strong>ä¸<strong>æµæ°´çº¿å¹¶è¡Œ</strong>éƒ½å±äº<strong>æ¨¡å‹å¹¶è¡Œ</strong>ï¼Œ<br>åŒºåˆ«åœ¨äºå¯¹æ¨¡å‹å‚æ•°çš„åˆ‡åˆ†â€œæ–¹å‘â€ä¸åŒï¼š<br><strong>å¼ é‡å¹¶è¡Œ</strong>æŠŠæ¨¡å‹çš„<strong>æ¯å±‚è¿›è¡Œåˆ‡åˆ† (intra-layer)<strong>ï¼Œè€Œ</strong>æµæ°´çº¿å¹¶è¡Œ</strong>åˆ™<strong>æŒ‰å±‚è¿›è¡Œåˆ‡åˆ† (inter-layer) å¹¶åœ¨ä¸åŒè®¾å¤‡å¤„ç†</strong>ã€‚[2]</p>
<h5><span id="å¼ é‡å¹¶è¡Œ-3">å¼ é‡å¹¶è¡Œ [3]</span><a href="#å¼ é‡å¹¶è¡Œ-3" class="header-anchor">#</a></h5> <img src="/www6vHomeAIGC/2023/01/06/gptTrainParallelism/tensor.png" class>

<ul>
<li>Megatron-LMï¼ˆ1Dï¼‰</li>
<li>Colossal-AIï¼ˆ2Dã€2.5Dã€3Dï¼‰</li>
</ul>
<h5><span id="æµæ°´çº¿å¹¶è¡Œ-3">æµæ°´çº¿å¹¶è¡Œ [3]</span><a href="#æµæ°´çº¿å¹¶è¡Œ-3" class="header-anchor">#</a></h5><img src="/www6vHomeAIGC/2023/01/06/gptTrainParallelism/pipeline.png" class>

<ul>
<li>GPipe</li>
<li>PipeDream</li>
</ul>
<h3><span id="å¤šç»´æ··åˆå¹¶è¡Œ5">å¤šç»´æ··åˆå¹¶è¡Œ[5]</span><a href="#å¤šç»´æ··åˆå¹¶è¡Œ5" class="header-anchor">#</a></h3><h5><span id="dp-pp">DP + PP</span><a href="#dp-pp" class="header-anchor">#</a></h5><h5><span id="3d-å¹¶è¡Œdp-pp-tp">3D å¹¶è¡Œï¼ˆDP + PP + TPï¼‰</span><a href="#3d-å¹¶è¡Œdp-pp-tp" class="header-anchor">#</a></h5><h5><span id="zero-dp-pp-tp">ZeRO-DP + PP + TP</span><a href="#zero-dp-pp-tp" class="header-anchor">#</a></h5><h1><span id="æ¡†æ¶">æ¡†æ¶</span><a href="#æ¡†æ¶" class="header-anchor">#</a></h1><ul>
<li>Megatron-LMï¼ˆå¼ é‡å¹¶è¡Œï¼‰</li>
<li>DeepSpeedï¼ˆZero-DPï¼‰</li>
<li>Colossal-AIï¼ˆé«˜ç»´æ¨¡å‹å¹¶è¡Œï¼Œå¦‚2Dã€2.5Dã€3Dï¼‰</li>
<li>Alpaï¼ˆè‡ªåŠ¨å¹¶è¡Œï¼‰</li>
</ul>
<h1><span id="æµæ°´çº¿å¹¶è¡Œpipeline-parallelism-pp4kimi">æµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelism, PPï¼‰[4][kimi]</span><a href="#æµæ°´çº¿å¹¶è¡Œpipeline-parallelism-pp4kimi" class="header-anchor">#</a></h1><p>å¼•å…¥æµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelism, PPï¼‰åå¯èƒ½ä¼šå­˜åœ¨ä»¥ä¸‹<strong>é—®é¢˜</strong>ä»¥åŠç›¸åº”çš„<strong>ä¼˜åŒ–æ–¹æ³•</strong>ï¼š</p>
<h3><span id="å¯èƒ½å­˜åœ¨çš„é—®é¢˜">å¯èƒ½å­˜åœ¨çš„é—®é¢˜</span><a href="#å¯èƒ½å­˜åœ¨çš„é—®é¢˜" class="header-anchor">#</a></h3><ol>
<li><p><strong>ç†è®ºä¸Šç•Œä¸æœ´ç´ ä¸²è¡Œæ–¹å¼çš„å·®å¼‚</strong>ï¼šåœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œä¸éœ€è¦æµæ°´çº¿å¹¶è¡Œï¼Œç›´æ¥å¯¹mini-batchçš„æ ·æœ¬åšå‰å‘å’Œåå‘æ“ä½œã€‚<strong>æœ´ç´ ä¸²è¡Œæ–¹å¼ä¼šå¯¼è‡´ç¡¬ä»¶åˆ©ç”¨ç‡ä½ï¼Œå› ä¸ºæ¯ä¸ªmicro-batchä¸²è¡Œé€ä¸ªåšå‰å‘å’Œåå‘ï¼Œå¯¼è‡´å¤§é‡è®¡ç®—èµ„æºé—²ç½®</strong>ã€‚</p>
</li>
<li><p><strong>Gpipeæµæ°´çº¿å¹¶è¡Œçš„ç­‰å¾…æ—¶é—´</strong>ï¼š<strong>Gpipeæµæ°´çº¿å¹¶è¡Œéœ€è¦ç­‰æ‰€æœ‰micro-batchéƒ½è®¡ç®—å®Œæ‰èƒ½æ‰§è¡Œåå‘è¿‡ç¨‹</strong>ï¼Œè¿™ä¼šå¯¼è‡´é¢å¤–çš„ç­‰å¾…æ—¶é—´ï¼Œå¢åŠ äº†æ€»è€—æ—¶ã€‚</p>
</li>
<li><p><strong>ç¡¬ä»¶èµ„æºçš„æµªè´¹</strong>ï¼šç”±äºä¸åŒé˜¶æ®µçš„è®¡ç®—ååä¸åŒï¼Œå¯èƒ½ä¼šå¯¼è‡´ç¡¬ä»¶èµ„æºçš„æµªè´¹ã€‚</p>
</li>
</ol>
<h3><span id="å¦‚ä½•ä¼˜åŒ–">å¦‚ä½•ä¼˜åŒ–</span><a href="#å¦‚ä½•ä¼˜åŒ–" class="header-anchor">#</a></h3><ol>
<li><p><strong>Bubble Ratioåˆ†æ</strong>ï¼šå®šä¹‰<strong>bubble ratio</strong>æ¥è¡¡é‡æµæ°´çº¿ç®—æ³•å¯¹ç¡¬ä»¶çš„æµªè´¹ç¨‹åº¦ï¼Œå€¼è¶Šå°è¯´æ˜æµæ°´çº¿æ•ˆç‡è¶Šé«˜ã€‚é€šè¿‡è°ƒæ•´micro-batchçš„å¤§å°ï¼Œå¯ä»¥å‡å°‘æ°”æ³¡ç©ºè…”çš„é¢ç§¯ï¼Œæé«˜ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚</p>
</li>
<li><p><strong>Micro-batchå¤§å°åˆ†æ</strong>ï¼šé€šè¿‡è°ƒæ•´micro-batchçš„å¤§å°bï¼Œå¯ä»¥ä½¿å¾—æµæ°´çº¿å¹¶è¡Œçš„é¢å¤–è€—æ—¶å°½å¯èƒ½å°ã€‚è¿™é€šå¸¸éœ€è¦é€šè¿‡å®é™…æµ‹è¯•æ¥è¿›è¡Œæ€§èƒ½åˆ†æã€‚</p>
</li>
<li><p><strong>PipeDream (Non-Interleaved 1F1B)<strong>ï¼š</strong>é€šè¿‡è§£è€¦åŒä¸€ä¸ªmini-batchçš„ä¸åŒmicro-batchï¼Œå…è®¸å®ƒä»¬ç‹¬ç«‹åœ°è¿›è¡Œå‰å‘å’Œåå‘è®¡ç®—</strong>ï¼Œä»è€Œå‡å°‘æ˜¾å­˜çš„ä½¿ç”¨ï¼Œå¹¶æé«˜ç¡¬ä»¶èµ„æºçš„åˆ©ç”¨ç‡ã€‚</p>
</li>
<li><p><strong>Interleaved 1F1B</strong>ï¼šå°†æµæ°´çº¿åˆ‡åˆ†æ›´ç»†ï¼Œä½¿å¾—æ¯ä¸ªè®¾å¤‡å¯ä»¥åˆ†é…æ›´å¤šçš„ç®—åŠ›ï¼Œå‡å°‘äº†æ¯ä¸ªlayerçš„è®¡ç®—æ—¶é—´ï¼Œä»è€Œå‡å°‘äº†æ€»è€—æ—¶ã€‚</p>
</li>
<li><p><strong>Re-materializationï¼ˆCheckpointingï¼‰</strong>ï¼šä½¿ç”¨checkpointæŠ€æœ¯ï¼Œå³åªä¿ç•™æ¯ä¸ªstageçš„è¾“å…¥activationï¼Œå¹¶åœ¨backwardæ—¶ä»stageå¼€å¤´é‡æ–°è®¡ç®—ï¼Œä»¥å‡å°‘æ˜¾å­˜å ç”¨ã€‚</p>
</li>
<li><p><strong>ä¼˜åŒ–é€šä¿¡ç­–ç•¥</strong>ï¼šå¯¹äºè·¨meshçš„é€šä¿¡ï¼Œä½¿ç”¨ä¼˜åŒ–ç­–ç•¥ï¼Œå¦‚scatter-gatheræˆ–all-gatherï¼Œä»¥å‡å°‘é€šä¿¡å¼€é”€ã€‚</p>
</li>
<li><p><strong>åŠ¨æ€è§„åˆ’æ±‚è§£</strong>ï¼šä½¿ç”¨åŠ¨æ€è§„åˆ’æ¥ä¼˜åŒ–å­å›¾å’Œè®¡ç®—èµ„æºçš„åˆ’åˆ†ï¼Œå‡å°‘è®¡ç®—å›¾ä¸­çš„éå¯†é›†å‹ç®—å­ï¼Œä»¥é™ä½æœç´¢ç©ºé—´ã€‚</p>
</li>
<li><p><strong>Alpaè‡ªåŠ¨åŒ–æœç´¢</strong>ï¼šAlpaé€šè¿‡æ•°å­¦å»ºæ¨¡å’Œä¼˜åŒ–æ¥å¯»æ‰¾æ¥è¿‘æœ€ä¼˜çš„å¹¶è¡Œç­–ç•¥ï¼Œå¯ä»¥è‡ªåŠ¨åŒ–åœ°æœç´¢å¹¶è¡Œç­–ç•¥ï¼Œå‡å°‘äººå·¥è®¾è®¡çš„å·¥ä½œé‡ã€‚</p>
</li>
</ol>
<p>é€šè¿‡ä¸Šè¿°æ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šä¼˜åŒ–æµæ°´çº¿å¹¶è¡Œå¸¦æ¥çš„é—®é¢˜ï¼Œæé«˜æ¨¡å‹è®­ç»ƒçš„æ•ˆç‡å’Œç¡¬ä»¶èµ„æºçš„åˆ©ç”¨ç‡ã€‚</p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><h3><span id></span><a href="#" class="header-anchor">#</a></h3><ol>
<li><p><a href="https://lilianweng.github.io/posts/2021-09-25-train-large/">How to Train Really Large Models on Many GPUs? </a></p>
</li>
<li><p><a href="https://finisky.github.io/how-to-train-large-language-model/">å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒçš„å¹¶è¡Œç­–ç•¥</a> *</p>
</li>
<li><p><a href="https://blog.csdn.net/v_JULY_v/article/details/132462452">å¤§æ¨¡å‹å¹¶è¡Œè®­ç»ƒæŒ‡å—ï¼šé€šä¿—ç†è§£Megatron-DeepSpeedä¹‹æ¨¡å‹å¹¶è¡Œä¸æ•°æ®å¹¶è¡Œ</a>  ***</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/664604792">[Transformer 101ç³»åˆ—] LLMåˆ†å¸ƒå¼è®­ç»ƒé¢é¢è§‚</a> ***</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/661279318">å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆå…­ï¼‰-å¤šç»´æ··åˆå¹¶è¡Œ</a></p>
</li>
<li><p><a href="https://www.zhihu.com/question/601594836/answer/3032763174">ä¸ŠåŠå¹´å¤§æ¨¡å‹éåœ°å¼€èŠ±ï¼Œå¤§æ¨¡å‹å‘å±•ä¸­æœ‰å“ªäº›ç»éªŒå’Œæ•™è®­ï¼Ÿ</a> åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶</p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/598714869">å¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒå¹¶è¡ŒæŠ€æœ¯ï¼ˆä¸€ï¼‰-æ¦‚è¿°</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/465967735">åˆ†å¸ƒå¼è®­ç»ƒç¡¬æ ¸æŠ€æœ¯â€”â€”é€šä¿¡åŸè¯­</a> </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/613196255">å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šæµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelismï¼‰ï¼Œä»¥Gpipeä¸ºä¾‹</a>  ç³»åˆ—æ–‡ç«  </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/622212228">å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šå¼ é‡æ¨¡å‹å¹¶è¡Œ(TP)ï¼ŒMegatron-LM</a> ***</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/450854172">å…¨ç½‘æœ€å…¨-è¶…å¤§æ¨¡å‹+åˆ†å¸ƒå¼è®­ç»ƒæ¶æ„å’Œç»å…¸è®ºæ–‡</a> </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/350707888">å¤§è§„æ¨¡è®­ç»ƒç³»åˆ—ä¹‹æŠ€æœ¯æŒ‘æˆ˜</a></p>
<h3><span id="å®æˆ˜">å®æˆ˜</span><a href="#å®æˆ˜" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/636488690">å¤§æ¨¡å‹æµæ°´çº¿å¹¶è¡Œï¼ˆPipelineï¼‰å®æˆ˜</a></p>
<h3><span id="å…¶ä»–">å…¶ä»–</span><a href="#å…¶ä»–" class="header-anchor">#</a></h3><p>1xx. <a href="https://techdiylife.github.io/big-model-training/deepspeed/deepspeed-chat.html">ç¬¬1ç« ï¼šDeepSpeed-Chat æ¨¡å‹è®­ç»ƒå®æˆ˜</a>  Bili<br>      <a href="https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat">DeepSpeed-Chat</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>train</category>
      </categories>
      <tags>
        <tag>train</tag>
      </tags>
  </entry>
  <entry>
    <title>Tokenizer</title>
    <url>/www6vHomeAIGC/2023/02/26/gptTrainTokenizer/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h3><span id="tokenizer-åˆ†è¯">tokenizer åˆ†è¯</span><a href="#tokenizer-åˆ†è¯" class="header-anchor">#</a></h3><ul>
<li>å•è¯åˆ†è¯æ³•</li>
<li>å•å­—åˆ†è¯æ³•</li>
<li>å­è¯åˆ†è¯æ³•<br>BPE [GPTç³»åˆ—], WordPiece</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://zhuanlan.zhihu.com/p/630696264">å¤§æ¨¡å‹è¯è¡¨æ‰©å……å¿…å¤‡å·¥å…·SentencePiece</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/458452872">NLPï¼ˆäºŒï¼‰ï¼šæµ…è°ˆåˆ†è¯</a><br>1xx. <a href="https://www.bilibili.com/video/BV1vN411p7t2/">https://www.bilibili.com/video/BV1vN411p7t2/</a><br>1xx. <a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648400849&idx=1&sn=58006756cccde4d06d273df59e2c8dd8">å¼€æºå¤§æ¨¡å‹å¦‚ä½•æ›´å¥½åœ°é€‚åº”ä¸­æ–‡åœºæ™¯ï¼šLLAMAæ‰©å……è¯è¡¨ã€BLOOMè£å‰ªè¯è¡¨åŸºæœ¬åŸç†ä¸å¼€æºå®ç°</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Tokenizer</category>
      </categories>
      <tags>
        <tag>Tokenizer</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Zero Deepspeed</title>
    <url>/www6vHomeAIGC/2023/03/23/gptTrainZeroDeepspeed/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>


<h1><span id="zero-dp-1-2">ZeRO-DP [1] [2]</span><a href="#zero-dp-1-2" class="header-anchor">#</a></h1><ul>
<li>ZeRO-DP<br>æ˜¯ä¸€ç§<strong>åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ</strong>è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡<strong>å‡å°‘å†—ä½™æ•°æ®</strong>æ¥é™ä½æ¯ä¸ªè®¾å¤‡çš„æ˜¾å­˜å ç”¨ï¼Œä»è€Œå…è®¸è®­ç»ƒæ›´å¤§çš„æ¨¡å‹</li>
</ul>
<h3><span id="zero-dp-ä¸‰ä¸ªä¼˜åŒ–é˜¶æ®µ">ZeRO-DP ä¸‰ä¸ªä¼˜åŒ–é˜¶æ®µ</span><a href="#zero-dp-ä¸‰ä¸ªä¼˜åŒ–é˜¶æ®µ" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2023/03/23/gptTrainZeroDeepspeed/zero.png" class>

<p>ä»¥ Adamä¼˜åŒ–å™¨ï¼Œ64å¼ GPUä¸ºä¾‹è®¡ç®—</p>
<ul>
<li><p>naive DPçš„é€šä¿¡é‡<br>é€šä¿¡é‡æ˜¯<strong>2X</strong><br>æ˜¾å­˜å ç”¨<strong>16X</strong></p>
</li>
<li><p>ZeRO Stage 1 ï¼ˆPosï¼‰<br>æ€»çš„é€šä¿¡é‡ä¸º<strong>2Xï¼Œè·Ÿnaive DPä¸€è‡´</strong><br>æ˜¾å­˜æ–¹é¢ çº¦ä¸º<strong>naive DPçš„ 1&#x2F;4</strong></p>
</li>
<li><p>ZeRO Stage 2 ï¼ˆPos+gï¼‰<br>é€šä¿¡é‡ä¹Ÿæ˜¯<strong>2X, è·Ÿnaive DPä¸€è‡´</strong><br>æ˜¾å­˜æ–¹é¢  çº¦ä¸º<strong>naive DPçš„1&#x2F;8</strong></p>
</li>
<li><p>ZeRO Stage 3 ï¼ˆPos+g+pï¼‰<br>æ€»çš„é€šä¿¡é‡ä¸ºï¼Œä¸º<strong>naive DPçš„1.5å€</strong>ï¼Œå¢åŠ 50%é€šä¿¡é‡<br>æ˜¾å­˜æ–¹é¢  çº¦ä¸º<strong>naive DPçš„1&#x2F;32</strong></p>
</li>
</ul>
<h1><span id="zero-offload3">ZeRO-Offload[3]</span><a href="#zero-offload3" class="header-anchor">#</a></h1><ul>
<li>ZeRO-Offload[2]<br>ZeROæŠ€æœ¯çš„ä¸€ä¸ªæ‰©å±•ï¼Œå®ƒå°†éƒ¨åˆ†æ•°æ®å’Œè®¡ç®—ä»GPUï¼ˆæˆ–å…¶ä»–ä¸»è¦è®­ç»ƒè®¾å¤‡ï¼‰å¸è½½åˆ°CPUï¼Œä»è€Œå‡è½»äº†GPUçš„æ˜¾å­˜è´Ÿæ‹…ï¼Œå¹¶ä½¿å¾—åœ¨æœ‰é™GPUèµ„æºä¸‹è®­ç»ƒæ›´å¤§çš„æ¨¡å‹æˆä¸ºå¯èƒ½</li>
</ul>
<p><strong>ç°åœ¨è¦åšçš„å°±æ˜¯æ²¿ç€è¾¹æŠŠæ•°æ®æµå›¾åˆ‡åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œåˆ†åˆ«å¯¹åº”GPUå’ŒCPUï¼Œ</strong>è®¡ç®—èŠ‚ç‚¹ï¼ˆçŸ©å½¢èŠ‚ç‚¹ï¼‰è½åœ¨å“ªä¸ªè®¾å¤‡ï¼Œå“ªä¸ªè®¾å¤‡å°±æ‰§è¡Œè®¡ç®—ï¼Œæ•°æ®èŠ‚ç‚¹ï¼ˆåœ†å½¢ï¼‰è½åœ¨å“ªä¸ªè®¾å¤‡ï¼Œå“ªä¸ªè®¾å¤‡å°±è´Ÿè´£å­˜å‚¨ï¼Œå°†è¢«åˆ‡åˆ†çš„è¾¹æƒé‡åŠ èµ·æ¥ï¼Œå°±æ˜¯CPUå’ŒGPUçš„é€šä¿¡æ•°æ®é‡ã€‚<br>ZeRO-Offloadçš„åˆ‡åˆ†æ€è·¯æ˜¯ï¼šå›¾ä¸­æœ‰å››ä¸ªè®¡ç®—ç±»èŠ‚ç‚¹ï¼š<strong>FWDã€BWDã€Param updateå’Œfloat2half</strong>ï¼Œå‰ä¸¤ä¸ªè®¡ç®—å¤æ‚åº¦å¤§è‡´æ˜¯ O(MB) ï¼Œ B æ˜¯batch sizeï¼Œåä¸¤ä¸ªè®¡ç®—å¤æ‚åº¦æ˜¯ O(M) ã€‚ä¸ºäº†ä¸é™ä½è®¡ç®—æ•ˆç‡ï¼Œ<strong>å°†å‰ä¸¤ä¸ªèŠ‚ç‚¹æ”¾åœ¨GPUï¼Œåä¸¤ä¸ªèŠ‚ç‚¹ä¸ä½†è®¡ç®—é‡å°è¿˜éœ€è¦å’ŒAdamçŠ¶æ€æ‰“äº¤é“ï¼Œæ‰€ä»¥æ”¾åœ¨CPUä¸Š</strong>ï¼ŒAdamçŠ¶æ€è‡ªç„¶ä¹Ÿæ”¾åœ¨å†…å­˜ä¸­ï¼Œä¸ºäº†ç®€åŒ–æ•°æ®å›¾ï¼Œå°†å‰ä¸¤ä¸ªèŠ‚ç‚¹èåˆæˆä¸€ä¸ªèŠ‚ç‚¹<strong>FWD-BWD Super Node</strong>ï¼Œå°†åä¸¤ä¸ªèŠ‚ç‚¹èåˆæˆä¸€ä¸ªèŠ‚ç‚¹<strong>Update Super Node</strong>ã€‚å¦‚ä¸‹å›¾å³è¾¹æ‰€ç¤ºï¼Œæ²¿ç€gradient 16å’Œparameter 16ä¸¤æ¡è¾¹åˆ‡åˆ†ã€‚</p>
<img src="/www6vHomeAIGC/2023/03/23/gptTrainZeroDeepspeed/zeroOffload.png" class>


<h1><span id="deepspeed-2">DeepSpeed [2]</span><a href="#deepspeed-2" class="header-anchor">#</a></h1><h3><span id="key-feature">Key feature</span><a href="#key-feature" class="header-anchor">#</a></h3><ul>
<li>ZeROï¼ˆZero Redundancy Optimizerï¼‰</li>
<li>æ¨¡å‹å¹¶è¡Œï¼ˆModel Parallelismï¼‰</li>
<li>æµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelismï¼‰</li>
<li>ç¨€ç–æ³¨æ„åŠ›ï¼ˆSparse Attentionï¼‰</li>
<li>æ˜¾å­˜å’Œå¸¦å®½ä¼˜åŒ–</li>
</ul>
<h1><span id="pytorch-fsdp-10">PyTorch FSDP [10]</span><a href="#pytorch-fsdp-10" class="header-anchor">#</a></h1><p>FairScale è¯´ <strong>FSDP ç›¸å½“äº ZeRO3 çš„ä¼˜åŒ–</strong></p>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/664604792">[Transformer 101ç³»åˆ—] LLMåˆ†å¸ƒå¼è®­ç»ƒé¢é¢è§‚</a> ***</p>
</li>
<li><p>ã€Šå¤§æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶Microsoft DeepSpeedã€‹ Aiå¤§æ¨¡å‹å¾®è°ƒ</p>
</li>
<li><p><a href="https://blog.csdn.net/weixin_43336281/article/details/126475071">éœ‡æƒŠï¼æˆ‘ç«Ÿç„¶åœ¨1080Tiä¸ŠåŠ è½½äº†ä¸€ä¸ª35äº¿å‚æ•°çš„æ¨¡å‹ï¼ˆZeRO, Zero Redundancy Optimizerï¼‰</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/644133265">FSDP æ·±åº¦è§£æï¼š2023 å¹´äº†ï¼Œå¤§æ¨¡å‹è®­ç»ƒè¿˜è¦ä¸è¦ç”¨ PyTorch çš„ FSDP ï¼Ÿ</a></p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/610587671">ã€æ·±åº¦å­¦ä¹ ã€‘ã€åˆ†å¸ƒå¼è®­ç»ƒã€‘DeepSpeedï¼šAllReduceä¸ZeRO-DP</a></p>
<p>1xx. <a href="https://blog.csdn.net/qq_18555105/article/details/130513812">Zeroç³»åˆ—ä¸‰éƒ¨æ›²ï¼šZeroã€Zero-Offloadã€Zero-Infinity</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/618865052">å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šæ•°æ®å¹¶è¡Œä¸‹ç¯‡( DeepSpeed ZeROï¼Œé›¶å†—ä½™ä¼˜åŒ–)</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/617133971">å›¾è§£å¤§æ¨¡å‹è®­ç»ƒä¹‹ï¼šæ•°æ®å¹¶è¡Œä¸Šç¯‡(DP, DDPä¸ZeRO)</a></p>
<p>1xx. <a href="https://www.bilibili.com/video/BV1mc411y7jW/">Deepspeedå¤§æ¨¡å‹åˆ†å¸ƒå¼æ¡†æ¶ç²¾è®²</a>  V åŸç†+å®æ“    ***</p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Zero</category>
      </categories>
      <tags>
        <tag>Zero</tag>
      </tags>
  </entry>
  <entry>
    <title>(åŸç†)Transformer</title>
    <url>/www6vHomeAIGC/2022/11/30/gptTransformer/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">ç¥ç»ç½‘ç»œ</a></li>
<li><a href="#attention-3">Attention [3]</a><ul>
<li><a href="#%E4%BC%98%E5%8C%964">ä¼˜åŒ–[4]</a></li>
</ul>
</li>
<li><a href="#transformer-2">Transformer [2]</a><ul>
<li><a href="#encoder-decoder%E6%9E%B6%E6%9E%84-1">Encoder-Decoderæ¶æ„ [1]</a></li>
<li><a href="#self-attention">Self-attention</a></li>
<li><a href="#multi-head-attentionmha">Multi-Head Attention(MHA)</a></li>
<li><a href="#positional-encoding-3031">Positional Encoding  [30][31]</a></li>
<li><a href="#normalization-20">Normalization [20]</a></li>
</ul>
</li>
<li><a href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B">å¤§æ¨¡å‹</a><ul>
<li><a href="#%E6%9E%B6%E6%9E%84-67">æ¶æ„ [6][7]</a></li>
<li><a href="#%E4%BC%98%E5%8C%96%E7%82%B9">ä¼˜åŒ–ç‚¹</a></li>
<li><a href="#%E5%85%B3%E6%B3%A8%E7%82%B95">å…³æ³¨ç‚¹[5]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a><ul>
<li><a href="#normalization">Normalization</a></li>
<li><a href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81">ä½ç½®ç¼–ç </a></li>
<li><a href="#attention">Attention</a></li>
<li><a href="#%E5%85%B6%E4%BB%96">å…¶ä»–</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="ç¥ç»ç½‘ç»œ">ç¥ç»ç½‘ç»œ</span><a href="#ç¥ç»ç½‘ç»œ" class="header-anchor">#</a></h1><ul>
<li><p>æ­£å‘ä¼ æ’­<br>æŸå¤±å‡½æ•°  </p>
</li>
<li><p>åç›¸ä¼ æ’­<br>æ¢¯åº¦</p>
</li>
</ul>
<h1><span id="attention-3">Attention [3]</span><a href="#attention-3" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/11/30/gptTransformer/self-attention.jpg" class>

<h3><span id="ä¼˜åŒ–4">ä¼˜åŒ–[4]</span><a href="#ä¼˜åŒ–4" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/11/30/gptTransformer/attentions.jpg" class>

<h1><span id="transformer-2">Transformer [2]</span><a href="#transformer-2" class="header-anchor">#</a></h1><h3><span id="encoder-decoderæ¶æ„-1">Encoder-Decoderæ¶æ„ [1]</span><a href="#encoder-decoderæ¶æ„-1" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/11/30/gptTransformer/Transformer_decoder.jpg" class>
<img src="/www6vHomeAIGC/2022/11/30/gptTransformer/transformer_resideual_layer_norm_3.jpg" class>

<p>transfomer æ¶æ„åœ¨GPUä¸Šçš„å¹¶è¡Œ</p>
<h3><span id="self-attention">Self-attention</span><a href="#self-attention" class="header-anchor">#</a></h3><p>Q&#x3D;K&#x3D;V<br>aligment</p>
<h3><span id="multi-head-attentionmha">Multi-Head Attention(MHA)</span><a href="#multi-head-attentionmha" class="header-anchor">#</a></h3><h3><span id="positional-encoding-3031">Positional Encoding  [30][31]</span><a href="#positional-encoding-3031" class="header-anchor">#</a></h3><h3><span id="normalization-20">Normalization [20]</span><a href="#normalization-20" class="header-anchor">#</a></h3><ul>
<li><p>batch normalization</p>
</li>
<li><p>Layer Normalization</p>
<ul>
<li>Post-LN</li>
<li>Pre-LN</li>
<li>Sandwich-LN<br>layerNormæ˜¯é’ˆå¯¹åºåˆ—æ•°æ®æå‡ºçš„ä¸€ç§å½’ä¸€åŒ–æ–¹æ³•ï¼Œä¸»è¦åœ¨layerç»´åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œå³å¯¹æ•´ä¸ªåºåˆ—è¿›è¡Œå½’ä¸€åŒ–ã€‚</li>
</ul>
</li>
<li><p>RMS Norm</p>
</li>
</ul>
<h1><span id="å¤§æ¨¡å‹">å¤§æ¨¡å‹</span><a href="#å¤§æ¨¡å‹" class="header-anchor">#</a></h1><h3><span id="æ¶æ„-67">æ¶æ„ [6][7]</span><a href="#æ¶æ„-67" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/11/30/gptTransformer/bigModelArch.jpg" class>

<img src="/www6vHomeAIGC/2022/11/30/gptTransformer/bigModelArch1.jpg" class>

<h3><span id="ä¼˜åŒ–ç‚¹">ä¼˜åŒ–ç‚¹</span><a href="#ä¼˜åŒ–ç‚¹" class="header-anchor">#</a></h3><img src="/www6vHomeAIGC/2022/11/30/gptTransformer/transformers.jpg" class>

<h3><span id="å…³æ³¨ç‚¹5">å…³æ³¨ç‚¹[5]</span><a href="#å…³æ³¨ç‚¹5" class="header-anchor">#</a></h3><ul>
<li><p><strong>Mask attention çš„ç­–ç•¥ä¸åŒ</strong></p>
<ul>
<li>bert  [åŒå‘éƒ½èƒ½çœ‹åˆ°]</li>
<li>chatgpt  [åªèƒ½çœ‹åˆ°å•é¡¹çš„]</li>
<li>chatglm  [å·¦è¾¹åƒbert, å³è¾¹åƒgpt]</li>
</ul>
</li>
<li><p><strong>è®­ç»ƒä»»åŠ¡ç›®æ ‡ä¸åŒ</strong></p>
<ul>
<li>bert [maskæ‰ä¸€ä¸ªæ¬¡, åœ¨åŸä½ç½®æŠŠå®ƒé¢„æµ‹å‡ºæ¥]</li>
<li>gpt [é¢„æµ‹ä¸‹ä¸€ä¸ªè¯]</li>
<li>chatglm [ç”¨gptçš„æ–¹å¼æ¥åšbertçš„ä»»åŠ¡]</li>
</ul>
</li>
</ul>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="http://jalammar.github.io/illustrated-transformer/">illustrated-transformer</a> ***<br><a href="https://baoyu.io/translations/llm/illustrated-transformer">å›¾è§£ Transformer [è¯‘]</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/311156298">Transformer - Attention is all you need</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/410776234">è¶…è¯¦ç»†å›¾è§£Self-Attention</a> ***</p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2328541">ä¸»æµå¤§è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯åŸç†ç»†èŠ‚</a>  *** [æ¶æ„]+è®­ç»ƒ+å¾®è°ƒ</p>
</li>
<li><p><a href="https://www.bilibili.com/video/BV1gY4y1d7nk/">åŸºäºChatGLMå¯¹è¯ç³»ç»Ÿå®æˆ˜</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/648050614">LLMå­¦ä¹ ç³»åˆ—1ï¼šå¤§æ¨¡å‹æ¶æ„è¦ç‚¹æ€»ç»“</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/2328541">ä¸»æµå¤§è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯åŸç†ç»†èŠ‚</a> *** è…¾è®¯     æ¶æ„ + è®­ç»ƒ + å¾®è°ƒ</p>
</li>
</ol>
<p>1xx. <a href="https://www.bilibili.com/video/BV16h4y1W7us/">ç¬¬ä¸€è¯¾ï¼šTransformer</a> ***  åä¸º<br>1xx. <a href="https://bbycroft.net/llm">LLM Visualization</a> ***  å¯è§†åŒ–<br>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/127411638">Transformeré€šä¿—ç¬”è®°ï¼šä»Word2Vecã€Seq2Seqé€æ­¥ç†è§£åˆ°GPTã€BERT</a> ***<br>1xx. <a href="https://baoyu.io/translations/llm/the-random-transformer">æ·±å…¥è§£æéšæœº Transformer [è¯‘]</a> ***<br>1xx. <a href="https://e2eml.school/transformers.html">Transformers from Scratch</a></p>
<h3><span id="normalization">Normalization</span><a href="#normalization" class="header-anchor">#</a></h3><ol start="20">
<li><a href="https://www.bilibili.com/video/BV1tk4y1F7b6/">Normalizationå½’ä¸€åŒ–ï¼šbatch normalization vs layer nomalization</a></li>
</ol>
<h3><span id="ä½ç½®ç¼–ç ">ä½ç½®ç¼–ç </span><a href="#ä½ç½®ç¼–ç " class="header-anchor">#</a></h3><ol start="30">
<li><a href="https://blog.csdn.net/v_JULY_v/article/details/134085503">ä¸€æ–‡é€šé€ä½ç½®ç¼–ç ï¼šä»æ ‡å‡†ä½ç½®ç¼–ç ã€æ—‹è½¬ä½ç½®ç¼–ç RoPEåˆ°ALiBiã€LLaMA 2 Long</a></li>
<li><a href="https://www.bilibili.com/video/BV1Xa4y1d7YY/">ã€NLPå…¥é—¨ã€‘TransformeråŸºæœ¬ç»“æ„ï¼šEmbeddingä¸ä½ç½®ç¼–ç </a>  V</li>
</ol>
<h3><span id="attention">Attention</span><a href="#attention" class="header-anchor">#</a></h3><p>1xx. <a href="https://blog.csdn.net/kkm09/article/details/120855658">æå®æ¯…ã€Šæ·±åº¦å­¦ä¹ ã€‹- Self-attention è‡ªæ³¨æ„åŠ›æœºåˆ¶</a><br>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/134228287">ä¸€æ–‡é€šé€å„ç§æ³¨æ„åŠ›ï¼šä»å¤šå¤´æ³¨æ„åŠ›MHAåˆ°åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›GQAã€å¤šæŸ¥è¯¢æ³¨æ„åŠ›MQA</a></p>
<h3><span id="å…¶ä»–">å…¶ä»–</span><a href="#å…¶ä»–" class="header-anchor">#</a></h3><p>1xx. <a href="https://zhuanlan.zhihu.com/p/640784855">[Transformer 101ç³»åˆ—] åˆæ¢LLMåŸºåº§æ¨¡å‹</a><br>1xx. <a href="https://zhuanlan.zhihu.com/p/664046612">LLMä»0å¼€å§‹é¢„è®­ç»ƒç³»åˆ—ï¼š2ã€å¤§æ¨¡å‹æŠ€æœ¯æŠ¥å‘Šæ€»ç»“ï¼ˆGPT&#x2F;PaLM&#x2F;GLM&#x2F;LLaMA&#x2F;Skyworkï¼‰</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Transformer</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>(å®æˆ˜)Transformer</title>
    <url>/www6vHomeAIGC/2023/02/16/gptTransformerCode/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><p>1xx. <a href="https://github.com/www6v/AIGC/blob/master/transformer/transformer.ipynb">transformer.ipynb</a> git<br>   <a href="https://www.bilibili.com/video/BV1nc411y7m4/">Transformerä»£ç å®ç°</a></p>
<p>1xx. <a href="https://paperswithcode.com/method/transformer">Transformer</a><br>   <a href="https://github.com/tunz/transformer-pytorch/blob/e7266679f0b32fd99135ea617213f986ceede056/model/transformer.py#L201">transformer.py</a> git</p>
<p>1xx. <a href="http://arthurchiao.art/blog/transformers-from-scratch-zh/">[è¯‘] Transformer æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼š600 è¡Œ Python ä»£ç å®ç° self-attention å’Œä¸¤ç±» Transformerï¼ˆ2019ï¼‰</a> V, github<br>    Transformers from scratch</p>
<p>1xx. <a href="https://blog.csdn.net/v_JULY_v/article/details/130090649">ä»é›¶å®ç°Transformerçš„ç®€æ˜“ç‰ˆä¸å¼ºå¤§ç‰ˆï¼šä»300å¤šè¡Œåˆ°3000å¤šè¡Œ</a></p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/398039366">Transformeræºç è¯¦è§£ï¼ˆPytorchç‰ˆæœ¬ï¼‰</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>Transformer</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>å‘é‡æ•°æ®åº“</title>
    <url>/www6vHomeAIGC/2022/11/27/gptVectorStore/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>



<h2><span id="ç›®å½•">ç›®å½•</span><a href="#ç›®å½•" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93">å‘é‡æ•°æ®åº“</a></li>
<li><a href="#%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F-7">å‘é‡æ•°æ®åº“-ç´¢å¼•æ–¹å¼ [7]</a></li>
<li><a href="#%E5%90%91%E9%87%8F%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%AE%97%E6%B3%953">å‘é‡çš„ç›¸ä¼¼åº¦ç®—æ³•[3]</a><ul>
<li><a href="#%E6%AF%94%E8%BE%834">æ¯”è¾ƒ[4]</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">å‚è€ƒ</a></li>
</ul>
<!-- tocstop -->

</div>


  
<h1><span id="å‘é‡æ•°æ®åº“">å‘é‡æ•°æ®åº“</span><a href="#å‘é‡æ•°æ®åº“" class="header-anchor">#</a></h1><ul>
<li><p>å›½äº§</p>
<ul>
<li>Milvus</li>
<li>Tencent </li>
<li>zilliz cloud</li>
</ul>
</li>
<li><p>å›½å¤–</p>
<ul>
<li>Pinecone</li>
<li>FAISS<br>[ANN]</li>
<li>Chroma</li>
<li>Weaviate</li>
</ul>
</li>
</ul>
<h1><span id="å‘é‡æ•°æ®åº“-ç´¢å¼•æ–¹å¼-7">å‘é‡æ•°æ®åº“-ç´¢å¼•æ–¹å¼ [7]</span><a href="#å‘é‡æ•°æ®åº“-ç´¢å¼•æ–¹å¼-7" class="header-anchor">#</a></h1><img src="/www6vHomeAIGC/2022/11/27/gptVectorStore/index.jpg" class>

<h1><span id="å‘é‡çš„ç›¸ä¼¼åº¦ç®—æ³•3">å‘é‡çš„ç›¸ä¼¼åº¦ç®—æ³•[3]</span><a href="#å‘é‡çš„ç›¸ä¼¼åº¦ç®—æ³•3" class="header-anchor">#</a></h1><ul>
<li>Cosine Similarity *<br>ä½™å¼¦</li>
<li>Dot Product *</li>
<li>Squared Euclidean (L2-Squared) *<br>æ¬§å¼è·ç¦»</li>
<li>Manhattan (L1 Norm or Taxicab Distance) *</li>
<li>Hamming *</li>
<li>ANN</li>
</ul>
<h3><span id="æ¯”è¾ƒ4">æ¯”è¾ƒ[4]</span><a href="#æ¯”è¾ƒ4" class="header-anchor">#</a></h3><table>
<thead>
<tr>
<th>Similarity Metric</th>
<th>Vector properties considered</th>
</tr>
</thead>
<tbody><tr>
<td>Euclidean distance</td>
<td>Magnitudes and direction</td>
</tr>
<tr>
<td>Cosine similarity</td>
<td>Only direction</td>
</tr>
<tr>
<td>Dot product similarity</td>
<td>Magnitudes and direction</td>
</tr>
</tbody></table>
<h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://zhuanlan.zhihu.com/p/476025527">äº‘åŸç”Ÿå‘é‡æ•°æ®åº“Milvusæ‰«ç›²ï¼Œçœ‹å®Œè¿™ç¯‡å°±å¤Ÿäº†</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/477231485">äº‘åŸç”Ÿå‘é‡æ•°æ®åº“Milvusï¼ˆäºŒï¼‰-æ•°æ®ä¸ç´¢å¼•çš„å¤„ç†æµç¨‹ã€ç´¢å¼•ç±»å‹åŠSchema</a></p>
</li>
<li><p><a href="https://weaviate.io/blog/distance-metrics-in-vector-search?ref=blog.langchain.dev">Distance Metrics in Vector Search</a></p>
</li>
<li><p><a href="https://www.pinecone.io/learn/vector-similarity/">Vector Similarity Explained</a></p>
</li>
<li><p>xxx</p>
</li>
<li><p>xxx</p>
</li>
<li><p><a href="https://www.modb.pro/db/1694527960317513728">å‘é‡æ•°æ®åº“ï¼ˆç¬¬ 1 éƒ¨åˆ†ï¼‰ï¼šæ¯ä¸ªæ•°æ®åº“æœ‰ä½•ä¸åŒï¼Ÿ</a></p>
</li>
</ol>
<p>1xx. <a href="https://cloud.tencent.com/developer/article/2352088">å¾®ä¿¡å‘é‡æ£€ç´¢åˆ†æä¸€ä½“åŒ–æ•°ä»“æ¢ç´¢ï¼šOLAP For Embedding</a> *** </p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/646832642">Metaå‘é‡æ•°æ®åº“Faissä»‹ç»</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>å‘é‡æ•°æ®åº“</category>
      </categories>
      <tags>
        <tag>å‘é‡æ•°æ®åº“</tag>
      </tags>
  </entry>
  <entry>
    <title>Query Transformation</title>
    <url>/www6vHomeAIGC/2023/04/20/gptQueryTransformation/</url>
    <content><![CDATA[<p></p>
<span id="more"></span>

<h1><span id="query-rewrite-12">query rewrite [1][2]</span><a href="#query-rewrite-12" class="header-anchor">#</a></h1><p><a href="https://arxiv.org/pdf/2305.14283.pdf">è®ºæ–‡</a><strong>ä½¿ç”¨LLMé‡å†™ç”¨æˆ·æŸ¥è¯¢</strong>ï¼Œè€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨åŸå§‹ç”¨æˆ·æŸ¥è¯¢è¿›è¡Œæ£€ç´¢ã€‚<br>å› ä¸ºå¯¹äºLLM è€Œè¨€ï¼Œ<strong>åŸå§‹æŸ¥è¯¢ä¸å¯èƒ½æ€»æ˜¯æœ€ä½³æ£€ç´¢ç»“æœ</strong>ï¼Œå¯ä»¥è®©LLMé‡å†™æŸ¥è¯¢ã€‚</p>
<p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/rewrite.ipynb">Repo</a> git<br>ã€é—®é¢˜çš„å¤šæ ·åŒ–ã€‘</p>
<h1><span id="step-back-prompting-12">Step-back Prompting [1][2]</span><a href="#step-back-prompting-12" class="header-anchor">#</a></h1><p><a href="https://arxiv.org/pdf/2310.06117.pdf">è®ºæ–‡</a>ä½¿ç”¨é€€ä¸€æ­¥æç¤ºï¼Œä½¿ç”¨LLMç”Ÿæˆ**â€åé€€â€(Step back prompting)é—®é¢˜**ã€‚<br>ä½¿ç”¨æ£€ç´¢æ—¶ï¼Œâ€åé€€â€é—®é¢˜å’ŒåŸå§‹é—®é¢˜éƒ½ä¼šè¢«ç”¨æ¥è¿›è¡Œæ£€ç´¢ï¼Œç„¶åè¿™ä¸¤ä¸ªç»“æœéƒ½ä¼šè¢«ç”¨æ¥ä½œä¸ºè¯­è¨€æ¨¡å‹å›å¤çš„åŸºç¡€ã€‚</p>
<p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/stepback-qa.ipynb">Repo</a> git</p>
<p>ã€é—®é¢˜çš„æŠ½è±¡åŒ–ã€‘</p>
<h1><span id="hyde">HyDE</span><a href="#hyde" class="header-anchor">#</a></h1><h1><span id="å‚è€ƒ">å‚è€ƒ</span><a href="#å‚è€ƒ" class="header-anchor">#</a></h1><ol>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&mid=2648406156&idx=1&sn=d91a4df105c4fc4c9523f7141bc1c24d">çŸ¥è¯†å›¾è°±ç”¨äºç»†ç²’åº¦å¤§æ¨¡å‹å¹»è§‰è¯„ä¼°ï¼šå…¼è®ºLangchain-RAGé—®ç­”ä¸­çš„é—®é¢˜æ”¹å†™èŒƒå¼ </a><br>  RAG:  rewrite , Step back prompting, fusion </p>
</li>
<li><p><a href="https://blog.langchain.dev/query-transformations/">Query Transformations</a></p>
</li>
</ol>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/393914267">ä¸šç•Œæ€»ç»“ï½œæœç´¢ä¸­çš„Queryç†è§£</a> ***</p>
<p>1xx. <a href="https://zhuanlan.zhihu.com/p/149429784">æ™ºèƒ½æ‰©å……æœºå™¨äººçš„â€œæ ‡å‡†é—®â€åº“ä¹‹Queryç”Ÿæˆ</a></p>
]]></content>
      <categories>
        <category>AIGC</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>RAG</tag>
      </tags>
  </entry>
</search>
