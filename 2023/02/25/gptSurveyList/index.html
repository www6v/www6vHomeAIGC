<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/www6vHomeAIGC/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/www6vHomeAIGC/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/www6vHomeAIGC/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/www6vHomeAIGC/images/logo.svg" color="#222">

<link rel="stylesheet" href="/www6vHomeAIGC/css/main.css">


<link rel="stylesheet" href="/www6vHomeAIGC/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www6v.github.io","root":"/www6vHomeAIGC/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="article">
<meta property="og:title" content="Survey List">
<meta property="og:url" content="https://www6v.github.io/2023/02/25/gptSurveyList/index.html">
<meta property="og:site_name" content="www6v的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-02-25T14:57:12.000Z">
<meta property="article:modified_time" content="2024-03-14T02:14:06.126Z">
<meta property="article:author" content="Wang Wei">
<meta property="article:tag" content="paper">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www6v.github.io/2023/02/25/gptSurveyList/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Survey List | www6v的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/www6vHomeAIGC/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">www6v的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录技术点滴</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/www6vHomeAIGC/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/www6vHomeAIGC/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/www6vHomeAIGC/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/www6vHomeAIGC/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www6v.github.io/2023/02/25/gptSurveyList/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/www6vHomeAIGC/images/avatar.gif">
      <meta itemprop="name" content="Wang Wei">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="www6v的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Survey List
        </h1>

        <div class="post-meta">





          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-02-25 22:57:12" itemprop="dateCreated datePublished" datetime="2023-02-25T22:57:12+08:00">2023-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-14 10:14:06" itemprop="dateModified" datetime="2024-03-14T10:14:06+08:00">2024-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/www6vHomeAIGC/categories/AIGC/" itemprop="url" rel="index"><span itemprop="name">AIGC</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/www6vHomeAIGC/categories/AIGC/paper/" itemprop="url" rel="index"><span itemprop="name">paper</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p></p>
<span id="more"></span>

<h1><span id="awesome-llm-survey">Awesome-LLM-Survey</span><a href="#awesome-llm-survey" class="header-anchor">#</a></h1><ul>
<li><a href="#awesome-llm-survey">Awesome-LLM-Survey</a><ul>
<li><p><a href="#general-survey">General Survey</a> *** </p>
</li>
<li><p><a href="#training-of-llm">Training of LLM</a></p>
<ul>
<li><a href="#instruction-tuning">Instruction Tuning</a> *** </li>
<li><a href="#human-alignment-for-llm">Human Alignment for LLM</a> *</li>
</ul>
</li>
<li><p><a href="#prompt-of-llm">Prompt of LLM</a></p>
<ul>
<li><a href="#chain-of-thought-for-llm">Chain of Thought for LLM</a> *** </li>
<li><a href="#prompt-engineering-for-llm">Prompt Engineering for LLM</a> * </li>
<li><a href="#retrieval-augmented-llm">Retrieval-Augmented LLM</a> ***</li>
</ul>
</li>
<li><p><a href="#challenge-of-llm">Challenge of LLM</a></p>
<ul>
<li><p><a href="#hallucination-in-llm">Hallucination in LLM</a> ***</p>
</li>
<li><p><a href="#compression-for-llm">Compression for LLM</a> ***</p>
</li>
<li><p><a href="#evaluation-of-llm">Evaluation of LLM</a></p>
</li>
<li><p><a href="#reasoning-with-llm">Reasoning with LLM</a></p>
</li>
<li><p><a href="#long-context-for-llm">Long-Context for LLM</a></p>
</li>
<li><p><a href="#factuality-in-llm">Factuality in LLM</a></p>
</li>
<li><p><a href="#knowledge-for-llm">Knowledge for LLM</a></p>
</li>
<li><p><a href="#self-correction-for-llm">Self-Correction for LLM</a></p>
</li>
<li><p><a href="#tool-using-of-llm">Tool Using of LLM</a> ***</p>
</li>
<li><p><a href="#agent-of-llm">Agent of LLM</a> ***</p>
</li>
<li><p><a href="#efficiency-of-llm">Efficiency of LLM</a> *** </p>
</li>
<li><p><a href="#data-of-llm">Data of LLM</a> ***</p>
</li>
<li><p><a href="#continual-learning-of-llm">Continual Learning of LLM</a></p>
</li>
</ul>
</li>
<li><p><a href="#mulitmodal-of-llm">Mulitmodal of LLM</a></p>
<ul>
<li><a href="#visual-llm">Visual LLM</a></li>
</ul>
</li>
<li><p><a href="#llm-for-domain-application">LLM for Domain Application</a></p>
<ul>
<li><a href="#llm-for-health">LLM for Health</a></li>
<li><a href="#llm-for-finance">LLM for Finance</a> ***</li>
<li><a href="#llm-for-education">LLM for Education</a></li>
<li><a href="#llm-for-law">LLM for Law</a></li>
<li><a href="#llm-for-mental-health">LLM for Mental Health</a></li>
</ul>
</li>
<li><p><a href="#llm-for-downstream-tasks">LLM for Downstream Tasks</a></p>
<ul>
<li><p><a href="#llm-for-recommendation">LLM for Recommendation</a></p>
</li>
<li><p><a href="#llm-for-information-retrieval">LLM for Information Retrieval</a></p>
</li>
<li><p><a href="#llm-for-software-engineering">LLM for Software Engineering</a></p>
</li>
<li><p><a href="#llm-for-time-series">LLM for Time Series</a></p>
</li>
<li><p><a href="#detection-of-llms-generated-content">Detection of LLMs-Generated Content</a></p>
</li>
<li><p><a href="#llm-for-information-extraction">LLM for Information Extraction</a></p>
</li>
</ul>
</li>
<li><p><a href="#star-history">Star History</a></p>
</li>
</ul>
</li>
</ul>
<hr>
<h2><span id="general-survey">General Survey</span><a href="#general-survey" class="header-anchor">#</a></h2><ul>
<li><p>Challenges and Applications of Large Language Models, 2023.07 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.10169">[paper]</a> *** </p>
</li>
<li><p>A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT, 2023.02 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2302.09419">[paper]</a> ***</p>
</li>
<li><p>A Survey of Large Language Models, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.18223">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/RUCAIBox/LLMSurvey">[project]</a>  ***</p>
</li>
<li><p>A Comprehensive Overview of Large Language Models *</p>
</li>
<li><p>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</p>
</li>
<li><p>Pre-Trained Models: Past, Present and Future</p>
</li>
<li><p>A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.12321.pdf">[paper]</a></p>
</li>
<li><p>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond, 2023.04  <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.13712">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/Mooler0410/LLMsPracticalGuide">[project]</a></p>
</li>
<li><p>Large language models: a comprehensive survey of its applications, challenges, limitations, and future prospects, 2023.12 <a target="_blank" rel="noopener" href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.23589741.v4">[paper]</a> <a target="_blank" rel="noopener" href="https://github.com/anas-zafar/LLM-Survey">[project]</a></p>
</li>
<li><p>The future of gpt: A taxonomy of existing chatgpt research, current challenges, and possible future directions, 2023.04 <a target="_blank" rel="noopener" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4413921">[paper]</a></p>
</li>
<li><p>A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges, 2023.10 <a target="_blank" rel="noopener" href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.24171183.v1">[paper]</a></p>
</li>
<li><p>Understanding LLMs: A Comprehensive Overview from Training to Inference, 2024.01 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.02038.pdf">[paper]</a></p>
</li>
</ul>
<hr>
<h2><span id="training-of-llm">Training of LLM</span><a href="#training-of-llm" class="header-anchor">#</a></h2><h3><span id="instruction-tuning">Instruction Tuning</span><a href="#instruction-tuning" class="header-anchor">#</a></h3><ul>
<li>Are Prompts All the Story? No. A Comprehensive and Broader View of Instruction Learning, 2023.03 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.10475.pdf">[paper]</a> <a target="_blank" rel="noopener" href="https://github.com/RenzeLou/awesome-instruction-learning">[project]</a></li>
<li>Vision-Language Instruction Tuning: A Review and Analysis, 2023,11 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.08172">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/palchenli/VL-Instruction-Tuning">[project]</a></li>
<li>Instruction Tuning for Large Language Models: A Survey, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.10792">[paper]</a>  ***</li>
</ul>
<h3><span id="human-alignment-for-llm">Human Alignment for LLM</span><a href="#human-alignment-for-llm" class="header-anchor">#</a></h3><ul>
<li><p>AI Alignment: A Comprehensive Survey, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.19852">[paper]</a><a target="_blank" rel="noopener" href="https://www.alignmentsurvey.com/">[project]</a></p>
</li>
<li><p>Large Language Model Alignment: A Survey, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.15025">[paper]</a></p>
</li>
<li><p>From Instructions to Intrinsic Human Values – A Survey of Alignment Goals for Big Model, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.12014">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/ValueCompass/Alignment-Goal-Survey">[project]</a></p>
</li>
<li><p>Aligning Large Language Models with Human: A Survey, 2023.07 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.12966">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/GaryYufei/AlignLLMHumanSurvey">[project]</a> ***</p>
</li>
</ul>
<hr>
<h2><span id="prompt-of-llm">Prompt of LLM</span><a href="#prompt-of-llm" class="header-anchor">#</a></h2><h3><span id="chain-of-thought-for-llm">Chain of Thought for LLM</span><a href="#chain-of-thought-for-llm" class="header-anchor">#</a></h3><ul>
<li><p>Towards Better Chain-of-Thought Prompting Strategies: A Survey, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.04959.pdf">[paper]</a></p>
</li>
<li><p>A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.06256">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/zchuz/CoT-Reasoning-Survey">[project]</a></p>
</li>
<li><p>Igniting Language Intelligence: The Hitchhiker’s Guide From Chain-of-Thought Reasoning to Language Agents, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.11797.pdf">[paper]</a> <a target="_blank" rel="noopener" href="https://github.com/Zoeyyao27/CoT-Igniting-Agent">[project]</a></p>
</li>
</ul>
<h3><span id="prompt-engineering-for-llm">Prompt Engineering for LLM</span><a href="#prompt-engineering-for-llm" class="header-anchor">#</a></h3><ul>
<li><p>Prompting Frameworks for Large Language Models: A Survey, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.12785.pdf">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/lxx0628/Prompting-Framework-Survey">[project]</a></p>
</li>
<li><p>Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.14735.pdf">[paper]</a></p>
</li>
<li><p>Towards Better Chain-of-Thought Prompting Strategies: A Survey, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.04959.pdf">[paper]</a></p>
</li>
</ul>
<h3><span id="retrieval-augmented-llm">Retrieval-Augmented LLM</span><a href="#retrieval-augmented-llm" class="header-anchor">#</a></h3><ul>
<li><p>Retrieving Multimodal Information for Augmented Generation: A Survey  *** </p>
</li>
<li><p>Retrieval-Augmented Generation for AI-Generated Content: A Survey *** </p>
</li>
<li><p>A Survey on Retrieval-Augmented Text Generation, 2022.02 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2202.01110">[paper]</a></p>
</li>
<li><p>Retrieval-Augmented Generation for Large Language Models: A Survey, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.10997.pdf">[paper]</a> <a target="_blank" rel="noopener" href="https://github.com/Tongji-KGLLM/RAG-Survey">[project]</a> ***</p>
</li>
</ul>
<hr>
<h2><span id="challenge-of-llm">Challenge of LLM</span><a href="#challenge-of-llm" class="header-anchor">#</a></h2><h3><span id="hallucination-in-llm">Hallucination in LLM</span><a href="#hallucination-in-llm" class="header-anchor">#</a></h3><ul>
<li><p>Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.07914">[paper]</a></p>
</li>
<li><p>A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.05232">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/LuckyyySTA/Awesome-LLM-hallucination">[project]</a> ***</p>
</li>
<li><p>A Survey of Hallucination in “Large” Foundation Models, 2023.09  <a target="_blank" rel="noopener" href="https://arxiv.org/paper/2309.05922">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/vr25/hallucination-foundation-model-survey">[project]</a></p>
</li>
<li><p>Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.01219">[paper]</a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.01219">[project]</a></p>
</li>
<li><p>Cognitive Mirage: A Review of Hallucinations in Large Language Models, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/paper/2309.06794.paper">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/hongbinye/Cognitive-Mirage-Hallucinations-in-LLMs">[project]</a></p>
</li>
<li><p>Augmenting LLMs with Knowledge: A survey on hallucination prevention, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.16459.pdf">[paper]</a></p>
</li>
<li><p>A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models, 2024.01 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.01313.pdf">[paper]</a></p>
</li>
<li><p>Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models’ Alignment, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.05374">[paper]</a></p>
</li>
</ul>
<h3><span id="compression-for-llm">Compression for LLM</span><a href="#compression-for-llm" class="header-anchor">#</a></h3><ul>
<li>A Survey on Model Compression for Large Language Models, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.07633">[paper]</a>  ***</li>
<li>A Comprehensive Survey of Compression Algorithms for Language Models, 2024.01 [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.15347.pdf">paper</a>]</li>
</ul>
<h3><span id="evaluation-of-llm">Evaluation of LLM</span><a href="#evaluation-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Evaluating Large Language Models: A Comprehensive Survey, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.19736.pdf">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers">[project]</a> ***</p>
</li>
<li><p>A Survey on Evaluation of Large Language Models, 2023.07 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.03109">[paper]</a><a target="_blank" rel="noopener" href="https://llm-eval.github.io/">[project]</a> ***</p>
</li>
</ul>
<h3><span id="reasoning-with-llm">Reasoning with LLM</span><a href="#reasoning-with-llm" class="header-anchor">#</a></h3><ul>
<li><p>Reasoning with Language Model Prompting: A Survey, 2022.12 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2212.09597">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/zjunlp/Prompt4ReasoningPapers">[project]</a></p>
</li>
<li><p>A Survey of Reasoning with Foundation Models, 2023.12 [[papaer]] (<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.11562.pdf)[[project]](https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models)">https://arxiv.org/pdf/2312.11562.pdf)[[project]](https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models)</a> ***</p>
</li>
</ul>
<h3><span id="long-context-for-llm">Long-Context for LLM</span><a href="#long-context-for-llm" class="header-anchor">#</a></h3><ul>
<li>Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.12351">[paper]</a></li>
<li>Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.17044">[paper]</a></li>
</ul>
<h3><span id="factuality-in-llm">Factuality in LLM</span><a href="#factuality-in-llm" class="header-anchor">#</a></h3><ul>
<li><p>A Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.07521">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/wangcunxiang/LLM-Factuality-Survey">[project]</a></p>
</li>
<li><p>Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.16570.pdf">[paper]</a></p>
</li>
</ul>
<h3><span id="knowledge-for-llm">Knowledge for LLM</span><a href="#knowledge-for-llm" class="header-anchor">#</a></h3><ul>
<li><p>Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.15766">[paper]</a></p>
</li>
<li><p>Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.05876.pdf">[paper]</a></p>
</li>
<li><p>Knowledge Editing for Large Language Models: A Survey, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.16218.pdf">[paper]</a></p>
</li>
<li><p>Editing Large Language Models: Problems, Methods, and Opportunities, 2023.05 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.13172">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/zjunlp/EasyEdit">[project]</a></p>
</li>
<li><p>Building trust in conversational ai: A comprehensive review and solution architecture for explainable, privacy-aware systems using llms and knowledge graph, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2308.13534.pdf">[paper]</a></p>
</li>
</ul>
<h3><span id="self-correction-for-llm">Self-Correction for LLM</span><a href="#self-correction-for-llm" class="header-anchor">#</a></h3><ul>
<li>Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.03188">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/teacherpeterpan/self-correction-llm-papers">[project]</a></li>
</ul>
<h3><span id="tool-using-of-llm">Tool Using of LLM</span><a href="#tool-using-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Foundation Models for Decision Making: Problems, Methods, and Opportunities, 2023.03 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.04129">[paper]</a></p>
</li>
<li><p>Augmented Language Models: a Survey, 2023.02 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2302.07842">[paper]</a> ***</p>
</li>
<li><p>Tool Learning with Foundation Models</p>
</li>
</ul>
<h3><span id="agent-of-llm">Agent of LLM</span><a href="#agent-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Understanding the planning of LLM agents: A survey, 2024 </p>
</li>
<li><p>A Survey on Large Language Model based Autonomous Agents, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.11432">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/Paitesanshi/LLM-Agent-Survey">[project]</a> ***</p>
</li>
<li><p>The Rise and Potential of Large Language Model Based Agents: A Survey, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.07864">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/WooooDyy/LLM-Agent-Paper-List">[project]</a> ***</p>
</li>
<li><p>Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.11970.pdf">[paper]</a></p>
</li>
</ul>
<h3><span id="efficiency-of-llm">Efficiency of LLM</span><a href="#efficiency-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning ***</p>
</li>
<li><p>The Power of Scale for Parameter-Efficient Prompt Tuning</p>
</li>
<li><p>Efficient Large Language Models: A Survey, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.03863">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey">[project]</a> ***</p>
</li>
<li><p>The Efficiency Spectrum of Large Language Models: An Algorithmic Survey, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.10844.pdf">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/tding1/Efficient-LLM-Survey">[project]</a></p>
</li>
<li><p>Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.12148.pdf">[paper]</a></p>
</li>
<li><p>A Survey on Hardware Accelerators for Large Language Models, 2024.01 [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.09890.pdf">paper</a>]</p>
</li>
</ul>
<h3><span id="data-of-llm">Data of LLM</span><a href="#data-of-llm" class="header-anchor">#</a></h3><ul>
<li><p>Data Management For Large Language Models: A Survey, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.01700">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/ZigeW/data_management_LLM">[project]</a></p>
</li>
<li><p>Data-centric Artificial Intelligence: A Survey</p>
</li>
</ul>
<h3><span id="continual-learning-of-llm">Continual Learning of LLM</span><a href="#continual-learning-of-llm" class="header-anchor">#</a></h3><ul>
<li>Continual Learning with Pre-Trained Models: A Survey, 2024.01 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.16386">[paper]</a> <a target="_blank" rel="noopener" href="https://github.com/sun-hailong/LAMDA-PILOT">[project]</a></li>
</ul>
<hr>
<h2><span id="mulitmodal-of-llm">Mulitmodal of LLM</span><a href="#mulitmodal-of-llm" class="header-anchor">#</a></h2><h3><span id="visual-llm">Visual LLM</span><a href="#visual-llm" class="header-anchor">#</a></h3><ul>
<li><p>An Empirical Study of Training End-to-End Vision-and-Language Transformers, 2022.03 *** microsoft +</p>
</li>
<li><p>Multimodal Foundation Models: From Specialists to General-Purpose Assistants, 2023.09 *** microsoft +</p>
</li>
<li><p>Foundational Models Defining a New Era in Vision: A Survey and Outlook, 2023.07 ***  大学 +</p>
</li>
<li><p>MM-LLMs: Recent Advances in MultiModal Large Language Models, 2024.02 *** 腾讯  +</p>
</li>
<li><p>Vision-Language Instruction Tuning: A Review and Analysis, 2023,11 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.08172">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/palchenli/VL-Instruction-Tuning">[project]</a> *** + </p>
</li>
<li><p>How to Bridge the Gap between Modalities: A Comprehensive Survey on Multimodal Large Language Model, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.07594.pdf">[paper]</a> *</p>
</li>
<li><p>A Survey on Multimodal Large Language Models, 2023.06  <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.13549">[paper]</a> <a target="_blank" rel="noopener" href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models">[project]</a> ***</p>
</li>
<li><p>Multimodal Large Language Models: A Survey, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.13165.pdf">[paper]</a> **</p>
</li>
<li><p>Large Language Models Meet Computer Vision: A Brief Survey, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.16673.pdf">[paper]</a> *</p>
</li>
<li><p>Foundational Models Defining a New Era in Vision: A Survey and Outlook, 2023.07 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2307.13721.pdf">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/awaisrauf/Awesome-CV-Foundational-Models">[project]</a> ***  + </p>
</li>
<li><p>Video Understanding with Large Language Models: A Survey, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.17432.pdf">[paper]</a> <a target="_blank" rel="noopener" href="https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding">[project]</a></p>
</li>
</ul>
<hr>
<h2><span id="llm-for-domain-application">LLM for Domain Application</span><a href="#llm-for-domain-application" class="header-anchor">#</a></h2><h3><span id="domain">domain</span><a href="#domain" class="header-anchor">#</a></h3><ul>
<li>Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey</li>
</ul>
<h3><span id="llm-for-health">LLM for Health</span><a href="#llm-for-health" class="header-anchor">#</a></h3><ul>
<li><p>A Survey of Large Language Models in Medicine: Progress, Application, and Challenge, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.05112">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/AI-in-Health/MedLLMsPracticalGuide">[project]</a></p>
</li>
<li><p>Large Language Models Illuminate a Progressive Pathway to Artificial  Healthcare Assistant: A Review, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.01918">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/mingze-yuan/Awesome-LLM-Healthcare">[project]</a></p>
</li>
<li><p>Large AI Models in Health Informatics: Applications, Challenges, and the Future, 2023.03 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.11568">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/Jianing-Qiu/Awesome-Healthcare-Foundation-Models">[project]</a></p>
</li>
<li><p>A SWOT (Strengths, Weaknesses, Opportunities, and Threats) Analysis of ChatGPT in the Medical Literature: Concise Review, 2023.11 <a target="_blank" rel="noopener" href="https://www.jmir.org/2023/1/e49368/PDF">[paper]</a></p>
</li>
<li><p>ChatGPT in Healthcare: A Taxonomy and Systematic Review, 2023.03 <a target="_blank" rel="noopener" href="https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1">[paper]</a></p>
</li>
</ul>
<h3><span id="llm-for-finance">LLM for Finance</span><a href="#llm-for-finance" class="header-anchor">#</a></h3><ul>
<li><p>Large Language Models in Finance: A Survey, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.10723">[paper]</a></p>
</li>
<li><p>A Survey of Large Language Models in Finance (FinLLMs) ***</p>
</li>
</ul>
<h3><span id="llm-for-education">LLM for Education</span><a href="#llm-for-education" class="header-anchor">#</a></h3><ul>
<li>ChatGPT and Beyond: The Generative AI Revolution in Education, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.15198">[paper]</a></li>
</ul>
<h3><span id="llm-for-law">LLM for Law</span><a href="#llm-for-law" class="header-anchor">#</a></h3><ul>
<li>Large Language Models in Law: A Survey, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.03718">[paper]</a></li>
</ul>
<h3><span id="llm-for-mental-health">LLM for Mental Health</span><a href="#llm-for-mental-health" class="header-anchor">#</a></h3><ul>
<li>A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement, 2023.10 <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10601652/">[paper]</a></li>
<li>Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.04578.pdf">[paper]</a></li>
<li>Large Language Models in Mental Health Care: a Scoping Review, 2024.01 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.02984.pdf">[paper]</a></li>
</ul>
<hr>
<h2><span id="llm-for-downstream-tasks">LLM for Downstream Tasks</span><a href="#llm-for-downstream-tasks" class="header-anchor">#</a></h2><h3><span id="llm-for-recommendation">LLM for Recommendation</span><a href="#llm-for-recommendation" class="header-anchor">#</a></h3><ul>
<li>User Modeling in the Era of Large Language Models: Current Research and Future Directions, 2023.12 <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2312.11518">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/TamSiuhin/LLM-UM-Reading">[project]</a></li>
<li>A Survey on Large Language Models for Personalized and Explainable  Recommendations, 2023.11 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.12338">[paper]</a></li>
<li>Large Language Models for Generative Recommendation: A Survey and Visionary Discussions, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.01157">[paper]</a></li>
<li>A Survey on Large Language Models for Recommendation, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.19860">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/WLiK/LLM4Rec-Awesome-Papers">[project]</a></li>
<li>How Can Recommender Systems Benefit from Large Language Models: A Survey, 2023.06 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.05817">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/CHIANGEL/Awesome-LLM-for-RecSys">[project]</a></li>
</ul>
<h3><span id="llm-for-information-retrieval">LLM for Information Retrieval</span><a href="#llm-for-information-retrieval" class="header-anchor">#</a></h3><ul>
<li>Large Language Models for Information Retrieval: A Survey, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.07107">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/RUC-NLPIR/LLM4IR-Survey">[project]</a></li>
</ul>
<h3><span id="llm-for-software-engineering">LLM for Software Engineering</span><a href="#llm-for-software-engineering" class="header-anchor">#</a></h3><ul>
<li>Large Language Models for Software Engineering: Survey and Open Problems, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.03533">[paper]</a></li>
<li>Large Language Models for Software Engineering: A Systematic Literature Review, 2023.08 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.10620">[paper]</a></li>
</ul>
<h3><span id="llm-for-time-series">LLM for Time Series</span><a href="#llm-for-time-series" class="header-anchor">#</a></h3><ul>
<li>Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.10196">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM">[project]</a></li>
</ul>
<h3><span id="detection-of-llms-generated-content">Detection of LLMs-Generated Content</span><a href="#detection-of-llms-generated-content" class="header-anchor">#</a></h3><ul>
<li>A Survey on Detection of LLMs-Generated Content, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.15654">[paper]</a><a target="_blank" rel="noopener" href="https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection">[project]</a></li>
<li>A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions, 2023.10 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.14724.pdf">[paper]</a><br><a target="_blank" rel="noopener" href="https://github.com/NLP2CT/LLM-generated-Text-Detection">[project]</a></li>
<li>Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text, 2023.09 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.07689.pdf">[paper]</a></li>
<li></li>
</ul>
<h3><span id="llm-for-information-extraction">LLM for Information Extraction</span><a href="#llm-for-information-extraction" class="header-anchor">#</a></h3><ul>
<li>Large Language Models for Generative Information Extraction: A Survey, 2023.12 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.17617.pdf">[paper]</a> <a target="_blank" rel="noopener" href="https://github.com/quqxui/Awesome-LLM4IE-Papers">[project]</a></li>
</ul>
<h1><span id="参考">参考</span><a href="#参考" class="header-anchor">#</a></h1><p><a target="_blank" rel="noopener" href="https://github.com/www6v/Awesome-LLM-Survey">Awesome-LLM-Survey</a></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Wang Wei
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://www6v.github.io/2023/02/25/gptSurveyList/" title="Survey List">https://www6v.github.io/2023/02/25/gptSurveyList/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/www6vHomeAIGC/tags/paper/" rel="tag"># paper</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/www6vHomeAIGC/2023/02/24/gptLlamaFamily/" rel="prev" title="LLaMA 家族">
      <i class="fa fa-chevron-left"></i> LLaMA 家族
    </a></div>
      <div class="post-nav-item">
    <a href="/www6vHomeAIGC/2023/02/26/gptTrainTokenizer/" rel="next" title="Tokenizer">
      Tokenizer <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Wang Wei</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/www6vHomeAIGC/archives/">
        
          <span class="site-state-item-count">166</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/www6vHomeAIGC/categories/">
          
        <span class="site-state-item-count">63</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/www6vHomeAIGC/tags/">
          
        <span class="site-state-item-count">56</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/www6v" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;www6v" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:www6v@126.com" title="E-Mail → mailto:www6v@126.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wang Wei</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/www6vHomeAIGC/lib/anime.min.js"></script>
  <script src="/www6vHomeAIGC/lib/velocity/velocity.min.js"></script>
  <script src="/www6vHomeAIGC/lib/velocity/velocity.ui.min.js"></script>

<script src="/www6vHomeAIGC/js/utils.js"></script>

<script src="/www6vHomeAIGC/js/motion.js"></script>


<script src="/www6vHomeAIGC/js/schemes/muse.js"></script>


<script src="/www6vHomeAIGC/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/www6vHomeAIGC/js/local-search.js"></script>













  

  

</body>
</html>
