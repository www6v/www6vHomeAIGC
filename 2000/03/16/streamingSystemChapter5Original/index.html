<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/www6vHomeHexo/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/www6vHomeHexo/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/www6vHomeHexo/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/www6vHomeHexo/images/logo.svg" color="#222">

<link rel="stylesheet" href="/www6vHomeHexo/css/main.css">


<link rel="stylesheet" href="/www6vHomeHexo/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www6v.github.io","root":"/www6vHomeHexo/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="article">
<meta property="og:title" content="《Streaming System》-Chapter 5. Exactly-Once and Side Effects [完整]">
<meta property="og:url" content="https://www6v.github.io/www6vHomeHexo/2000/03/16/streamingSystemChapter5Original/index.html">
<meta property="og:site_name" content="www6v的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2000-03-16T11:27:27.000Z">
<meta property="article:modified_time" content="2023-04-21T02:11:12.992Z">
<meta property="article:author" content="Wang Wei">
<meta property="article:tag" content="Streaming System">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www6v.github.io/www6vHomeHexo/2000/03/16/streamingSystemChapter5Original/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>《Streaming System》-Chapter 5. Exactly-Once and Side Effects [完整] | www6v的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/www6vHomeHexo/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">www6v的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录技术点滴</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/www6vHomeHexo/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/www6vHomeHexo/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/www6vHomeHexo/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/www6vHomeHexo/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www6v.github.io/www6vHomeHexo/2000/03/16/streamingSystemChapter5Original/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/www6vHomeHexo/images/avatar.gif">
      <meta itemprop="name" content="Wang Wei">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="www6v的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《Streaming System》-Chapter 5. Exactly-Once and Side Effects [完整]
        </h1>

        <div class="post-meta">





          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2000-03-16 19:27:27" itemprop="dateCreated datePublished" datetime="2000-03-16T19:27:27+08:00">2000-03-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-21 10:11:12" itemprop="dateModified" datetime="2023-04-21T10:11:12+08:00">2023-04-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/www6vHomeHexo/categories/Streaming-System/" itemprop="url" rel="index"><span itemprop="name">Streaming System</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p></p>
<span id="more"></span>

<h2><span id="目录">目录</span><a href="#目录" class="header-anchor">#</a></h2><div class="toc">

<!-- toc -->

<ul>
<li><a href="#why-exactly-once-matters"><strong>Why Exactly Once Matters</strong></a></li>
<li><a href="#accuracy-versus-completeness"><strong>Accuracy Versus Completeness</strong></a><ul>
<li><a href="#side-effects"><strong>Side Effects</strong></a></li>
<li><a href="#problem-definition"><strong>Problem Definition</strong></a></li>
</ul>
</li>
<li><a href="#ensuring-exactly-once-in-shuffle"><strong>Ensuring Exactly Once in Shuffle</strong></a></li>
<li><a href="#addressing-determinism"><strong>Addressing Determinism</strong></a></li>
<li><a href="#performance"><strong>Performance</strong></a><ul>
<li><a href="#graph-optimization"><strong>Graph Optimization</strong></a></li>
<li><a href="#bloom-filters"><strong>Bloom Filters</strong></a></li>
<li><a href="#garbage-collection"><strong>Garbage Collection</strong></a></li>
</ul>
</li>
<li><a href="#exactly-once-in-sources"><strong>Exactly Once in Sources</strong></a></li>
<li><a href="#exactly-once-in-sinks"><strong>Exactly Once in Sinks</strong></a></li>
<li><a href="#use-cases"><strong>Use Cases</strong></a><ul>
<li><a href="#example-source-cloud-pubsub"><strong>Example Source: Cloud Pub&#x2F;Sub</strong></a></li>
<li><a href="#example-sink-files"><strong>Example Sink: Files</strong></a></li>
<li><a href="#example-sink-google-bigquery"><strong>Example Sink: Google BigQuery</strong></a></li>
</ul>
</li>
<li><a href="#other-systems"><strong>Other Systems</strong></a><ul>
<li><a href="#apache-spark-streaming"><strong>Apache Spark Streaming</strong></a></li>
<li><a href="#apache-flink"><strong>Apache Flink</strong></a></li>
</ul>
</li>
<li><a href="#summary"><strong>Summary</strong></a></li>
</ul>
<!-- tocstop -->

</div>

<p>Page 127</p>
<details><summary>点击 原文</summary><p>We now shift from discussing programming models and APIs to the systems</p>
<p>that implement them. A model and API allows users to describe what they</p>
<p>want to compute. Actually running the computation accurately at scale</p>
<p>requires a system—usually a distributed system.</p>
<p>In this chapter, we focus on how an implementing system can correctly</p>
<p>implement the Beam Model to produce accurate results. Streaming systems</p>
<p>often talk about <em>exactly-once processing</em>; that is, ensuring that every record is</p>
<p>processed exactly one time. We will explain what we mean by this, and how</p>
<p>it might be implemented.</p>
<p>As a motivating example, this chapter focuses on techniques used by Google</p>
<p>Cloud Dataflow to efficiently guarantee exactly-once processing of records.</p>
<p>Toward the end of the chapter, we also look at techniques used by some other</p>
<p>popular streaming systems to guarantee exactly once.</p>
</details>


<details><summary>点击 原文</summary><h1><span id="why-exactly-once-matters"><strong>Why Exactly Once Matters</strong></span><a href="#why-exactly-once-matters" class="header-anchor">#</a></h1><p>It almost goes without saying that for many users, any risk of dropped records</p>
<p>or data loss in their data processing pipelines is unacceptable. Even so,</p>
<p>historically many general-purpose streaming systems made no guarantees</p>
<p>about record processing—all processing was “best effort” only. Other systems</p>
<p>provided at-least-once guarantees, ensuring that records were always</p>
<p>processed at least once, but records might be duplicated (and thus result in</p>
<p>inaccurate aggregations); in practice, many such at-least-once systems</p>
<p>performed aggregations in memory, and thus their aggregations could still be</p>
<p>lost when machines crashed. These systems were used for low-latency,</p>
<p>speculative results but generally could guarantee nothing about the veracity of</p>
<p>these results.</p>
<p>As Chapter 1 points out, this led to a strategy that was coined the <em>Lambda</em></p>
<p><em>Architecture</em>—run a streaming system to get fast, but inaccurate results.</p>
<p>Sometime later (often after end of day), a batch system runs to the correct</p>
<p>answer. This works only if the data stream is replayable; however, this was</p>
<p>true for enough data sources that this strategy proved viable. Nonetheless,</p>
<p>many people who tried this experienced a number of issues with the Lambda</p>
<p>Architecture:</p>
<ul>
<li>Inaccuracy</li>
</ul>
<p>Users tend to underestimate the impact of failures. They often assume that</p>
<p>a small percentage of records will be lost or duplicated (often based on</p>
<p>experiments they ran), and are shocked on that one bad day when 10% (or</p>
<p>more!) of records are lost or are duplicated. In a sense, such systems</p>
<p>provide only “half” a guarantee—and without a full one, anything is</p>
<p>possible.</p>
<ul>
<li>Inconsistency</li>
</ul>
<p>The batch system used for the end-of-day calculation often has different</p>
<p>data semantics than the streaming system. Getting the two pipelines to</p>
<p>produce comparable results proved more difficult than initially thought.</p>
<ul>
<li>Complexity</li>
</ul>
<p>By definition, Lambda requires you to write and maintain two different</p>
<p>codebases. You also must run and maintain two complex distributed</p>
<p>systems, each with different failure modes. For anything but the simplest</p>
<p>of pipelines, this quickly becomes overwhelming.</p>
<ul>
<li>Unpredictability</li>
</ul>
<p>In many use cases, end users will see streaming results that differ from the</p>
<p>daily results by an uncertain amount, which can change randomly. In</p>
<p>these cases, users will stop trusting the streaming data and wait for daily</p>
<p>batch results instead, thus destroying the value of getting low-latency</p>
<p>results in the first place.</p>
<ul>
<li>Latency</li>
</ul>
<p>Some business use cases <em>require</em> low-latency correct results, which the</p>
<p>Lambda Architecture does not provide by design.</p>
<p>Fortunately, many Beam runners can do much better. In this chapter, we</p>
<p>explain how exactly-once stream processing helps users count on accurate</p>
<p>results and avoid the risk of data loss while relying on a single codebase and</p>
<p>API. Because a variety of issues that can affect a pipeline’s output are often</p>
<p>erroneously conflated with exactly-once guarantees, we first explain precisely</p>
<p>which issues are in and out of scope when we refer to “exactly once” in the</p>
<p>context of Beam and data processing.</p>
</details>





<details><summary>点击 原文</summary><h1><span id="accuracy-versus-completeness"><strong>Accuracy Versus Completeness</strong></span><a href="#accuracy-versus-completeness" class="header-anchor">#</a></h1><p>Whenever a Beam pipeline processes a record for a pipeline, we want to</p>
<p>ensure that the record is never dropped or duplicated. However, the nature of</p>
<p>streaming pipelines is such that records sometimes show up late, after</p>
<p>aggregates for their time windows have already been processed. The Beam</p>
<p>SDK allows the user to configure how long the system should wait for late</p>
<p>data to arrive; any (and only) records arriving later than this deadline are</p>
<p>dropped. This feature contributes to <em>completeness</em>, not to accuracy: all records</p>
<p>that showed up in time for processing are accurately processed exactly once,</p>
<p>whereas these late records are explicitly dropped.</p>
<p>Although late records are usually discussed in the context of streaming</p>
<p>systems, it’s worth noting that batch pipelines have similar completeness</p>
<p>issues. For example, a common batch paradigm is to run a job at 2 AM over</p>
<p>all the previous day’s data. However, if some of yesterday’s data wasn’t</p>
<p>collected until after 2 AM, it won’t be processed by the batch job! Thus, batch</p>
<p>pipelines also provide accurate but not always complete results.</p>
<h3><span id="side-effects"><strong>Side Effects</strong></span><a href="#side-effects" class="header-anchor">#</a></h3><p>One characteristic of Beam and Dataflow is that users inject custom code that</p>
<p>is executed as part of their pipeline graph. Dataflow does <em>not</em> guarantee that</p>
<p>this code is run only once per record,  whether by the streaming or batch</p>
<p>runner. It might run a given record through a user transform multiple times, or</p>
<p>it might even run the same record simultaneously on multiple workers; this is</p>
<p>necessary to guarantee at-least-once processing in the face of worker failures.</p>
<p>Only one of these invocations can “win” and produce output further down the</p>
<p>pipeline.</p>
<p>As a result, nonidempotent side effects are not guaranteed to execute exactly</p>
<p>once; if you write code that has side effects external to the pipeline, such as</p>
<p>contacting an outside service, these effects might be executed more than once</p>
<p>for a given record. This situation is usually unavoidable because there is no</p>
<p>way to atomically commit Dataflow’s processing with the side effect on the</p>
<p>external service. Pipelines do need to eventually send results to the outside</p>
<p>world, and such calls might not be idempotent. As you will see later in the</p>
<p>chapter, often such sinks are able to add an extra stage to restructure the call</p>
<p>into an idempotent operation first.</p>
<h3><span id="problem-definition"><strong>Problem Definition</strong></span><a href="#problem-definition" class="header-anchor">#</a></h3><p>So, we’ve given a couple of examples of what we’re <em>not</em> talking about. What</p>
<p>do we mean then by exactly-once processing? To motivate this, let’s begin</p>
<p>with a simple streaming pipeline,  shown in Example 5-1.</p>
<p><em>Example 5-1. A simple streaming pipeline</em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Pipeline p = Pipeline.create(options);</span><br><span class="line">// Calculate 1-minute counts of events per user.</span><br><span class="line">PCollection&lt;..&gt; perUserCounts =</span><br><span class="line">p.apply(ReadFromUnboundedSource.read())</span><br><span class="line">.apply(new KeyByUser())</span><br><span class="line">.Window.&lt;..&gt;into(FixedWindows.of(Duration.standardMinutes(1)))</span><br><span class="line">.apply(Count.perKey());</span><br><span class="line">// Process these per-user counts, and write the output somewhere.</span><br><span class="line">perUserCounts.apply(new ProcessPerUserCountsAndWriteToSink());</span><br><span class="line">// Add up all these per-user counts to get 1-minute counts of all events.</span><br><span class="line">perUserCounts.apply(Values.&lt;..&gt;create())</span><br><span class="line">.apply(Count.globally())</span><br><span class="line">.apply(new ProcessGlobalCountAndWriteToSink());</span><br><span class="line">p.run();</span><br></pre></td></tr></table></figure>

<p>This pipeline computes two different windowed aggregations. The first counts</p>
<p>how many events came from each individual user over the course of a minute,</p>
<p>and the second counts how many total events came in each minute. Both</p>
<p>aggregations are written to unspecified streaming sinks.</p>
<p>Remember that Dataflow executes pipelines on many different workers in</p>
<p>parallel. After each GroupByKey (the Count operations use GroupByKey under</p>
<p>the covers), all records with the same key are processed on the same machine</p>
<p>following a process called <em>shuffle</em>. The Dataflow workers shuffle data</p>
<p>between themselves using Remote Procedure Calls (RPCs), ensuring that</p>
<p>records for a given key all end up on the same machine.</p>
<p>Figure 5-1 shows the shuffles that Dataflow creates for the pipeline in</p>
<p>Example 5-1.  The Count.perKey shuffles all the data for each user onto a</p>
<p>given worker, whereas the Count.globally shuffles all these partial counts</p>
<p>to a single worker to calculate the global sum.</p>
<p><em>Figure 5-1. Shuffles in a pipeline</em></p>
<p>For Dataflow to accurately process data, this shuffle process must ensure that</p>
<p>every record is shuffled exactly once. As you will see in a moment, the</p>
<p>distributed nature of shuffle makes this a challenging problem.</p>
<p>This pipeline also both reads and writes data from and to the outside world, so</p>
<p>Dataflow must ensure that this interaction does not introduce any</p>
<p>inaccuracies. Dataflow has always supported this task—what Apache Spark</p>
<p>and Apache Flink call <em>end-to-end exactly once</em>—for sources and sinks</p>
<p>whenever technically feasible.</p>
<p>The focus of this chapter will be on three things:</p>
<ul>
<li>Shuffle</li>
</ul>
<p>How Dataflow guarantees that every record is shuffled exactly once.</p>
<ul>
<li>Sources</li>
</ul>
<p>How Dataflow guarantees that every source record is processed exactly</p>
<p>once.</p>
<ul>
<li>Sinks</li>
</ul>
<p>How Dataflow guarantees that every sink produces accurate output.</p>
</details>





<details><summary>点击 原文</summary><h1><span id="ensuring-exactly-once-in-shuffle"><strong>Ensuring Exactly Once in Shuffle</strong></span><a href="#ensuring-exactly-once-in-shuffle" class="header-anchor">#</a></h1><p>As just explained, Dataflow’s streaming shuffle uses RPCs. Now, any time</p>
<p>you have two machines communicating via RPC, you should think long and</p>
<p>hard about data integrity. First of all, RPCs can fail for many reasons. The</p>
<p>network might be interrupted, the RPC might time out before completing, or</p>
<p>the receiving server might decide to fail the call. To guarantee that records are</p>
<p>not lost in shuffle, Dataflow employs <em>upstream backup</em>. This simply means</p>
<p>that the sender will retry RPCs until it receives positive acknowledgment of</p>
<p>receipt. Dataflow also ensures that it will continue retrying these RPCs even if</p>
<p>the sender crashes. This guarantees that every record is delivered <em>at least</em></p>
<p><em>once</em>.</p>
<p>Now, the problem is that these retries might themselves create duplicates.</p>
<p>Most RPC frameworks, including the one Dataflow uses, provide the sender</p>
<p>with a status indicating success or failure. In a distributed system, you need to</p>
<p>be aware that RPCs can sometimes succeed even when they have appeared to</p>
<p>fail. There are many reasons for this: race conditions with the RPC timeout,</p>
<p>positive acknowledgment from the server failing to transfer even though the</p>
<p>RPC succeeded, and so on. The only status that a sender can really trust is a</p>
<p>successful one.</p>
<p>An RPC returning a failure status generally indicates that the call might or</p>
<p>might not have succeeded. Although specific error codes can communicate</p>
<p>unambiguous failure, many common RPC failures, such as Deadline</p>
<p>Exceeded, are ambiguous. In the case of streaming shuffle, retrying an RPC</p>
<p>that really succeeded means delivering a record twice! Dataflow needs some</p>
<p>way of detecting and removing these duplicates.</p>
<p>At a high level, the algorithm for this task is quite simple (see Figure 5-2):</p>
<p>every message sent is tagged with a unique identifier. Each receiver stores a</p>
<p>catalog of all identifiers that have already been seen and processed. Every</p>
<p>time a record is received, its identifier is looked up in this catalog. If it is</p>
<p>found, the record is dropped as a duplicate. Because Dataflow is built on top</p>
<p>of a scalable key&#x2F;value store, this store is used to hold the deduplication</p>
<p>catalog.</p>
<p><em>Figure 5-2. Detecting duplicates in shuffle</em></p>
<h1><span id="addressing-determinism"><strong>Addressing Determinism</strong></span><a href="#addressing-determinism" class="header-anchor">#</a></h1><p>Making this strategy work in the real world requires a lot of care, however.</p>
<p>One immediate wrinkle is that the Beam Model allows for user code to</p>
<p>produce nondeterministic output. This means that a ParDo can execute twice</p>
<p>on the same input record (due to a retry), yet produce different output on each</p>
<p>retry. The desired behavior is that only one of those outputs will commit into</p>
<p>the pipeline; however, the nondeterminism involved makes it difficult to</p>
<p>guarantee that both outputs have the same deterministic ID. Even trickier, a</p>
<p>ParDo can output multiple records, so each of these retries might produce a</p>
<p>different number of outputs!</p>
<p>So, why don’t we simply require that all user processing be deterministic?</p>
<p>Our experience is that in practice, many pipelines require nondeterministic</p>
<p>transforms And all too often, pipeline authors do not realize that the code they</p>
<p>wrote is nondeterministic. For example, consider a transform that looks up</p>
<p>supplemental data in Cloud Bigtable in order to enrich its input data. This is a</p>
<p>nondeterministic task, as the external value might change in between retries</p>
<p>of the transform. Any code that relies on current time is likewise not</p>
<p>deterministic. We have also seen transforms that need to rely on random</p>
<p>number generators. And even if the user code is purely deterministic, any</p>
<p>event-time aggregation that allows for late data might have nondeterministic</p>
<p>inputs.</p>
<p>Dataflow addresses this issue by using checkpointing to make</p>
<p>nondeterministic processing effectively deterministic. Each output from a</p>
<p>transform is checkpointed, together with its unique ID, to stable storage</p>
<p><em>before</em> being delivered to the next stage.  Any retries in the shuffle delivery</p>
<p>simply replay the output that has been checkpointed—the user’s</p>
<p>nondeterministic code is not run again on retry. To put it another way, the</p>
<p>user’s code may be run multiple times but only one of those runs can “win.”</p>
<p>Furthermore, Dataflow uses a consistent store that allows it to prevent</p>
<p>duplicates from being written to stable storage.</p>
</details>




<details><summary>点击 原文</summary><h1><span id="performance"><strong>Performance</strong></span><a href="#performance" class="header-anchor">#</a></h1><p>To implement exactly-once shuffle delivery, a catalog of record IDs is stored</p>
<p>in each receiver key. For every record that arrives, Dataflow looks up the</p>
<p>catalog of IDs already seen to determine whether this record is a duplicate.</p>
<p>Every output from step to step is checkpointed to storage to ensure that the</p>
<p>generated record IDs are stable.</p>
<p>However, unless implemented carefully, this process would significantly</p>
<p>degrade pipeline performance for customers by creating a huge increase in</p>
<p>reads and writes. Thus, for exactly-once processing to be viable for Dataflow</p>
<p>users, that I&#x2F;O has to be reduced, in particular by preventing I&#x2F;O on every</p>
<p>record.</p>
<p>Dataflow achieves this goal via two key techniques: <em>graph optimization</em> and</p>
<p><em>Bloom filters</em>.</p>
<h3><span id="graph-optimization"><strong>Graph Optimization</strong></span><a href="#graph-optimization" class="header-anchor">#</a></h3><p>The Dataflow service runs a series of optimizations on the pipeline graph</p>
<p>before executing it. One such optimization is <em>fusion</em>, in which the service</p>
<p>fuses many logical steps into a single execution stage. Figure 5-3 shows some</p>
<p>simple examples.</p>
<p><em>Figure 5-3. Example optimizations: fusion</em></p>
<p>All fused steps are run as an in-process unit, so there’s no need to store</p>
<p>exactly-once data for each of them. In many cases, fusion reduces the entire</p>
<p>graph down to a few physical steps, greatly reducing the amount of data</p>
<p>transfer needed (and saving on state usage, as well).</p>
<p>Dataflow also optimizes associative and commutative Combine operations</p>
<p>(such as Count and Sum) by performing partial combining locally before</p>
<p>sending the data to the main grouping operation, as illustrated in Figure 5-4.</p>
<p>This approach can greatly reduce the number of messages for delivery,</p>
<p>consequently also reducing the number of reads and writes.</p>
<p><em>Figure 5-4. Example optimizations: combiner lifting</em></p>
<h3><span id="bloom-filters"><strong>Bloom Filters</strong></span><a href="#bloom-filters" class="header-anchor">#</a></h3><p>The aforementioned optimizations are general techniques that improve</p>
<p>exactly-once performance as a byproduct. For an optimization aimed strictly</p>
<p>at improving exactly-once processing, we turn to <em>Bloom filters</em>.</p>
<p>In a healthy pipeline, most arriving records will not be duplicates. We can use</p>
<p>that fact to greatly improve performance via Bloom filters, which are compact</p>
<p>data structures that allow for quick set-membership checks. Bloom filters</p>
<p>have a very interesting property: they can return false positives but never false</p>
<p>negatives. If the filter says “Yes, the element is in the set,” we know that the</p>
<p>element is <em>probably</em> in the set (with a probability that can be calculated).</p>
<p>However, if the filter says an element is <em>not</em> in the set, it definitely isn’t. This</p>
<p>function is a perfect fit for the task at hand.</p>
<p>The implementation in Dataflow works like this: each worker keeps a Bloom</p>
<p>filter of every ID it has seen. Whenever a new record ID shows up, it looks it</p>
<p>up in the filter. If the filter returns false, this record is not a duplicate and the</p>
<p>worker can skip the more expensive lookup from stable storage. It needs to do</p>
<p>that second lookup only if the Bloom filter returns true, but as long as the</p>
<p>filter’s false-positive rate is low, that step is rarely needed.</p>
<p>Bloom filters tend to fill up over time, however, and as that happens, the</p>
<p>false-positive rate increases. We also need to construct this Bloom filter anew</p>
<p>any time a worker restarts by scanning the ID catalog stored in state.</p>
<p>Helpfully, Dataflow attaches a system timestamp to each record.  Thus,</p>
<p>instead of creating a single Bloom filter, the service creates a separate one for</p>
<p>every 10-minute range. When a record arrives, Dataflow queries the</p>
<p>appropriate filter based on the system timestamp. This step prevents the</p>
<p>Bloom filters from saturating because filters are garbage-collected over time,</p>
<p>and it also bounds the amount of data that needs to be scanned at startup.</p>
<p>Figure 5-5 illustrates this process: records arrive in the system and are</p>
<p>delegated to a Bloom filter based on their arrival time. None of the records</p>
<p>hitting the first filter are duplicates, and all of their catalog lookups are</p>
<p>filtered. Record r1 is delivered a second time, so a catalog lookup is needed</p>
<p>to verify that it is indeed a duplicate; the same is true for records r4 and r6.</p>
<p>Record r8 is not a duplicate; however, due to a false positive in its Bloom</p>
<p>filter, a catalog lookup is generated (which will determine that r8 is not a</p>
<p>duplicate and should be processed).</p>
<p><em>Figure 5-5. Exactly-once Bloom filters</em></p>
<h3><span id="garbage-collection"><strong>Garbage Collection</strong></span><a href="#garbage-collection" class="header-anchor">#</a></h3><p>Every Dataflow worker persistently stores a catalog of unique record IDs it</p>
<p>has seen. As Dataflow’s state and consistency model is per-key, in reality</p>
<p>each key stores a catalog of records that have been delivered to that key. We</p>
<p>can’t store these identifiers forever, or all available storage will eventually fill</p>
<p>up. To avoid that issue, you need garbage collection of acknowledged record</p>
<p>IDs.</p>
<p>One strategy for accomplishing this goal would be for senders to tag each</p>
<p>record with a strictly increasing sequence number in order to track the earliest</p>
<p>sequence number still in flight (corresponding to an unacknowledged record</p>
<p>delivery). Any identifier in the catalog with an earlier sequence number could</p>
<p>then be garbage-collected because all earlier records have already been</p>
<p>acknowledged.</p>
<p>There is a better alternative, however. As previously mentioned, Dataflow</p>
<p>already tags each record with a system timestamp that is used for bucketing</p>
<p>exactly-once Bloom filters. Consequently, instead of using sequence numbers</p>
<p>to garbage-collect the exactly-once catalog, Dataflow calculates a garbage</p>
<p>collection watermark based on these system timestamps (this is the</p>
<p>processing-time watermark discussed in Chapter 3). A nice side benefit of this</p>
<p>approach is that because this watermark is based on the amount of physical</p>
<p>time spent waiting in a given stage (unlike the data watermark, which is based</p>
<p>on custom event times), it provides intuition on what parts of the pipeline are</p>
<p>slow. This metadata is the basis for the System Lag metric shown in the</p>
<p>Dataflow WebUI.</p>
<p>What happens if a record arrives with an old timestamp and we’ve already</p>
<p>garbage-collected identifiers for this point in time? This can happen due to an</p>
<p>effect we call <em>network remnants</em>, in which an old message becomes stuck for</p>
<p>an indefinite period of time inside the network and then suddenly shows up.</p>
<p>Well, the low watermark that triggers garbage collection won’t advance until</p>
<p>record deliveries have been acknowledged, so we know that this record has</p>
<p>already been successfully processed. Such network remnants are clearly</p>
<p>duplicates and are ignored.</p>
</details>





<details><summary>点击 原文</summary><h1><span id="exactly-once-in-sources"><strong>Exactly Once in Sources</strong></span><a href="#exactly-once-in-sources" class="header-anchor">#</a></h1><p>Beam provides a source API for reading data into a Dataflow pipeline. Dataflow might retry reads from a source if processing fails and needs to</p>
<p>ensure that every unique record produced by a source is processed exactly</p>
<p>once.</p>
<p>For most sources Dataflow handles this process transparently; such sources</p>
<p>are <em>deterministic</em>. For example, consider a source that reads data out of files.</p>
<p>The records in a file will always be in a deterministic order and at</p>
<p>deterministic byte locations, no matter how many times the file is read. The</p>
<p>filename and byte location uniquely identify each record, so the service can</p>
<p>automatically generate unique IDs for each record. Another source that</p>
<p>provides similar determinism guarantees is Apache Kafka; each Kafka topic</p>
<p>is divided into a static set of partitions, and records in a partition always have</p>
<p>a deterministic order. Such deterministic sources will work seamlessly in</p>
<p>Dataflow with no duplicates.</p>
<p>However, not all sources are so simple. For example, one common source for</p>
<p>Dataflow pipelines is Google Cloud Pub&#x2F;Sub. Pub&#x2F;Sub is a <em>nondeterministic</em></p>
<p>source: multiple subscribers can pull from a Pub&#x2F;Sub topic, but which</p>
<p>subscribers receive a given message is unpredictable. If processing fails</p>
<p>Pub&#x2F;Sub will redeliver messages but the messages might be delivered to</p>
<p>different workers than those that processed them originally, and in a different</p>
<p>order. This nondeterministic behavior means that Dataflow needs assistance</p>
<p>for detecting duplicates because there is no way for the service to</p>
<p>deterministically assign record IDs that will be stable upon retry. (We dive</p>
<p>into a more detailed case study of Pub&#x2F;Sub later in this chapter.)</p>
<p>Because Dataflow cannot automatically assign record IDs, nondeterministic</p>
<p>sources are required to inform the system what the record IDs should be.</p>
<p>Beam’s Source API provides the UnboundedReader.getCurrentRecordId method. If a source provides unique IDs per record and notifies Dataflow that</p>
<p>it requires deduplication, records with the same ID will be filtered out.</p>
<h1><span id="exactly-once-in-sinks"><strong>Exactly Once in Sinks</strong></span><a href="#exactly-once-in-sinks" class="header-anchor">#</a></h1><p>At some point, every pipeline needs to output data to the outside world, and a</p>
<p>sink is simply a transform that does exactly that. Keep in mind that delivering</p>
<p>data externally is a side effect, and we have already mentioned that Dataflow</p>
<p>does not guarantee exactly-once application of side effects. So, how can a</p>
<p>sink guarantee that outputs are delivered exactly once?</p>
<p>The simplest answer is that a number of built-in sinks are provided as part of</p>
<p>the Beam SDK. These sinks are carefully designed to ensure that they do not</p>
<p>produce duplicates, even if executed multiple times. Whenever possible,</p>
<p>pipeline authors are encouraged to use one of these built-in sinks.</p>
<p>However, sometimes the built-ins are insufficient and you need to write your</p>
<p>own. The best approach is to ensure that your side-effect operation is</p>
<p>idempotent and therefore robust in the face of replay. However, often some</p>
<p>component of a side-effect DoFn is nondeterministic and thus might change</p>
<p>on replay. For example, in a windowed aggregation, the set of records in the</p>
<p>window can also be nondeterministic!</p>
<p>Specifically, the window might attempt to fire with elements e0, e1, e2, but</p>
<p>the worker crashes before committing the window processing (but not before</p>
<p>those elements are sent as a side effect). When the worker restarts, the</p>
<p>window will fire again, but now a late element e3 shows up. Because this</p>
<p>element shows up before the window is committed, it’s not counted as late</p>
<p>data, so the DoFn is called again with elements e0, e1, e2, e3. These are then</p>
<p>sent to the side-effect operation. Idempotency does not help here, because</p>
<p>different logical record sets were sent each time.</p>
<p>There are other ways nondeterminism can be introduced. The standard way to</p>
<p>address this risk is to rely on the fact that Dataflow currently guarantees that</p>
<p>only one version of a DoFn’s output can make it past a shuffle boundary.</p>
<p>A simple way of using this guarantee is via the built-in Reshuffle transform.</p>
<p>The pattern presented in Example 5-2 ensures that the side-effect operation</p>
<p>always receives a deterministic record to output.</p>
<p><em>Example 5-2. Reshuffle example</em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c.apply(Window.&lt;..&gt;into(FixedWindows.of(Duration.standardMinutes(1))))</span><br><span class="line">.apply(GroupByKey.&lt;..&gt;.create())</span><br><span class="line">.apply(new PrepareOutputData())</span><br><span class="line">.apply(Reshuffle.&lt;..&gt;of())</span><br><span class="line">.apply(WriteToSideEffect());</span><br></pre></td></tr></table></figure>

<p>The preceding pipeline splits the sink into two steps: PrepareOutputData</p>
<p>and WriteToSideEffect.  PrepareOutputData outputs  records</p>
<p>corresponding to idempotent writes. If we simply ran one after the other, the</p>
<p>entire process might be replayed on failure, PrepareOutputData might</p>
<p>produce a different result, and both would be written as side effects. When we</p>
<p>add the Reshuffle in between the two, Dataflow guarantees this can’t</p>
<p>happen.</p>
<p>Of course, Dataflow might still run the WriteToSideEffect operation</p>
<p>multiple times. The side effects themselves still need to be idempotent, or the</p>
<p>sink will receive duplicates. For example, an operation that sets or overwrites</p>
<p>a value in a data store is idempotent, and will generate correct output even if</p>
<p>it’s run several times. An operation that appends to a list is not idempotent; if</p>
<p>the operation is run multiple times, the same value will be appended each</p>
<p>time.</p>
<p>While Reshuffle provides a simple way of achieving stable input to a DoFn,</p>
<p>a GroupByKey works just as well. However, there is currently a proposal that</p>
<p>removes the need to add a GroupByKey to achieve stable input into a DoFn.</p>
<p>Instead, the user could annotate WriteToSideEffect with a special</p>
<p>annotation, @RequiresStableInput, and the system would then ensure stable</p>
<p>input to that transform.</p>
</details>





<details><summary>点击 原文</summary><h1><span id="use-cases"><strong>Use Cases</strong></span><a href="#use-cases" class="header-anchor">#</a></h1><p>To illustrate, let’s examine some built-in sources and sinks to see how they</p>
<p>implement the aforementioned patterns.</p>
<h3><span id="example-source-cloud-pubx2fsub"><strong>Example Source: Cloud Pub&#x2F;Sub</strong></span><a href="#example-source-cloud-pubx2fsub" class="header-anchor">#</a></h3><p>Cloud Pub&#x2F;Sub is a fully managed, scalable, reliable, and low-latency system</p>
<p>for delivering messages from publishers to subscribers. Publishers publish</p>
<p>data on named topics, and subscribers create named subscriptions to pull data</p>
<p>from these topics. Multiple subscriptions can be created for a single topic, in</p>
<p>which case each subscription receives a full copy of all data published on the</p>
<p>topic from the time of the subscription’s creation. Pub&#x2F;Sub guarantees that</p>
<p>records will continue to be delivered until they are acknowledged; however, a</p>
<p>record might be delivered multiple times.</p>
<p>Pub&#x2F;Sub is intended for distributed use, so many publishing processes can</p>
<p>publish to the same topic and many subscribing processes can pull from the</p>
<p>same subscription. After a record has been pulled, the subscriber must</p>
<p>acknowledge it within a certain amount of time, or that pull expires and</p>
<p>Pub&#x2F;Sub will redeliver that record to another of the subscribing processes.</p>
<p>Although these characteristics make Pub&#x2F;Sub highly scalable, they also make</p>
<p>it a challenging source for a system like Dataflow. It’s impossible to know</p>
<p>which record will be delivered to which worker, and in which order. What’s</p>
<p>more, in the case of failure, redelivery might send the records to different</p>
<p>workers in different orders!</p>
<p>Pub&#x2F;Sub provides a stable message ID with each message, and this ID will be</p>
<p>the same upon redelivery. The Dataflow Pub&#x2F;Sub source will default to using</p>
<p>this ID for removing duplicates from Pub&#x2F;Sub. (The records are shuffled</p>
<p>based on a hash of the ID, so that repeated deliveries are always processed on</p>
<p>the same worker.) In some cases, however, this is not quite enough. The</p>
<p>user’s publishing process might retry publishes, and as a result introduce</p>
<p>duplicates into Pub&#x2F;Sub. From that service’s perspective these are unique</p>
<p>records, so they will get unique record IDs. Dataflow’s Pub&#x2F;Sub source</p>
<p>allows the user to provide their own record IDs as a custom attribute. As long</p>
<p>as the publisher sends the same ID when retrying, Dataflow will be able to</p>
<p>detect these duplicates.</p>
<p>Beam (and therefore Dataflow) provides a reference source implementation</p>
<p>for Pub&#x2F;Sub. However, keep in mind that this is <em>not</em> what Dataflow uses but</p>
<p>rather an implementation used only by non-Dataflow runners (such as Apache</p>
<p>Spark, Apache Flink, and the DirectRunner). For a variety of reasons,</p>
<p>Dataflow handles Pub&#x2F;Sub internally and does not use the public Pub&#x2F;Sub</p>
<p>source.</p>
<h3><span id="example-sink-files"><strong>Example Sink: Files</strong></span><a href="#example-sink-files" class="header-anchor">#</a></h3><p>The streaming runner can use Beam’s file sinks (TextIO, AvroIO, and any</p>
<p>other sink that implements FileBasedSink) to continuously output records to</p>
<p>files. Example 5-3 provides an example use case.</p>
<p><em>Example 5-3. Windowed file writes</em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c.apply(Window.&lt;..&gt;into(FixedWindows.of(Duration.standardMinutes(1))))</span><br><span class="line">.apply(TextIO.writeStrings().to(new MyNamePolicy()).withWindowedWrites());</span><br></pre></td></tr></table></figure>

<p>The snippet in Example 5-3 writes 10 new files each minute, containing data</p>
<p>from that window. MyNamePolicy is a user-written function that determines</p>
<p>output filenames based on the shard and the window. You can also use</p>
<p>triggers, in which case each trigger pane will be output as a new file.</p>
<p>This process is implemented using a variant on the pattern in Example 5-3.</p>
<p>Files are written out to temporary locations, and these temporary filenames</p>
<p>are sent to a subsequent transform through a GroupByKey. After the</p>
<p>GroupByKey is a finalize transform that atomically moves the temporary files</p>
<p>into their final location. The pseudocode in Example 5-4 provides a sketch of</p>
<p>how a consistent streaming file sink is implemented in Beam. (For more</p>
<p>details, see FileBasedSink and WriteFiles in the Beam codebase.)</p>
<p><em>Example 5-4. File sink</em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">c</span><br><span class="line">// Tag each record with a random shard id.</span><br><span class="line">.apply(&quot;AttachShard&quot;, WithKeys.of(new RandomShardingKey(getNumShards())))</span><br><span class="line">// Group all records with the same shard.</span><br><span class="line">.apply(&quot;GroupByShard&quot;, GroupByKey.&lt;..&gt;())</span><br><span class="line">// For each window, write per-shard elements to a temporary file. This is the</span><br><span class="line">// non-deterministic side effect. If this DoFn is executed multiple times, it</span><br><span class="line">will</span><br><span class="line">// simply write multiple temporary files; only one of these will pass on through</span><br><span class="line">// to the Finalize stage.</span><br><span class="line">.apply(&quot;WriteTempFile&quot;, ParDo.of(new DoFn&lt;..&gt; &#123;</span><br><span class="line">@ProcessElement</span><br><span class="line">public void processElement(ProcessContext c, BoundedWindow window) &#123;</span><br><span class="line">// Write the contents of c.element() to a temporary file.</span><br><span class="line">// User-provided name policy used to generate a final filename.</span><br><span class="line">c.output(new FileResult()).</span><br><span class="line">&#125;</span><br><span class="line">&#125;))</span><br><span class="line">// Group the list of files onto a singleton key.</span><br><span class="line">.apply(&quot;AttachSingletonKey&quot;, WithKeys.&lt;..&gt;of((Void)null))</span><br><span class="line">.apply(&quot;FinalizeGroupByKey&quot;, GroupByKey.&lt;..&gt;create())</span><br><span class="line">// Finalize the files by atomically renaming them. This operation is idempotent.</span><br><span class="line">// Once this DoFn has executed once for a given FileResult, the temporary file</span><br><span class="line">// is gone, so any further executions will have no effect.</span><br><span class="line">.apply(&quot;Finalize&quot;, ParDo.of(new DoFn&lt;..&gt;, Void&gt; &#123;</span><br><span class="line">@ProcessElement</span><br><span class="line">public void processElement(ProcessContext c) &#123;</span><br><span class="line">for (FileResult result : c.element()) &#123;</span><br><span class="line">rename(result.getTemporaryFileName(), result.getFinalFilename());</span><br><span class="line">&#125;</span><br><span class="line">&#125;&#125;));</span><br></pre></td></tr></table></figure>

<p>You can see how the nonidempotent work is done in WriteTempFile. After</p>
<p>the GroupByKey completes, the Finalize step will always see the same</p>
<p>bundles across retries. Because file rename is idempotent, this give us an</p>
<p>exactly-once sink.</p>
<h3><span id="example-sink-google-bigquery"><strong>Example Sink: Google BigQuery</strong></span><a href="#example-sink-google-bigquery" class="header-anchor">#</a></h3><p>Google BigQuery is a fully managed, cloud-native data warehouse. Beam</p>
<p>provides a BigQuery sink, and BigQuery provides a streaming insert API that</p>
<p>supports extremely low-latency inserts. This streaming insert API allows</p>
<p>allows you to tag inserts with a unique ID, and BigQuery will attempt to filter</p>
<p>duplicate inserts with the same ID. To use this capability, the BigQuery sink</p>
<p>must generate statistically unique IDs for each record. It does this by using</p>
<p>the java.util.UUID package, which generates statistically unique 128-bit</p>
<p>IDs.</p>
<p>Generating a random universally unique identifier (UUID) is a</p>
<p>nondeterministic operation, so we must add a Reshuffle before we insert</p>
<p>into BigQuery. After we do this, any retries by Dataflow will always use the</p>
<p>same UUID that was shuffled. Duplicate attempts to insert into BigQuery will</p>
<p>always have the same insert ID, so BigQuery is able to filter them. The</p>
<p>pseudocode shown in Example 5-5 illustrates how the BigQuery sink is</p>
<p>implemented.</p>
<p><em>Example 5-5. BigQuery sink</em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">// Apply a unique identifier to each record</span><br><span class="line">c</span><br><span class="line">.apply(new DoFn&lt;&gt; &#123;</span><br><span class="line">@ProcessElement</span><br><span class="line">public void processElement(ProcessContext context) &#123;</span><br><span class="line">String uniqueId = UUID.randomUUID().toString();</span><br><span class="line">context.output(KV.of(ThreadLocalRandom.current().nextInt(0, 50),</span><br><span class="line">new RecordWithId(context.element(),</span><br><span class="line">uniqueId)));</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">// Reshuffle the data so that the applied identifiers are stable and will not</span><br><span class="line">change.</span><br><span class="line">.apply(Reshuffle.&lt;Integer, RecordWithId&gt;of())</span><br><span class="line">// Stream records into BigQuery with unique ids for deduplication.</span><br><span class="line">.apply(ParDo.of(new DoFn&lt;..&gt; &#123;</span><br><span class="line">@ProcessElement</span><br><span class="line">public void processElement(ProcessContext context) &#123;</span><br><span class="line">insertIntoBigQuery(context.element().record(), context.element.id());</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>Again we split the sink into a nonidempotent step (generating a random</p>
<p>number), followed by a step that is idempotent.</p>
</details>



<details><summary>点击 原文</summary><h1><span id="other-systems"><strong>Other Systems</strong></span><a href="#other-systems" class="header-anchor">#</a></h1><p>Now that we have explained Dataflow’s exactly once in detail, let us contrast</p>
<p>this with some brief overviews of other popular streaming systems. Each</p>
<p>implements exactly-once guarantees in a different way and makes different</p>
<p>trade-offs as a result.</p>
<h3><span id="apache-spark-streaming"><strong>Apache Spark Streaming</strong></span><a href="#apache-spark-streaming" class="header-anchor">#</a></h3><p>Spark Streaming uses a microbatch architecture for continuous data</p>
<p>processing. Users logically deal with a stream object; however, under the</p>
<p>covers, Spark represents this stream as a continuous series of RDDs. Each</p>
<p>RDD is processed as a batch, and Spark relies on the exactly-once nature of</p>
<p>batch processing to ensure correctness; as mentioned previously, techniques</p>
<p>for correct batch shuffles have been known for some time. This approach can</p>
<p>cause increased latency to output—especially for deep pipelines and high</p>
<p>input volumes—and often careful tuning is required to achieve desired</p>
<p>latency.</p>
<p>Spark does assume that operations are all idempotent and might replay the</p>
<p>chain of operations up the current point in the graph. A checkpoint primitive</p>
<p>is provided, however, that causes an RDD to be materialized, guaranteeing</p>
<p>that history prior to that RDD will not be replayed. This checkpoint feature is</p>
<p>intended for performance reasons (e.g., to prevent replaying an expensive</p>
<p>operation); however, you can also use it to implement nonidempotent side</p>
<p>effects.</p>
<h3><span id="apache-flink"><strong>Apache Flink</strong></span><a href="#apache-flink" class="header-anchor">#</a></h3><p>Apache Flink also provides exactly-once processing for streaming pipelines</p>
<p>but does so in a manner different than either Dataflow or Spark. Flink</p>
<p>streaming pipelines periodically compute consistent snapshots, each</p>
<p>representing the consistent point-in-time state of an entire pipeline. Flink</p>
<p>snapshots are computed progressively, so there is no need to halt all</p>
<p>processing while computing a snapshot. This allows records to continue</p>
<p>flowing through the system while taking a snapshot, alleviating some of the</p>
<p>latency issues with the Spark Streaming approach.</p>
<p>Flink implements these snapshots by inserting special numbered snapshot</p>
<p>markers into the data streams flowing from sources. As each operator receives</p>
<p>a snapshot marker, it executes a specific algorithm allowing it to copy its state</p>
<p>to an external location and propagate the snapshot marker to downstream</p>
<p>operators. After all operators have executed this snapshot algorithm, a</p>
<p>complete snapshot is made available. Any worker failures will cause the</p>
<p>entire pipeline to roll back its state from the last complete snapshot. In-flight</p>
<p>messages do not need to be included in the snapshot. All message delivery in</p>
<p>Flink is done via an ordered TCP-based channel. Any connection failures can</p>
<p>be handled by resuming the connection from the last good sequence</p>
<p>number; unlike Dataflow, Flink tasks are statically allocated to workers, so</p>
<p>it can assume that the connection will resume from the same sender and</p>
<p>replay the same payloads.</p>
<p>Because Flink might roll back to the previous snapshot at any time, any state</p>
<p>modifications not yet in a snapshot must be considered tentative. A sink that</p>
<p>sends data to the world outside the Flink pipeline must wait until a snapshot</p>
<p>has completed, and then send only the data that is included in that snapshot.</p>
<p>Flink provides a notifySnapshotComplete callback that allows sinks to</p>
<p>know when each snapshot is completed, and send the data onward. Even</p>
<p>though this does affect the output latency of Flink pipelines, this latency is</p>
<p>introduced only at sinks. In practice, this allows Flink to have lower end-to</p>
<p>end latency than Spark for deep pipelines because Spark introduces batch</p>
<p>latency at each stage in the pipeline.</p>
<p>Flink’s distributed snapshots are an elegant way of dealing with consistency</p>
<p>in a streaming pipeline; however, a number of assumptions are made about</p>
<p>the pipeline. Failures are assumed to be rare, as the impact of a failure</p>
<p>(rolling back to the previous snapshot) is substantial. To maintain low-latency</p>
<p>output, it is also assumed that snapshots can complete quickly. It remains to</p>
<p>be seen whether this causes issues on very large clusters where the failure rate</p>
<p>will likely increase, as will the time needed to complete a snapshot.</p>
<p>Implementation is also simplified by assuming that tasks are statically</p>
<p>allocated to workers (at least within a single snapshot epoch). This</p>
<p>assumption allows Flink to provide a simple exactly-once transport between</p>
<p>workers because it knows that if a connection fails, the same data can be</p>
<p>pulled in order from the same worker. In contrast, tasks in Dataflow are</p>
<p>constantly load balanced between workers (and the set of workers is</p>
<p>constantly growing and shrinking), so Dataflow is unable to make this</p>
<p>assumption. This forces Dataflow to implement a much more complex</p>
<p>transport layer in order to provide exactly-once processing.</p>
</details>



<details><summary>点击 原文</summary><h1><span id="summary"><strong>Summary</strong></span><a href="#summary" class="header-anchor">#</a></h1><p>In summary, exactly-once data processing, which was once thought to be</p>
<p>incompatible with low-latency results, is quite possible—Dataflow does it</p>
<p>efficiently without sacrificing latency. This enables far richer uses for stream</p>
<p>processing.</p>
<p>Although this chapter has focused on Dataflow-specific techniques, other</p>
<p>streaming systems also provide exactly-once guarantees. Apache Spark</p>
<p>Streaming runs streaming pipelines as a series of small batch jobs, relying on</p>
<p>exactly-once guarantees in the Spark batch runner. Apache Flink uses a</p>
<p>variation on Chandy Lamport distributed snapshots to get a running consistent</p>
<p>state and can use these snapshots to ensure exactly-once processing. We</p>
<p>encourage you to learn about these other systems, as well, for a broad</p>
<p>understanding of how different stream-processing systems work!</p>
<ol>
<li>In fact, no system we are aware of that provides at-least once (or better) is</li>
</ol>
<p>able to guarantee this, including all other Beam runners.</p>
<ol>
<li>Dataflow also provides an accurate batch runner; however, in this context</li>
</ol>
<p>we are focused on the streaming runner.</p>
<ol>
<li>The Dataflow optimizer groups many steps together and adds shuffles only</li>
</ol>
<p>where they are needed.</p>
<ol>
<li>Batch pipelines also need to guard against duplicates in shuffle. However</li>
</ol>
<p>the problem is much easier to solve in batch, which is why historical batch</p>
<p>systems did do this and streaming systems did not. Streaming runtimes that</p>
<p>use a microbatch architecture, such as Spark Streaming, delegate duplicate</p>
<p>detection to a batch shuffler.</p>
<ol>
<li>A lot of care is taken to make sure this checkpointing is efficient; for</li>
</ol>
<p>example, schema and access pattern optimizations that are intimately tied to</p>
<p>the characteristics of the underlying key&#x2F;value store.</p>
<ol>
<li>This is not the custom user-supplied timestamp used for windowing. Rather</li>
</ol>
<p>this is a deterministic processing-time timestamp that is assigned by the</p>
<p>145sending worker.</p>
<ol>
<li>Some care needs to be taken to ensure that this algorithm works. Each</li>
</ol>
<p>sender must guarantee that the system timestamps it generates are strictly</p>
<p>increasing, and this guarantee must be maintained across worker restarts.</p>
<ol>
<li>In theory, we could dispense with startup scans entirely by lazily building</li>
</ol>
<p>the Bloom filter for a bucket only when a threshold number of records show</p>
<p>up with timestamps in that bucket.</p>
<ol>
<li>At the time of this writing, a new, more-flexible API called SplittableDoFn</li>
</ol>
<p>is available for Apache Beam.</p>
<ol>
<li>We assume that nobody is maliciously modifying the bytes in the file while</li>
</ol>
<p>we are reading it.</p>
<ol>
<li>Again note that the SplittableDoFn API has different methods for this.</li>
<li>Using the requiresDedupping override.</li>
<li>Note that these determinism boundaries might become more explicit in the</li>
</ol>
<p>Beam Model at some point. Other Beam runners vary in their ability to handle</p>
<p>nondeterministic user code.</p>
<ol>
<li>As long as you properly handle the failure when the source file no longer</li>
</ol>
<p>exists.</p>
<ol>
<li>Due to the global nature of the service, BigQuery does not guarantee that</li>
</ol>
<p>all duplicates are removed. Users can periodically run a query over their</p>
<p>tables to remove any duplicates that were not caught by the streaming insert</p>
<p>API. See the BigQuery documentation for more information.</p>
<ol>
<li>Resilient Distributed Datasets; Spark’s abstraction of a distributed dataset,</li>
</ol>
<p>similar to PCollection in Beam.</p>
<ol>
<li>These sequence numbers are per connection and are unrelated to the</li>
</ol>
<p>snapshot epoch number.</p>
<ol>
<li>Only for nonidempotent sinks. Completely idempotent sinks do not need to</li>
</ol>
<p>wait for the snapshot to complete.</p>
<ol>
<li>Specifically, Flink assumes that the mean time to worker failure is less than</li>
</ol>
<p>the time to snapshot; otherwise, the pipeline would be unable to make</p>
<p>progress.</p>
</details>
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Wang Wei
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://www6v.github.io/www6vHomeHexo/2000/03/16/streamingSystemChapter5Original/" title="《Streaming System》-Chapter 5. Exactly-Once and Side Effects [完整]">https://www6v.github.io/www6vHomeHexo/2000/03/16/streamingSystemChapter5Original/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/www6vHomeHexo/tags/Streaming-System/" rel="tag"># Streaming System</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/www6vHomeHexo/2000/03/16/streamingSystemChapter5/" rel="prev" title="《Streaming System》-第五章：精确一次和副作用 [完整]">
      <i class="fa fa-chevron-left"></i> 《Streaming System》-第五章：精确一次和副作用 [完整]
    </a></div>
      <div class="post-nav-item">
    <a href="/www6vHomeHexo/2000/03/17/streamingSystemChapter2/" rel="next" title="《Streaming System》-第二章： 数据处理的什么、何地、何时以及如何进行[完整]">
      《Streaming System》-第二章： 数据处理的什么、何地、何时以及如何进行[完整] <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Wang Wei</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/www6vHomeHexo/archives/">
        
          <span class="site-state-item-count">411</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/www6vHomeHexo/categories/">
          
        <span class="site-state-item-count">248</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/www6vHomeHexo/tags/">
          
        <span class="site-state-item-count">128</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/www6v" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;www6v" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:www6v@126.com" title="E-Mail → mailto:www6v@126.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wang Wei</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/www6vHomeHexo/lib/anime.min.js"></script>
  <script src="/www6vHomeHexo/lib/velocity/velocity.min.js"></script>
  <script src="/www6vHomeHexo/lib/velocity/velocity.ui.min.js"></script>

<script src="/www6vHomeHexo/js/utils.js"></script>

<script src="/www6vHomeHexo/js/motion.js"></script>


<script src="/www6vHomeHexo/js/schemes/muse.js"></script>


<script src="/www6vHomeHexo/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/www6vHomeHexo/js/local-search.js"></script>













  

  

</body>
</html>
